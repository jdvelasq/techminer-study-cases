{"Authors":"Hajiabotorabi Z., Kazemi A., Samavati F.F., Maalek Ghaini F.M.","Author(s) ID":"57210187197;24070754400;6603142390;26644170500;","Title":"Improving DWT-RNN model via B-spline wavelet multiresolution to forecast a high-frequency time series","Year":2019,"Source title":"Expert Systems with Applications","Volume":"138","Issue":null,"Art. No.":" 112842","Page start":null,"Page end":null,"Page count":null,"Cited by":null,"DOI":"10.1016\/j.eswa.2019.112842","Affiliations":"Department of Mathematics, Faculty of Science, Yazd University, Yazd, Iran; Department of Mathematics, Faculty of Science, Payame Noor University, Yazd, Iran; Department of Industrial Management, Faculty of Management, University of Tehran, Tehran, Iran; Department of Computer Science, University of Calgary, Calgary, Alberta, Canada","Document Type":"Article","Access Type":null,"Source":"Scopus","EID":"2-s2.0-85069827868","Abstract":"The importance of an interference-less machine learning scheme in time series prediction is crucial, as an oversight can have a negative cumulative effect, especially when predicting many steps ahead of the currently available data. The on-going research on noise elimination in time series forecasting has led to a successful approach of decomposing the data sequence into component trends to identify noise-inducing information. The empirical mode decomposition method separates the time series\/signal into a set of intrinsic mode functions ranging from high to low frequencies, which can be summed up to reconstruct the original data. The usual assumption that random noises are only contained in the high-frequency component has been shown not to be the case, as observed in our previous findings. The results from that experiment reveal that noise can be present in a low frequency component, and this motivates the newly-proposed algorithm. Additionally, to prevent the erosion of periodic trends and patterns within the series, we perform the learning of local and global trends separately in a hierarchical manner which succeeds in detecting and eliminating short\/long term noise. The algorithm is tested on four datasets from financial market data and physical science data. The simulation results are compared with the conventional and state-of-the-art approaches for time series machine learning, such as the non-linear autoregressive neural network and the long short-term memory recurrent neural network, respectively. Statistically significant performance gains are recorded when the meta-learning algorithm for noise reduction is used in combination with these artificial neural networks. For time series data which cannot be decomposed into meaningful trends, applying the moving average method to create meta-information for guiding the learning process is still better than the traditional approach. Therefore, this new approach is applicable to the forecasting of time series with a low signal to noise ratio, with a potential to scale adequately in a multi-cluster system due to the parallelized nature of the algorithm. \u00a9 2017 by the authors.","Author Keywords":"Component trends; Empirical mode decomposition; Interference-less machine learning; Long short-term memory; Meta-learning; Moving average; Noise reduction; Nonlinear autoregressive neural network; Time series forecasting","Index Keywords":null,"References":"Bengio, Y., Frasconi, P., Input-output HMMs for sequence processing (1996) IEEE Trans. Neural Netw, 7, pp. 1231-1249; Gunn, S.R., Support Vector Machines for Classification and Regression (1998) ISIS Tech. Rep, 14, pp. 85-86; \u0160tepni\u010dka, M., Pavliska, V., Nov\u00e1k, V., Perfilieva, I., Vav\u0159\u00ed\u010dkov\u00e1, L., Tomanov\u00e1, I., Time Series Analysis and Prediction Based on Fuzzy Rules and the Fuzzy Transform (2009) Proceedings of the Joint 2009 International Fuzzy Systems Association World Congress and 2009 European Society of Fuzzy Logic and Technology Conference, pp. 483-488. , Lisbon, Portugal, 20-24 July; Bemdt, D.J., Clifford, J., Using Dynamic Time Warping to Find Patterns in Time Series (1994) Proceedings of the 3rd International Conference on Knowledge Discovery and Data Mining, pp. 359-370. , Seattle, WA, USA, 31 July-1 August; Afolabi, D.O., Guan, S.-U., Man, K.L., Wong, P.W.H., Meta-learning with Empirical Mode Decomposition for Noise Elimination in Time Series Forecasting (2016) Advanced Multimedia and Ubiquitous Engineering: FutureTech & MUE, pp. 405-413. , Park, J.J.H., Jin, H., Jeong, Y.-S., Khan, M.K., Eds.; Springer Singapore: Singapore; Wong, W., Miller, R.B., Repeated Time Series Analysis of ARIMA-Noise Models (1990) J. Bus. Econ. Stat, 8, pp. 243-250; Pesentia, M., Pirasa, M., A Modified Forward Search Approach Applied to Time Series Analysis (2008) The International Archives of the Photogrammetry, Remote Sensing and Spatial Information Sciences, 37, pp. 787-792. , ISPRS: Beijing, China; Yin, W., Kann, K., Yu, M., Sch\u00fctze, H., (2017) Comparative Study of CNN and RNN for Natural Language Processing; Singh, S., Noise impact on time-series forecasting using an intelligent pattern matching technique (1999) Pattern Recognit, 32, pp. 1389-1398; Lin, T., Horne, B.G., Tino, P., Giles, C.L., Learning long-term dependencies in NARX recurrent neural networks (1996) IEEE Trans. Neural Netw, 7, pp. 1329-1338; Wei, W.W.-S., (2006) Time Series Analysis: Univariate and Multivariate Methods, 2nd ed, , Addison-Wesley Pearson Higher Ed: Boston, MA, USA; Huang, N.E., Shen, Z., Long, S.R., Wu, M.C., Shih, H.H., Zheng, Q., Yen, N.-C., Liu, H.H., The empirical mode decomposition and the Hilbert spectrum for nonlinear and non-stationary time series analysis (1998) Proceedings of the Royal Society of London A: Mathematical, 454, pp. 903-995. , Physical and Engineering Sciences, London, UK, 8 March; Rato, R.T., Ortigueira, M.D., Batista, A.G., On the HHT, its problems, and some solutions (2008) Mech. Syst. Signal Process, 22, pp. 1374-1394; Kim, D., Oh, H.-S., EMD: A package for empirical mode decomposition and hilbert spectrum (2009) R J, 1, pp. 40-46; Wei, Y., Chaudhary, V., The Influence of Sample Reconstruction on Stock Trend Prediction via NARX Neural Network (2015) Proceedings of the 2015 IEEE 14th International Conference on Machine Learning and Applications (ICMLA), pp. 52-57. , IMiami, FL, USA, 9-11 December; Hertz, P., Feigelson, E.D., A sample of astronomical time series (1997) Applications of Time Series Analysis in Astronomy and Meteorology, pp. 340-356. , Subba Rao, T., Priestley, M.B., Lessi, O., Eds.; Chapman & Hall: London, UK; Weigend, A.S., The Future of Time Series (1994) Proceedings of the International Conference On Neural Information Processing, 3, pp. 853-856. , Seoul, Korea, January; Akbilgic, O., Bozdogan, H., Balaban, M.E., A novel Hybrid RBF Neural Networks model as a forecaster (2014) Stat. Comput, 24, pp. 365-375; http:\/\/www.mathworks.com\/help\/nnet\/gs\/neural-network-time-series-prediction-and-modeling.html, accessed on 15 February 2016; Chollet, F., (2015) Keras, , GitHub: San Francisco, CA, USA; Zupan, B., Bohanec, M., Bratko, I., Demsar, J., Machine learning by function decomposition (1997) Proceedings of the Fourteenth International Conference (ICML'97) on Machine Learning, pp. 421-429. , Nashville, TN, USA, 8-12 July; Wang, Y.-H., Yeh, C.-H., Young, H.-W.V., Hu, K., Lo, M.-T., On the computational complexity of the empirical mode decomposition algorithm (2014) Phys. Stat. Mech. Its Appl, 400, pp. 159-167; Hua Ang, J., Guan, S.-U., Tan, K.C., Mamun, A.A., Interference-less neural network training (2008) Neurocomputing, 71, pp. 3509-3524"}
{"Authors":"\u0141ady\u017cy\u0144ski P., \u017bbikowski K., Gawrysiak P.","Author(s) ID":"55897965200;55860046500;24337898500;","Title":"Direct marketing campaigns in retail banking with the use of deep learning and random forests","Year":2019,"Source title":"Expert Systems with Applications","Volume":"134","Issue":null,"Art. No.":null,"Page start":28.0,"Page end":35.0,"Page count":null,"Cited by":null,"DOI":"10.1016\/j.eswa.2019.05.020","Affiliations":"Faculty of Mathematics and Computer Science, Warsaw University of Technology, Koszykowa 75, Warsaw, 00-662, Poland; Institute of Computer Science, Warsaw University of Technology, Nowowiejska 15\/19, Warsaw, 00-665, Poland","Document Type":"Article","Access Type":null,"Source":"Scopus","EID":"2-s2.0-85066271331","Abstract":"This paper proposes a novel application of deep learning models, Paragraph Vector, and Long Short-Term Memory (LSTM), to financial time series forecasting. Investors make decisions according to various factors, including consumer price index, price-earnings ratio, and miscellaneous events reported in newspapers. In order to assist their decisions in a timely manner, many automatic ways to analyze those information have been proposed in the last decade. However, many of them used either numerical or textual information, but not both for a single company. In this paper, we propose an approach that converts newspaper articles into their distributed representations via Paragraph Vector and models the temporal effects of past events on opening prices about multiple companies with LSTM. The performance of the proposed approach is demonstrated on real-world data of fifty companies listed on Tokyo Stock Exchange. \u00a9 2016 IEEE.","Author Keywords":null,"Index Keywords":"Earnings; Financial data processing; Information science; Newsprint; Consumer price index; Distributed representation; Financial time series forecasting; Long short term memory; Novel applications; Stock predictions; Textual information; Tokyo Stock Exchange; Costs","References":"Kim, K.-J., Financial time series forecasting using support vector machines (2003) Neurocomputing, 55 (1), pp. 307-319; Lavrenko, V., Schmill, M., Lawrie, D., Ogilvie, P., Jensen, D., Allan, J., Language models for financial news recommendation (2000) Proceedings of the 9th International Conference on Information and Knowledge Management (CIKM-00), pp. 389-396; Tay, F.E., Cao, L., Application of support vector machines in financial time series forecasting (2001) Omega, 29 (4), pp. 309-317; Bick, B., Kraft, H., Munk, C., Solving constrained consumptioninvestment problems by simulation of artificial market strategies (2013) Management Science, 59 (2), pp. 485-503; Adrian, B., Nathan, L., An introduction to artificial prediction markets for classification (2012) Journal of Machine Learning Research, 13, pp. 2177-2204; Devitt, A., Ahmad, K., Sentiment polarity identification in financial news: A cohesion-based approach (2007) Proceedings of the 45th Annual Meeting of the Association of Computational Linguistics (ACL-07), pp. 984-991. , June; Lavrenko, V., Schmill, M., Lawrie, D., Ogilvie, P., Jensen, D., Allan, J., Mining of concurrent text and time series (2000) Proceedings of the KDD-2000 Workshop on Text Mining, pp. 37-44; Schumaker, R.P., Chen, H., Textual analysis of stock market prediction using breaking financial news: The AZFin text system (2009) ACM Transactions on Information Systems (TOIS-09), 27 (2), pp. 121-1219; Ding, X., Zhang, Y., Liu, T., Duan, J., Using structured events to predict stock price movement: An empirical investigation (2014) Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP-14). Association for Computational Linguistics, pp. 1415-1425; Hagenau, M., Liebmann, M., Hedwig, M., Neumann, D., Automated news reading: Stock price prediction based on financial news using context-specific features (2012) System Sciences, 2012. Proceedings of the 45th Annual Hawaii International Conference on System Sciences (HICSS-12). IEEE, pp. 1040-1049; Robert, M., Bharath, R., Mohammad, S., Gert, K., Vijay, P., Understanding protein dynamics with l1-regularized reversible hidden markov models (2014) Proceedings of the 31st International Conference on Machine Learning (ICML-14), pp. 1197-1205. , http\/\/jmlr.org\/proceedings\/papers\/v32\/mcgibbon14.pdf; Hochreiter, S., Schmidhuber, J., Long short-term memory (1997) Neural Computation, 9 (8), pp. 1735-1780; Gers, F.A., Schmidhuber, J.A., Cummins, F.A., Learning to forget: Continual prediction with lstm (2000) Neural Computation, 12 (10), pp. 2451-2471; Gidofalvi, G., Elkan, C., Using news articles to predict stock price movements (2001) Department of Computer Science and Engineering, , University of California, San Diego; Izumi, K., Goto, T., Matsui, T., Trading tests of long-term market forecast by text mining (2010) Proceedings of the Tenth IEEE International Conference on Data Mining Workshops (ICDM-10), pp. 935-942; Johan, B., Huina, M., Twitter mood as a stock market predictor (2011) IEEE Computer, 44 (10), pp. 91-94; Andr Mittermayer, M., Forecasting intraday stock price trends with text mining techniques (2004) System Sciences, 2004. Proceedings of the 37th Annual Hawaii International Conference on System Sciences (HICSS-04); Jianfeng, S., Arjun, M., Bing, L., Sinno, J.P., Qing, L., Huayi, L., Exploiting social relations and sentiment for stock prediction (2014) Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP-14), pp. 1139-1145; Kudo, T., (2005) Mecab: Yet Another Part-of-speech and Morphological Analyzer, , http\/\/mecab.sourceforge.net\/; Wojciech, Z., Ilya, S., Oriol, V., Recurrent neural network regularization (2014) CoRR, , http\/\/arxiv.org\/abs\/1409.2329, abs\/1409.2329; Kingma, D.P., Ba, J., Adam: A method for stochastic optimization (2014) CoRR, , http\/\/arxiv.org\/abs\/1412.6980, abs\/1412.6980"}
{"Authors":"Rodrigues F., Markou I., Pereira F.C.","Author(s) ID":"36647999000;56724096100;7201689596;","Title":"Combining time-series and textual data for taxi demand prediction in event areas: A deep learning approach","Year":2019,"Source title":"Information Fusion","Volume":"49","Issue":null,"Art. No.":null,"Page start":120.0,"Page end":129.0,"Page count":null,"Cited by":3.0,"DOI":"10.1016\/j.inffus.2018.07.007","Affiliations":"Technical University of Denmark (DTU), Bygning 116B, 2800 Kgs, Lyngby, Denmark","Document Type":"Article","Access Type":null,"Source":"Scopus","EID":"2-s2.0-85054192390","Abstract":"A novel type of recurrent neural network, the regularized Dynamic Self Organised Neural Network Inspired by the Immune Algorithm, is presented. The Regularization technique is used with the Dynamic self-organized multilayer perceptrons network that is inspired by the immune algorithm. The regularization has been addressed to improve the generalization and to solve the over-fitting problem. The results of an average 30 simulations generated from ten stationary signals are demonstrates. The results of the proposed network were compared with the regularized multilayer neural networks and the regularized self organized neural network inspired by the immune algorithm. The simulation results indicated that the proposed network showed better values in terms of the annualized return in comparison to the benchmarked networks. \u00a9 2014 Springer International Publishing Switzerland.","Author Keywords":"And financial time series prediction; Dynamic neural network; Exchange rate time series","Index Keywords":"Bioinformatics; Financial data processing; Intelligent computing; Multilayer neural networks; Recurrent neural networks; Dynamic neural networks; Exchange rates; Financial time series predictions; Immune algorithms; Regularization technique; Self-organised; Self-organized neural networks; Stationary signal; Algorithms","References":"Kamruzzaman, J., ANN-based forecasting of foreign currency exchange rates (2004) Neural Information Processing - Letters and Reviews, 3 (2), pp. 49-58; Espinoza, R., Lombardi, M.J., Fornari, F., The role of financial variables in predicting economic activity (2009) ECB Working Paper Series, 1108. , Frankfurt am Main, Germany; Leondes, C.T., (2010) Intelligent Knowledge-Based Systems: Business and Technology in the New Millennium Illustrate, , Springer; Kamruzzaman, J., Sarker, R., Forecasting of currency exchange rates using ANN: A case study (2003) Proceedings of the 2003 International Conference on Neural Networks and Signal Processing, 1, pp. 793-797. , IEEE, Nanjing; Krollner, B., (2011) Risk Management in the Australian Stockmarket Using Artificial Neural Networks, , PhD Thesis; Tan, T.Z., Quek, C., Ng, G.S., Brain-inspired genetic complementary learning for stock market prediction (2005) IEEE Congress on Evolutionary Computation, 3, pp. 2653-2660; Ahmadifard, M., Sadenejad, F., Mohammadi, I., Aramesh, K., Forecasting stock market return using ANFIS: The case of Tehran Stock Exchange (2013) International Journal of Advanced Studies in Humanities and Social Science, 1 (5), pp. 452-459; Mahdi, A., (2010) The Application of Neural Network InFinancial Time Series Analysis and Prediction Using Immune System, , Liverpool John Moores University; Mahdi, A., Hussain, A., Al-Jumeily, D., The prediction of non-stationary physical time series using the application of regularization technique in self-organised multilayer perceptrons inspired by the immune algorithm (2010) E-systems Eng., pp. 213-218. , September; Jordan, M.I., Attractor dynamics and parallelism in a connectionist sequential machine (1990) Artificial Neural Networks, pp. 112-127. , NJ, USA, IEEE Press, Piscataway; Voegtlin, T., Recursive self-organizing maps (2002) Neural Netw., 15 (8-9), pp. 79-91; Widyanto, M.R., Nobuhara, H., Kawamoto, K., Hirota, K., Kusumoputro, B., Improving recognition and generalization capability of back-propagation NN using self-organized network inspired by immune algorithm (2005) Appl. Soft Comput., 6, pp. 72-84; Bishop, C.M., (1995) Neural Networks for Pattern Recognition, , Cambridge, UK; Thomason, M., The practitioner method and tools (1999) J. Comput. Intell. Financ., 7 (3), pp. 36-45; Cao, L.J., Tay, F.E.H., Financial time series forecasting (2003) IEEE Trans. Neural Networks, 14 (6), pp. 1506-1518; Dunis, C.L., Williams, M., (2003) Applications of Advanced Regression Analysis for Trading and Investment, , John Wiley & Sons, Ltd; Cao, L.J., Tay, F.E.H., Support vector machine with adaptive parameters in financial time series forecasting (2003) IEEE Trans. Neural Networks, 14 (6), pp. 1506-1518"}
{"Authors":"Cao J., Wang J.","Author(s) ID":"57207830408;57207828548;","Title":"Stock price forecasting model based on modified convolution neural network and financial time series analysis","Year":2019,"Source title":"International Journal of Communication Systems","Volume":"32","Issue":"12","Art. No.":" e3987","Page start":null,"Page end":null,"Page count":null,"Cited by":null,"DOI":"10.1002\/dac.3987","Affiliations":"University of Science and Technology of China, Hefei, China; Illinois Institute of Technology, Chicago, IL, United States","Document Type":"Article","Access Type":null,"Source":"Scopus","EID":"2-s2.0-85066486217","Abstract":"Computational technologies have offered faster and efficient solutions to many diverse areas including the financial sector. In the financial market, the advancements in computational field have been mainly achieved through the use of neural networks and machine learning tools that delivered a number of financial applications. These applications include: stock market prediction, bankruptcy prediction, risk assessment etc. Thus, in this paper, we are developing a technique to predict the stock market index for the \u201cDow Jones\u201d using deep learning algorithms. We propose a model based on an adaptive NARX neural network that can predict the closing price of a moderately stable market. In our model, non-linear auto regressive exogenous input model inserts delays into the input as well as the output acting as memory slots thereby raising the accuracy of the prediction. This model uses a time series analysis to improve the prediction accuracy. In addition, Levenberg-Marquardt algorithm has been used for training the network. The accuracy of the model is determined by the mean squared error between the predicted and the actual prices. \u00a9 2018 Association for Computing Machinery.","Author Keywords":"Artificial intelligence; Deep learning; Financial forecasting; NARX algorithm; Stock prediction","Index Keywords":"Artificial intelligence; Big data; Commerce; Deep learning; Electronic trading; Financial markets; Forecasting; Mean square error; Risk assessment; Time series analysis; Auto-regressive exogenous inputs; Bankruptcy prediction; Computational technology; Financial applications; Financial forecasting; Levenberg-Marquardt algorithm; Stock market prediction; Stock predictions; Learning algorithms","References":"Thakur, A., Tiwari, A., Kumar, S., Jain, A., Singh, J., NARX Based Forecasting of Petrol Prices (2016) 5th International Conference on Reliability, Infocom Technologies and Optimization (ICRITO) (Trends and Future Directions), pp. 610-614; Graham, B., Dodd, D., Buffett, W., (2009) Security Analysis, , New York: McGraw-Hill; Reinkensmeyer, B., (2011) StockTrader.Com, , https:\/\/www.stocktrader.com\/, Jun 16th, Retrieved December 27, 2017, from; Devi, B.U., Sundar, D., Alli, P., An optimized approach to predict the stock market behavior and investment decision making using benchmark algorithms for Na\u00efve investors (2013) 2013 IEEE International Conference on Computational Intelligence and Computing Research; Dunis, C., Williams, M., Modeling and Trading the EUR\/USD Exchange Rate: Do Neural Network Models Perform Better? (2002) Liverpool Business School and CIBEF; Wang, C., Time series neural network systems in stock index forecasting (2015) Computer Modelling & New Technologies, 19 (1), pp. 57-61; Diaconescu, E., The use of NARX Neural Networks to predict Chaotic Time Series (2017) WSEAS Transactions on Computer Research, 3 (3), pp. 182-192; Rajput, G., Kaulwar, B., (2017) Artificial Neural Network (Ann) Based Prediction of Stock Closing Price in Nse of India, pp. 19-27; Demuth, H., Beale, M., Hagan, M., (2007) MATLAB Neural Network Toolbox 5, Users Guide; Ercan, H., (2017) Baltic Stock Market Prediction by Using NARX, pp. 464-467; https:\/\/investopedia.adblade.com, Retrieved January 04, 2018, from; Shoven, J., Sialm, C., The Dow Jones Industrial Average The Journal of Wealth Management, 3 (3), pp. 9-18; Crnkovic-Friis, L., Erlandson, M., Geology Driven EUR Prediction Using Deep Learning (2015) SPE Annual Technical Conference and Exhibition; Dunne, M., (2017) Stock Market Prediction, , Unpublished thesis). University College Cork. Retrieved December 26; Vargas, M.R., De Lima, B.S.L.P., Evsukoff, A.G., Deep learning for stock market prediction from financial news articles (2017) 2017 IEEE International Conference on Computational Intelligence and Virtual Environments for Measurement Systems and Applications (CIVEMSA); McCaffrey, (2015) Neural Network Train-Validate-Test Stopping, , May 13; Shahbazi, N., Memarzadeh, M., Gryz, J., Forex Market Prediction Using NARX Neural Network with Bagging (2016) MATEC Web of Conferences, 68, p. 19001; Soman, P., (2008) An Adaptive NARX Neural Network Approach for Financial Time Series Prediction, , Unpublished thesis). The State University of New Jersey; Al-Shayea, Q., Neural Networks to Predict Stock Market Price (2017) World Congress on Engineering and Computer Science, pp. 1-7. , San Fransisco; Cavalcante, R., Brasileiro, R., Souza, V., Nobrega, J., Oliveira, A., Computational Intelligence and Financial Markets: A Survey and Future Directions (2016) Expert Systems With Applications, 55 (1), pp. 194-211; Singh, R., Srivastava, S., Stock prediction using deep learning (2016) Multimedia Tools and Applications, 76 (18), pp. 18569-18584; Chaigusin, S., Chirathamjaree, C., Clayden, J., The Use of Neural Networks in the Prediction of the Stock Exchange of Thailand (SET) Index (2008) 2008 International Conference on Computational Intelligence for Modelling Control & Automation; Labde, S., Patel, S., Shukla, M., Time Series Regression Model for Prediction of Closing Values of the Stock using an Adaptive NARX Neural Network (2017) International Journal of Computer Applications, 158 (10), pp. 29-35; Gao, T., Li, X., Chai, Y., Tang, Y., Deep learning with stock indicators and two-dimensional principal component analysis for closing price prediction system (2016) 2016 7th IEEE International Conference on Software Engineering and Service Science (ICSESS); (2012) Training An Artificial Neural Network \u2013 Intro, , August 02; Chen, W., Zhang, Y., Yeo, C.K., Lau, C.T., Lee, B.S., Stock market prediction using neural network through news on online social networks (2017) 2017 International Smart Cities Conference (ISC2); www.mathworks.com\/help\/nnet\/ref\/trainlm.html; Yetis, Y., Kaplan, H., Jamshidi, M., Stock market prediction by using artificial neural network (2014) 2014 World Automation Congress (WAC)"}
{"Authors":"Xing F.Z., Cambria E., Zhang Y.","Author(s) ID":"57196019442;56140547500;56462264800;","Title":"Sentiment-aware volatility forecasting","Year":2019,"Source title":"Knowledge-Based Systems","Volume":"176","Issue":null,"Art. No.":null,"Page start":68.0,"Page end":76.0,"Page count":null,"Cited by":3.0,"DOI":"10.1016\/j.knosys.2019.03.029","Affiliations":"School of Computer Science & Engineering, Nanyang Technological University, Singapore; Institute of Advanced Technology, Westlake University, China","Document Type":"Article","Access Type":null,"Source":"Scopus","EID":"2-s2.0-85063733190","Abstract":"Deep learning has recently received growing interest and attention. It has been successfully applied to many fields. Stock market time-series forecasting is one the most challenging problems for a variety of learning methodologies. In this paper, we studied the integration of deep learning methodologies into stock market forecasting. We evaluated and compared a number of variants of Deep Recurrent Neural Network based on LSTM and GRU. Both bidirectional and unidirectional stacked architectures with multivariate inputs were employed to perform short- and long-term forecasting. The deep learning architectures were also compared to shallow neural networks using S P500 index historical data. It has been noticed that a stacked LSTM architecture has demonstrated the highest forecasting performance for both short- and long-term. \u00a9 2018 IEEE.","Author Keywords":null,"Index Keywords":"Commerce; Deep learning; Electronic trading; Financial markets; Forecasting; Multivariant analysis; Network architecture; Forecasting performance; Historical data; Learning architectures; Long-term forecasting; Market forecast; Multi variate analysis; Stock market forecasting; Time series forecasting; Long short-term memory","References":"Larochelle, H., Bengio, Y., Louradour, J., Lamblin, P., Exploring strategies for training deep neural networks (2009) Journal of Machine Learning Research, 10, pp. 1-40. , no. Jan; Hinton, G.E., Osindero, S., Teh, Y.-W., A fast learning algorithm for deep belief nets (2006) Neural Computation, 18 (7), pp. 1527-1554; Gamboa, J.C.B., (2017) Deep Learning for Time-Series Analysis, , arXiv preprint arXiv:1701.01887; Buczkowski, P., Predicting stock trends based on expert recommendations using gru\/lstm neural networks (2017) International Symposium on Methodologies for Intelligent Systems, pp. 708-717. , Springer; Li, J., Bu, H., Wu, J., Sentiment-Aware stock market prediction: A deep learning method (2017) International Conference on Service Systems and Service Management (ICSSSM)., pp. 1-6; Bao, W., Yue, J., Rao, Y., A deep learning framework for financial time series using stacked autoencoders and long-short term memory (2017) PloS One, 12 (7), p. e0180944; Edet, S., (2017) Recurrent Neural Networks in Forecasting s&p 500 Index; Zhang, X., Shen, F., Zhao, J., Yang, G., Time series forecasting using gru neural network with multi-lag after decomposition (2017) International Conference on Neural Information Processing, pp. 523-532. , Springer; Hochreiter, S., Schmidhuber, J., Long short-Term memory (1997) Neural Computation, 9 (8), pp. 1735-1780; Gers, F.A., Schmidhuber, J., Cummins, F., Learning to forget: Continual prediction with lstm (2000) Neural Computation, 12 (10), pp. 2451-2471; Zhao, R., Wang, D., Yan, R., Mao, K., Shen, F., Wang, J., Machine health monitoring using local feature-based gated recurrent unit networks (2018) IEEE Transactions on Industrial Electronics, 65 (2), pp. 1539-1548; Graves, A., Schmidhuber, J., Framewise phoneme classification with bidirectional lstm and other neural network architectures (2005) Neural Networks, 18 (5), pp. 602-610; Schuster, M., Paliwal, K.K., Bidirectional recurrent neural networks (1997) IEEE Transactions on Signal Processing, 45 (11), pp. 2673-2681; Zhang, J., Rong, W., Liang, Q., Sun, H., Xiong, Z., Data augmentation based stock trend prediction using self-organising map (2017) International Conference on Neural Information Processing, pp. 903-912. , Springer; Yao, S., Hu, S., Zhao, Y., Zhang, A., Abdelzaher, T., Deepsense: A unified deep learning framework for time-series mobile sensing data processing (2017) Proceedings of the 26th International Conference on World Wide Web, pp. 351-360. , International World Wide Web Conferences Steering Committee; Di Persio, L., Honchar, O., Artificial neural networks architectures for stock price prediction: Comparisons and applications (2016) International Journal of Circuits, Systems and Signal Processing, 10, pp. 403-413; Verma, I., Dey, L., Meisheri, H., Detecting, quantifying and accessing impact of news events on Indian stock indices (2017) Proceedings of the International Conference on Web Intelligence, pp. 550-557; Di Persio, L., Honchar, O., Analysis of recurrent neural networks for short-Term energy load forecasting (2017) AIP Conference Proceedings, 1906 (1), p. 190006; Cui, Z., Ke, R., Wang, Y., Deep stacked bidirectional and unidirectional lstm recurrent neural network for network-wide traffic speed prediction 6th International Workshop on Urban Computing (UrbComp 2017; Lu, R., Duan, Z., Bidirectional Gru For Sound Event Detection; Zhao, R., Wang, D., Yan, R., Mao, K., Shen, F., Wang, J., Machine health monitoring using local feature-based gated recurrent unit networks (2017) IEEE Transactions on Industrial Electronics; Chollet, F., (2015) Keras, , https:\/\/github.com\/fchollet\/keras"}
{"Authors":"Zhang Z., Zohren S., Roberts S.","Author(s) ID":"57208652822;14057447500;57203276441;","Title":"DeepLOB: Deep convolutional neural networks for limit order books","Year":2019,"Source title":"IEEE Transactions on Signal Processing","Volume":"67","Issue":"11","Art. No.":" 8673598","Page start":3001.0,"Page end":3012.0,"Page count":null,"Cited by":null,"DOI":"10.1109\/TSP.2019.2907260","Affiliations":"Oxford-Man Institute of Quantitative Finance, Department of Engineering Science, University of Oxford, Oxford, OX1 2JD, United Kingdom","Document Type":"Article","Access Type":null,"Source":"Scopus","EID":"2-s2.0-85065427368","Abstract":"This paper presents improvements in financial time series prediction using a Deep Neural Network (DNN) in conjunction with a Discrete Wavelet Transform (DWT). When comparing our model to other three alternatives, including ARIMA and other deep learning topologies, ours has a better performance. All of the experiments were conducted on High-Frequency Data (HFD). Given the fact that DWT decomposes signals in terms of frequency and time, we expect this transformation will make a better representation of the sequential behavior of high-frequency data. The input data for every experiment consists of 27 variables: The last 3 one-minute pseudo-log-returns and last 3 one-minute compressed tick-by-tick wavelet vectors, each vector is a product of compressing the tick-by-tick transactions inside a particular minute using a DWT with length 8. Furthermore, the DNN predicts the next one-minute pseudo-log-return that can be transformed into the next predicted one-minute average price. For testing purposes, we use tick-by-tick data of 19 companies in the Dow Jones Industrial Average Index (DJIA), from January 2015 to July 2017. The proposed DNN\u2019s Directional Accuracy (DA) presents a remarkable forecasting performance ranging from 64% to 72%. \u00a9 Springer International Publishing AG, part of Springer Nature 2018.","Author Keywords":"Computational finance; Deep Neural Networks; Discrete Wavelet Transform; High-frequency forecasting; Short-term forecasting","Index Keywords":"Discrete wavelet transforms; Financial data processing; Forecasting; Metadata; Signal reconstruction; Topology; Computational finance; Directional accuracy; Dow Jones Industrial averages; Financial time series predictions; Forecasting performance; High frequency data; High frequency HF; Short-term forecasting; Deep neural networks","References":"Ar\u00e9valo, A., Ni\u00f1o, J., Hern\u00e1ndez, G., Sandoval, J., High-frequency trading strategy based on deep neural networks (2016) ICIC 2016. LNCS (LNAI), 9773, pp. 424-436. , https:\/\/doi.org\/10.1007\/978-3-319-42297-840, Huang, D.-S., Han, K., Hussain, A. (eds.); Ar\u00e9valo Murillo, A.R., Short-term forecasting of financial time series with deep neural networks (2016) Bdigital.Unal.Edu.Co, , http:\/\/www.bdigital.unal.edu.co\/54538; Arnold, L., Rebecchi, S., Chevallier, S., Paugam-Moisy, H., (2011) An Introduction to Deep Learning, , https:\/\/www.elen.ucl.ac.be\/Proceedings\/esann\/esannpdf\/es2011-4.pdf; Chao, J., Shen, F., Zhao, J., Forecasting exchange rate with deep belief networks (2011) 2011 International Joint Conference on Neural Networks, pp. 1259-1266. , https:\/\/doi.org\/10.1109\/IJCNN.2011.6033368, IEEE, July; Cho, K., van Merrienboer, B., Gulcehre, C., Bahdanau, D., Bougares, F., Schwenk, H., Bengio, Y., Learning phrase representations using RNN encoder-decoder for statistical machine translation (2014) Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP), pp. 1724-1734. , http:\/\/arxiv.org\/abs\/1406.1078, June; de Gooijer, J.G., Hyndman, R.J., 25 years of time series forecasting (2006) Int. J. Forecast., 22 (3), pp. 443-473. , https:\/\/doi.org\/10.1016\/j.ijforecast.2006.01.001; Ding, X., Zhang, Y., Liu, T., Duan, J., Deep learning for event-driven stock prediction (2015) Proceedings of the Twenty-Fourth International Joint Conference on Artificial Intelligence (ICJAI), , http:\/\/ijcai.org\/papers15\/Papers\/IJCAI15-329.pdf; Gallo, C., Letizia, C., Stasio, G., (2006) Artificial Neural Networks in Financial Modelling, , http:\/\/citeseerx.ist.psu.edu\/viewdoc\/download?doi=10.1.1.114.2740&rep=rep1&type=pdf; Gen\u00e7ay, R., Sel\u00e7uk, F., Whitcher, B., (2002) An Introduction to Wavelets and Other Filtering Methods in Finance and Economics, , Academic Press, Cambridge; Goodfellow, I., Bengio, Y., Courville, A., (2016) Deep Learning, , http:\/\/www.deeplearningbook.org, MIT press, Cambridge; Haykin, S., (2009) Neural Networks and Learning Machines, , Prentice Hall, Upper Saddle River; He, T.X., Nguyen, T., Wavelet analysis and applications in economics and finance (2015) Res. Rev. J. Stat. Math. Sci., 1 (1), pp. 22-37; Hochreiter, S., Schmidhuber, J., Long short-term memory (1997) Neural Comput, 9 (8), pp. 1735-1780. , https:\/\/doi.org\/10.1162\/neco.1997.9.8.1735; Hyndman, R.J., Koehler, A.B., Another look at measures of forecast accuracy (2005) Int. J. Forecast, pp. 679-688. , http:\/\/www.sciencedirect.com\/science\/article\/pii\/S0169207006000239%5Cncore.ac.uk\/download\/pdf\/6340761.pdf; Kamijo, K., Tanigawa, T., Stock price pattern recognition-a recurrent neural network approach (1990) International Joint Conference on Neural Networks, pp. 215-221. , http:\/\/ieeexplore.ieee.org\/lpdocs\/epic03\/wrapper.htm?arnumber=5726532; Krollner, B., Vanstone, B., Finnie, G., (2010) Financial Time Series Forecasting with Machine Learning Techniques: A Survey, , http:\/\/works.bepress.com\/brucevanstone\/17\/; Li, X., Huang, X., Deng, X., Zhu, S., Enhancing quantitative intra-day stock return prediction by integrating both market news and stock prices information (2014) Neurocomputing, 142, pp. 228-238. , https:\/\/doi.org\/10.1016\/j.neucom.2014.04.043; Marszalek, A., Burczy\u0144ski, T.:., Modeling and forecasting financial time series with ordered fuzzy candlesticks (2014) Inf. Sci., 273, pp. 144-155. , https:\/\/doi.org\/10.1016\/j.ins.2014.03.026; Medsker, L., Jain, L.C., (1999) Recurrent Neural Networks: Design and Applications. International Series on Computational Intelligence, , CRC Press, Boca Raton; Mills, T.C., Markellos, R.N., (2008) The Econometric Modelling of Financial Time Series, , https:\/\/doi.org\/10.1017\/CBO9780511817380, Cambridge University Press, Cambridge; Preethi, G., Santhi, B., Stock market forecasting techniques: A survey (2012) J. Theor. Appl. Inf. Technol., 46 (1), pp. 24-30; Schnader, M.H., Stekler, H.O., Evaluating predictions of change (1990) J. Bus., 63 (1), pp. 99-107; Sureshkumar, K., Elango, N., Performance analysis of stock price prediction using artificial neural network (2012) Global Journal of Computer Science and Technology, 12, pp. 19-26. , http:\/\/computerresearch.org\/index.php\/computer\/article\/view\/426; Takeuchi, L., Lee, Y., (2013) Applying Deep Learning to Enhance Momentum Trading Strategies in Stocks; Tsay, R.S., (2005) Analysis of Financial Time Series, 543. , Wiley, Hoboken; Walnut, D.F., (2002) An Introduction to Wavelet Analysis, , Birkh\u00e4user, Boston; Wilder, J.W., (1978) New Concepts in Technical Trading Systems. Trend Research; Yeh, S., Wang, C., Tsai, M., (2014) Corporate Default Prediction via Deep Learning, , http:\/\/teacher.utaipei.edu.tw\/"}
{"Authors":"Shi L., Teng Z., Wang L., Zhang Y., Binder A.","Author(s) ID":"55520303300;57191849336;57189032831;57202890579;7103335240;","Title":"DeepClue: Visual interpretation of text-based deep stock prediction","Year":2019,"Source title":"IEEE Transactions on Knowledge and Data Engineering","Volume":"31","Issue":"6","Art. No.":" 8408524","Page start":1094.0,"Page end":1108.0,"Page count":null,"Cited by":1.0,"DOI":"10.1109\/TKDE.2018.2854193","Affiliations":"SKLCS, Institute of Software, Chinese Academy of Sciences, Beijing, 100864, China; University of Chinese Academy of Sciences (UCAS), Beijing, 100049, China; Singapore University of Technology Design, Singapore, 487372, Singapore","Document Type":"Article","Access Type":null,"Source":"Scopus","EID":"2-s2.0-85049670640","Abstract":"In this paper, we develop a new Hybrid method based on machine learning algorithms for jump detection in financial time series. Jump is an important behavior in financial time series, since it implies a change in volatility. Ones can buy the volatility instrument if ones expect the volatility will bloom up in the future. A jump detection model attempts to detect short-term market instability, since it could be jumping up or down, instead of a directional prediction. The directional prediction can be considered as a momentum or trend following, which is not the focus of this paper. A jump detection model is commonly applied in a systematic fast-moving strategy, which reallocates the assets automatically. Also, a systematic opening position protection strategy can be driven by a jump detection model. For example, for a tail risk protection strategy, a pair of long call and put option order could be placed in the same time, in order to protect the open position given a huge change in volatility. One of the key differentiations of the proposed model with the classical methods of time-series anomaly detection is that, jump threshold parameters are not required to be predefined in our proposed model. Also the model is a combination of a Long short-term memory (LSTM) neural network model and a machine learning pattern recognition model. The LSTM model is applied for time series prediction, which predicts the next data point. The historical prediction errors sequence can be used as the information source or input of the jump detection model\/module. The machine learning pattern recognition model is applied for jump detection. The combined model attempts to determine whether the current data point is a jump or not. LSTM neural network is a type of Recurrent Neural Networks (RNNs). LSTM records not only the recent market, but also the historical status. A stacked RNN is trained on a dataset which is mixed with normal and anomalous data. We compare the performance of the proposed Hybrid jump detection model and different pattern classification algorithms, such as k-nearest neighbors algorithm identifier, Hampel identifier, and Lee Mykland test. The model is trained and tested using real financial market data, including 11 global stock market in both developed and emerging markets in US, China, Hong Kong, Taiwan, Japan, UK, German, and Israel. The experiment result shows that the proposed Hybrid jump detection model is effective to detect jumps in terms of accuracy, comparing to the other classical jump detection methods. \u00a9 2019, Springer-Verlag GmbH Germany, part of Springer Nature.","Author Keywords":"Anomaly detection; Long short-term memory (LSTM)\u00a0neural network; Machine learning; Recurrent neural network","Index Keywords":"Anomaly detection; Binary alloys; Brain; Commerce; Electronic trading; Financial markets; Forecasting; Learning algorithms; Learning systems; Machine learning; Nearest neighbor search; Pattern recognition; Potassium alloys; Recurrent neural networks; Time series; Uranium alloys; Classification algorithm; Directional predictions; Financial time series; Global stock markets; Neural network model; Recurrent neural network (RNNs); Threshold parameters; Time series prediction; Long short-term memory","References":"A\u00eft-Sahalia, Y., Jacod, J., Testing for jumps in a discretely observed process (2009) Ann Stat, 37 (1), pp. 184-222; Barndorff-Nielsen, O., Shephard, N., (2005) Variation, Jumps, Market Frictions and High Frequency Data in Financial Econometrics, , https:\/\/EconPapers.repec.org\/RePEc:nuf:econwp:0516, economics papers 2005-W16, Economics Group, Nuffield College, University of Oxford, Accessed 14 July 2005; Chandola, V., Banerjee, A., Kumar, V., Anomaly detection: a survey (2009) ACM Comput Surv (CSUR), 41 (3), p. 15; Chen, Q., Chetty, K., Woodbridge, K., Tan, B., Signs of life detection using wireless passive radar (2016) Radar Conference (Radarconf), 2016 IEEE, pp. 1-5. , IEEE; Choi, O.T., In depth analysis of the dually listed companies in hong kong and china stock markets prior and posterior to the global financial turmoil (2013) Int J Econ Finance, 5 (10), pp. 100-110; Cortes, C., Vapnik, V., Support vector networks (1995) Mach Learn, 20 (3), pp. 273-297; Cunningham, P., Delany, S.J., k-Nearest neighbour classifiers (2007) Mult Classif Syst, 34, pp. 1-17; Freund, Y., Mason, L., The alternating decision tree learning algorithm (1999) Proceedings of the Sixteenth International Conference on Machine Learning, pp. 124-133; Goodfellow, I., Bengio, Y., Courville, A., (2016) Deep learning, , MIT press, Cambridge; Hermans, M., Schrauwen, B., Training and analysing deep recurrent neural networks (2013) Advances in Neural Information Processing Systems, 26. , NIPS 2013; Hochreiter, S., Schmidhuber, J., Long short-term memory (1997) Neural Comput, 9 (8), pp. 1735-1780; Knorr, E.M., Ng, R.T., Tucakov, V., Distance-based outliers: algorithms and applications (2000) Int J Very Large Data Bases, 8 (3-4), pp. 237-253; Lee, S.S., Mykland, P.A., Jumps in financial markets: a new nonparametric test and jump dynamics (2008) Rev Financial Stud, 21 (6), pp. 2535-2563; Makinen, M., Kanniainen, J., Gabbouj, M., Iosifidis, A., (2018) Forecasting of jump arrivals in stock prices: New attention-based network architecture using limit order book data; Malhotra, P., Vig, L., Shroff, G., Agarwal, P., Long short term memory networks for anomaly detection in time series (2015) Proceedings, Presses Universitaires De Louvain, p. 89; Pearson, R.K., Outliers in process modeling and identification (2002) IEEE Trans Control Syst Technol, 10 (1), pp. 55-63; Pearson, R.K., Neuvo, Y., Astola, J., Gabbouj, M., The class of generalized hampel filters (2015) 2015 23Rd European Signal Processing Conference (EUSIPCO), IEEE, pp. 2501-2505; Perron, P., Yabu, T., Testing for shifts in trend with an integrated or stationary noise component (2009) J Bus Econ Stat, 27 (3), pp. 369-396; Ramaswamy, S., Rastogi, R., Shim, K., Efficient algorithms for mining outliers from large data sets (2000) Proceedings of the 2000 ACM SIGMOD International Conference on Management of Data, 29 (2), pp. 427-438; Suykens, J.A., Vandewalle, J., Least squares support vector machine classifiers (1999) Neural Process Lett, 9 (3), pp. 293-300; Tauchen, G., Zhou, H., Realized jumps on financial markets and predicting credit spreads (2011) J Econom, 160 (1), pp. 102-118; Tong, S., Koller, D., Support vector machine active learning with applications to text classification (2001) J Mach Learn Res, 2 (Nov), pp. 45-66; Wang, Q., Garrity, G.M., Tiedje, J.M., Cole, J.R., Naive bayesian classifier for rapid assignment of rrna sequences into the new bacterial taxonomy (2007) Appl Environ Microbiol, 73 (16), pp. 5261-5267"}
{"Authors":"Yeze Z., Yiying W.","Author(s) ID":"57209140407;57209134544;","Title":"Stock Price Prediction Based on Information Entropy and Artificial Neural Network","Year":2019,"Source title":"5th International Conference on Information Management, ICIM 2019","Volume":null,"Issue":null,"Art. No.":" 8714662","Page start":248.0,"Page end":251.0,"Page count":null,"Cited by":null,"DOI":"10.1109\/INFOMAN.2019.8714662","Affiliations":"School of Computer and Information Technology, Beijing Jiaotong University, Beijing, China; Department of Mathematics, University of Liverpool, Liverpool, United Kingdom","Document Type":"Conference Paper","Access Type":null,"Source":"Scopus","EID":"2-s2.0-85066631662","Abstract":"Forecasting a financial asset's price is important as one can lower the risk of investment decision- making with accurate forecasts. Recently, the deep neural network is popularly applied in this area of research; however, it is prone to overfitting owing to limited availability of data points for training. We propose a novel data augmentation approach for stock market index forecasting through our ModAugNet framework, which consists of two modules: an overfitting prevention LSTM module and a prediction LSTM module. The performance of the proposed model is evaluated using two different representative stock market data (S&P500 and Korea Composite Stock Price Index 200 (KOSPI200)). The results confirm the excellent forecasting accuracy of the proposed model. ModAugNet-c yields a lower test error than the comparative model (SingleNet) in which an overfitting prevention LSTM module is absent. The test mean squared error (MSE), mean absolute percentage error (MAPE), and mean absolute error (MAE) for S&P500 decreased to 54.1%, 35.5%, and 32.7%, respectively, of the corresponding S&P500 forecasting errors of SingleNet, while the same for KOSPI200 decreased to 48%, 23.9%, and 32.7%, respectively, of the corresponding KOSPI200 forecasting errors of SingleNet. Furthermore, through the analyses of the trained ModAugNet-c, we found that test performance is entirely dependent on the prediction LSTM module. The contribution of this study is its applicability in various instances where it is challenging to artificially augment data, such as medical data analysis and financial time-series modeling. \u00a9 2018 Elsevier Ltd","Author Keywords":"Data augmentation; Deep learning; Long short-term memory; Overfitting; Stock market index","Index Keywords":"Commerce; Decision making; Deep learning; Deep neural networks; Errors; Financial data processing; Financial markets; Forecasting; Investments; Mean square error; Time series analysis; Data augmentation; Financial time series; Investment decision making; Mean absolute percentage error; Medical data analysis; Overfitting; Overfitting preventions; Stock market index; Long short-term memory","References":"Abu-Mostafa, Y.S., Atiya, A.F., Introduction to financial forecasting (1996) Applied Intelligence, 6 (3), pp. 205-213; Adhikari, R., A mutual association based nonlinear ensemble mechanism for time series forecasting (2015) Applied Intelligence, 43 (2), pp. 233-250; Akita, R., Yoshihara, A., Matsubara, T., Uehara, K., Deep learning for stock prediction using numerical and textual information (2016) Proceedings of the IEEE\/ACIS fifteenth international conference on computer and information science (ICIS), pp. 1-6. , IEEE; Ariyo, A.A., Adewumi, A.O., Ayo, C.K., Stock price prediction using the ARIMA model (2014) Proceedings of the UKSim-AMSS sixteenth international conference on computer modelling and simulation (UKSim), pp. 106-112. , IEEE; Atsalakis, G.S., Valavanis, K.P., Forecasting stock market short-term trends using a neuro-fuzzy based methodology (2009) Expert Systems with Applications, 36 (7), pp. 10696-10707; Bachelier, L., Th\u00e9orie de la sp\u00e9culation (1900), Gauthier-Villars; Bao, W., Yue, J., Rao, Y., A deep learning framework for financial time series using stacked autoencoders and long-short term memory (2017) PloS ONE, 12 (7); Box, G.E., Jenkins, G.M., Reinsel, G.C., Ljung, G.M., Time series analysis: forecasting and control (2015), John Wiley & Sons; Chatfield, K., Simonyan, K., Vedaldi, A., Zisserman, A., (2014), Return of the devil in the details: Delving deep into convolutional nets. arXiv 1405.3531; Chen, A.S., Leung, M.T., Daouk, H., Application of neural networks to an emerging financial market: Forecasting and trading the Taiwan Stock Index (2003) Computers & Operations Research, 30 (6), pp. 901-923; Chen, K., Zhou, Y., Dai, F., A LSTM-based method for stock returns prediction: A case study of China stock market (2015) Proceedings of the IEEE international conference on big data (Big Data), pp. 2823-2824. , IEEE; Chiang, W.C., Enke, D., Wu, T., Wang, R., An adaptive stock index trading decision support system (2016) Expert Systems with Applications, 59, pp. 195-207; Chollet, F., Keras (2015), https:\/\/github.com\/keras-team\/keras; Chong, E., Han, C., Park, F.C., Deep learning networks for stock market analysis and prediction: Methodology, data representations, and case studies (2017) Expert Systems with Applications, 83, pp. 187-205; Cootner, P.H., (1964) The random character of stock market prices, , MIT Press Cambridge, MA; Diebold, F.X., Mariano, R.S., Comparing predictive accuracy (2002) Journal of Business & Economic Statistics, 20 (1), pp. 134-144; Duda, R.O., Hart, P.E., Stork, D.G., Pattern classification (2012), John Wiley & Sons; Fama, E.F., The behavior of stock-market prices (1965) The Journal of Business, 38 (1), pp. 34-105; Fuertes, A.M., Izzeldin, M., Kalotychou, E., On forecasting daily stock volatility: The role of intraday information and market conditions (2009) International Journal of Forecasting, 25 (2), pp. 259-281; Goodfellow, I., Bengio, Y., Courville, A., Bengio, Y., (2016) Deep learning, 1. , MIT press Cambridge; G\u00f6\u00e7ken, M., \u00d6z\u00e7al\u0131c\u0131, M., Boru, A., Dosdo\u011fru, A.T., Integrating metaheuristics and artificial neural networks for improved stock price prediction (2016) Expert Systems with Applications, 44, pp. 320-331; Hajizadeh, E., Seifi, A., Zarandi, M.F., Turksen, I.B., A hybrid modeling approach for forecasting the volatility of S&P 500 index return (2012) Expert Systems with Applications, 39 (1), pp. 431-436; Hendricks, D., Using real-time cluster configurations of streaming asynchronous features as online state descriptors in financial markets (2017) Pattern Recognition Letters, 97, pp. 21-28; Hochreiter, S., The vanishing gradient problem during learning recurrent neural nets and problem solutions (1998) International Journal of Uncertainty, Fuzziness and Knowledge-Based Systems, 6 (2), pp. 107-116; Hochreiter, S., Schmidhuber, J., Long short-term memory (1997) Neural computation, 9 (8), pp. 1735-1780; Hornik, K., Stinchcombe, M., White, H., Multilayer feedforward networks are universal approximators (1989) Neural networks, 2 (5), pp. 359-366; Kam, H.J., Kim, H.Y., Learning representations for the early detection of sepsis with deep neural networks (2017) Computers in Biology and Medicine, 89, p. 248; Kim, K.J., Han, I., Genetic algorithms approach to feature discretization in artificial neural networks for the prediction of stock price index (2000) Expert systems with Applications, 19 (2), pp. 125-132; Kim, Y., Enke, D., Developing a rule change trading system for the futures market using rough set analysis (2016) Expert Systems with Applications, 59, pp. 165-173; Kingma, D.P., Ba, J., (2014), Adam: A method for stochastic optimization. arXiv 1412.6980; Koyano, S., Ikeda, K., Online portfolio selection based on the posts of winners and losers in stock microblogs (2017) Proceedings of the IEEE symposium series on computational intelligence (SSCI), pp. 1-4. , IEEE; Kristjanpoller, W., Fadic, A., Minutolo, M.C., Volatility forecast using hybrid neural network models (2014) Expert Systems with Applications, 41 (5), pp. 2437-2442; Kristjanpoller, W., Minutolo, M.C., Forecasting volatility of oil price using an artificial neural network-GARCH model (2016) Expert Systems with Applications, 65, pp. 233-241; Krizhevsky, A., Sutskever, I., Hinton, G.E., Imagenet classification with deep convolutional neural networks (2012) Proceedings of the advances in neural information processing systems, pp. 1097-1105; LeCun, Y., Bengio, Y., Hinton, G., Deep learning (2015) Nature, 521 (7553), p. 436; Lee, M.C., Using support vector machine with a hybrid feature selection method to the stock trend prediction (2009) Expert Systems with Applications, 36 (8), pp. 10896-10904; Lendasse, A., de Bodt, E., Wertz, V., Verleysen, M., Non-linear financial time series forecasting-Application to the Bel 20 stock market index (2000) European Journal of Economic and Social Systems, 14 (1), pp. 81-91; L'heureux, A., Grolinger, K., Elyamany, H.F., Capretz, M.A., Machine learning with big data: Challenges and approaches (2017) IEEE Access, 5, pp. 7776-7797; Li, J., Bu, H., Wu, J., Sentiment-aware stock market prediction: A deep learning method (2017) Proceedings of the international conference on service systems and service management (ICSSSM), pp. 1-6. , IEEE; Lipton, Z.C., Kale, D.C., Elkan, C., Wetzel, R., (2015), Learning to diagnose with LSTM recurrent neural networks. arXiv 1511.03677; Malkiel, B.G., Fama, E.F., Efficient capital markets: A review of theory and empirical work (1970) The Journal of Finance, 25 (2), pp. 383-417; Nair, V., Hinton, G.E., Rectified linear units improve restricted boltzmann machines (2010) Proceedings of the twenty seventh international conference on machine learning (ICML-10), pp. 807-814; Nelson, D.M., Pereira, A.C., de Oliveira, R.A., Stock market's price movement prediction with LSTM neural networks (2017) Proceedings of the international joint conference on neural networks (IJCNN), pp. 1419-1426. , IEEE; Nowlan, S.J., Hinton, G.E., Simplifying neural networks by soft weight-sharing (1992) Neural Computation, 4 (4), pp. 473-493; Patel, J., Shah, S., Thakkar, P., Kotecha, K., Predicting stock market index using fusion of machine learning techniques (2015) Expert Systems with Applications, 42 (4), pp. 2162-2172; Perez, L., Wang, J., (2017), The effectiveness of data augmentation in image classification using deep learning. arXiv preprint arXiv 1712.04621; Rather, A.M., Agarwal, A., Sastry, V.N., Recurrent neural network and a hybrid model for prediction of stock returns (2015) Expert Systems with Applications, 42 (6), pp. 3234-3241; Ryu, D., The information content of trades: An analysis of KOSPI 200 index derivatives (2015) Journal of Futures Markets, 35 (3), pp. 201-221; Sak, H., Senior, A., Beaufays, F., Long short-term memory recurrent neural network architectures for large scale acoustic modeling (2014) Proceedings of the fifteenth annual conference of the international speech communication association; Salamon, J., Bello, J.P., Deep convolutional neural networks and data augmentation for environmental sound classification (2017) IEEE Signal Processing Letters, 24 (3), pp. 279-283; Soulas, E., Shasha, D., Online machine learning algorithms for currency exchange prediction (2013) Online machine learning algorithms for currency exchange prediction, 31. , Computer Science Department in New York University Technical Report; Srivastava, N., Hinton, G., Krizhevsky, A., Sutskever, I., Salakhutdinov, R., Dropout: A simple way to prevent neural networks from overfitting (2014) The Journal of Machine Learning Research, 15 (1), pp. 1929-1958; Sundermeyer, M., Schl\u00fcter, R., Ney, H., LSTM neural networks for language modeling (2012) Proceedings of the thirteenth annual conference of the international speech communication association; Ticknor, J.L., A Bayesian regularized artificial neural network for stock market forecasting (2013) Expert Systems with Applications, 40 (14), pp. 5501-5506; Vanstone, B., Finnie, G., An empirical methodology for developing stockmarket trading systems using artificial neural networks (2009) Expert Systems with Applications, 36 (3), pp. 6668-6680; Virtanen, I., Yli-Olli, P., Forecasting stock market prices in a thin security market (1987) Omega, 15 (2), pp. 145-155; Wang, J., Wang, J., Forecasting stock market indexes using principle component analysis and stochastic time effective neural networks (2015) Neurocomputing, 156, pp. 68-78; Wang, J.H., Leu, J.Y., Stock market trend prediction using ARIMA-based neural networks (1996) Proceedings of the IEEE international conference on neural networks, 4, pp. 2160-2165. , IEEE; Wang, J.J., Wang, J.Z., Zhang, Z.G., Guo, S.P., Stock index forecasting based on a hybrid model (2012) Omega, 40 (6), pp. 758-766; Zeiler, M.D., Fergus, R., Visualizing and understanding convolutional networks (2014) Proceedings of the European conference on computer vision, Cham, pp. 818-833. , Springer; Zhong, X., Enke, D., Forecasting daily stock market return using dimensionality reduction (2017) Expert Systems with Applications, 67, pp. 126-139"}
{"Authors":"Passalis N., Tefas A., Kanniainen J., Gabbouj M., Iosifidis A.","Author(s) ID":"56897101400;6701672908;23394868200;7005332419;36720841400;","Title":"Deep Temporal Logistic Bag-of-features for Forecasting High Frequency Limit Order Book Time Series","Year":2019,"Source title":"ICASSP, IEEE International Conference on Acoustics, Speech and Signal Processing - Proceedings","Volume":"2019-May","Issue":null,"Art. No.":" 8682297","Page start":7545.0,"Page end":7549.0,"Page count":null,"Cited by":null,"DOI":"10.1109\/ICASSP.2019.8682297","Affiliations":"School of Informatics, Aristotle University of Thessaloniki, Greece; Faculty of Information Technology and Communication Sciences, Tampere University, Finland; Dept. of Engineering, Aarhus University, Denmark","Document Type":"Conference Paper","Access Type":null,"Source":"Scopus","EID":"2-s2.0-85069000578","Abstract":"Most approaches to forecasting time series data employ one-step-ahead prediction approaches. However, recently there has been focus on multi-step-ahead prediction approaches. These approaches demonstrate enhanced prediction capabilities. However, multi-step-ahead prediction increases the complexity of the prediction process in comparison to one-step-ahead approaches. Typically, studies in the examination of multi-step ahead methods have addressed issues such as the increased complexity, inaccuracy, uncertainty, and error variance on the prediction horizon, and have been deployed in various domains such as finance, economics, agriculture and hydrology. When determining which algorithm to use in a time series analyses, the approach is to analyze the series for numerous characteristics and features, such as heteroscedasticity, auto-correlation, seasonality and stationarity. In this work, a comparative analysis of 20 different time series datasets is presented and a demonstration of the complexity in deciding which approach to use is given. The study investigates some of the main prediction approaches such as ARIMA (Autoregressive integrated moving average), NN (Neural Network), RNN (Recurrent neural network) and SVR (Support vector regression), which focus on the recursive prediction strategy and compare them to a new approach known as MRFA (Multi-Resolution Forecast Aggregation). \u00a9 Springer Nature Switzerland AG 2018.","Author Keywords":null,"Index Keywords":"Complex networks; Data mining; Economics; Forecasting; Recurrent neural networks; Time series; Time series analysis; Algorithmic approach; Auto-regressive integrated moving average; Comparative analysis; Forecasting time series; Multi-step-ahead predictions; Prediction capability; Recursive prediction; Support vector regression (SVR); Big data","References":"Aweya, J., (1999) Sensitivity Methods for Congestion Control in Computer Networks, , Ph.D thesis, Ottawa, Ontario, Canada, AAINQ48085; Bahrpeyma, F., Roantree, M., McCarren, A., Multi-resolution forecast aggregation for time series in agri datasets (2017) In: Proceedings of the 25Th Irish Conference on Artificial Intelligence and Cognitive Science, pp. 193-205. , Dublin, Ireland, 7\u20138 December 2017; Bontempi, G., Ben Taieb, S., Le Borgne, Y.-A., (2013) Machine Learning Strategies for Time Series Forecasting, 138, pp. 62-77. , https:\/\/doi.org\/10.1007\/978-3-642-36318-4_3, Aufaure, M.-A., Zim\u00e1nyi, E. (eds.) eBISS 2012. LNBIP, Springer, Heidelberg; Box, G.E.P., Jenkins, G.M., Reinsel, G.C., Ljung, G.M., (2015) Time Series Analysis: Forecasting and Control, , Wiley, Hoboken; Brockwell, P.J., Davis, R.A., (2016) Introduction to Time Series and Forecasting, , https:\/\/doi.org\/10.1007\/978-3-319-29854-2, Springer, Heidelberg; Browne, A., (1997) Neural Network Analysis, Architectures and Applications, , CRC Press, Boca Raton; Cadavid, A.C., Lawrence, J.K., Ruzmaikin, A., Principal components and independent component analysis of solar and space data (2007) Solar Image Analysis and Visualization, , https:\/\/doi.org\/10.1007\/978-0-387-98154-3_5, Ireland, J., Young, C.A. (eds.), Springer, New York; Chatfield, C., (2016) The Analysis of Time Series: An Introduction, , CRC Press, New York; Chu, H., Wei, J., Li, T., Jia, K., Application of support vector regression for mid-and long-term runoff forecasting in \u201cyellow river headwater\u201d region (2016) Procedia Eng, 154, pp. 1251-1257; Corder, G.W., Foreman, D.I., (2014) Nonparametric Statistics: A Step-By-Step Approach, , Wiley, Hoboken; Dickey, D.A., Fuller, W.A., Distribution of the estimators for autoregressive time series with a unit root (1979) J. Am. Stat. Assoc., 74 (366a), pp. 427-431; Fischer, T., Krauss, C., Deep learning with long short-term memory networks for financial market predictions (2017) Eur. J. Oper. Res., 270, pp. 654-669; Hurst, H.E., Long term storage capacity of reservoirs (1951) ASCE Trans, 116 (776), pp. 770-808; Kantelhardt, J.W., Koscielny-Bunde, E., Rego, H.H.A., Havlin, S., Bunde, A., Detecting long-range correlations with detrended fluctuation analysis (2001) Phys. a Stat. Mech. Appl, 295 (3-4), pp. 441-454; Ko\u010denda, E., \u010cern\u1ef3, A., Elements of Time Series Econometrics: An Applied Approach (2015) Charles University in Prague, Karolinum Press, Prague; Kwiatkowski, D., Phillips, P.C.B., Schmidt, P., Shin, Y., Testing the null hypothesis of stationarity against the alternative of a unit root: How sure are we that economic time series have a unit root? (1992) J. Econom., 54 (1-3), pp. 159-178; Mandic, D.P., Chambers, J.A., (2001) Recurrent Neural Networks for Prediction: Learning Algorithms, Architectures and Stability, , Wiley Online Library; Parlos, A.G., Rais, O.T., Atiya, A.F., Multi-step-ahead prediction using dynamic recurrent neural networks (2000) Neural Netw, 13 (7), pp. 765-786; Richman, J.S., Lake, D.E., Moorman, J.R., Sample entropy (2004) Methods in Enzymology, 384, pp. 172-184. , Elsevier; Soofi, A.S., Cao, L., (2012) Modelling and Forecasting Financial Data: Techniques of Nonlinear Dynamics, 2. , https:\/\/doi.org\/10.1007\/978-1-4615-0931-8, Springer, New York; Xiong, W., Xu, B., Study on optimization of SVR parameters selection based on PSO (2006) J. Syst. Simul., 9, p. 017; Zhang, G., Hu, M.Y., Neural network forecasting of the British pound\/US dollar exchange rate (1998) Omega, 26 (4), pp. 495-506"}
{"Authors":"Karmiani D., Kazi R., Nambisan A., Shah A., Kamble V.","Author(s) ID":"57208722670;57208718984;57208719870;57208721548;56919409700;","Title":"Comparison of Predictive Algorithms: Backpropagation, SVM, LSTM and Kalman Filter for Stock Market","Year":2019,"Source title":"Proceedings - 2019 Amity International Conference on Artificial Intelligence, AICAI 2019","Volume":null,"Issue":null,"Art. No.":" 8701258","Page start":228.0,"Page end":234.0,"Page count":null,"Cited by":null,"DOI":"10.1109\/AICAI.2019.8701258","Affiliations":"Sardar Patel Institute of Technology, Mumbai, India","Document Type":"Conference Paper","Access Type":null,"Source":"Scopus","EID":"2-s2.0-85065601062","Abstract":"A low complexity Polynomial Functional link Artificial Recurrent Neural Network (PFLARNN) has been proposed for the prediction of financial time series data. Although different types of polynomial functions have been used for low complexity neural network architectures earlier for stock market prediction, a comparative study is needed to choose the optimal combinations of the nonlinear functions for a reasonably accurate forecast. Further a recurrent version of the Functional link neural network is used to model more accurately a chaotic time series like stock market indices with a lesser number of nonlinear basis functions. The proposed PFLARNN model when trained with the well known gradient descent algorithm produces reasonable accuracy with a choice of range of weight parameters of the network. However, to improve the accuracy of the forecast further, the weight parameters of the recurrent functional neural network are optimized using an evolutionary learning algorithm like the differential evolution (DE). A comparison with other well known neural architectures shows that the proposed low complexity neural model can provide significant prediction accuracy for one day advance and speed of convergence using the International Business Machines Corp. (IBM) stock market indices. \u00a9 2015 the authors.","Author Keywords":"AMAPE; backpropagation learning algorithm; differential evolution; IBM stock indices; MAPE; PFLARNN; Polynomial functions","Index Keywords":"Algorithms; Backpropagation; Backpropagation algorithms; Commerce; Complex networks; Evolutionary algorithms; Finance; Financial data processing; Financial markets; Forecasting; Functions; Learning algorithms; Network architecture; Neural networks; Optimization; Parameter estimation; Polynomials; Recurrent neural networks; Time series; AMAPE; Backpropagation learning algorithm; Differential Evolution; Mape; PFLARNN; Polynomial functions; Stock indices; Electronic trading","References":"Contreras, J., Rosario, E., Nogales, F.J., Conejo, A.J., ARIMA Models to Predict Next-Day Electricity Prices (2003) IEEE Transactions on Power Systems, 18, pp. 1014-1020; Valenzuelab, R.O., Rojas, F., Guillen, A., Herrera, L.J., Pomares, H., Marquez, L., Pasadas, M., Soft-computing techniques and ARMA model for time series prediction (2008) Neural Computing, Elsevier, Vol-71, pp. 519-537; Flores, J.J., Graff, M., Rodriguez, H., Evaluative design of ARMA and ANN models for time series forecasting (2012) Renewable Energy, Elsevier, Vol-44, pp. 225-230; Chen, A.S., Leung, M.T., Daouk, H., Application of Neural Networks to an emerging financial market: Forecasting and trading the Taiwan Stock Index (2003) Computers & Operations Research on Elsevier, Vol-30, pp. 901-923; (2011) \u201cThe Use of Artificial Neural Networks in the Analysis and Prediction of Stock Prices\u201d, IEEE International Conference on Systems, Man and Cybernetics (SMC, pp. 2151-2155; Singh, M.P., Kumar, S., Sharma, N.K., (2010) \u2018Mathematical formulation of second derivative of backpropagation error with nonlinear output function in feedforward neural networks\u2019, International Journal of Information and Decision sciences, 2 (4), pp. 352-374; Sun, Y.F., Liang, Y.C., Zhang, W.L., Lee, H.P., Lin, W.Z., Cao, L.J., Optimal partition algorithm for the RBF neural network for financial time series forecasting (2005) Neural Computing and Applications, 14 (1), pp. 36-44; Hsieh, T.J., Hsiao, H.F., Yeh, W.C., Forecasting stock markets using wavelet transforms and recurrent neural networks: an integrated system based on artificial bee colony algorithm (2011) Applied Soft Computing, 11 (2), pp. 2510-2525; Yumlu, S., Gurgen, F.S., Okay, N., \u2018A Comparison of global, recurrent and smoothed-piecewise neural models for Istanbul stock exchange prediction (2005) Pattern Recognition Letters, 26 (13), pp. 2093-2103; Majhi Banshidhar, S.H., Mowafak, F., (2005) \u2018FLANN Based Forecasting of S&P 500 Index\u2019, Information Technology Journal, 4 (3), pp. 289-292; Patra, J.C., Bornand, C., Meher, P.K., Laguerre Neural Network-based Smart Sensors for Wireless Sensor Networks (2009) Instrumentation and Measurement Technology Conference, 2009. I2MTC '09. IEEE, pp. 832-837; Nanda, S.K., Tripathy, D.P., Mahapatra, S.S., Application of Legendre Neural Network for Air Quality Prediction (2011) the 5th PSU-UNS International Conference on Engineering and Technology (ICET-2011); Patra, J.C., Chebyshev Neural Network-Based Model for Dual-Junction Sollar Cells (2011) IEEE Transactions on Energy Conversion, 26, pp. 132-139; Chang, P.C., Fan, C.Y., \u2018A Hybrid System Integrating a Wavelet and TSK Fuzzy Rules for stock price forecasting (2008) IEEE Transactions on Man, Machine, and Cybernetics: Part-C, 38 (6), pp. 802-815; Chang, P.C., Fan, C.Y., A Hybrid System Integrating a Wavelet and TSK Fuzzy Rules for Stock Price Forecasting (2008) IEEE Transactions on Systems, Man, and Cybernetics, 38, pp. 802-815; Boyacioglu, M.A., Avci, D., An Adaptive Network Based Fuzzy Inference System (ANFIS) for the Prediction of Stock Market Return: The Case of the Istanbul Stock Exchange (2010) Experts Systems with Applications, ELSIVER, 37, pp. 7908-7912; Pao, Y.H., Takefji, Y., Functional-Link Net Computing (1992) IEEE Computer Journal, pp. 76-79; Majhi, R., Panda, G., Sahoo, G., (2008) Development and performance evaluation of FLANN based model for forecasting of stock markets, 36, pp. 6800-6808; Bebarta, D.K., Rout, A.K., Biswal, B., Dash, P.K., (2012) \u2018Forecasting and classification of Indian stocks using different polynomial functional link; Bebarta, D.K., Biswal, B., Dash, P.K., Comparative study of stock market forecasting using different functional link artificial neural networks (2012) International Journal of Data Analysis Techniques and Strategies, 4 (4-2012), pp. 398-427. , Inderscience Publishers; Khan Asif, U., Bandopadhyaya, T.K., Sharma, S., Comparisons of Stock Rates Prediction Accuracy using Different Technical Indicators with Back propagation Neural Network and Genetic Algorithm Based Back propagation Neural Network (2008) First International Conference on Emerging Trends in Engineering and Technology, pp. 575-580; Hatem Abdul, K., Abdul Salam, M., Evaluation of Differential Evaluation and Particle swarm Optimization Algorithms at Training of Neural Network for stock Prediction (2012) International Arab Journal of e-Technology, 2 (3), pp. 145-151; Faissal Mili, M.H., A Hybrid Evolutionary Functional Link Artificial Neural Network for Data Mining and Classification (2012) International Journal of Advanced Computer Science and Applications, 3 (8), pp. 89-95; Yadav, J.S., Patidar, N.P., Singhai Sidhartha, P.J., Differential Evolution Algorithm for Model Reduction of SISO Discrete Systems (2009) World Congress on Nature & Biologically Inspired"}
{"Authors":"Wang B., Wang J.","Author(s) ID":"57205691331;55946707000;","Title":"Energy futures prices forecasting by novel DPFWR neural network and DS-CID evaluation","Year":2019,"Source title":"Neurocomputing","Volume":"338","Issue":null,"Art. No.":null,"Page start":1.0,"Page end":15.0,"Page count":null,"Cited by":null,"DOI":"10.1016\/j.neucom.2019.01.092","Affiliations":"School of Science, Beijing Jiaotong University, Beijing, 100044, China","Document Type":"Article","Access Type":null,"Source":"Scopus","EID":"2-s2.0-85061162689","Abstract":"Opponents of the efficient markets hypothesis argue that predictability reflects the psychological factors and \"fads\" of irrational investors in a speculative market. In that, conventional time series analysis often fails to give an accurate forecast for financial processes due to inherent noise patterns, fat tails, and nonlinear components. A recent stream of literature on behavioral finance has revealed that boundedly rational agents using simple rules of thumb for their decisions under uncertainty provides a more realistic description of human behavior than perfect rationality with optimal decision rules. Consequently, the application of technical analysis in trading could produce high returns. Machine learning techniques have been employed in economic systems in modeling nonlinearities and simulating human behavior. In this study, we expand the literature that evaluates return sign forecasting ability by introducing a recurrent neural network approach that combines heuristic learning and short-term memory emulation, thus mimicking the decision-making process of boundedly rational agents. We investigate the relative direction-of-change predictability of the neural network structure implied by the Lee-White-Granger test as well as compare it to other well-established models for the DJIA index. Moreover, we examine the relationship between stock return volatility and returns. Overall, the proposed model presents high profitability, in particular during \"bear\" market periods. \u00a9 2013 Elsevier Inc.","Author Keywords":"Machine learning; Neural networks; Stock predictability; Volatility trading","Index Keywords":null,"References":"Adya, M., Collopy, F., How effective are neural networks at forecasting and prediction? A review and evaluation (1998) Journal of Forecasting, 17, pp. 481-495; Bekaert, G., Wu, G., Asymmetric volatility and risk in equity markets (2000) The Review of Financial Studies, 13 (1), pp. 1-42; Black, F., Noise (1986) Journal of Finance, 41, pp. 529-543; Box, G., Jenkins, G., (1970) Time Series Analysis: Forecasting and Control, , Holden-day, Inc., San Francisco, CA; Camillo, L., A Combined Signal Approach to Technical Analysis on the S&P 500 (2008) Journal of Business & Economics Research, 6, pp. 41-51; Chen, S.N., An examination of risk return relationship in bull and bear markets using time varying betas (1982) Journal of Financial and Quantitative Analysis, 17 (2), pp. 265-286; Christie, A.A., The stochastic behavior of common stock variances-value, leverage and interest rate effects (1982) Journal of Financial Economics, 10, pp. 407-432; Christoffersen, P.F., Diebold, F.X., Financial asset returns, direction-of-change forecasting, and volatility dynamics (2006) Management Science, 52, pp. 1273-1287; Cybenko, G., Approximation by superposition of a sigmoidal function, mathematics of control (1989) Signals and Systems, 2, pp. 303-314; Elman, J.L., Finding structure in time (1990) Cognitive Science, 14, pp. 179-211; Ersoy, O., (1990) Tutorial at Hawaii International Conference on Systems Sciences; Fabozzi, F.J., Francis, J.C., Stability tests for alphas and betas over bull and bear market conditions (1977) Journal of Finance, 32 (4), pp. 1093-1099; Fama, E.F., Blume, M.E., Filter rules and stock-market trading (1966) Journal of Business, 39, pp. 226-241; Fama, E.F., French, K.R., Size and book-to-market factors in earnings and returns (1995) Journal of Finance, 50, pp. 131-155; Fern\u00e1ndez-Rodriguez, F., Gonzalez-Martel, C., Sosvilla-Rivero, S., On the profitability of technical trading rules based on artificial neural networks: evidence from the Madrid stock market (2000) Economic Letters, 69, pp. 89-94; Fern\u00e1ndez-Rodriguez, F., Sosvilla-Rivero, S., Garca-Artiles, M.D., Dancing with bulls and bears: nearest-neighbour forecasts for the Nikkei index (1999) Japan and the World Economy, 11, pp. 395-413; Foresee, F.D., Hagan, M.T., Gauss-Newton approximation to Bayesian learning (1997) Proceedings of IEEE International Conference on Neural Networks, 3, pp. 1930-1935; Funahashi, K., On the approximate realization of continuous mappings by neural networks (1989) Neural Networks, 2, pp. 183-192; Gen\u00e7ay, R., The predictability of security returns with simple technical trading rules (1998) Journal of Empirical Finance, 5, pp. 347-359; Gen\u00e7ay, R., Optimization of technical strategies and the profitability in security markets (1998) Economics Letters, 59, pp. 249-254; Giot, P., Relationships between implied volatility indexes and stock index returns (2005) Journal of Portfolio Management, pp. 92-100; Green, H., Pearson, M., Neural nets for foreign exchange trading (1994) Trading on the Edge: Neural, Genetic, and Fuzzy Systems for Chaotic Financial Markets, , Wiley, New York; Harvey, A.C., (1989) Forecasting structural time series models and the Kalman filter, , Cambridge University Press, Cambridge; Hecht-Nielsen, R., Theory of the backpropagation neural networks (1989) Proceedings of the International Joint Conference on Neural Networks, Washington, DC, 1, pp. 593-605. , IEEE Press, New York; Henriksson, R.D., Merton, R.C., On the market timing and investment performance II: statistical procedures for evaluating forecasting skills (1981) Journal of Business, 54, pp. 513-533; Hochberg, Y., A sharper Bonferroni procedure for multiple tests of significance (1988) Biometrika, 75, pp. 800-802; Hommes, C.H., Financial markets as complex adaptive evolutionary systems (2001) Quantitative Finance, 1, pp. 149-167; Hommes, C.H., Heterogeneous agent models in economics and finance (2006) Handbook of Computational Economics, Volume 2: Agent-Based Computational Economics, pp. 1109-1186. , Elsevier Science B.V. L. Tesfatsion, K.L. Judd (Eds.); Hornik, K., Approximation capabilities of multilayer feedforward networks (1991) Neural Networks, 4, pp. 251-257; Hornik, K., Stinchcombe, M., White, H., Multilayer feedforward networks are universal approximators (1989) Neural Networks, 2, pp. 359-366; Hsu, P.-H., Kuan, C.-M., Reexamining the profitability of technical analysis with data snooping checks (2005) Journal of Financial Econometrics, 3, pp. 606-628; Irwin, S.H., Park, C.H., What do we know about the profitability of technical analysis? (2007) Journal of Economic Surveys, 21, pp. 786-826; Jasic, T., Wood, D., The profitability of daily stock market indices trades based on neural network predictions: case study for the S&P 500, the DAX, the TOPIX, and the FTSE in the period 1965-1999 (2004) Applied Financial Economics, 14, pp. 285-297; Kao, G.W., Ma, C.K., Memories, heteroscedasticity and prices limit in currency futures markets (1992) Journal of Futures Markets, 12, pp. 672-692; Katz, J.O., Developing neural network forecasters for trading (1992) Technical Analysis of Stocks and Commodities, pp. 58-70; Kaufman, J.P., (1998) Trading Systems and Methods, , John Wiley & Sons, New York; Kirkpatrick, C.D., Dahlquist, J.R., (2007) Technical Analysis: The Complete Resource for Financial Market Technicians, , Financial Times Press, Upper Saddle River, (New Jersey); Krugman, P., Trigger Strategies and Price Dynamics in Equity and Foreign Exchange Markets (1987) NBER Working Paper No 2459; Kuan, C.-M., White, H., Artificial neural networks: an econometric perspective (1994) Econometric Reviews, 13, pp. 1-91; La Porta, R., Lakonishok, J., Shliefer, A., Vishny, R., Good news for value stocks: further evidence on market efficiency (1997) Journal of Finance, 52, pp. 859-874; Lee, T.-H., White, H., Granger, C.W.J., Testing for neglected nonlinearity in time series models (1993) Journal of Econometrics, 56, pp. 269-290; Levich, R.M., Thomas, L.R., The significance of technical trading rule profits in the foreign exchange market: a bootstrap approach (1993) Strategic Currency Investing - Trading and Hedging in the Foreign Exchange Market, pp. 336-365. , Probus, Chicago; Lo, A.W., Mamaysky, H., Wang, J., Foundations of technical analysis: computational algorithms, statistical inference, and empirical implementation (2000) Journal of Finance, 55, pp. 1705-1765; Lunde, A., Timmermann, A., Duration dependence in stock prices: an analysis of bull and bear markets (2004) Journal of Business and Economic Statistics, 3 (22), pp. 253-273; Masters, T., (1993) Advanced Algorithms for Neural Networks, , John Wiley; Murphy, J.J., (1999) Technical Analysis of the Financial Markets: A Comprehensive Guide to Trading Methods and Applications, , Prentice Hall Press, Paramus, New Jersey; Pesaran, M.H., Timmermann, A., A simple non-parametric test of predictive performance (1992) Journal of Business and Economic Statistics, 10, pp. 461-465; Pesaran, M.H., Timmermann, A., Predictability of stock returns: robustness and economic significance (1995) Journal of Finance, 50, pp. 1201-1228; Plummer, T., Ridley, A., (2003) Forecasting Financial Markets: The Psychology of Successful Investing, , Kogan, London; Poddig, A., Short term forecasting of the USD\/DM exchange rate (1993) Proceedings of First International Workshop on Neural Networks in Capital Markets, London; Rawani, A., Forecasting and trading strategy for foreign exchange market (1993) Information Decision Technology, 1, p. 19; Shiller, R.J., From Efficient Market Theory to Behavioral Finance (2002) Cowles Foundation Discussion Paper No. 1385; Shleifer, A., Summers, L.H., The noise trader approach to finance (1990) Journal of Economic Perspectives, 4 (2), pp. 19-33; Simon, H.A., (1957) Models of Man, , Wiley, New York, NY; Weigend, A.S., Generalization by weight-elimination applied to currency exchange rate prediction (1991) Proceedings of the IEEE International Joint Conference on Neural Networks, Singapore; White, H., Learning in artificial neural networks: a statistical perspective (1989) Neural Computing, 1, pp. 425-464; Yao, J.T., Poh, H.-L., Jasic, T., Foreign exchange rates forecasting with neural networks (1996) Proceedings of the International Conference on Neural Information Processing, Hong Kong, pp. 754-759; Zhang, X.R., Non-linear predictive models for intra-day foreign exchange trading (1994) International Journal of Intelligent Systems Accounting and Finance Management, 3 (4), pp. 293-302"}
{"Authors":"Moews B., Herrmann J.M., Ibikunle G.","Author(s) ID":"57204789588;16412284700;55509976400;","Title":"Lagged correlation-based deep learning for directional trend change prediction in financial time series","Year":2019,"Source title":"Expert Systems with Applications","Volume":"120","Issue":null,"Art. No.":null,"Page start":197.0,"Page end":206.0,"Page count":null,"Cited by":1.0,"DOI":"10.1016\/j.eswa.2018.11.027","Affiliations":"School of Physics & Astronomy, University of Edinburgh, Edinburgh, EH9 3HJ, United Kingdom; School of Informatics, University of Edinburgh, Edinburgh, EH8 9AB, United Kingdom; Business School, University of Edinburgh, Edinburgh, EH8 9JS, United Kingdom","Document Type":"Article","Access Type":null,"Source":"Scopus","EID":"2-s2.0-85057188554","Abstract":"Time series analysis is an important field that, recently, captivate researchers attention. It represents a lot of real problems, one of them is the prediction of the stock prices. As known, the recurrent neural network (RNN) is the most used model for the prediction problem, since it gives good results for time series forecasting. This paper aims to forecast the stock price of Total Maroc for 29 days from Casablanca Stock Exchange, using principal component analysis (PCA) in order to reduce the number of features from eight to six. The use of dimensionality reduction enhances the accuracy of the recurrent neural network model and gives a good prediction for the stock price. \u00a9 2019 The Authors.","Author Keywords":"Forecasting Stock Prices; Principal Component Analysis; Recurrent Neural Network","Index Keywords":"Costs; Electronic trading; Financial markets; Forecasting; Intelligent computing; Recurrent neural networks; Time series analysis; Dimensionality reduction; Forecasting stock prices; Prediction problem; Real problems; Recurrent neural network (RNN); Recurrent neural network model; Stock exchange; Time series forecasting; Principal component analysis","References":"Jasic, T., Wood, D., The profitability of daily stock market indices trades based on neural network predictions: Case study for the S&P 500, the DAX, the TOPIX and the FTSE in the period 19651999 (2004) Applied Financial Economics, 14 (4), pp. 285-297; Niaki, S.T.A., Hoseinzade, S., Forecasting S&P 500 index using artificial neural networks and design of experiments (2013) Journal of Industrial Engineering International, 9 (1), p. 1; Leung, M.T., Daouk, H., Chen, A.S., Forecasting stock indices: A comparison of classification and level estimation models (2000) International Journal of Forecasting, 16 (2), pp. 173-190; De Oliveira, F.A., Nobre, C.N., Zrate, L.E., Applying Artificial Neural Networks to prediction of stock price and improvement of the directional prediction indexCase study of PETR4, Petrobras, Brazil (2013) Expert Systems with Applications, 40 (18), pp. 7596-7606; Zhong, X., Enke, D., Forecasting daily stock market return using dimensionality reduction (2017) Expert Systems with Applications, 67, p. 126139; Pearson, K., On lines and planes of closest fit to systems of points in space (1901) Philosophical Magazine, 2 (6), pp. 559-572; Schlkopf, B., Smola, A., Mller, K.R., Nonlinear component analysis as a kernel eigenvalue problem (1998) Neural Computation, 10 (5), pp. 1299-1319; Kazem, A., Sharifi, E., Hussain, F.K., Saberi, Hussain, O.K., Support vector regression with chaos-based firefly algorithm for stock market price forecasting (2013) Applied Soft Computing, 13 (2), pp. 947-958; Dai, W., Wu, J.Y., Lu, C.J., Combining nonlinear independent component analysis and neural network for the prediction of Asian stock market indexes (2012) Expert Systems with Applications, 39 (4), pp. 4444-4452; Van Der Maaten, L., Postma, E., Van Den Herik, J., Dimensionality reduction: A comparative (2009) J Mach Learn Res, 10, pp. 66-71; Kruskal, J.B., Multidimensional scaling by optimizing goodness of fit to a nonmetric hypothesis (1964) Psychometrika, 29 (1), pp. 1-27; Tenenbaum, J.B., De Silva, V., Langford, J.C., A global geometric framework for nonlinear dimensionality reduction (2000) Science, 290 (5500), pp. 2319-2323; Weinberger, K.Q., Saul, L.K., (2006) An Introduction to Nonlinear Dimensionality Reduction by Maximum Variance Unfolding, pp. 1683-1686. , AAAI (July). In (6); Roweis, S., Saul, L., Nonlinear dimensionality reduction by locally linear embedding (2000) Science, 290 (5500), p. 23232326; Belkin, M., Niyogi, P., Laplacian eigenmaps for dimensionality reduction and data representation (2003) Neural Computation, 15 (6), pp. 1373-1396; Donoho, D.L., Grimes, C., Hessian eigenmaps: Locally linear embedding techniques for high-dimensional data (2003) Proceedings of the National Academy of Sciences, 100 (10), pp. 5591-5596; Lin, T., Zha, H., Riemannian manifold learning (2008) IEEE Transactions on Pattern Analysis and Machine Intelligence, 30 (5), pp. 796-809; Lecun, Y., Bengio, Y., Hinton, G., Deep learning (2015) Nature, 521 (7553), p. 436; Funahashi, K.I., Nakamura, Y., Approximation of dynamical systems by continuous time recurrent neural networks (1993) Neural Networks, 6 (6), pp. 801-806; Darbellay, G.A., Slama, M., Forecasting the short-term demand for electricity: Do neural networks stand a better chance? (2000) International Journal of Forecasting, 16 (1), pp. 71-83; Hochreiter, S., Schmidhuber, J., Long short-term memory (1997) Neural Computation, 9 (8), pp. 1735-1780; Sak, H., Senior, A., Beaufays, F., Long short-term memory recurrent neural network architectures for large scale acoustic modeling (2014) Fifteenth Annual Conference of the International Speech Communication Association; Lipton, Z.C., Kale, D.C., Elkan, C., Wetzel, R., (2015) Learning to Diagnose with LSTM Recurrent Neural Networks; Nelson, D.M., Pereira, A.C., De Oliveira, R.A., Stock market's price movement prediction with LSTM neural networks (2017) Neural Networks (IJCNN), 2017 International Joint Conference on, pp. 1419-1426. , May, IEEE; Chung, J., Gulcehre, C., Cho, K., Bengio, Y., (2014) Empirical Evaluation of Gated Recurrent Neural Networks on Sequence Modeling; Bianchi, F.M., Maiorino, E., Kampffmeyer, M.C., Rizzi, A., Jenssen, R., (2017) An Overview and Comparative Analysis of Recurrent Neural Networks for Short Term Load Forecasting"}
{"Authors":"Sismanoglu G., Onde M.A., Kocer F., Sahingoz O.K.","Author(s) ID":"57209730058;57209731841;57209734258;14054797000;","Title":"Deep learning based forecasting in stock market with big data analytics","Year":2019,"Source title":"2019 Scientific Meeting on Electrical-Electronics and Biomedical Engineering and Computer Science, EBBT 2019","Volume":null,"Issue":null,"Art. No.":" 8741818","Page start":null,"Page end":null,"Page count":null,"Cited by":null,"DOI":"10.1109\/EBBT.2019.8741818","Affiliations":"Computer Engineering Department, Istanbul Kultur University, Istanbul, 34158, Turkey","Document Type":"Conference Paper","Access Type":null,"Source":"Scopus","EID":"2-s2.0-85068552387","Abstract":"In recent years the advancement in neural network architecture and introduction of recurrent neural network has attracted a lot of interest to work with sequence data. LSTM is derived from the basic architecture of Recurrent Neural Network. It has memory units which extends the power of Recurrent Neural Network. In this paper, we analyze the performance of different advanced neural network architectures and classical time series forecasting method, e.g., ARIMA on selective stock prices from Dhaka Stock Exchange (DSE). Our experimental results show that the neural network models perform better than the ARIMA model in reducing RMSE (Root Mean Square Error). \u00a9 Springer Nature Switzerland AG 2019.","Author Keywords":"ARIMA model; Gated recurrent unit; Long short term memory; Recurrent neural network; Stock price forecasting; Time series forecasting","Index Keywords":"Electronic trading; Financial markets; Forecasting; Long short-term memory; Mean square error; Memory architecture; Recurrent neural networks; Time series; ARIMA modeling; Financial forecasting; Gated recurrent unit; Performance analysis; RMSE (root mean square error); Statistical modeling; Stock price forecasting; Time series forecasting; Network architecture","References":"Samuelson, P., Proof that properly anticipated prices fluctuate randomly. Ind (1965) Manag. Rev., 6, pp. 41-49; Cootner, P., (1964) The Random Character of Stock Market Prices, , MIT Press, Cambridge; Ariyo, A., Adewumi, A., Ayo, C., Stock price prediction using the ARIMA model. In: Proceedings-UKSim-AMSS 16th International Conference on Computer Modelling and Simulation (2014) Uksim, , https:\/\/doi.org\/10.1109\/UKSim.2014.67; Fischer, T., Krauss, C., (2017) Deep Learning with Long Short-Term Memory Networks for Financial Market Predictions, , FAU Discussion Papers in Economics, no. 11\/2017. Friedrich-Alexander-Universitat Erlang-Nurberg, Institute for Economics, Erlang; Chen, K., Zhou, Y., Dai, F., A LSTM-based method for stock returns prediction: A case study of China stock market (2015) IEEE International Conference on Big Data, China; Yao, J., North, P., Tan, C.L., Guidelines for financial forecasting with neural networks (2001) Proceedings of International Conference on Neural Information Processing, Shanghai, China, pp. 1-6. , 14\u201318 November, pp; Yoo, P.D., Kim, M.H., Jan, T., Financial forecasting: Advanced machine learning techniques in stock market analysis (2005) 2005 Pakistan Section Multitopic Conference, Karachi, pp. 1-7. , https:\/\/doi.org\/10.1109\/inmic.2005.334420, pp; Korczak, J., Hernes, M., Deep learning for financial time series forecasting in A-Trader system (2017) Federated Conference on Computer Science and Information Systems (Fedcsis), pp. 905-912. , https:\/\/doi.org\/10.15439\/2017f449, pp; Samarawickrama, J., Fernando, T.G.I., A recurrent neural network approach in predicting daily stock prices: An application to the sri lankan stock market 2017 IEEE International Conference on Industrial and Information Systems (ICIIS), , https:\/\/doi.org\/10.1109\/iciinfs.2017.8300345; Kingma, D., Ba, J., Adam: A method for stochastic optimization (2015) 3Rd International Conference on Learning Representations, , https:\/\/arxiv.org\/abs\/1412.6980, San Diego; http:\/\/oneminutestock.com\/limitations-of-the-macd-indicator\/, Limitations of MACD; https:\/\/www.statsmodels.org\/stable\/index.html, StatsModel Library; https:\/\/pandas.pydata.org\/pandas-docs\/version\/0.23.4\/generated\/pandas.DataFrame.html, Pandas Library"}
{"Authors":"Yan X., Zhao J.","Author(s) ID":"50562404800;57206579718;","Title":"Application of improved convolution neural network in financial forecasting","Year":2019,"Source title":"2019 IEEE 4th International Conference on Cloud Computing and Big Data Analytics, ICCCBDA 2019","Volume":null,"Issue":null,"Art. No.":" 8725661","Page start":321.0,"Page end":326.0,"Page count":null,"Cited by":null,"DOI":"10.1109\/ICCCBDA.2019.8725661","Affiliations":"Foreign Trade College, Chongqing Normal University, NO.9 Xuefu Road, Hechuan District Chongqing, China","Document Type":"Conference Paper","Access Type":null,"Source":"Scopus","EID":"2-s2.0-85067471318","Abstract":"We present a method for conditional time series forecasting based on an adaptation of the recent deep convolutional WaveNet architecture. The proposed network contains stacks of dilated convolutions that allow it to access a broad range of historical data when forecasting. It also uses a rectified linear unit (ReLU) activation function, and conditioning is performed by applying multiple convolutional filters in parallel to separate time series, which allows for the fast processing of data and the exploitation of the correlation structure between the multivariate time series. We test and analyze the performance of the convolutional network both unconditionally and conditionally for financial time series forecasting using the Standard & Poor\u2019s 500 index, the volatility index, the Chicago Board Options Exchange interest rate and several exchange rates, and we extensively compare its performance with those of the well-known autoregressive model and a long short-term memory network. We show that a convolutional network is well suited to regression-type problems and is able to effectively learn dependencies in and between the series without the need for long historical time series, that it is a time-efficient and easy-to-implement alternative to recurrent-type networks, and that it tends to outperform linear and recurrent models. \u00a9 Infopro Digital Limited 2019. All rights reserved.","Author Keywords":"Convolutional neural network (CNN); Deep learning; Financial time series; Forecasting; Multivariate time series","Index Keywords":null,"References":"Aussem, A., Murtagh, F., Combining neural network forecasts on wavelet-transformed time series (1997) Connection Science, 9 (1), pp. 113-122. , https:\/\/doi.org\/10.1080\/095400997116766; Bengio, Y., Simard, P., Frasconi, P., Learning long-term dependencies with gradient descent is difficult (1994) IEEE Transactions on Neural Networks, 5 (2), pp. 157-166. , https:\/\/doi.org\/10.1109\/72.279181; Bi\u0144kowski, M., Marti, G., Donnat, P., Autoregressive convolutional neural networks for asynchronous time series (2017) Lecture, August 11, International Conference on Machine Learning 2017, , Time Series Workshop; Chakraborty, K., Mehrotra, K., Mohan, C.K., Ranka, S., Forecasting the behavior of multivariate time series using neural networks (1992) Neural Networks, 5 (6), pp. 961-970. , https:\/\/doi.org\/10.1016\/S0893-6080(05)80092-9; Chung, J., Gulcehre, C., Cho, K., Bengio, Y., (2014) Empirical Evaluation of Gated Recurrent Neural Networks on Sequence Modeling, , Preprint (arXiv:1412.3555); Cont, R., Empirical properties of asset returns: Stylized facts and statistical issues (2001) Quantitative Finance, 1, pp. 223-236. , https:\/\/doi.org\/10.1080\/713665670; Fisher, T., Krauss, C., (2017) Deep Learning with Long Short-Term Memory Networks for Financial Market Predictions, , FAU Discussion Paper in Economics 11\/2017, Friedrich-Alexander University Erlangen-Nuremberg; Glorot, X., Bengio, Y., Understanding the difficulty of training deep feedforward neural networks (2010) Proceedings of the 13Th International Conference on Artificial Intelligence and Statistics, 9, pp. 249-256. , Proceedings of Machine Learning Research, PMLR Press, Cambridge, MA; Hamilton, J.D., (1994) Time Series Analysis, 2. , Volume, Princeton University Press, Princeton, NJ; He, K., Zhang, X., Ren, S., Sun, J., Delving deep into rectifiers: Surpassing human-level performance on imagenet classification (2015) Proceedings of the 2015 IEEE International Conference on Computer Vision, pp. 1026-1034. , IEEE Press, Piscataway, NJ; He, K., Zhang, X., Ren, S., Sun, J., Deep residual learning for image recognition (2016) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 770-778. , IEEE Press, Piscataway, NJ; Hochreiter, S., Schmidhuber, J., Long short-term memory (1997) Neural Computation, 9 (8), pp. 1735-1780. , https:\/\/doi.org\/10.1162\/neco.1997.9.8.1735; Hornik, K., Approximation capabilities of multilayer feedforward networks (1991) Neural Networks, 4 (2), pp. 251-257. , https:\/\/doi.org\/10.1016\/0893-6080(91)90009-T; Hsu, D., (2017) Time Series Forecasting Based on Augmented Long Short-Term Memory, , Preprint, (arXiv:1707.00666); Kingma, D.P., Ba, J., (2014) Adam: A Method for Stochastic Optimization, , Preprint, (arXiv:1412.6980); Krizhevsky, A., Sutskever, I., Hinton, G.E., ImageNet classification with deep convolutional neural networks (2012) Advances in Neural Information Processing Systems, 25 (2), pp. 1097-1105; Lahmiri, S., Wavelet low-and high-frequency components as features for predicting stock prices with backpropagation neural networks (2014) Journal of King Saud University \u2013 Computer and Information Sciences, 26 (2), pp. 218-227. , https:\/\/doi.org\/10.1016\/j.jksuci.2013.12.001; Lecun, Y., Bottou, L., Bengio, Y., Haffner, P., Gradient-based learning applied to document recognition (1998) Proceedings of the IEEE, 86 (11), pp. 2278-2324. , https:\/\/doi.org\/10.1109\/5.726791; Mathieu, M., Henaff, M., Lecun, Y., Fast training of convolutional networks through FFTs (2013) Preprint, , (arXiv; Mittelman, R., (2015) Time-Series Modeling with Undecimated Fully Convolutional Neural Networks, , Preprint (arXiv:1508.00317); Ramachandran, P., Paine, T.L., Khorrami, P., Babaeizadeh, M., Chang, S., Zhang, Y., Hasegawa-Johnson, M.A., Huang, T.S., (2017) Fast Generation for Convolutional Autoregressive Models, , Preprint (arXiv:1704.06001); Rippel, O., Snoek, J., Adams, R.P., Spectral representations for convolutional neural networks (2015) Proceedings of the 28Th International Conference on Neural Information Processing Systems, 2, pp. 2449-2457. , MIT Press, Cambridge, MA; van den Oord, A., Dieleman, S., Zen, H., Simonyan, K., Vinyals, O., Graves, A., Kalchbrenner, N., Kavukcuoglu, K., (2016) Wavenet: A Generative Model for Raw Audio, , Preprint (arXiv; Oord, A., Kalchbrenner, N., Kavukcuoglu, K., Pixel recurrent neural networks (2016) Preprint, , arXiv:1601.06759; Oord, A., Kalchbrenner, N., Vinyals, O., Espeholt, L., Graves, A., Kavukcuoglu, K., (2016) Conditional Image Generation with Pixelcnn Decoders, , Preprint, (arXiv:1606.05328); Wang, Z., Yan, W., Oates, T., (2016) Time Series Classification from Scratch with Deep Neural Networks: A Strong Baseline, , Preprint (arXiv:1611.06455); Yu, F., Koltun, V., Multi-scale context aggregation by dilated convolutions (2015) Preprint, , (arXiv; Zhang, G.P., Time series forecasting using a hybrid ARIMA and neural network model (2003) Neurocomputing, 50, pp. 159-175. , https:\/\/doi.org\/10.1016\/S0925-2312(01)00702-0; Zhang, G.P., Patuwo, B.E., Hu, M.Y., Forecasting with artificial neural networks: The state of the art (1998) International Journal of Forecasting, 14 (1), pp. 35-62; Zheng, Y., Liu, Q., Chen, E., Ge, Y., Zhao, J., Exploiting multi-channels deep convolutional neural networks for multivariate time series classification (2016) Frontiers of Computer Science, 10 (1), pp. 96-112. , https:\/\/doi.org\/10.1007\/s11704-015-4478-2"}
{"Authors":"Yu M.-H., Wu J.-L.","Author(s) ID":"57208408426;36816648000;","Title":"CEAM: A Novel Approach Using Cycle Embeddings with Attention Mechanism for Stock Price Prediction","Year":2019,"Source title":"2019 IEEE International Conference on Big Data and Smart Computing, BigComp 2019 - Proceedings","Volume":null,"Issue":null,"Art. No.":" 8679218","Page start":null,"Page end":null,"Page count":null,"Cited by":null,"DOI":"10.1109\/BIGCOMP.2019.8679218","Affiliations":"Departement of Computer Sicence and Information Engineering, National Taiwan University, Taipei, Taiwan; School of Big Data Management, Soochow University, Taipei, Taiwan","Document Type":"Conference Paper","Access Type":null,"Source":"Scopus","EID":"2-s2.0-85064682040","Abstract":"Forecasting financial time series using past observations has been a significant topic of interest. While temporal relationships in the data exist, they are difficult to analyze and predict accurately due to the non-linear trends and noise present in the series. We propose to learn these dependencies by a convolutional neural network. In particular the focus is on multivariate time series forecasting. Effectively, we use multiple financial time series as input in the neural network, thus conditioning the forecast of a time series x(t) on both its own history as well as that of a second (or third) time series y(t). Training a model on multiple stock series allows the network to exploit the correlation structure between these series so that the network can learn the market dynamics in shorter sequences of data. We show that long-term temporal dependencies in and between financial time series can be learned by means of a deep convolutional neural network based on the WaveNet model [2]. The network makes use of dilated convolutions applied to multiple time series so that the receptive field of the network is wide enough to learn both short and long-term dependencies. The architecture includes batch normalization and uses a 1 \u00d7 k convolution with parametrized skip connections from the input time series as well as the time series we condition on, in this way learning long-term interdependencies in an efficient manner [1]. This improves the forecast, while at the same time limiting the requirement for a long historical price series and reducing the noise. Knowing the strong performance of CNNs on classification problems we show that they can be applied successfully to forecasting financial time series, without the need of large samples of data. We compare the performance of the WaveNet model to a state-of-the-art fully convolutional network (FCN), and an autoregressive model popular in econometrics and show that our model is much better able to learn important dependencies in between financial time series resulting in a more robust and accurate forecast. \u00a9 Springer International Publishing AG 2017.","Author Keywords":"Convolutional neural network; Financial time series","Index Keywords":"Convolution; Deep neural networks; Economics; Finance; Financial data processing; Forecasting; Learning systems; Neural networks; Statistics; Auto regressive models; Convolutional neural network; Financial time series; Forecasting financial time series; Long-term dependencies; Multivariate time series; Temporal relationships; Time series forecasting; Time series","References":"Borovykh, A., Bohte, S., Oosterlee, C., Conditional time series forecasting with convolutional neural networks (2017) Arxiv E-Prints; Van Den Oord, A., Dieleman, S., Zen, H., Simonyan, K., Vinyals, O., Graves, A., Kalchbrenner, N., Kavukcuoglu, K., WaveNet: A generative model for raw audio (2016) Arxiv E-Prints"}
{"Authors":"Du J., Liu Q., Chen K., Wang J.","Author(s) ID":"15060001900;57209464952;57209470539;57209477365;","Title":"Forecasting stock prices in two ways based on LSTM neural network","Year":2019,"Source title":"Proceedings of 2019 IEEE 3rd Information Technology, Networking, Electronic and Automation Control Conference, ITNEC 2019","Volume":null,"Issue":null,"Art. No.":" 8729026","Page start":1083.0,"Page end":1086.0,"Page count":null,"Cited by":null,"DOI":"10.1109\/ITNEC.2019.8729026","Affiliations":"College of Electrical and Control Engineering, Xi'An University of Science and Technology, Xi'an, China","Document Type":"Conference Paper","Access Type":null,"Source":"Scopus","EID":"2-s2.0-85067881822","Abstract":"Deep Learning is a consolidated, state-of-the-art Machine Learning tool to fit a function (Formula Presented) when provided with large data sets of examples (Formula Presented). However, in regression tasks, the straightforward application of Deep Learning models provides a point estimate of the target. In addition, the model does not take into account the uncertainty of a prediction. This represents a great limitation for tasks where communicating an erroneous prediction carries a risk. In this paper we tackle a real-world problem of forecasting impending financial expenses and incomings of customers, while displaying predictable monetary amounts on a mobile app. In this context, we investigate if we would obtain an advantage by applying Deep Learning models with a Heteroscedastic model of the variance of a network\u2019s output. Experimentally, we achieve a higher accuracy than non-trivial baselines. More importantly, we introduce a mechanism to discard low-confidence predictions, which means that they will not be visible to users. This should help enhance the user experience of our product. \u00a9 2019, Springer Nature Switzerland AG.","Author Keywords":"Aleatoric models; Deep Learning; Time-series; Uncertainty","Index Keywords":"Forecasting; Machine learning; Time series; Uncertainty analysis; Confidence predictions; Heteroscedastic; Learning models; Real-world problem; State of the art; Uncertainty; Uncertainty modelling; User experience; Deep learning","References":"Abadi, M., Tensorflow: A system for large-scale machine learning (2016) OSDI, 16, pp. 265-283. , November; Anderson-Cook, C.M., (2007) Generalized Additive Models: An Introduction with R, , American Statistical Association, UK; Bishop, C.M., (1994) Mixture Density Networks, p. 7. , Technical report NCRG\/4288. Aston University, Birmingham, UK; Blundell, C., Cornebise, J., Kavukcuoglu, K., Wierstra, D., Weight uncertainty in neural networks (2015) Proceedings of the 32Nd International Conference on International Conference on Machine Learning, 37, pp. 1613-1622. , July; Bridle, J.S., Probabilistic interpretation of feedforward classification network outputs, with relationships to statistical pattern recognition (1990) Neurocomputing. NATO ASI Series, 68, pp. 227-236. , https:\/\/doi.org\/10.1007\/978-3-642-76153-928, Souli\u00e9, F.F., H\u00e9rault, J. (eds.), Springer, Heidelberg; Cho, K., (2014) Learning Phrase Representations Using RNN Encoder-Decoder for Statistical Machine Translation; Chollet, F., (2015) Keras: Deep Learning Library for Theano and Tensorflow; Ciprian, M., Evaluating uncertainty scores for deep regression networks in financial short time series forecasting (2016) NIPS Workshop on Machine Learning for Spatiotemporal Forecasting; der Kiureghian, A., Ditlevsen, O., Aleatory or epistemic? Does it matter? (2009) Struct. Saf., 31 (2), pp. 105-112; Gal, Y., Ghahramani, Z., (2016) Dropout as a Bayesian Approximation: Representing Model Uncertainty in Deep Learning, , ICML, June; Gers, F.A., Schmidhuber, J., Cummins, F., Learning to forget: Continual prediction with LSTM (1999) IET Digital Library; Marra, G., Wood, S.N., Coverage properties of confidence intervals for generalized additive model components (2012) SJS, 39 (1), pp. 53-74; Hendrycks, D., Gimpel, K., (2016) A Baseline for Detecting Misclassified and Out-Of-Distribution Examples in Neural Networks, , arXiv preprint arXiv; Hern\u00e1ndez-Lobato, J.M., Adams, R., Probabilistic backpropagation for scalable learning of Bayesian neural networks (2015) ICML, pp. 1861-1869. , June; Hochreiter, S., Schmidhuber, J., Long short-term memory (1997) Neural Comput, 9 (8), pp. 1735-1780; Hornik, K., Stinchcombe, M., White, H., Multilayer feedforward networks are universal approximators (1989) Neural Netw, 2 (5), pp. 359-366; Hyndman, R.J., Koehler, A.B., Another look at measures of forecast accuracy (2006) Int. J. Forecast., 22 (4), pp. 679-688; Kendall, A., Gal, Y., (2017) What Uncertainties Do We Need in Bayesian Deep Learning for Computer Vision? In: NIPS, pp. 5574-5584; Mitrovi\u0107, S., Singh, G., (2016) Predicting Branch Visits and Credit Card Up-Selling Using Temporal Banking Data; Mutanen, T., Ahola, J., Nousiainen, S., Customer churn prediction-a case study in retail banking (2006) Proceedings of ECML\/PKDD Workshop on Practical Data Mining, pp. 13-19. , September; Rasmussen, C.E., A practical Monte Carlo implementation of Bayesian learning (1996) Advances in Neural Information Processing Systems, pp. 598-604; Wistuba, M., Duong-Trung, N., Schilling, N., Schmidt-Thieme, L., (2016) Bank Card Usage Prediction Exploiting Geolocation Information"}
{"Authors":"Thipprachak K., Tangamchit P.","Author(s) ID":"57207926780;6506821304;","Title":"Spatio-temporal Model for Limit Order Books in the Stock Exchange of Thailand","Year":2019,"Source title":"2019 1st International Symposium on Instrumentation, Control, Artificial Intelligence, and Robotics, ICA-SYMP 2019","Volume":null,"Issue":null,"Art. No.":" 8645980","Page start":119.0,"Page end":122.0,"Page count":null,"Cited by":null,"DOI":"10.1109\/ICA-SYMP.2019.8645980","Affiliations":"Department of Control System and Instrumentation Engineering, King Mongkut's University of Technology Thonburi, 254 Phayathai Road, Pathumwan, Bangkok, Thailand","Document Type":"Conference Paper","Access Type":null,"Source":"Scopus","EID":"2-s2.0-85063296627","Abstract":"Predicting the future value of the stock is very difficult task, mostly because of a number of variables that need to be taken into account. This paper tackles problem of stock market predicting feasibility, especially when predictions are based only on a subset of available information, namely: financial experts\u2019 recommendations. Analysis was based on data and results from ISMIS 2017 Data Mining Competition. An original method was proposed and evaluated. Participants managed to perform substantially better than random guessing, but no participant outperformed baseline solution. \u00a9 Springer International Publishing AG 2017.","Author Keywords":"Artificial neural networks; Recurrent neural networks; Sequence modeling; Stock exchange; Time series prediction","Index Keywords":"Electronic trading; Financial markets; Forecasting; Intelligent systems; Neural networks; Expert recommendations; Financial experts; Sequence modeling; Stock exchange; Time series prediction; Recurrent neural networks","References":"Fama, E., Efficient capital markets: A review of theory and empirical work (1970) J. Finan., 25 (2), pp. 383-417; Lecun, Y., Bottou, L., Orr, G.B., M\u00fcller, K.-R., Efficient BackProp (1998) Neural Networks: Tricks of the Trade. LNCS, 1524, pp. 9-50. , Orr, G.B., M\u00fcller, K.-R. (eds.), Springer, Heidelberg; Hochreiter, S., The vanishing gradient problem during learning recurrent neural nets and problem solutions (1998) Int. J. Uncertainty Fuzziness Knowl. Based Syst., 6, p. 107; Hochreiter, S., Schmidhuber, J., Long short-term memory (1997) Neural Comput, 9, pp. 1735-1780; Cho, H., (2014) Learning Phrase Representations Using RNN Encoder-Decoder for Statistical Machine Translation; Yao, K., Cohn, T., (2015) Depth-Gated Recurrent Neural Networks; Greff, K., Srivastava, R., (2015) LSTM: A Search Space Odyssey; Jozefowicz, R., Zaremba, W., (2015) An Empirical Exploration of Recurrent Network Architectures; Geoffrey, H., Where do features come from? (2014) Cogn. Sci., 38, pp. 1078-1101; Rosenblatt, F., (1961) Principles of Neurodynamics: Perceptrons and the Theory of Brain Mechanisms, , Spartan Books, Washington DC; Tieleman, T., Hinton, G., Lecture 6.5 - RMSProp, COURSERA: Neural networks for machine learning (2012) Technical Report; Hinton, G., Srivastava, N., Krizhevsky, A., (2012) Improving Neural Networks by Preventing Co-Adaptation of Feature Detectors; Srivastava, N., (2013) Improving Neural Networks with Dropout"}
{"Authors":"Wu C.-H., Lu C.-C., Ma Y.-F., Lu R.-S.","Author(s) ID":"55713072400;57207760751;57207762684;7402969813;","Title":"A new forecasting framework for bitcoin price with LSTM","Year":2019,"Source title":"IEEE International Conference on Data Mining Workshops, ICDMW","Volume":"2018-November","Issue":null,"Art. No.":" 8637486","Page start":168.0,"Page end":175.0,"Page count":null,"Cited by":1.0,"DOI":"10.1109\/ICDMW.2018.00032","Affiliations":"Department of Digital Content and Technology, National Taichung University of Education, Taipei, Taiwan; Department of Business Administration, St. John's University, Taipei, Taiwan; Department of International Business, National Taipei University of Business, Taipei, Taiwan; Department of Management Information Systems, Takming University of Science and Technology, Taipei, Taiwan","Document Type":"Conference Paper","Access Type":null,"Source":"Scopus","EID":"2-s2.0-85062887338","Abstract":"Forecasting volatility is an important issue in financial econometric analysis. This paper aims to seek a computationally feasible approach for predicting large scale conditional volatility and covariance of financial time series. In the case of multi-variant time series, the volatility is represented by a Conditional Covariance Matrix (CCM). Traditional models for predicting CCM such as GARCH models are incapable of dealing with high-dimensional cases as there are O(N 2) parameters to be estimated in the case of N-variant asset return, and it is difficult to accelerate the computation of estimating these parameters by utilizing modern multi-core architecture. These GARCH models also have difficulties in modeling non-linear properties. The widely used Restricted Boltzmann Machine (RBM) is an energy-based stochastic recurrent neural network and its extended model, Conditional RBM (CRBM), has shown its capability in modeling high-dimensional time series. In this paper, we first propose a CRBM-based approach to forecast CCM and show how to capture the long memory properties in volatility, and then we implement the proposed model on GPU by using CUDA and CUBLAS. Experiment results indicate that the proposed CRBM-based model obtains better forecasting accuracy for low-dimensional volatility and it also shows great potential in modeling for large-scale cases compared with traditional GARCH models. \u00a9 2012 Springer Science+Business Media New York.","Author Keywords":"Conditional restricted Boltzmann machine; Covariance matrix forecasting; GPU; High dimensional conditional covariance matrix; Neural network; Volatility forecasting","Index Keywords":"Conditional restricted boltzmann machines; Forecasting volatility; GPU; High-dimensional; Multicore architectures; Restricted boltzmann machine; Stochastic recurrent neural network; Volatility forecasting; Computer architecture; Computer software; Covariance matrix; Financial data processing; Neural networks; Recurrent neural networks; Stochastic models; Time series; Forecasting","References":"Bollerslev, T., Engle, R., Nelson, D., Arch models (1986) Handbook of Econometrics, pp. 2959-3038. , 4 Elsevier Amsterdam; Bollerslev, T., Generalized autoregressive conditional heteroskedasticity (1986) J Econom, 31 (3), pp. 307-327. , 853051 0616.62119 10.1016\/0304-4076(86)90063-1; De Oliveira, M., The influence of Arima-Garch parameters in feed forward neural networks prediction (2011) Neural Comput Appl, 20 (5), pp. 687-701. , 10.1007\/s00521-010-0410-8; Gavrishchaka, V.V., Banerjee, S., Support vector machine as an efficient framework for stock market volatility forecasting (2006) Comput Manag Sci, 3 (2), pp. 147-160. , 2229396 1142.91718 10.1007\/s10287-005-0005-5; Tang, L.B., Tang, L.X., Sheng, H.Y., Forecasting volatility based on wavelet support vector machine (2009) Expert Syst Appl, 36 (2), pp. 2901-2909. , 10.1016\/j.eswa.2008.01.047; Taylor, G., Hinton, G., Roweis, S., Modeling human motion using binary latent variables (2007) Adv Neural Inf Process Syst, 19, p. 1345; Merton, R., On estimating the expected return on the market. 1. An exploratory investigation (1980) J Financ Econ, 8 (4), pp. 323-361. , 10.1016\/0304-405X(80)90007-0; Smolensky, P., Information processing in dynamical systems: Foundations of harmony theory (1986) Parallel Distributed Processing: Explorations in the Microstructure of Cognition, pp. 194-281. , 1; Hinton, G., Salakhutdinov, R., Reducing the dimensionality of data with neural networks (2006) Science, 313 (5786), p. 504. , 2242509 1226.68083 10.1126\/science.1127647; Sutskever, I., Hinton, G., Learning multilevel distributed representations for high-dimensional sequences (2007) Proceeding of the Eleventh International Conference on Artificial Intelligence and Statistics, pp. 544-551; Taylor, G., Hinton, G., Roweis, S., Two distributed-state models for generating high-dimensional time series (2011) J Mach Learn Res, 12, pp. 1025-1068. , 2786917; Hinton, G., Training products of experts by minimizing contrastive divergence (2002) Neural Comput, 14 (8), pp. 1771-1800. , 2978160 1010.68111 10.1162\/089976602760128018; Liu, Y., Gopikrishnan, P., Stanley, H., Statistical properties of the volatility of price fluctuations (1999) Phys Rev E, Stat Nonlinear Soft Matter Phys, 60 (2), p. 1390. , 10.1103\/PhysRevE.60.1390; Lockett, A.J., Miikkulainen, R., (2009) Temporal Convolution Machines for Sequence Learning, , Tech rep AI-09-04, Department of Computer Sciences, the University of Texas at Austin; Nvidia, C., (2007) Compute Unified Device Architecture Programming Guide, p. 129. , 83 NVIDIA Santa Clara; Nvidia, C., (2008) Cublas Library, , 15 NVIDIA Santa Clara; Tsay, R., (2005) Analysis of Financial Time Series, , 543 Wiley-Interscience New York 1086.91054 10.1002\/0471746193; Watkins, D., Fundamentals of matrix computations (2002) LibreDigital, 56; Ding, Z., (1996) Time Series Analysis of Speculative Returns, , University of California, Department of Economics San Diego; Bollerslev, T., Modelling the coherence in short-run nominal exchange rates: A multivariate generalized arch model (1990) Rev Econ Stat, 72 (3), pp. 498-505. , 10.2307\/2109358"}
{"Authors":"Borovykh A., Bohte S., Oosterlee C.W.","Author(s) ID":"57193126885;55893905100;6701797256;","Title":"Dilated convolutional neural networks for time series forecasting","Year":2019,"Source title":"Journal of Computational Finance","Volume":"22","Issue":"4","Art. No.":null,"Page start":73.0,"Page end":101.0,"Page count":null,"Cited by":1.0,"DOI":"10.21314\/JCF.2018.358","Affiliations":"Dipartimento di Matematica, Universit\u00e0 di Bologna, Piazza di Porta San Donata, 5, Bologna, 40126, Italy; Centrum Wiskunde & Informatica, Science Park 123, Amsterdam, 1098 XG, Netherlands; Delft University of Technology, Van Mourik Broekmanweg 6, Delft, 2628 XE, Netherlands","Document Type":"Article","Access Type":null,"Source":"Scopus","EID":"2-s2.0-85065197924","Abstract":"To forecast the future trend of financial activities through its rules, a convolutional neural network (CNN) is used to forecast stock index. Firstly, a CNN stock index prediction model is constructed, the structural parameter relationship of the CNN model is analyzed, and a CNN model algorithm is implemented. Secondly, the influence of model parameters on prediction results is discussed, and the stock index prediction model based on CNN-support vector machine (SVM) is established. At last, the empirical analysis is made, and the results show that the two prediction models are feasible and effective. It is concluded that the use of neural networks for financial prediction can deal with the continuous and categorical prediction variables and obtain good prediction results. \u00a9 2019 John Wiley & Sons, Ltd.","Author Keywords":"CNN; financial prediction; neural network; stock prediction","Index Keywords":"Convolution; Electronic trading; Financial markets; Neural networks; Support vector machines; Time series analysis; Convolution neural network; Convolutional neural network; Financial prediction; Financial time series; Stock index predictions; Stock predictions; Stock price forecasting; Structural parameter; Forecasting","References":"Nonejad, N., Prediction aggregate stock market volatility using financial and macroeconomic predictors: which models forecast best, when and why* (2017) J Empir Financ, 42, pp. 131-154; Bhandari, A., Mammadov, B., Thevenot, M., The impact of executive inside debt on sell-side financial analyst forecast characteristics (2018) Rev Quant Finan Acc, 51 (1), pp. 1-33; Demerens, F., Delvaille, P., Manh, A., The use of segment information by financial analysts and forecast accuracy: a study on European intermediate-size companies (2016) Thunderbird Int Bus Rev, 59 (5), p. 448; Triantafyllou, K., Gkolfakis, P., Viazis, N., Tsibouris, P., Tsigaridas, A., A 13-year time trend analysis of 3724 small bowel video capsule endoscopies and a forecast model during the financial crisis in Greece (2016) Eur J Gastroenterol Hepatol, 29 (2), p. 185; Kim, H., Ko, K., Improving forecast accuracy of financial vulnerability: partial least squares factor model approach (2017) Work Pap, 64 (8), pp. 559-567; Chen, J.-S., Lin, P.-C., An intelligent financial ratio selection mechanism for earning forecast (2017) J Oper Res Soc Jpn, 45 (4), pp. 373-384; Wen-Ze, W., Yu-Mu, L., Research on financial revenue forecast based on holt-winter methods (2018) J Hubei Norm Univ, 227 (3), pp. 216-231; Fedyk, T., Refining financial analysts' forecasts by predicting earnings forecast errors (2017) Soc Sci Electron Publ, 25 (2), pp. 256-272; Spelta, A., Financial market predictability with tensor decomposition and links forecast (2017) Appl Netw Sci, 2 (1), p. 7; Muramiya, K., Takada, T., A research note: quality of financial inputs and management earnings forecast accuracy in Japan (2017) J Contemp Account Econ, 13 (2), pp. 179-191; Chung, H., Shin, K.S., Genetic algorithm-optimized long short-term memory network for stock market prediction (2018) Sustainability, 10 (10), p. 3765; Ahmadi, E., Jasemi, M., Monplaisir, L., Nabavi, M.A., Mahmoodi, A., Jam, P.A., New efficient hybrid candlestick technical analysis model for stock market timing on the basis of the support vector machine and heuristic algorithms of imperialist competition and genetic (2018) Expert Syst Appl, 94, pp. 21-31; Nahil, A., Lyhyaoui, A., Short-term stock price forecasting using kernel principal component analysis and support vector machines: the case of Casablanca stock exchange (2018) Procedia Comput Sci, 127, pp. 161-169; Wang, S.H., Hong, J., Yang, M., Sensorineural hearing loss identification via nine-layer convolutional neural network with batch normalization and dropout (2018) Multimed Tools Appl, pp. 1-16; Zhou, J., Liu, H., Xu, Y., Jiang, W., A hybrid framework for short term multi-step wind speed forecasting based on variational model decomposition and convolutional neural network (2018) Energies, 11 (9), p. 2292; Bai, Y., Sun, Z., Zeng, B., A comparison of dimension reduction techniques for support vector machine modeling of multi-parameter manufacturing quality prediction (2018) J Intell Manuf, pp. 1-12; Feres, M., Louzoun, Y., Haber, S., Faveri, M., Figueiredo, L.C., Levin, L., Support vector machine-based differentiation between aggressive and chronic periodontitis using microbial profiles (2018) Int Dent J, 68 (1), pp. 39-46; Cao, Y., Ding, Z., Xue, F., Rong, X., An improved twin support vector machine based on multi-objective cuckoo search for software defect prediction (2018) Int J Bio Inspired Comput, 11 (4), pp. 282-291; Thanh Noi, P., Kappas, M., Comparison of random forest, k-nearest neighbor, and support vector machine classifiers for land cover classification using Sentinel-2 imagery (2018) Sensors, 18 (1), p. 18; Kumar, P.J., Pan, M., Yung, Y., Huan, T.L., Support vector machine based retinal therapeutic for glaucoma using machine learning algorithm (2018) Int J Med Eng Informat, 5 (3), p. 7; You, S.D., Liu, C.H., Chen, W.K., Comparative study of singing voice detection based on deep neural networks and ensemble learning (2018) HCIS, 8 (1), p. 34; Khoobjou, E., Mazinan, A.H., On hybrid intelligence-based control approach with its application to flexible robot system (2017) HCIS, 7 (1), p. 5; Singh, J., Singh, G., Singh, R., Optimization of sentiment analysis using machine learning classifiers (2017) HCIS, 7 (1), p. 32; Alireza, S., Shafigheh, H., Masoud, R.A., Personality classification based on profiles of social networks' users and the five-factor model of personality (2018) HCIS, 8 (1), p. 24; Iam-On, N., Boongoen, T., Generating descriptive model for student dropout: a review of clustering approach (2017) HCIS, 7 (1), p. 1; Yili, W., Kyungtae, K., Byungjun, L., Yong, Y.H., Word clustering based on pos feature for efficient twitter sentiment analysis (2018) Hum Cent Comput Inform Sci, 8 (1), p. 17; Vilakone, P., Park, D.S., Xinchang, K., Hao, F., An efficient movie recommendation algorithm based on improved k-clique (2018) HCIS, 8 (1), p. 38; Zouina, M., Outtaj, B., A novel lightweight URL phishing detection system using SVM and similarity index (2017) Hindawi Limited, 7 (17), p. 23; Rao, M., Kamila, N.K., Tracking intruder ship in wireless environment (2017) Hindawi Limited, 7 (14), pp. 35-38; Song, W., Zou, S., Tian, Y., Fong, S., Cho, K., Classifying 3d objects in lidar point clouds with a back-propagation neural network (2018) HCIS, 8 (1), p. 29; Wang, H., Zheng, B., Yoon, S.W., Ko, H.S., A support vector machine-based ensemble algorithm for breast cancer diagnosis (2018) Eur J Oper Res, 267 (2), pp. 687-699; Al-Smadi, M., Qawasmeh, O., Al-Ayyoub, M., Jararweh, Y., Gupta, B., Deep recurrent neural network vs. support vector machine for aspect-based sentiment analysis of Arabic hotels' reviews (2018) J Comput Sci, 27, pp. 386-393; Song, Y., Kim, I., DeepAct: a deep neural network model for activity detection in untrimmed videos (2018) J Inf Process Syst, 14 (1), pp. 150-161; Zeng, H., Liu, Y., Li, S., Che, J.Y., Wang, X., Convolutional neural network based multi-feature fusion for non-rigid 3D model retrieval (2018) J Inf Process Syst, 14 (1), pp. 176-190; Lee, S.-G., Sung, Y., Kim, Y.-G., Cha, E.-Y., Variations of AlexNet and GoogLeNet to improve Korean character recognition performance (2018) J Inf Process Syst, 14 (1), pp. 205-217; Lotfi, A., Benyettou, A., Cross-validation probabilistic neural network based face identification (2018) J Inf Process Syst, 14 (5), pp. 1075-1086; Lee, S., Kim, I., Video captioning with visual and semantic features (2018) J Inf Process Syst, 14 (6), pp. 1318-1330; Li, C., Liang, M., Song, W., Xiao, K., A multi-scale parallel convolutional neural network based intelligent human identification using face information (2018) J Inf Process Syst, 14 (6), pp. 1494-1507; Cao, K., Kim, H., Hwang, C., Jung, H., CNN-LSTM coupled model for prediction of waterworks operation data (2018) J Inf Process Syst, 14 (6), pp. 1508-1520; Kumar, S., Chandra, M., Detection of microcalcification using the wavelet based adaptive sigmoid function and neural network (2017) J Inf Process Syst, 13 (4), pp. 703-715; Li, D., Gang, W., Zhao, J., Niu, W., Qi, L., Wireless channel identification algorithm based on feature extraction and BP neural network (2017) J Inf Process Syst, 13 (1), pp. 141-151; Teldja Amghar, Y., Fizazi, H., A hybrid bacterial foraging optimization algorithm and a radial basic function network for image classification (2017) J Inf Process Syst, 13 (2), pp. 215-235"}
{"Authors":"Huang H.-S., Liu C.-L., Tseng V.S.","Author(s) ID":"57196051044;57129735000;6507335623;","Title":"Multivariate time series early classification using multi-domain deep neural network","Year":2019,"Source title":"Proceedings - 2018 IEEE 5th International Conference on Data Science and Advanced Analytics, DSAA 2018","Volume":null,"Issue":null,"Art. No.":" 8631422","Page start":90.0,"Page end":98.0,"Page count":null,"Cited by":1.0,"DOI":"10.1109\/DSAA.2018.00019","Affiliations":"National Chiao Tung University, Hsinchu, Taiwan","Document Type":"Conference Paper","Access Type":null,"Source":"Scopus","EID":"2-s2.0-85062878628","Abstract":"A novel financial time-series analysis method based on deep learning technique is proposed in this paper. In recent years, the explosive growth of deep learning researches have led to several successful applications in various artificial intelligence and multimedia fields, such as visual recognition, robot vision, and natural language processing. In this paper, we focus on the time-series data processing and prediction in financial markets. Traditional feature extraction approaches in intelligent trading decision support system are used to applying several technical indicators and expert rules to extract numerical features. The major contribution of this paper is to improve the algorithmic trading framework with the proposed planar feature representation methods and deep convolutional neural networks (CNN). The proposed system is implemented and benchmarked in the historical datasets of Taiwan Stock Index Futures. The experimental results show that the deep learning technique is effective in our trading simulation application, and may have greater potentialities to model the noisy financial data and complex social science problems. In the future, we expected that the proposed methods and deep learning framework could be applied to more innovative applications in the next financial technology (FinTech) generation. \u00a9 2016 IEEE.","Author Keywords":"convolutional neural networks; data visualization; Deep learning; machine learning; trend prediction","Index Keywords":"Artificial intelligence; Big data; Cloud computing; Commerce; Convolution; Data handling; Data visualization; Decision support systems; Deep learning; Deep neural networks; Finance; Financial data processing; Intelligent robots; Learning algorithms; Learning systems; Natural language processing systems; Network function virtualization; Neural networks; Time series analysis; Visual languages; Algorithmic trading; Convolutional neural network; Feature representation; Financial time series; Learning frameworks; Simulation applications; Technical indicator; Trend prediction; Electronic trading","References":"Cao, L.J., Tay, F.E., Support vector machine with adaptive parameters in financial time series forecasting (2003) Neural Networks IEEE Transactions on, 14 (6), pp. 1506-1518; Kercheval, A.N., Zhang, Y., (2013) Modeling High-Frequency Limit Order Book Dynamics with Support Vector Machines; Smailovic, J., Grcar, M., Lavrac, N., \u1e90nidar\u015dic, M., Streambased active learning for sentiment analysis in the financial domain (2014) Information Sciences, 285, pp. 181-203; Kranjc, J., Smailovic, J., Podpecan, V., Grcar, M., \u1e90nidar\u015dic, M., Lavrac, N., Active learning for sentiment analysis on data streams: Methodology and workflow implementation in the clowdflows platform (2015) Information Processing & Management, 51 (2), pp. 187-203; Hagenau, M., Liebmann, M., Neumann, D., Automated news reading: Stock price prediction based on financial news using contextcapturing features (2013) Decision Support Systems, 55 (3), pp. 685-697; Li, X., Xie, H., Chen, L., Wang, J., Deng, X., News impact on stock price return via sentiment analysis (2014) Knowledge-Based Systems, 69, pp. 14-23; Chapados, N., Bengio, Y., Cost functions and model combination for var-based asset allocation using neural networks (2001) Neural Networks IEEE Transactions on, 12 (4), pp. 890-906; Sitte, R., Sitte, J., Analysis of the predictive ability of time delay neural networks applied to the s&p 500 time series (2000) Systems, Man, and Cybernetics, Part C: Applications and Reviews IEEE Transactions on, 30 (4), pp. 568-572; Zhang, G.P., A neural network ensemble method with jittered training data for time series forecasting (2007) Information Sciences, 177 (23), pp. 5329-5346; Gen\u00e7ay, R., Gibson, R., Model risk for european-style stock index options (2007) Neural Networks IEEE Transactions on, 18 (1), pp. 193-202; Armano, G., Marchesi, M., Murru, A., A hybrid genetic-neural architecture for stock indexes forecasting (2005) Information Sciences, 170 (1), pp. 3-33; Kwon, Y.K., Moon, B.R., A hybrid neurogenetic approach for stock forecasting (2007) Neural Networks IEEE Transactions on, 18 (3), pp. 851-864; Geva, T., Zahavi, J., Empirical evaluation of an automated intraday stock recommendation system incorporating both market data and textual news (2014) Decision Support Systems, 57, pp. 212-223; LeCun, Y., Bengio, Y., Convolutional networks for images, speech, and time series (1995) The Handbook of Brain Theory and Neural Networks, 3361 (10), p. 1995; LeCun, Y., Bottou, L., Bengio, Y., Haffner, P., Gradient-based learning applied to document recognition (1998) Proc. IEEE, 86 (11), pp. 2278-2324. , Nov; Hinton, G.E., Osindero, S., Teh, Y.W., A fast learning algorithm for deep belief nets (2006) Neural Computation, 18 (7), pp. 1527-1554; Hinton, G.E., Salakhutdinov, R.R., Reducing the dimensionality of data with neural networks (2006) Science, 313 (5786), pp. 504-507; Zhang, Z., Luo, P., Loy, C.C., Tang, X., (2015) Learning Deep Representation for Face Alignment with Auxiliary Attributes; Kavukcuoglu, K., Ranzato, M.A., Fergus, R., Le-Cun, Y., Learning invariant features through topographic filter maps (2009) Computer Vision and Pattern Recognition 2009. CVPR 2009. IEEE Conference on, pp. 1605-1612. , June IEEE; Wong, W.K., Sun, M., Deep learning regularized fisher mappings (2011) Neural Networks IEEE Transactions on, 22 (10), pp. 1668-1675; Larochelle, H., Bengio, Y., Louradour, J., Lamblin, P., Exploring strategies for training deep neural networks (2009) The Journal of Machine Learning Research, 10, pp. 1-40; Erhan, D., Bengio, Y., Courville, A., Manzagol, P.A., Vincent, P., Bengio, S., Why does unsupervised pre-training help deep learning? (2010) The Journal of Machine Learning Research, 11, pp. 625-660; Montavon, G., Braun, M.L., M\u00fcller, K.R., Kernel analysis of deep networks (2011) The Journal of Machine Learning Research, 12, pp. 2563-2581; Yuan, Y., Mou, L., Lu, X., Scene recognition by manifold regularized deep learning architecture (2015) IEEE Transactions on Neural Networks and Learning Systems, 26 (10), pp. 2222-2233; Krizhevsky, A., Sutskever, I., Hinton, G.E., Imagenet classification with deep convolutional neural networks (2012) Advances in Neural Information Processing Systems, pp. 1097-1105; Ngiam, J., Khosla, A., Kim, M., Nam, J., Lee, H., Ng, A.Y., Multimodal deep learning (2011) Proceedings of the 28th International Conference on Machine Learning (ICML-11), pp. 689-696; Theis, L., Gerwinn, S., Sinz, F., Bethge, M., In all likelihood, deep belief is not enough (2011) The Journal of Machine Learning Research, 12, pp. 3071-3096; Nair, V., Hinton, G.E., 3d object recognition with deep belief nets (2009) InAdvances in Neural Information Processing Systems, pp. 1339-1347; Palm, R.B., (2012) Prediction As A Candidate for Learning Deep Hierarchical Models of Data, 25. , Technical University of Denmark, Palm; Wang, Z., Oates, T., (2015) Imaging Time-Series to Improve Classification and Imputation, , arXiv preprint arXiv: 1506.00327; Huang, S.H., Tai, S.H., Lai, S.H., A learning based contrarian trading strategy via dual classifiers model (2011) ACM Transactions on Intelligent Systems and Technology, 2, p. 3; Huang, S.H., Pan, Y.C., Automated visual inspection in semiconductor industry: A survey (2015) Computers in Industry, 66, pp. 1-10; Huang, S.H., Pan, Y.C., Ergonomic job rotation strategy based on an automated rgb-d anthropometric measuring system (2014) Journal of Manufacturing Systems, 33 (4), pp. 699-710"}
{"Authors":"Hossain M.A., Karim R., Thulasiram R., Bruce N.D.B., Wang Y.","Author(s) ID":"57207728673;55407386600;6602683636;8347469300;56112468400;","Title":"Hybrid Deep Learning Model for Stock Price Prediction","Year":2019,"Source title":"Proceedings of the 2018 IEEE Symposium Series on Computational Intelligence, SSCI 2018","Volume":null,"Issue":null,"Art. No.":" 8628641","Page start":1837.0,"Page end":1844.0,"Page count":null,"Cited by":1.0,"DOI":"10.1109\/SSCI.2018.8628641","Affiliations":"Department of Computer Science, University of Manitoba, Winnipeg, Canada","Document Type":"Conference Paper","Access Type":null,"Source":"Scopus","EID":"2-s2.0-85062770567","Abstract":"Stock market prediction has attracted a lot of attention from both business and academia. In this paper, we implement a model based on Recurrent Neural Networks (RNN) with Gated Recurrent Units (GRU) to predict the stock volatility in the Chinese stock market. We also propose many price related features which are used as inputs for our model. Apart from that, we carefully select official accounts from Chinese largest online social networks-Sina Weibo and extract the content posted by these accounts to analyze the public moods. An influence feature is derived based on the public moods to further improve the prediction model. The experimental results show that our model outperforms the baseline method and can achieve a good prediction performance. \u00a9 2017 IEEE.","Author Keywords":"Online Social Networks; Recurrent Neural Networks; Time Series Prediction","Index Keywords":"Commerce; Electronic trading; Finance; Financial markets; Forecasting; Recurrent neural networks; Smart city; Baseline methods; Chinese stock market; On-line social networks; Prediction model; Prediction performance; Recurrent neural network (RNN); Stock market prediction; Time series prediction; Social networking (online)","References":"Fama, E.F., Fisher, L., Jensen, M.C., Roll, R., The adjustment of stock prices to new information (1969) International Economic Review, 10 (1), pp. 1-21; Fama, E.F., Efficient capital markets: II (1991) The Journal of Finance, 46 (5), pp. 1575-1617; Osborne, M.M., Brownian motion in the stock market (1959) Operations Research, 7 (2), pp. 145-173; Fox, J., Sklar, A., (2009) The Myth of the Rational Market: A History of Risk, Reward, and Delusion on Wall Street, , Harper Business New York; Nocera, J., Poking holes in a theory on markets (2009) New York Times, 5; Smith, V.L., Constructivist and ecological rationality in economics (2003) The American Economic Review, 93 (3), pp. 465-508; Nofsinger, J.R., Social mood and financial economics (2005) The Journal of Behavioral Finance, 6 (3), pp. 144-160; Qian, B., Rasheed, K., Stock market prediction with multiple classifiers (2007) Applied Intelligence, 26 (1), pp. 25-33; Quayes, S., Jamal, A.M., Impact of demographic change on stock prices The Quarterly Review of Economics and Finance, 60 (2016), pp. 172-179; Sun, X.-Q., Shen, H.-W., Cheng, X.-Q., Trading network predicts stock price (2014) Scientific Reports, 4, p. 3711; Chowdhury, S.G., Routh, S., Chakrabarti, S., News analytics and sentiment analysis to predict stock price trends (2014) International Journal of Computer Science and Information Technologies, 5 (3), pp. 3595-3604; Heston, S.L., Sinha, N.R., News versus sentiment: Comparing textual processing approaches for predicting stock returns (2014) Robert H. Smith School Research Paper; Nofer, M., Hinz, O., Using twitter to predict the stock market (2015) Business & Information Systems Engineering, 57 (4), pp. 229-242; Si, J., Mukherjee, A., Liu, B., Li, Q., Li, H., Deng, X., Exploiting topic based twitter sentiment for stock prediction (2013) ACL, 2013 (2), pp. 24-29; Azar, P.D., Lo, A.W., The wisdom of twitter crowds: Predicting stock market reactions to fomc meetings via twitter feeds (2016) The Journal of Portfolio Management, 42 (5), pp. 123-134; Burnap, P., Gibson, R., Sloan, L., Southern, R., Williams, M., 140 characters to victory?: Using twitter to predict the UK 2015 general election (2016) Electoral Studies, 41, pp. 230-233; Thigale, S., Prasad, T., Makhija, U.K., Ravichandran, V., Prediction of box office success of movies using hype analysis of twitter data (2014) Int J Invent Eng Sci, 3 (1), pp. 1-6; Zhang, X., Fuehres, H., Gloor, P.A., Predicting stock market indicators through twitter i hope it is not as bad as i fear (2011) Procedia-Social and Behavioral Sciences, 26, pp. 55-62; Loughran, T., McDonald, B., When is a liability not a liability? Textual analysis, dictionaries, and 10-ks (2011) The Journal of Finance, 66 (1), pp. 35-65; Choudhry, R., Garg, K., A hybrid machine learning system for stock market forecasting (2008) World Academy of Science, Engineering and Technology, 39 (3), pp. 315-318; Ding, X., Zhang, Y., Liu, T., Duan, J., Deep learning for event-driven stock prediction (2015) IJCAI, pp. 2327-2333; Liu, Y., Qin, Z., Li, P., Wan, T., (2017) Stock Volatility Prediction Using Recurrent Neural Networks with Sentiment Analysis, , arXiv preprint arXiv 1705.02447; Patel, J., Shah, S., Thakkar, P., Kotecha, K., Predicting stock market index using fusion of machine learning techniques (2015) Expert Systems with Applications, 42 (4), pp. 2162-2172; Nofer, M., Hinz, O., Are crowds on the internet wiser than experts? the case of a stock prediction community (2014) Journal of Business Economics, 84 (3), pp. 303-338; Si, J., Mukherjee, A., Liu, B., Pan, S.J., Li, Q., Li, H., Exploiting social relations and sentiment for stock prediction (2014) EMNLP, 14, pp. 1139-1145; Bajpai, P., The Worlds Top 10 Economies, , http:\/\/www.investopedia.com\/articles\/investing\/022415\/worlds-Top-10-economies.asp, accessed: 2017-06-14"}
{"Authors":"Uygun Y., Erboy M.O., Aktas M.S., Kalipsiz O., Aykurt I.","Author(s) ID":"57207696480;57190650159;8410237700;13408912900;57207684506;","Title":"Technical Analysis on Financial Time Series Data Based on Map-Reduce Programming Model: A Case Study [E\u015fle-Indirge Programlama Modeline Dayali Olarak Finansal Zaman Serisi Verileri \u00dczerinde Teknik Analiz: Durum \u00c7ali\u015fmasi]","Year":2019,"Source title":"International Congress on Big Data, Deep Learning and Fighting Cyber Terrorism, IBIGDELFT 2018 - Proceedings","Volume":null,"Issue":null,"Art. No.":" 8625357","Page start":92.0,"Page end":97.0,"Page count":null,"Cited by":null,"DOI":"10.1109\/IBIGDELFT.2018.8625357","Affiliations":"Bilgisayar M\u00fchendisli\u01e7i B\u00f6l\u00fcm\u00fc, Yildiz Teknik \u00dcniversitesi, Istanbul, Esenler, Turkey; YT\u00fc-Teknopark, Finnet-Elektronik, Istanbul, Esenler, Turkey","Document Type":"Conference Paper","Access Type":null,"Source":"Scopus","EID":"2-s2.0-85062733197","Abstract":"It has always been a challenging issue for people to understand the stock market and make reasonable predictions. For a very long period, investors are trying to manually extract useful features from the financial market which generates an enormous volume of data every single day. People create a lot of technical indicators like MACD, TR, MFI to describe momentum, volume and volatility signals of the financial time series. However, the limitation is evident due to the efficiency of manually feature engineering. With the rapidly growing volume of data, deep neural network shows excellent performance in many research areas like natural language processing, voice recognition, image identification. It provides a new view to dig out potentially useful information automatically. In this paper, we present a novel end-to-end training using an embedding method to automatically extract features and get a summary representation of the daily market. Moreover, we apply the Long Short-Term Memory (LSTM) with attention mechanism to predict daily return ratio of HS300 index. The features extracted by the embedding layer show greater predictive power than manually defined technical signals by 92.42% lower MSE. Moreover, the use of attention mechanism also provides an average enhance of 55.68% in MSE. Our study shows that deep neuron network structure has a strong potential for better understanding market complex behaviors. \u00a9 2018 IEEE.","Author Keywords":"Embedding Method; LSTM; Market Prediction; Market Vector; Technical Indicator","Index Keywords":null,"References":"Jiang, Z.-Q., Zhou, W.-X., Sornette, D., Woodard, R., Bastiaensen, K., Cauwels, P., Bubble diagnosis and prediction of the 2005-2007 and 2008-2009 Chinese stock market bubbles (2010) Journal of Economic Behavior & Organization, 74 (3), pp. 149-162; Cong, R.-G., Wei, Y.-M., Jiao, J.-L., Fan, Y., Relationships between oil price shocks and stock market: An empirical analysis from China (2008) Energy Policy, 36 (9), pp. 3544-3553; Fama, E.F., The behavior of stock-market prices (1965) The Journal of Business, 38 (1), pp. 34-105; Fama, E.F., The adjustment of stock prices to new information (1969) International Economic Review, 10 (1), pp. 1-21; Fama, E.F., Efficient capital markets: II (1991) The Journal of Finance, 46 (5), pp. 1575-1617; Cootner, P.H., (1964) The Random Character of Stock Market Prices; Qian, B., Rasheed, K., Stock market prediction with multiple classifiers (2007) Applied Intelligence, 26 (1), pp. 25-33; Kavussanos, M.G., Dockery, E., A multivariate test for stock market efficiency: The case of ase (2001) Applied Financial Economics, 11 (5), pp. 573-579; Gencay, R., The predictability of security returns with simple technical trading rules (1998) Journal of Empirical Finance, 5, pp. 347-359; Gencay, R., Linear, non-linear, and essential exchange rate prediction with simple technical trading rules (1997) Journal of International Economics, 47, pp. 91-107; Yu, H., Nartea, G.V., Gan, C., Yao, L.J., Predictive ability and profitability of simple technical trading rules: Recent evidence from southeast asian stock markets (2013) International Review of Economics and Finance, 25, pp. 356-371; Sermpinis, G., Laws, J., Karathanasopoulos, A., Dunis, C.L., Forecasting and trading the eur\/usd exchange rate with gene expression and psi sigma neural networks (2012) Expert Systems with Applications, 39, pp. 8865-8877; Ghazali, R., Hussain, A.J., Liatsis, P., Dynamic ridge polynomial neural network: Forecasting the univariate non-stationary and stationary trading signals (2011) Expert Systems with Applications, 38, pp. 3765-3776; Bahrepour, M., Akbarzadeh, T., Yaghoobi, M., Naghibi, S., An adaptive ordered fuzzy time series with application to forex (2011) Expert Systems with Applications, 38, pp. 475-485; Premanode, B., Toumazou, C., Improving prediction of exchange rates using differential emd (2013) Expert Systems with Applications, 40, pp. 377-384; Huang, S.-C., Chuang, P.-J., Wu, C.-F., Lai, H.-J., Chaosbased support vector regressions for exchange rate forecasting (2010) Expert Systems with Applications, 37, pp. 8590-8598; Mabu, S., Hirasawa, K., Obayashi, M., Kuremoto, T., Enhanced decision making mechanism of rule-based genetic network programming for creating stock trading signals (2013) Expert Systems with Applications, 40, pp. 6311-6320; Bao, W., Yue, J., Rao, Y., A deep learning framework for financial time series using stacked autoencoders and long-short term memory (2017) PloS One, 12 (7), p. e0180944; Takeuchi, L., Lee, Y.Y.A., (2013) Applying Deep Learning to Enhance Momentum Trading Strategies in Stocks, , Working paper, Stanford University; Hassan, R., Nath, B., Stock market forecasting using hidden markov model: A new approach (2005) Intelligent Systems Design and Applications, 2005. ISDA'05. Proceedings. 5th International Conference on, pp. 192-196. , IEEE; Mikolov, T., Sutskever, I., Chen, K., Corrado, G.S., Dean, J., Distributed representations of words and phrases and their compositionality (2013) Advances in Neural Information Processing Systems; Hochreiter, S., Schmidhuber, J., Long short-term memory (1997) Neural Computation, 9 (8), pp. 1735-1780; Itti, L., Koch, C., Niebur, E., A model of saliencybased visual attention for rapid scene analysis (1998) IEEE Transactions on Pattern Analysis & Machine Intelligence, 11, pp. 1254-1259; Desimone, R., Duncan, J., Neural mechanisms of selective visual attention (1995) Annual Review of Neuroscience, 18 (1), pp. 193-222; Cho, K., Van Merrienboer, B., Gulcehre, C., Bahdanau, D., Bougares, F., Schwenk, H., Bengio, Y., (2014) Learning Phrase Representations Using RNN Encoder-Decoder for Statistical Machine Translation; Chung, J., Gulcehre, C., Cho, K., Bengio, Y., (2014) Empirical Evaluation of Gated Recurrent Neural Networks on Sequence Modeling; Palangi, H., Deng, L., Shen, Y.L., Gao, J.F., He, X.D., Chen, J.S., Deep sentence embedding using long short-term memory networks: Analysis and application to information retrieval (2016) IEEE-ACM Trans Audio Speech Lang, 24 (4), pp. 694-707; Palangi, H., Ward, R., Deng, L., Distributed compressive sensing: A deep learning approach (2016) IEEE Transactions on Signal Processing, 64 (17), pp. 4504-4518; Sundermeyer, M., Schl\u00fcter, R., Ney, H., Lstm neural networks for language modeling (2012) Interspeech; Abadi, M., Agarwal, A., Barham, P., Brevdo, E., (2015) TensorFlow: Large-scale Machine Learning on Heterogeneous Systems, , Software available from tensorflow. org; Alexander, M., A neural attention model for abstractive sentence summarization (2015) [1402. 1128] Long Short-Term Memory Based Recurrent Neural Network Architectures for Large Vocabulary Speech Recognition, , 3 Sept"}
{"Authors":"Islam S.R., Khaled Ghafoor S., Eberle W.","Author(s) ID":"57195922078;57207579157;24558789000;","Title":"Mining Illegal Insider Trading of Stocks: A Proactive Approach","Year":2019,"Source title":"Proceedings - 2018 IEEE International Conference on Big Data, Big Data 2018","Volume":null,"Issue":null,"Art. No.":" 8622303","Page start":1397.0,"Page end":1406.0,"Page count":null,"Cited by":null,"DOI":"10.1109\/BigData.2018.8622303","Affiliations":"Computer Science, Tennessee Technological University, Cookeville, United States","Document Type":"Conference Paper","Access Type":null,"Source":"Scopus","EID":"2-s2.0-85062622552","Abstract":"Stock market prediction plays an important role in financial decision-making for investors. Many of them rely on news disclosures to make their decisions in buying or selling stocks. However, accurate modelling of stock market trends via news disclosures is a challenging task, considering the complexity and ambiguity of natural languages used. Unlike previous work along this line of research, which typically applies bag-of-words to extract tens of thousands of features to build a prediction model, we propose a sentiment analysis-based approach for financial market prediction using news disclosures. Specifically, sentiment analysis is carried out in the pre-processing phase to extract sentiment-related features from financial news. Historical stock market data from the perspective of time series analysis is also included as an input feature. With the extracted features, we use a support vector machine (SVM) to build the prediction model, with its parameters optimised through particle swarm optimisation (PSO). Experimental results show that our proposed SVM and PSO-based model is able to obtain better results than a deep learning model in terms of time and accuracy. The results presented here are to date the best in the literature based on the financial news dataset tested. This excellent performance is attributed to the sentiment analysis done during the pre-processing stage, as it reduces the feature dimensions significantly. \u00a9 2018 Copyright held by the owner\/author(s).","Author Keywords":"Financial market prediction; Particle swarm optimisation; Sentiment analysis; Support vector machine","Index Keywords":"Commerce; Data mining; Decision making; Deep learning; Financial markets; Forecasting; Information retrieval; Modeling languages; Particle swarm optimization (PSO); Sentiment analysis; Support vector machines; Time series analysis; Analysis-based approaches; Feature dimensions; Financial decisions; Machine learning approaches; Market prediction; Particle swarm optimisation; Pre-processing stages; Stock market prediction; Investments","References":"Clerc, M., (2010) Particle Swarm Optimization, 93. , John Wiley & Sons; Devitt, A., Ahmad, K., Sentiment polarity identification in financial news: A cohesion-based approach (2007) ACL, 7, pp. 984-991; Hagenau, M., Liebmann, M., Neumann, D., Automated news reading: Stock price prediction based on financial news using context-capturing features (2013) Decision Support Systems, 55 (3), pp. 685-697. , 2013; Hu, Z., Bao, Y., Chiong, R., Xiong, T., Profit guided or statistical error guided? a study of stock index forecasting using support vector regression (2017) Journal of Systems Science and Complexity, 30 (6), pp. 1425-1442. , 2017; Kraus, M., Feuerriegel, S., Decision support from financial disclosures with deep neural networks and transfer learning (2017) Decision Support Systems, 104, pp. 38-48. , 2017; Manning, C.D., Sch\u00fctze, H., (1999) Foundations of Statistical Natural Language Processing, , MIT press; Vapnik, V., (2013) The Nature of Statistical Learning Theory, , Springer"}
{"Authors":"Siami-Namini S., Tavakoli N., Siami Namin A.","Author(s) ID":"57201302278;57198291892;36171214700;","Title":"A Comparison of ARIMA and LSTM in Forecasting Time Series","Year":2019,"Source title":"Proceedings - 17th IEEE International Conference on Machine Learning and Applications, ICMLA 2018","Volume":null,"Issue":null,"Art. No.":" 8614252","Page start":1394.0,"Page end":1401.0,"Page count":null,"Cited by":1.0,"DOI":"10.1109\/ICMLA.2018.00227","Affiliations":"Department of Applied Economics, Texas Tech University, United States; Department of Computer Science, Georgia Institute of Technology, United States","Document Type":"Conference Paper","Access Type":null,"Source":"Scopus","EID":"2-s2.0-85062240139","Abstract":"With the advent of the artificial intelligence (AI) era, the combination of AI with financial technology (FinTech) has become a development trend in the financial industry. However, deep learning (DL) on the application of automated financial management has been rarely investigated. Thus, this research focuses on the applications of FinTech and DL in asset allocation and aims to optimize investment portfolio. The best investment portfolio in index-based funds based on Taiwan's index-type security investment trust funds are the main investment targets. Time series models for DL, that is, long short-term memory, predict the increase of each investment target and find the best investment portfolio in combination with the relevant asset allocation theory. In this research, we use the Markowitz mean-variance and Black-Litterman models as our asset allocation models for robo-advisor. Results show that the Black-Litterman model has a better accumulated return performance than the Morkowitz model and outperforms other strategies. The Human-Computer Interaction (HCI) dialogue service adopts artificial intelligence markup language (AIML) and a generative model. The main contribution of this paper is that we have developed an integrated knowledge-based and generative-based models for AI conversational robo-advisor. \u00a9 2018 IEEE.","Author Keywords":"Artificial Intelligence (AI); Conversational Commerce; Deep Learning; Financial Technology (FinTech); Robo-Advisor","Index Keywords":"Artificial intelligence; Deep learning; Human computer interaction; Knowledge based systems; Markup languages; Artificial intelligence mark up languages; Financial industry; Financial managements; Financial Technology (FinTech); Human Computer Interaction (HCI); Investment portfolio; Robo-Advisor; Security investments; Investments","References":"Alonso-Mart\u00edn, F., Castro-Gonz\u00e1lez, A., Luengo, F.J.F.D.G., Salichs, M.A., Augmented robotics dialog system for enhancing human-robot interaction (2015) Sensors, 15 (7), pp. 15799-15829; Black, F., Litterman, R., (1990) Asset Allocation: Combining Investor Views with Market Equilibrium, , Discussion paper, Goldman, Sachs & Co; Cho, K., Van Merri\u00ebnboer, B., Bahdanau, D., Bengio, Y., (2014) On the Properties of Neural Machine Translation: Encoder-decoder Approaches, , arXiv preprint arXiv:1409.1259; Chung, J., Gulcehre, C., Cho, K., Bengio, Y., (2014) Empirical Evaluation of Gated Recurrent Neural Networks on Sequence Modeling, , arXiv preprint arXiv:1412.3555; Dodiya, T., Jain, S., Question classification for medical domain Question Answering system (2016) 2016 IEEE International WIE Conference on Electrical and Computer Engineering (WIECON-ECE), pp. 204-207; Fernandes, B., Fernandes, C., Street, A., Vallad\u00e3o, D., On an adaptive Black-Litterman investment strategy using conditional fundamentalist information: A Brazilian case study (2018) Finance Research Letters; Guu, K., Hashimoto, T.B., Oren, Y., Liang, P., (2017) Generating Sentences by Editing Prototypes, , arXiv preprint arXiv:1709.08878; Hansson, M., (2017) On Stock Return Prediction with LSTM Networks, , Lund university libraries; Hinton, G.E., Salakhutdinov, R.R., Reducing the dimensionality of data with neural networks (2006) Science, 313 (5786), pp. 504-507; Hochreiter, S., Schmidhuber, J., Long short-term memory (1997) Neural Computation, 9 (8), pp. 1735-1780; Idzorek, T., A step-by-step guide to the Black-Litterman model: Incorporating user-specified confidence levels (2007) Forecasting Expected Returns in the Financial Markets, pp. 17-38; Kaya, O., Schildbach, J., Schneider, S., Robo-advice - A true innovation in asset management (2017) Deutsche Bank Research, , August; LeCun, Y., Who is afraid of non-convex loss functions (2007) NIPS Workshop on Efficient Machine Learning; LeCun, Y., Bengio, Y., Hinton, G., Deep learning (2015) Nature, 521 (7553), p. 436; Lwin, K.T., Qu, R., MacCarthy, B.L., Mean-VaR portfolio optimization: A nonparametric approach (2017) European Journal of Operational Research, 260 (2), pp. 751-766; Markowitz, H., Portfolio selection (1952) The Journal of Finance, 7 (1), pp. 77-91; McCarthy, J., Minsky, M.L., Rochester, N., Shannon, C.E., A proposal for the dartmouth summer research project on artificial intelligence (2006) AI Magazine, 27 (4), p. 12. , august 31, 1955; McCulloch, W.S., Pitts, W., A logical calculus of the ideas immanent in nervous activity (1943) The Bulletin of Mathematical Biophysics, 5 (4), pp. 115-133; Nunamaker, J.F., Jr., Chen, M., Purdin, T.D., Systems development in information systems research (1990) Journal of Management Information Systems, 7 (3), pp. 89-106; Rumelhart, D.E., Hinton, G.E., Williams, R.J., Learning internal representation by backpropagation (1986) Parallel Distributed Processing: Exploration in the Microstructure of Cognition, 1; Russell, S.J., Norvig, P., (2016) Artificial Intelligence: A Modern Approach, , Pearson; Sutskever, I., Vinyals, O., Le, Q.V., Sequence to sequence learning with neural networks (2014) Advances in Neural Information Processing Systems, pp. 3104-3112; Tieleman, T., Hinton, G., Lecture 6.5-rmsprop: Divide the gradient by a running average of its recent magnitude (2012) COURSERA: Neural Networks for Machine Learning, 4 (2), pp. 26-31; Utgoff, P.E., Stracuzzi, D.J., Many-layered learning (2002) Neural Computation, 14 (10), pp. 2497-2529"}
{"Authors":"Morris K.J., Egan S.D., Linsangan J.L., Leung C.K., Cuzzocrea A., Hoi C.S.H.","Author(s) ID":"57198863686;57207108540;57207114198;7402612526;23388216900;57202789966;","Title":"Token-Based Adaptive Time-Series Prediction by Ensembling Linear and Non-linear Estimators: A Machine Learning Approach for Predictive Analytics on big Stock Data","Year":2019,"Source title":"Proceedings - 17th IEEE International Conference on Machine Learning and Applications, ICMLA 2018","Volume":null,"Issue":null,"Art. No.":" 8614267","Page start":1486.0,"Page end":1491.0,"Page count":null,"Cited by":1.0,"DOI":"10.1109\/ICMLA.2018.00242","Affiliations":"University of Manitoba, Winnipeg, MB, Canada; University of Trieste, Trieste, Italy","Document Type":"Conference Paper","Access Type":null,"Source":"Scopus","EID":"2-s2.0-85062213716","Abstract":"Multivariate time series forecasting involves the learning of historical multivariate information in order to predict the future values of several quantities of interests, accounting for interdependencies among them. In finance, several of this quantities of interests (stock valuations, return, volatility) have been shown to be mutually influencing each other, making the prediction of such quantities a difficult task, especially while dealing with an high number of variables and multiple horizons in the future. Here we propose a machine learning based framework, the DFML, based on the Dynamic Factor Model, to first perform a dimensionality reduction and then perform a multiple step ahead forecasting of a reduced number of components. Finally, the components are transformed again into an high dimensional space, providing the desired forecast. Our results, comparing the DFML with several state of the art techniques from different domanins (PLS, RNN, LSTM, DFM), on both traditional stock markets and cryptocurrencies market and for different families of volatility proxies show that the DFML outperforms the concurrent methods, especially for longer horizons. We conclude by explaining how we wish to further improve the performances of the framework, both in terms of accuracy and computational efficiency. \u00a9 Springer Nature Switzerland AG 2019.","Author Keywords":"Dynamic factor models; Multi-step ahead forecast; Multivariate time series forecasting; Volatility forecasting","Index Keywords":"Computational efficiency; Electronic money; Long short-term memory; Machine components; Machine learning; Time series; Dimensionality reduction; Dynamic factor modeling; Dynamic factor models; Machine learning approaches; Multi-step; Multivariate time series; State-of-the-art techniques; Volatility forecasting; Forecasting","References":"Alessandretti, L., Elbahrawy, A., Aiello, L.M., Baronchelli, A., (2018) Machine Learning the Cryptocurrency Market, , arXiv preprint arXiv; Andersen, T.G., Bollerslev, T., (1998) ARCH and GARCH Models. Encyclopedia of Statistical Sciences; Bollerslev, T., Patton, A.J., Quaedvlieg, R., (2018) Multivariate Leverage Effects and Realized Semicovariance GARCH Models, , https:\/\/doi.org\/10.2139\/ssrn.3164361; Bontempi, G., Le Borgne, Y.A., de Stefani, J., A dynamic factor machine learning method for multi-variate and multi-step-ahead forecasting (2017) 2017 IEEE International Conference on Data Science and Advanced Analytics (DSAA), pp. 222-231. , pp., IEEE; Bontempi, G., Taieb, S.B., Conditionally dependent strategies for multiple-step-ahead prediction in local learning (2011) Int. J. Forecast., 27 (3), pp. 689-699; Catania, L., Grassi, S., Ravazzolo, F., Forecasting cryptocurrencies financial time series (2018) In: CAMP Working Paper Series 3, BI Norwegian Business School; Catania, L., Grassi, S., Ravazzolo, F., Predicting the volatility of cryptocurrency time-series (2018) In: CAMP Working Paper Series 5, BI Norwegian Business School; de Stefani, J., Caelen, O., Hattab, D., Bontempi, G., Machine learning for multi-step ahead forecasting of volatility proxies (2017) 2Nd Workshop on Mining Data for Financial Applications (MIDAS). CEUR Workshop Proceedings, 1941, pp. 17-28. , http:\/\/ceur-ws.org\/Vol-1941\/MIDAS2017paper3.pdf, Aachen, vol., pp; de Stefani, J., Le Borgne, Y.A., Caelen, O., Hattab, D., Bontempi, G., Batch and Incremental Dynamic Factor Machine Learning for Multivariate and Multi-Step-Ahead Forecasting, , https:\/\/doi.org\/10.1007\/s41060-018-0150-x; Degiannakis, S., Multiple days ahead realized volatility forecasting: Single, combined and average forecasts (2018) Glob. Financ. J., 36, pp. 41-61; Elbahrawy, A., Alessandretti, L., Kandler, A., Pastor-Satorras, R., Baronchelli, A., Evolutionary dynamics of the cryptocurrency market (2017) Roy. Soc. Open Sci., 4 (11); Engle, R.F., Ito, T., Lin, W.L., (1988) Meteor Showers Or Heat Waves? Heteroskedastic Intra-Daily Volatility in the Foreign Exchange Market; Fengler, M.R., Herwartz, H., Raters, F., Multivariate volatility models (2017) Applied Quantitative Finance, pp. 25-37. , https:\/\/doi.org\/10.1007\/978-3-540-69179-215, H\u00e4rdle, W.K., Hautsch, N., Overbeck, L. (eds.), pp., Springer, Heidelberg; Forni, M., Hallin, M., Lippi, M., Reichlin, L., The generalized dynamic factor model (2005) J. Am. Stat. Assoc., 100 (471), pp. 830-840. , https:\/\/doi.org\/10.1198\/016214504000002050; Franses, P., Legerstee, R., A unifying view on multi-step forecasting using an autoregression (2010) J. Econ. Surv., 24 (3), pp. 389-401; Garman, M.B., Klass, M.J., On the estimation of security price volatilities from historical data (1980) J. Bus., 53 (1), pp. 67-78; Graves, A., (2012) Supervised Sequence Labelling with Recurrent Neural Networks, , https:\/\/doi.org\/10.1007\/978-3-642-24797-2, Springer, Heidelberg; Hafner, C.M., Herwartz, H., Structural analysis of portfolio risk using beta impulse response functions (1998) Statistica Neerlandica, 52 (3), pp. 336-355; Hansen, P.R., Lunde, A., A forecast comparison of volatility models: Does anything beat a garch (1, 1)? (2005) J. Appl. Econometrics, 20 (7), pp. 873-889; Hochreiter, S., Schmidhuber, J., Long short-term memory (1997) Neural Comput, 9 (8), pp. 1735-1780; Kim, H.Y., Won, C.H., Forecasting the volatility of stock price index: A hybrid model integrating LSTM with multiple GARCH-type models (2018) Expert Syst. Appl., 103, pp. 25-37; Kim, J.M., Jung, H., Time series forecasting using functional partial least square regression with stochastic volatility, GARCH, and exponential smoothing (2018) J. Forecast., 37 (3), pp. 269-280; Lipton, Z.C., Berkowitz, J., Elkan, C., (2015) A Critical Review of Recurrent Neural Networks for Sequence Learning, , arXiv preprint arXiv; Parkinson, M., The extreme value method for estimating the variance of the rate of return (1980) J. Bus., 53 (1), pp. 61-65; Peng, Y., Albuquerque, P.H.M., de S\u00e1, J.M.C., Padula, A.J.A., Montenegro, M.R., The best of two worlds: Forecasting high frequency volatility for cryptocurrencies and traditional currencies with support vector regression (2018) Expert Syst. Appl., 97, pp. 177-192; Petneh\u00e1zi, G., G\u00e1ll, J., (2018) Exploring the Predictability of Range-Based Volatility Estimators Using Rnns, , arXiv preprint arXiv; Poon, S.H., Granger, C.W., Forecasting volatility in financial markets: A review (2003) J. Econ. Lit., 41 (2), pp. 478-539; Stock, J., Watson, M., Dynamic factor models (2010) Oxford Handbook of Economic Forecasting, , Clements, M., Hendry, D. (eds.), Oxford University Press, Oxford; Tashman, L.J., Out-of-sample tests of forecasting accuracy: An analysis and review (2000) Int. J. Forecast., 16 (4), pp. 437-450. , The M3-Competition; Tsay, R.S., (2005) Analysis of Financial Time Series, 543. , Wiley, Hoboken; Vincent, P., Larochelle, H., Lajoie, I., Bengio, Y., Manzagol, P.A., Stacked denoising autoencoders: Learning useful representations in a deep network with a local denoising criterion (2010) J. Mach. Learn. Res., 11, pp. 3371-3408; Walther, T., Klein, T., (2018) Exogenous Drivers of Cryptocurrency Volatility-A Mixed Data Sampling Approach to Forecasting, , https:\/\/doi.org\/10.2139\/ssrn.3192474; Yu, S.L., Li, Z., Forecasting stock price index volatility with LSTM deep neural network (2018) Recent Developments in Data Science and Business Analytics. SPBE, pp. 265-272. , https:\/\/doi.org\/10.1007\/978-3-319-72745-529, Tavana, M., Patnaik, S. (eds.), pp., Springer, Cham"}
{"Authors":"Long W., Lu Z., Cui L.","Author(s) ID":"36792418900;57207322594;57189992988;","Title":"Deep learning-based feature engineering for stock price movement prediction","Year":2019,"Source title":"Knowledge-Based Systems","Volume":"164","Issue":null,"Art. No.":null,"Page start":163.0,"Page end":173.0,"Page count":null,"Cited by":5.0,"DOI":"10.1016\/j.knosys.2018.10.034","Affiliations":"School of Economics & Management, University of Chinese Academy of Sciences, Beijing, 100190, PR China; Research Center on Fictitious Economy & Data Science, Chinese Academy of Sciences, Beijing, 100190, PR China; Key Laboratory of Big Data Mining & Knowledge Management, Chinese Academy of Sciences, Beijing, 100190, PR China","Document Type":"Article","Access Type":null,"Source":"Scopus","EID":"2-s2.0-85057856973","Abstract":"In this paper we propose a new neural networks based regularization method requiring only 4 additional hyperparameter and that can be easily injected in any machine learning architecture. It is based on the use of auxiliary loss functions designed to appropriately learn data momenta. Our approach can be used both for classification and regression problems. A comparative analysis with real time series will be provided concerning cryptocurrency data, showing improvements in accuracy of about 5% with respect to existing approaches, without requiring additional training data or further parameters. The presented approach constitutes an innovative, new step towards the statistical moments oriented regularization scheme for statistical forecasting. \u00a9 2018, North Atlantic University Union. All rights reserved.","Author Keywords":"Cryptocurrency; Deep learning; Forecasting; Machine learning; Multitask learning; Neural networks","Index Keywords":"Artificial intelligence; Electronic money; Forecasting; Learning algorithms; Learning systems; Neural networks; Time series analysis; Comparative analysis; Financial forecasting; Multitask learning; Regression problem; Regularization methods; Regularization schemes; Statistical forecasting; Statistical moments; Deep learning","References":"Abe, M., Nakayama, H., Deep Learning for Forecasting Stock Returns in the Cross-Section; Carter, C.K., Kohn, R., (1994) On Gibbs sampling for state space models, 81 (3), pp. 541-553; Chen, R., Liu, J.S., Mixture Kalman filters, 62 (3), pp. 493-508. , Series B: Statistical Methodology; Di Persio, L., Cecchin, A., Cordoni, F., (2017) Novel approaches to the energy load unbalance forecasting in the Italian electricity market, 7 (1), p. 5; Di Persio, L., Perin, I., (2015) An ambit stochastic approach to pricing electricity forward contracts: The case of the German Energy Market, 2015, p. 626020; D\u00e9sir, C., Bernard, S., Petitjean, C., Heutte, L., (2013) One class random forests, 46 (12), pp. 3490-3506; Di Persio, L., Honchar, O., (2017) Analysis of recurrent neural networks for short-term energy load forecasting, 1906, p. 190006; Di Persio, L., Honchar, O., (2016) Artificial neural networks architectures for stock price prediction: Comparisons and applications, 10, pp. 403-413; Cook, T.R., Hall, A.S., Macroeconomic Indicator Forecasting with Deep Neural Networks, pp. 17-111. , Paper No; Dewancker, I., Mccourt, M., A Stratified Analysis of Bayesian Optimization Methods; Krogh, A., Vedelsby, J., (1995) Neural network ensembles, cross validation, and active learning; Ting, K.M., (2011) Encyclopedia of machine learning, , Springer; Liew, J.K.-S., Mayster, B., Forecasting ETFs with Machine Learning Algorithms; Dixon, M.F., A High Frequency Trade Execution Model for Supervised Learning; Qian, X.-Y., Financial Series Prediction: Comparison Between Precision of Time Series Models and Machine Learning Methods; Madge, S., (2015) Predicting Stock Price Direction using Support Vector Machines, , Independent Work Report Spring, Princeton University; Jiao, Y., Ma, C., Scotti, S., Sgarra, C., (2018) A branching process approach to power markets; Tiwari, S., Pandit, R., Richhariya, V., Predicting Stock Price Direction using Support Vector Machines; Qian, X.-Y., Financial Series Prediction: Comparison Between Precision of Time Series Models and Machine Learning Methods; Reddi, S.J., Kale, S., Kumar, S., On the Convergence of Adam and Beyond, , ICLR 2018 Conference Blind Submission; Shumway, R.H., Stoffer, D.S., (1982) AN APPROACH TO TIME SERIES SMOOTHING AND FORECASTING USING THE EM ALGORITHM, 3 (4), pp. 253-264; Zaidi, M., (2016) Forecasting stock market trends with logistic regression and neural networks, 4 (6). , June; Zhang, G.P., (2000) Neural networks for classification: A survey, 30 (4), pp. 451-462; Zhang, Q., Yang, L.T., Chen, Z., Li, P., (2018) A survey on deep learning for big data, 42, pp. 146-157"}
{"Authors":"Le L., Xie Y.","Author(s) ID":"57193344346;55710281400;","Title":"Recurrent Embedding Kernel for Predicting Stock Daily Direction","Year":2019,"Source title":"Proceedings - 5th IEEE\/ACM International Conference on Big Data Computing, Applications and Technologies, BDCAT 2018","Volume":null,"Issue":null,"Art. No.":" 8606647","Page start":160.0,"Page end":166.0,"Page count":null,"Cited by":null,"DOI":"10.1109\/BDCAT.2018.00027","Affiliations":"Institute of Analytics and Data Science, Kennesaw State University, Kennesaw, GA, United States; Department of Information Technology, Kennesaw State University, Kennesaw, GA, United States","Document Type":"Conference Paper","Access Type":null,"Source":"Scopus","EID":"2-s2.0-85061796761","Abstract":"We present an Artificial Neural Network (ANN) approach to predict stock market indices, particularly with respect to the forecast of their trend movements up or down. Exploiting different Neural Networks architectures, we provide numerical analysis of concrete financial time series. In particular, after a brief r\u00b4esum\u00b4e of the existing literature on the subject, we consider the Multi-layer Perceptron (MLP), the Convolutional Neural Networks (CNN), and the Long Short-Term Memory (LSTM) recurrent neural networks techniques. We focus on the importance of choosing the correct input features, along with their preprocessing, for the specific learning algorithm one wants to use. Eventually, we consider the S&P500 historical time series, predicting trend on the basis of data from the past days, and proposing a novel approach based on combination of wavelets and CNN, which outperforms the basic neural networks ones. We show, that neural networks are able to predict financial time series movements even trained only on plain time series data and propose more ways to improve results. \u00a9 2016, North Atlantic University Union. All rights reserved.","Author Keywords":"Artificial neural networks; Convolutional neural network; Deep Learning; Financial forecasting; Long shortterm memory; Multi-layer neural network; Recurrent neural network; Stock markets analysis; Time series analysis","Index Keywords":"Commerce; Convolution; Deep learning; Electronic trading; Financial markets; Forecasting; Learning algorithms; Long short-term memory; Memory architecture; Network layers; Neural networks; Recurrent neural networks; Time series analysis; Convolutional neural network; Convolutional Neural Networks (CNN); Financial forecasting; Financial time series; Multi layer perceptron; Neural networks architecture; Stock market index; Stock price prediction; Network architecture","References":"Bergstra, J., Algorithms for Hyper-Parameter Optimization NIPS 2015; Bennett, J., (2007) The Netflix Prize Proceedings of KDD Cup and Workshop; Benazzoli, C., Di Persio, L., (2016) Default Contagion in Financial Networks International Journal of Mathematics and Computers in Simulation, 10, pp. 112-117; Chen, S.-H., (2002) Genetic Algorithms and Genetic Programming in Computational Finance, , Springer; Chevalier, E., Vath, V.L., Scotti, S., An optimal dividend and investment control problem under debt constraints (2013) SIAM Journal on Financial Mathematics, 4 (1), pp. 297-326; Chevalier, E., Vath, V.L., Scotti, S., Roch, A., Optimal execution cost for liquidation through a limit order market International (2016) Journal of Theoretical and Applied Finance; Cordoni, F., Di Persio, L., Backward stochastic differential equations approach to hedging, option pricing, and insurance problems (2014) (2014) International Journal of Stochastic Analysis; Cordoni, F., Di Persio, L., Invariant measure for the Vasicek interest rate model in the Heath- Jarrow-Morton-Musiela framework (2015) Infinite Dimensional Analysis Quantum Probability and Related Topics, 18 (3); Cordoni, F., Di Persio, L., First order correction for the characteristic function of a multidimensional and multiscale stochastic volatility model (2014) International Journal of Pure and Applied Mathematics, 93 (5), pp. 741-752; Cont, R., Kukanov, A., (2016) Optimal Order Placement in Limit Order Markets Quantitative Finance, pp. 1-19; Di Persio, L., Pellegrini, G., Bonollo, M., Polynomial chaos expansion approach to interest rate models (2015) Journal of Probability and Statistics; Di Persio, L., Frigo, M., Gibbs sampling approach to regime switching analysis of financial time series (2016) Journal of Computational and Applied Mathematics, 300, pp. 43-55; Di Persio, L., Frigo, M., Maximum likelihood approach to markov switching models (2015) WSEAS Transactions on Business and Economics, 12, pp. 239-242; Di Persio, L., Perin, I., (2015) An Ambit Stochastic Approach to Pricing Electricity Forward Contracts, , The case of the German Energy Market, Journal of Probability and Statistics; Dutta, A., Bandopadhyay, G., Sengupta, S., Prediction of Stock Performance in the Indian Stock Market Using Logistic Regression (2012) International Journal of Business and Information; Huang, W., Nakamori, Y., Wang, S.-Y., Forecasting stock market movement direction with support vector machine (2005) Computers and Operations Research, Archive, 32 (10), pp. 2513-2522; Kingma, D.P., Lei Ba, J., (2015) Adam: A Method for Stochastic Optimization, , 3rd Int. Conf. for Learning Representations, San Diego; Krizhevsky, A., Sutskever, I., Hinton, G.E., (2012) Imagenet Classification with Deep Convolutional Neural Networks, NIPS 2012, Nevada; Lauretto, M.S., Silva, B.C., Andrade, P.M., (2013) Evaluation of a Supervised Learning Approach for Stock Market Operations, , arXiv:1301.4944[stat.ML]; Marinelli, C., Di, P., Ziglio, L., Approximation and convergence of solutions to semilinear stochastic evolution equations with jumps (2013) Journal of Functional Analysis, 264 (12), pp. 2784-2816; Pearson, K., On Lines and Planes of Closest Fit to Systems of Points in Space (1901) Philosophical Magazine, 2, p. 559572; Rodan, A., Faris, H., (2016) Credit Risk Evaluation Using Cycle Reservoir Neural Networks with Support Vector Machines Readout Lecture Notes in Computer Science (Including Subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics), 9621, pp. 595-604; Pedregosa, F., Varoquaux, G., Gramfort, A., Michel, V., Thirion, B., Grisel, O., Blondel, M., Duchesnay, E., Scikit-learn: Machine Learning in Python (2011) Journal of Machine Learning Research, 12, pp. 2825-2830; Novak, G., Veluscek, D., (2016) Prediction of Stock Price Movement Based on Daily High Prices Quantitative Finance, 16 (5), pp. 793-826; Tan, C., (2009) Financial Time Series Forecasting Using Improved Wavelet Neural Network, , Master Thesis, University of Aarhus; Wang, Y., Choi, I.-C., Market Index and Stock Price Direction Prediction Using Machine Learning Techniques: An Empirical Study on the KOSPI and HSI, , Technical report, 2013; Kondratenko, V.V., A Kuperin, Y.U., (2003) Using Recurrent Neural Networks to Forecasting of Forex, , arXiv:cond-mat\/0304469 [cond-mat.disnn]"}
{"Authors":"Zheng J., Fu X., Zhang G.","Author(s) ID":"44062068800;57005856100;56949237700;","Title":"Research on exchange rate forecasting based on deep belief network","Year":2019,"Source title":"Neural Computing and Applications","Volume":"31","Issue":null,"Art. No.":null,"Page start":573.0,"Page end":582.0,"Page count":null,"Cited by":3.0,"DOI":"10.1007\/s00521-017-3039-z","Affiliations":"College of Economics, Hangzhou Dianzi University, Hangzhou, 310018, China; Institute of Innovation and Development, Hangzhou Dianzi University, Hangzhou, 310018, China; Institute of Applied Mathematics, Hangzhou Dianzi University, Hangzhou, 310018, China","Document Type":"Article","Access Type":null,"Source":"Scopus","EID":"2-s2.0-85019084658","Abstract":"This paper is intended as a follow up to a previous study of ours - Financial Time Series Forecasting - A Machine Learning Approach. The aforementioned study evaluates traditional machine learning techniques for the task of financial time series forecasting. In this paper, we attempt to make use of the same base dataset, with the difference of making use of a novel branch of machine learning techniques known as Deep Learning. These techniques have been introduced with the objective of moving Machine Learning closer to one of its original goals: Artificial Intelligence. These deep architectures are known to excel in tasks such as image and text recognition, but have not been exploited as much in the field of finance. In particular, for this study we will be making use of Convolutional Neural Networks (CNNs) to forecast the next period price direction with respect to the current price. We achieve an accuracy of 65% when forecasting the next month price direction and 60% for the next week price direction forecast. Whilst these results are anything but random, we are not able to match or surpass results obtained by industry leading techniques such as Logistic Regression and Support Vector Machines.","Author Keywords":"Data science; Deep learning; Fintech; Machine learning; Stock market","Index Keywords":null,"References":"(2017) Deep MNIST for experts, , https:\/\/www.tensorflow.org\/versions\/r0.9\/tutorials\/mnist\/pros\/index.htm, (February); LeCun, Y., (1998) 'Gradient-based learning applied to document recognition, ', , IEEE; LeCun, Y., (2013) 'Convolutional neural networks (LeNet), deep learning 0.1 documentation, ', , University of Montreal; Siripurapu, A., (2014) 'Convolutional Networks for Stock Trading', , Stanford University Department of Computer Science; Kim, K.H., 'Predicting the success of bank telemarketing using deep convolutional neural network, ' (2015) Proc. 7th International Conference of Soft Computing and Pattern Recognition (SoCPaR), , Fukuoka; Ding, X., 'Deep learning for event-driven stock prediction, ' (2015) Proc. the Twenty-Fourth International Joint Conference on Artificial Intelligence; Tang, Y., (2013) 'Deep Learning Using Linear Support Vector Machines', , Department of Computer Science, University of Toronto, Toronto, Ontario, Canada; Glassman, B., (2017) Currency's impact on your portfolio: Five things you need to know now, , https:\/\/www.forbes.com\/sites\/advisor\/2012\/10\/03\/currencys-impact-on-your-portfolio-five-things-you-need-to-know-now\/#71d3bdec5dcb, (February); (2017) Index, , http:\/\/www.investopedia.com\/terms\/i\/index.asp, (January)"}
{"Authors":"Yasir M., Durrani M.Y., Afzal S., Maqsood M., Aadil F., Mehmood I., Rho S.","Author(s) ID":"35231560800;24775626200;57210197386;57197810097;53983838100;36628922400;10738984000;","Title":"An intelligent event-sentiment-based daily foreign exchange rate forecasting system","Year":2019,"Source title":"Applied Sciences (Switzerland)","Volume":"9","Issue":"15","Art. No.":" 2980","Page start":null,"Page end":null,"Page count":null,"Cited by":null,"DOI":"10.3390\/app9152980","Affiliations":"Department of Management Sciences, COMSATS University Islamabad, Attock Campus, Attock, 43600, Pakistan; Department of Computer Science, COMSATS University Islamabad, Attock Campus, Attock, 43600, Pakistan; Department of Media Design and Technology, Faculty of Engineering and Informatics, University of Bradford, Bradford, BD7 1DP, United Kingdom; Department of Software, Sejong University, Seoul, 05006, South Korea","Document Type":"Article","Access Type":"Open Access","Source":"Scopus","EID":"2-s2.0-85070561213","Abstract":"Recurrent neural networks (RNNs) are types of artificial neural networks (ANNs) that are well suited to forecasting and sequence classification. They have been applied extensively to forecasting univariate financial time series, however their application to high frequency trading has not been previously considered. This paper solves a sequence classification problem in which a short sequence of observations of limit order book depths and market orders is used to predict a next event price-flip. The capability to adjust quotes according to this prediction reduces the likelihood of adverse price selection. Our results demonstrate the ability of the RNN to capture the non-linear relationship between the near-term price-flips and a spatio-temporal representation of the limit order book. The RNN compares favorably with other classifiers, including a linear Kalman filter, using S&P500 E-mini futures level II data over the month of August 2016. Further results assess the effect of retraining the RNN daily and the sensitivity of the performance to trade latency. \u00a9 2017 Elsevier B.V.","Author Keywords":"Futures markets; Limit order book; Recurrent neural networks","Index Keywords":"Classification (of information); Commerce; Correlation theory; Costs; Electronic trading; Financial data processing; Financial markets; Forecasting; Neural networks; Financial time series; High-frequency trading; Limit order book; Linear Kalman filters; Non-linear relationships; Recurrent neural network (RNNs); Sequence classification; Short sequences; Recurrent neural networks","References":"Abadi, M., Barham, P., Chen, J., Chen, Z., Davis, A., Dean, J., TensorFlow: a system for large-scale machine learning (2016) Proceedings of the 12th USENIX Conference on Operating Systems Design and Implementation, OSDI'16, pp. 265-283; Bloomfield, R., O'Hara, M., Saar, G., The \u201cmake or take\u201d decision in an electronic market: evidence on the evolution of liquidity (2005) J. Financ. Econ., 75 (1), pp. 165-199; Breiman, L., Statistical modeling: the two cultures (with comments and a rejoinder by the author) (2001) Stat. Sci., 16 (3), pp. 199-231. , ISSN: 0883-4237, 2168-8745; Cao, C., Hansch, O., Wang, X., The information content of an open limit order book (2009) J. Futures Mark., 29, pp. 16-41; Chavez-Casillas, J.A., Figueroa-Lopez, J.E., A one-level limit order book model with memory and variable spread (2017) Stoch. Process. Appl., 127 (8), pp. 2447-2481. , http:\/\/www.sciencedirect.com\/science\/article\/pii\/S0304414916302150, ISSN: 0304-4149; Cont, R., de Larrard, A., Linking volatility with order flow: heavy traffic approximations and diffusion limits of order book dynamics (2010), Working paper; Cont, R., Larrard de, A., Price dynamics in a Markovian limit order market (2013) SIAM J. Financ. Math., 4 (1), pp. 1-25; Cont, R., Stoikov, S., Talreja, R., A stochastic model for order book dynamics (2010) Oper. Res., 58 (3), pp. 549-563. , http:\/\/www.jstor.org\/stable\/40792679, ISSN: 0030364X, 15265463; Cont, R., Kukanov, S., Stoikov, S., The price impact of order book events (2014) J. Financ. Econom., 12, pp. 47-88; Palguna, D., Pollak, I., Mid-price prediction in a limit order book (2014) IEEE J. Select. Top. Signal Process., 10; Dixon, M., Klabjan, D., Bang, J.H., Classification-based financial markets prediction using deep neural networks (2016) Algorithmic Finance; Dixon, M., Polson, N., Sokolov, V., Deep learning for spatio-temporal modeling: Dynamic traffic flows and high frequency trading (2017); Dobrislav, D., Schaumburg, E., High-frequency cross-market trading: model free measurement and applications. Technical report (2016), Federal Reserve Bank of New York; Elman, J.L., Distributed representations, simple recurrent networks, and grammatical structure (1991) Mach. Learn., 7 (2), pp. 195-225. , ISSN: 1573-0565; Engle, R.F., Russell, J.R., Autoregressive conditional duration: a new model for irregularly spaced transaction data (1998) Econometrica, 66 (5), pp. 1127-1162. , http:\/\/www.jstor.org\/stable\/2999632, 14680262; Faraway, J., Chatfield, C., Time series forecasting with neural networks: a comparative study using the air line data (1998) J. R. Stat. Soc.: Ser. C (Appl. Stat.), 47 (2), pp. 231-250; Friedman, J., Hastie, T., Tibshirani, R., Regularization paths for generalized linear models via coordinate descent (2010) J. Stat. Softw., 33 (1), pp. 1-22; Glorot, X., Bengio, Y., Understanding the difficulty of training deep feedforward neural networks (2010) Proceedings of the International Conference on Artificial Intelligence and Statistics (AISTATS? 10). Society for Artificial Intelligence and Statistics; Glosten, L., Is the electronic open limit order book inevitable? (1994) J. Finance, pp. 1127-1161; Graves, A., Generating sequences with recurrent neural networks. CoRR, abs\/1308.0850 (2013), http:\/\/arxiv.org\/abs\/1308.0850; Gultekin, S., Paisley, J., Nonlinear Kalman Filtering with Divergence Minimization (2017); Heaton, J.B., Polson, N.G., Witte, J.H., Deep learning for finance: deep portfolios (2017) Appl. Stoch. Models Bus. Ind., 33 (1), pp. 3-12; Helske, J., KFAS: exponential family state space models in R (2017) J. Stat. Softw., 78 (10), pp. 1-39; Kaastra, L., Boyd, M.S., Forecasting futures trading volume using neural networks (1995) J. Futures Mark., 15 (8), pp. 953-970. , ISSN: 1096-9934; Kearns, M., Nevmyvaka, Y., Machine learning for market microstructure and high frequency trading (2013) High Frequency Trading \u2013 New Realities for Traders; Kercheval, A., Zhang, Y., Modeling high-frequency limit order book dynamics with support vector machines (2015) J. Quant. Finance, 15 (8), pp. 1315-1329; Leung, M., Daouk, H., Chen, A., Forecasting stock indices: a comparison of classification and level estimation models (2000) Int. J. Forecast., 16 (2), pp. 173-190; Parlour, C., Price dynamics in limit order markets (1998) Rev. Financ. Stud., 11, pp. 789-816; Refenes, A., Neural Networks in the Capital Markets (1994), John Wiley & Sons, Inc. New York, NY, USA; Rojas, R., Neural Networks: A Systematic Introduction (1996), Springer-Verlag New York, Inc. New York, NY, USA; Seppi, D., Liquidity provision with limit orders and a strategic specialist (1997) Rev. Financ. Stud., 10, pp. 103-150; Simon, N., Friedman, J., Hastie, T., Tibshirani, R., Regularization paths for Cox's proportional hazards model via coordinate descent (2011) J. Stat. Softw., 39 (5), pp. 1-13; Sirignano, J.A., Deep learning for limit order books (2016); Srivastava, N., Hinton, G.E., Krizhevsky, A., Sutskever, I., Salakhutdinov, R., Dropout: a simple way to prevent neural networks from overfitting (2014) J. Mach. Learn. Res., 15 (1), pp. 1929-1958; Tran, D., Hoffman, D.M., Saurous, A.R., Brevdo, E., Murphy, K., Blei, M.D., Deep probabilistic programming (2017); Trippi, R., DeSieno, D., Trading equity index futures with a neural network (1992) J. Portf. Manag., 19 (1), pp. 27-33; Zheng, B., Moulines, E., Abergel, F., Price jump prediction in a limit order book (2013) J. Math. Finance, 3, pp. 242-255"}
{"Authors":"Zhang C., Dai Q., Song G.","Author(s) ID":"56072612200;35315440400;57104239400;","Title":"DeepCascade-WR: a cascading deep architecture based on weak results for time series prediction","Year":2019,"Source title":"International Journal of Machine Learning and Cybernetics","Volume":null,"Issue":null,"Art. No.":null,"Page start":null,"Page end":null,"Page count":null,"Cited by":null,"DOI":"10.1007\/s13042-019-00994-7","Affiliations":"College of Computer Science and Technology, Nanjing University of Aeronautics and Astronautics, Nanjing, 211106, China","Document Type":"Article","Access Type":null,"Source":"Scopus","EID":"2-s2.0-85070276611","Abstract":"Time series forecasting is one of the most effective ways to settle the elusive problems of increased penetration of energy industry and financial field. In recent years, neural networks are utilized in time series forecasting owing to the rationality and practicability. However, neural networks always overrate the performance of training data, which results in underestimating the test error. In this work, four important training tactics are proposed for the training and modeling of the networks, and the proposed model has a better forecasting result and a better extrapolation performance. The numerical simulation shows that the proposed methods have broader application in time series forecasting, it is not only effective for over-fitting problems but also has promoted the model accuracy considerably. \u00a9 2017 Elsevier B.V.","Author Keywords":"Artificial neural networks; Convolutional neural networks; Feature learning; Time series forecasting","Index Keywords":"Neural networks; Numerical methods; Rectifying circuits; Time series; Convolutional neural network; Energy industry; Feature learning; Over fitting problem; Perceptron neural networks; Research and application; Time series forecasting; Training tactics; Forecasting","References":"Azirah, S.A., Hussin, B., Yusof, M., A data-driven prognostic model for industrial equipment using time series prediction methods (2013) Am. Mineral., 90, pp. 586-591; Galar, D., Thaduri, A., Catelani, M., Ciani, L., Context awareness for maintenance decision making: a diagnosis and prognosis approach (2015) Measurement, 67, pp. 137-150; Tran, V.T., Yang, B.S., Tan, A.C.C., Multi-step Ahead Direct Prediction for the Machine Condition Prognosis Using Regression Trees and Neuro-fuzzy Systems (2009), Pergamon Press Inc; Mcnaught, K.R., Zagorecki, A., Using dynamic Bayesian networks for prognostic modelling to inform maintenance decision making (2010) IEEE Int. Conf. Ind. Eng. Eng. Manag., pp. 1155-1159; Baraldi, P., Mangili, F., Zio, E., Investigation of uncertainty treatment capability of model-based and data-driven prognostic methods using simulated data (2013) Reliab. Eng. Syst. Saf., 112, pp. 94-108; Wang, W., Carr, M., A stochastic filtering based data driven approach for residual life prediction and condition based maintenance decision making support (2010) Progn. Heal. Manag. Conf., pp. 1-10; Oikonomou-Filandras, P.A., Wong, K.K., Zhang, Y., Informed scheduling by stochastic residual belief propagation in distributed wireless networks (2015) IEEE Wirel. Commun. Lett., 4, pp. 90-93; Zhang, L., Suganthan, P.N., A Survey of Randomized Algorithms for Training Neural Networks (2016), Elsevier Science Inc; Donate, J.P., Cortez, P., S\u00e1nchez, G.G., De Miguel, A.S., Time series forecasting using a weighted cross-validation evolutionary artificial neural network ensemble (2013) Neurocomputing, 109, pp. 27-32; Krizhevsky, A., Sutskever, I., Hinton, G.E., ImageNet classification with deep convolutional neural networks (2012) Int. Conf. Neural Inf. Process. Syst., pp. 1097-1105; Wang, X., Ma, J., Wang, S., Bi, D., Time series forecasting for energy-efficient organization of wireless sensor networks (2007) Sensors, 7, pp. 1766-1792; Sfetsos, A., Siriopoulos, C., Time series forecasting of averaged data with efficient use of information (2005) IEEE Trans. Syst. Man, Cybern. \u2212 Part A Syst. Hum., 35, pp. 738-745; Lee, C.H., Chang, F.Y., Lin, C.M., An efficient interval type-2 fuzzy CMAC for chaos time-Series prediction and synchronization (2014) IEEE Trans. Cybern., 44, pp. 329-341; Tao, Q.Q., Zhan, S., Li, X.H., Kurihara, T., Robust face detection using local CNN and SVM based on kernel combination (2016) Neurocomputing, 211, pp. 98-105; Chen, C.P., A rapid supervised learning neural network for function interpolation and approximation (1996) IEEE Trans. Neural Networks, 7, p. 1220; Ramirez-Quintana, J.A., Chacon-Murguia, M.I., Self-adaptive SOM-CNN Neural System for Dynamic Object Detection in Normal and Complex Scenarios (2015), Elsevier Science Inc; Gordon, N.J., Salmond, D.J., Smith, A.F.M., Novel approach to nonlinear\/non-Gaussian Bayesian state estimation (2002) IEE Proc. F \u2212 Radar Signal Process., 140, pp. 107-113; Krizhevsky, A., Sutskever, I., Hinton, G.E., Hinton. ImageNet classification with deep convolutional neural networks (2012) International Conference on Neural Information Processing Systems Curran Associates Inc., pp. 1097-1105; Simonyan, K., Zisserman, A., Very deep convolutional networks for large-Scale image recognition (2014) Comput. Sci., , ICLR 2015; Srivastava, R.K., Greff, K., Schmidhuber, J., Training very deep networks (2015) Comput. Sci., , eprint arXiv:1507.06228 Publication Date 06\/2015; Srivastava, R.K., Greff, K., Schmidhuber, J., Highway networks (2015) Comput. Sci., , eprint arXiv:1505.00387 Publication Date 02\/2015; Hamilton, J.D., A new approach to the economic analysis of nonstationary time series and the business cycle (1989) Econometrica, 57, pp. 357-384; Borucki, S., Boczar, T., Cichon, A., Lorenc, M., The evaluation of neural networks application for recognizing single-source PD forms generated in paper-oil insulation systems based on the AE signal analysis (2008) Eur. Phys. J. Spec. Top., 154, pp. 23-29; Nanda, J., Sachan, A., Pradhan, L., M.L.B.T.-A, Operation and management, 1997. apscom-97 (1997) Fourth International Conference On, Application of Artificial Neural Network to Economic Load Dispatch, 2, pp. 707-711. , P.S.C. Kothari; Yip, D.H.F., Hines, E.L., (2002), 4, pp. 2121-2124. , W.W.H.B.T.-I.C. on N.N. Yu Application of artificial neural networks in sales forecasting; Kalogirou, S.A., Applications of artificial neural-networks for energy systems (2000) Appl. Energy, 67, pp. 17-35; Vafaei, M., Afrand, M., Sina, N., Kalbasi, R., Sourani, F., Teimouri, H., Evaluation of thermal conductivity of MgO-MWCNTs\/EG hybrid nanofluids based on experimental data by selecting optimal artificial neural networks (2017) Phys. E Low-Dimensional Syst. Nanostructures., 85, pp. 90-96; Lauret, P., Heymes, F., Aprin, L., Johannet, A., Atmospheric dispersion modeling using Artificial Neural Network based cellular automata (2016) Environ. Model. Softw., 85, pp. 56-69; Santamaria-Bonfil, G., Reyes-Ballesteros, A., Gershenson, C., Wind speed forecasting for wind farms: a method based on support vector regression (2016) Renew. Energy, 85, pp. 790-809; Rubio, A., Berm\u00fadez, J.D., Vercher, E., Forecasting portfolio returns using weighted fuzzy time series methods (2016) Int. J. Approx. Reason., 75, pp. 1-12; Wang, S., Zhang, N., Wu, L., Wang, Y., Wind speed forecasting based on the hybrid ensemble empirical mode decomposition and GA-BP neural network method (2016) Renew. Energy, 94, pp. 629-636; Wang, Y., Wu, L., On practical challenges of decomposition-based hybrid forecasting algorithms for wind speed and solar irradiation (2016) Energy, 112, pp. 208-220; Zhang, C., Wei, H., Zhao, J., Liu, T., Zhu, T., Zhang, K., Short-term wind speed forecasting using empirical mode decomposition and feature selection (2016) Renew. Energy, 96, pp. 727-737; Camu, N., De Winter, T., Addo, S.K., Takrama, J.S., Bernaert, H., De Vuyst, L., Fermentation of cocoa beans: influence of microbial activities and polyphenol concentrations on the flavour of chocolate (2008) J. Sci. Food Agric., 88, pp. 2288-2297; Lopes, A.T., De Aguiar, E., De Souza, A.F., Oliveira-Santos, T., Facial expression recognition with Convolutional Neural Networks: coping with few data and the training sample order (2017) Pattern Recognit., 61, pp. 610-628; Chen, D., Cao, X., Wen, J.B.T.-C.V., Blessing of Dimensionality: High-Dimensional Feature and Its Efficient Compression for Face Verification (2013), pp. 3025-3032; He, K., Zhang, X., Ren, S., Sun, J., Delving Deep into Rectifiers: Surpassing Human-Level Performance on ImageNet Classification (2015), pp. 1026-1034; Yuan, C., Lin, H.T., Yang, S.W., Cost-aware pre-training for multiclass cost-sensitive deep learning (2015) Comput. Sci., , eprint arXiv:1511.09337v3 Publication Date 05\/2016; Bociort, F., Serebriakov, A., Braat, J.J.M.B.T.-I.O.D.C., Local Optimization Strategies to Escape from Poor Local Minima (2002); Vincent, P., Larochelle, H., Lajoie, I., Bengio, Y., Manzagol, P.A., Stacked denoising autoencoders: learning useful representations in a deep network with a local denoising criterion (2010) J. Mach. Learn. Res., 11, pp. 3371-3408; Simonyan, K., Zisserman, A., Very deep convolutional networks for large-Scale image recognition (2014) Comput. Sci., , ICLR 2015; Qiu, X., Zhang, L., Ren, Y., Suganthan, P.N., G.B.T.-C.I, (2015) Ensemble Deep Learning for Regression and Time Series Forecasting, pp. 1-6. , E.L. Amaratunga; Mukhopadhyay, S., Parzen, E., Nonlinear time series modeling by LPTime, nonparametric empirical learning (2013) Statistics (Ber); Deng, J., Dong, W., Socher, R., Li, L.J., Li, K., F.F.B.T.-C.V, Li, P.R., Cvpr 2009 (2009) IEEE Conference On, ImageNet: A Large-scale Hierarchical Image Database, pp. 248-255; Fan, J., Xu, W., Wu, Y., Gong, Y., Human tracking using convolutional neural networks (2010) IEEE Trans. Neural Networks, 21, pp. 1610-1623; Chandrasekhar, V., Lin, J., Goh, H., Veillard, A., A practical guide to CNNs and Fisher Vectors for image instance retrieval (2016) Signal Proces., 128, pp. 426-439; Candes, E.J., Tao, T., Decoding by linear programming (2005) IEEE Trans. Inf. Theory, 51, pp. 4203-4215; Elleuch, M., Maalej, R., Kherallah, M., A new design based-SVM of the CNN classifier architecture with dropout for offline arabic handwritten recognition (2016) Procedia Comput. Sci., 80, pp. 1712-1723; Russakovsky, O., Deng, J., Su, H., Krause, J., Satheesh, S., Ma, S., Huang, Z., Bernstein, M., ImageNet large scale visual recognition challenge (2014) Int. J. Comput. Vis., 115, pp. 211-252; L\u00e4ngkvist, M., Karlsson, L., Loutfi, A., A review of unsupervised feature learning and deep learning for time-series modeling (2014) Pattern Recognit. Lett., 42, pp. 11-24; Boese, K.D., (1993), 4, pp. 2572-2575. , A.B.B.T.-I.I.S. on C. and S. Kahng Simulated annealing of neural networks: The \u2018cooling\u2019 strategy reconsidered; Long, J., Shelhamer, E., T.B.T.-C.V, Darrell, P.R., Fully Convolutional Networks for Semantic Segmentation (2015), pp. 3431-3440; Pao, Y.H., Takefuji, Y., Functional-link net computing: theory system architecture, and functionalities (1992) Computer (Long. Beach. Calif), 25, pp. 76-79; Tu, Y., Yi, Y., Forecasting cointegrated nonstationary time series with time-varying variance (2017) J. Econ., 196, pp. 83-98; Batselier, J., Vanhoucke, M., Improving project forecast accuracy by integrating earned value management with exponential smoothing and reference class forecasting (2017) Int. J. Proj. Manage., 35, pp. 28-43; Gori, M., Tesi, A., On the problem of local minima in backpropagation (1992) Pattern Anal. Mach. Intell. IEEE Trans., 14, pp. 76-86; Igelnik, B., Pao, Y.H., Stochastic choice of basis functions in adaptive function approximation and the functional-link net (1995) IEEE Trans. Neural Networks, 6, p. 1320; Jarrett, K., Kavukcuoglu, K., Ranzato, M., YBT-IIC, (2010) What Is the Best Multi-stage Architecture for Object Recognition?, pp. 2146-2153. , C.V. Lecun; Lecun, Y., Bottou, L., Bengio, Y., Haffner, P.B.T.-I., Gradient-Based Learning Applied to Document Recognition (1998), pp. 2278-2324; Palivonaite, R., Ragulskis, M., Short-term Time Series Algebraic Forecasting with Internal Smoothing (2014), Elsevier Science Publishers B.V; Wang, J., Liu, F., Song, Y., Zhao, J., A novel model: dynamic choice artificial neural network (DCANN) for an electricity price forecasting system (2016) Appl. Soft Comput., 48, pp. 281-297; Pravilovic, S., Bilancia, M., Appice, A., Malerba, D., Using multiple time series analysis for geosensor data forecasting (2016) Inf. Sci. (Ny), 380; Aram, Z., Jafari, S., Ma, J., Sprott, J.C., Zendehrouh, S., Pham, V.T., Using chaotic artificial neural networks to model memory in the brain (2017) Commun. Nonlinear Sci. Numer. Simul., 44, pp. 449-459; Askari, S., Montazerin, N., Zarandi, M.H.F., A clustering based forecasting algorithm for multivariable fuzzy time series using linear combinations of independent variables (2015) Appl. Soft Comput., 35, pp. 151-160; Kumar, L., Rath, S.K., Hybrid functional link artificial neural network approach for predicting maintainability of object-oriented software (2016) J. Syst. Softw., 121, pp. 170-190; Norets, A., Estimation of dynamic discrete choice models using artificial neural network approximations (2012) Econom. Rev., 31, pp. 84-106; Rao, A.M., Durai, B.K., Travel Mode Choice Modeling Using Artificial Neural Networks (ANN) (2012), https:\/\/www.lap-Publishing.com\/; Morando, S., Jemei, S., Hissel, D., Gouriveau, R., Zerhouni, N., ANOVA method applied to proton exchange membrane fuel cell ageing forecasting using an echo state network (2015) Math. Comput. Simul., 131, pp. 283-294; Durbach, I., Merven, B., Mccall, B., Expert Elicitation of Autocorrelated Time Series with Application to e3 (energy-environment-economic) Forecasting Models (2017), Elsevier Science Publishers B.V; Brentan, B.M., Luvizotto, M., Jr, Herrera, J., P\u00e9rez-Garc\u00eda, R., Hybrid regression model for near real-time urban water demand forecasting (2016) J. Comput. Appl. Math., 309, pp. 532-541; Yolcu, O.C., Yolcu, U., Egrioglu, E., Aladag, C.H., High order fuzzy time series forecasting method based on an intersection operation (2016) Appl. Math. Model., 40, pp. 8750-8765; Corr\u00eaa, J.M., Neto, A.C., Teixeira J\u00faniorc, L.A., Franco, E.M.C., Faria, A.E., Jr., ime series forecasting with the WARIMAX-GARCH method (2016) Neurocomputing, 216, pp. 805-815; Hou, C., Nie, F., Li, X., Yi, D., Wu, Y., Joint embedding learning and sparse regression: a framework for unsupervised feature selection (2017) IEEE Trans. Cybern., 44 (6), pp. 793-804; Ng, A., Unsupervised Feature Learning and Deep Learning (2017), (n.d.); Sterling, S., Sustainable education-Towards a deep learning response to unsustainability (2008) Policy Pract. \u2212 A Dev. Educ. Rev., 6; Zhao, X., Shi, X., Zhang, S., Facial expression recognition via deep learning (2015) Iete Tech. Rev., 32, pp. 347-355; Gao, S., Tian, J., Wang, F., Bai, Y., (2015), Q.B.T.-I.C. on M. Yang Simulation and Applied Mathematics, The Study of GRNN for Wind Speed Forecasting Based on Markov Chain, in; Sideratos, G., Hatziargyriou, N.B.T.-P.E.S.G.M., Using Radial Basis Neural Networks to Estimate Wind Power Production (2007), pp. 1-7; Cao, Q., Ewing, B.T., Thompson, M.A., Forecasting wind speed with recurrent neural networks (2012) Eur. J. Oper. Res., 221, pp. 148-154; Liu, H., Tian, H.Q., Li, Y.F., Comparison of new hybrid FEEMD-MLP, FEEMD-ANFIS Wavelet Packet-MLP and Wavelet Packet-ANFIS for wind speed predictions (2015) Energy Convers. Manage., 89, pp. 1-11; Dur\u00e3o, R.M., Mendes, M.T., Pereira, M.J., Forecasting O 3 levels in industrial area surroundings up to 24\u202fh in advance, combining classification trees and MLP models (2016) Atmos. Pollut. Res., 7, pp. 961-970; Ebrahimpour, R., Nikoo, H., Masoudnia, S., Yousefi, M.R., Ghaemi, M.S., Mixture of MLP-experts for trend forecasting of time series: a case study of the Tehran stock exchange (2011) Int. J. Forecast., 27, pp. 804-816; Azimi, R., Ghayekhloo, M., Ghofrani, M., A hybrid method based on a new clustering technique and multilayer perceptron neural networks for hourly solar radiation forecasting (2016) Energy Convers. Manage., 118, pp. 331-344; He, X., Ji, M., Zhang, C., Bao, H., A variance minimization criterion to feature selection using laplacian regularization (2011) IEEE Trans. Pattern Anal. Mach. Intell., 33, pp. 2013-2025; Vasudevan, A.R., Selvakumar, S., Intraclass and interclass correlation coefficient-based feature selection in NIDS dataset (2016) Secur. Commun. Networks, 8, pp. 3441-3458; Zhang, H., Li, L., Luo, C., Sun, C., Chen, Y., Dai, Z., Yuan, Z., Informative gene selection and direct classification of tumor based on Chi-square test of pairwise gene interactions (2014) Biomed Res. Int., 2014, p. 589290; Amiri, F., Yousefi, M.M.R., Lucas, C., Shakery, A., Yazdani, N., Mutual information-based feature selection for intrusion detection systems (2011) J. Netw. Comput. Appl., 34, pp. 1184-1199; Hu, C., Raman spectra exploring breast tissues: comparison of principal component analysis and support vector machine-recursive feature elimination (2013) Med. Phys., 40 (6). , (063501); Liang, Y., Wang, L., Yao, X., Zou, B., Feature selection via sparse approximation for face recognition (2011) Comput. Sci. \u2212 Comput. Vis. Pattern Recognit., , eprint arXiv:1102.2748 Publication Date: 02\/2011"}
{"Authors":"Moro G., Pasolini R., Domeniconi G., Ghini V.","Author(s) ID":"8702087400;56412031400;56411905800;6507031598;","Title":"Deep Neural Trading: Comparative Study with Feed Forward, Recurrent and Autoencoder Networks","Year":2019,"Source title":"Communications in Computer and Information Science","Volume":"862","Issue":null,"Art. No.":null,"Page start":189.0,"Page end":209.0,"Page count":null,"Cited by":null,"DOI":"10.1007\/978-3-030-26636-3_9","Affiliations":"Department of Computer Science and Engineering, University of Bologna, Via dell\u2019Universit\u00e0, 50, Cesena, 47522, Italy; IBM TJ Watson Research Center, 1101 Kitchawan Road, Yorktown Heights, NY  10598, United States","Document Type":"Conference Paper","Access Type":null,"Source":"Scopus","EID":"2-s2.0-85070196844","Abstract":"Due to the extensive application of deep learning in processing time series and recent progress, LSTM (Long Short-Term Memory) neural network is the most commonly used and most powerful tool for time series models. The LSTM neural network is used to predict Apple stocks by using single feature input variables and multi-feature input variables to verify the prediction effect of the model on stock time series. The experimental results show that the model has a high accuracy of 0.033 for the multivariate input and is accurate, which is in line with the actual demand. For the univariate feature input, the predicted squared absolute error is 0.155, which is inferior to the multi-feature variable input. \u00a9 2019 IEEE.","Author Keywords":"LSTM; Multivariate feature input; RNN; Stock price; Univariate feature input","Index Keywords":"Costs; Deep learning; Electronic trading; Financial markets; Forecasting; Time series; Feature input; Forecasting stock prices; LSTM; Processing time; Recent progress; Stock price; Stock time series; Time series models; Long short-term memory","References":"Deng, F., Wang, H., Application of lstm neural network in stock price trend forecast-based on the research of stock market data in us and Hong Kong stock markets[J] (2018) Financial Economy, 14, pp. 96-98; Ma, C., Wang, X., Forecast of vegetable sales based on lstm network model[J] (2018) Modern Computer (Professional Edition), 23, pp. 26-30; Bao, W., Yue, J., Rao, Y., A deep learning framework for financial time series using stacked autoencoders and long-short term memory[J] (2017) Plos One, 12, p. 7; Zachary, C.L., John, B., Charles, E., A critical review of recurrent neural networks for sequence learning[m] (2015) Computer Science; Hochreiter, S., Schmidhuber, J., Long short-term memory[J] (1997) Neural Computation, 9 (8), pp. 1735-1780; Lipton, Z.C., Berkowitz, J., Elkan, C., (2015) A Critical Review of Recurrent Neural Networks for Sequence Learning[J], , arXiv preprint arXiv : 1506.00019; Liang, J., Chai, Y., Yuan, H., Sentiment analysis based on polar transfer and lstm recursive network[J] (2015) Journal of Chinese Information Processing, 29 (5), pp. 152-160; Bao, Z., Zhou, Y., Study on the extraction of fresh comment keywords based on lstm[J] (2018) Fujian Computer, 34 (10), pp. 90-92; Soltau, H., Liao, H., Sak, H., Neural speech recognizer: Acoustic-to-word (2016) LSTM Model for Large Vocabulary Speech Recognition[J], pp. 3707-3711; Glorot, X., Bordes, A., Bengio, Y., Deep sparse rectifier neural networks[C] (2011) International Conference on Artificial Intelligence and Statis-tics; Bahdanau, D., Cho, K., Bengio, Y., (2016) Neural Machine Translation by Jointly Learningto Align and Translate[J\/OL].[, , https:\/\/arxiv.org\/pdf\/1409.0473.pdf; Chen, Z., Hu, W., Simplified speech synthesis of lstm[J] (2018) Computer Engineering and Applications, 54 (3), pp. 131-135"}
{"Authors":"Weytjens H., Lohmann E., Kleinsteuber M.","Author(s) ID":"37071509600;57195594980;8257006600;","Title":"Cash flow prediction: MLP and LSTM compared to ARIMA and Prophet","Year":2019,"Source title":"Electronic Commerce Research","Volume":null,"Issue":null,"Art. No.":null,"Page start":null,"Page end":null,"Page count":null,"Cited by":null,"DOI":"10.1007\/s10660-019-09362-7","Affiliations":"Gruenwald, Germany; Mercateo AG, Munich, Germany; Technische Universit\u00e4t M\u00fcnchen (TUM), Munich, Germany","Document Type":"Article","Access Type":null,"Source":"Scopus","EID":"2-s2.0-85069515246","Abstract":"Time series forecasting has been regarded as a key research problem in various fields. such as financial forecasting, traffic flow forecasting, medical monitoring, intrusion detection, anomaly detection, and air quality forecasting etc. In this paper, we propose a sequence-to-sequence deep learning framework for multivariate time series forecasting, which addresses the dynamic, spatial-temporal and nonlinear characteristics of multivariate time series data by LSTM based encoder-decoder architecture. Through the air quality multivariate time series forecasting experiments, we show that the proposed model has better forecasting performance than classic shallow learning and baseline deep learning models. And the predicted PM2.5 value can be well matched with the ground truth value under single timestep and multi-timestep forward forecasting conditions. The experiment results show that our model is capable of dealing with multivariate time series forecasting with satisfied accuracy. \u00a9 2018 IEEE.","Author Keywords":"Encoder-decoder; LSTM; PM2.5; Sequence-to-sequence deep learning; Time series forecasting","Index Keywords":"Air quality; Anomaly detection; Decoding; Forecasting; Intrusion detection; Long short-term memory; Parallel architectures; Signal encoding; Time series; Encoder-decoder; Encoder-decoder architecture; LSTM; Multivariate time series; Nonlinear characteristics; PM2.5; Time series forecasting; Traffic flow forecasting; Deep learning","References":"De Gooijer, J.G., Hyndman, R.J., 25 Years of time series forecasting (2006) International Journal of Forecasting, 22 (3), pp. 443-473; Fu, T., A review of time series data mining (2011) Engineering Applications of Artificial Intelligence, 24 (1), pp. 164-181; Zhang, G.P., Time series forecasting using a hybrid arima and neural network model (2003) Neurocomputing, 50, pp. 159-175; Pai, P.F., Lin, K.P., Lin, C.S., Time series forecasting by a seasonal support vector regression model (2010) Expert Systems with Applications, 37 (6), pp. 4261-4265; Zhang, G.P., Qi, M., Neural network forecasting for seasonal and trend time series (2005) European Journal of Operational Research, 160 (2), pp. 501-514; L\u00e4ngkvist, M., Karlsson, L., Loutfi, A., A review of unsupervised feature learning and deep learning for time-series modeling (2014) Pattern Recognition Letters, 42, pp. 11-24; Schmidhuber, J., Deep learning in neural networks: An overview (2015) Neural Networks, 61, pp. 85-117; Krizhevsky, A., Sutskever, I., Hinton, G.E., Imagenet classification with deep convolutional neural networks (2012) Proceedings of Advances in Neural Information Processing Systems., pp. 1097-1105; Karpathy, A., Li, F.F., Deep visual-semantic alignments for generating image descriptions (2015) Proceedings of the 2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), pp. 3128-3137; Cho, K., Van Merri\u00ebnboer, B., G\u00fcl\u00e7ehre, C., Bahdanau, D., Bougares, F., Schwenk, H., Bengio, Y., Learning phrase representations using rnn encoder-decoder for statistical machine translation (2014) Proc. Of 2014 Conf. On Empirical Methods in Natural Language Processing(EMNLP), pp. 1724-1734. , Oct; Gamboa, J.C.B., (2017) Deep Learning for Time-series Analysis, , arXiv preprint arXiv: 1701.01887; Lipton, Z.C., Kale, D.C., Elkan, C., (2015) Learning to Diagnose with LSTM Recurrent Neural Networks, , arXiv preprint arXiv: 1511.03677; Sutskever, I., Vinyals, O., Le, Q.V., Sequence to sequence learning with neural networks [C] (2014) Advances in Neural Information Processing Systems., pp. 3104-3112; Laptev, N., Yosinski, J., Li, L.E., Time-series extreme event forecasting with neural networks at uber [C] (2017) International Conference on Machine Learning., (34), pp. 1-5; Park, S.H., Lee, J.H., Song, J.W., Forecasting change directions for financial time series using hidden markov model [C] (2009) International Conference on Rough Sets and Knowledge Technology., pp. 184-191. , Springer, Berlin, Heidelberg; Hassan, M.R., Nath, B., Kirley, M., A hybrid of multiobjective evolutionary algorithm and hmm-fuzzy model for time series prediction (2012) Neurocomputing, 81, pp. 1-11; Ahmed, N.K., Atiya, A.F., Gayar, N.E., An empirical comparison of machine learning models for time series forecasting (2010) Econometric Reviews, 29 (5-6), pp. 594-621; Yao, S., Hu, S., Zhao, Y., Deepsense: A unified deep learning framework for time-series mobile sensing data processing [C] (2017) Proceedings of the 26th International Conference on World Wide Web. International World Wide Web Conferences Steering Committee, pp. 351-360; Chambon, S., Galtier, M.N., Arnal, P.J., A deep learning architecture for temporal sleep stage classification using multivariate and multimodal time series (2018) IEEE Transactions on Neural Systems and Rehabilitation Engineering; Freeman, B.S., Taylor, G., Gharabaghi, B., Forecasting air quality time series using deep learning (2018) Journal of the Air & Waste Management Association, pp. 1-21; Venugopalan, S., Rohrbach, M., Donahue, J., Sequence to sequencevideo to text [C] (2015) Proceedings of the IEEE International Conference on Computer Vision., pp. 4534-4542; Kuznetsov, V., Mariet, Z., (2018) Foundations of Sequence-To-Sequence Modeling for Time Series, , arXiv preprint arXiv: 1805.03714; Beijing PM2.5 Data Set, , https:\/\/archive.ics.uci.edu\/ml\/datasets\/Beijing+PM2.5+Data, [Online]; Hochreiter, S., Schmidhuber, J., Long short-Term memory (1997) Neural Computation, 9 (8), pp. 1735-1780; Kingma, D.P., Ba, J., (2014) Adam: A Method for Stochastic Optimization, , arXiv preprint arXiv: 1412.6980"}
{"Authors":"Liashenko O., Kravets T.","Author(s) ID":"57210112572;14063413700;","Title":"The relationship between oil and gas prices, dow jones and US dollar indexes: A wavelet co-movement estimation and neural network forecasting","Year":2019,"Source title":"CEUR Workshop Proceedings","Volume":"2393","Issue":null,"Art. No.":null,"Page start":348.0,"Page end":363.0,"Page count":null,"Cited by":null,"DOI":null,"Affiliations":"Taras Shevchenko National University of Kyiv, Ukraine","Document Type":"Conference Paper","Access Type":null,"Source":"Scopus","EID":"2-s2.0-85069440052","Abstract":"The motivation for this paper is to investigate the use of alternative novel neural network (NN) architectures when applied to the task of forecasting and trading the euro\/dollar (EUR\/USD) exchange rate, using the European Central Bank (ECB) fixing series with only auto-regressive terms as inputs. This is done by benchmarking four different NN designs representing a higher-order neural network (HONN), a Psi Sigma Network and a recurrent neural network with the classic multilayer perception (MLP) and some traditional techniques,either statistical such as an auto-regressive moving average model,or technical such as a moving average convergence\/divergence model, plus a na\u00efve strategy. More specifically, the trading performance of all models is investigated in a forecast and trading simulation on the EUR\/USD ECB fixing time series over the period 1999-2007 using the last one and half years for out-of-sample testing, an original feature of this paper. We use the EUR\/USD daily fixing by the ECB as many financial institutions are ready to trade at this level and it is therefore possible to leave orders with a bank for business to be transacted on that basis. As it turns out, the MLP does remarkably well and outperforms all other models in a simple trading simulation exercise. However, when more sophisticated trading strategies using confirmation filters and leverage are applied, the HONN network produces better results and outperforms all other NN and traditional statistical models in terms of annualized return. \u00a9 2010 Taylor & Francis.","Author Keywords":"Confirmation filters; Higher-order neural networks; Leverage; Multi-layer perception networks; Psi Sigma networks; Quantitative trading strategies; Recurrent neural networks","Index Keywords":null,"References":"Andersen, T.G., S\u00f8rensen, B.E., GMM estimation of a stochastic volatility model:A Monte Carlo study (1996) Journal of Business & Economic Statistics, 14 (3), pp. 328-352; Andrews, D.W.K., Heteroskedasticity and autocorrelation consistent covariance matrix estimation (1991) Econometrica, 59 (3), pp. 817-858; Andrews, D.W.K., Monahan, J.C., An improved heteroskedasticity and autocorrelation consistent covariance matrix estimator (1992) Econometrica, 60 (4), pp. 953-966; Benth, F.E., \u0160altyte-Benth, J., Stochastic modelling of temperature variations with a view towards weather derivatives (2005) Applied Mathematical Finance, 12 (1), pp. 53-85; Caballero, R., Jewson, S., Brix, A., Long memory in surface air temperature: Detection, modelling and application to weather derivative valuation (2002) Climate Research, 21 (2), pp. 127-140; Campbell, S.D., Diebold, F.X., Weather forecasting for weather derivatives (2005) Journal of The American Statistical Association, 100 (469), pp. 6-16; Cao, M., Wei, J., Weather derivatives valuation and market price of weather risk (2004) The Journal of Futures Markets, 24 (11), pp. 1065-1089; Chiang, M., Kao, C., Spectral density bandwidth choice and prewhitening in the generalized method of moments estimators for the asset pricing model (2005) Economics Bulletin, 3 (10), pp. 1-13; Constantinides, G.M., Duffie, D., Asset pricing with heterogeneous consumers (1996) Journal of Political Economy, 104 (2), pp. 219-240; Duffie, D., Singleton, K.J., Simulated moments estimation of Markov models of asset prices (1993) Econometrica, 61 (4), pp. 929-952; Ferson, W.E., Constantinides, G.M., Habit persistence and durability in aggregate consumption (1991) Journal of Financial Economics, 29 (2), pp. 199-240; Hamisultane, H., (2006) Pricing the Weather Derivatives In the Presence of Long Memory In Temperatures, , http:\/\/helene-hamisultane.site.voila.fr, Working Paper. University of Paris X-Nanterre; Hansen, L.P., Large sample properties of generalized method of moments estimators (1982) Econometrica, 50 (4), pp. 1029-1054; Hansen, L.P., Singleton, K.J., Generalized instrumental variables estimation of nonlinear rational expectations models (1982) Econometrica, 50 (5), pp. 1269-1286; Lee, B., Ingram, B.F., Simulation estimation of time-series models (1991) Journal of Econometrics, 47 (2), pp. 197-205; Lucas Jr., R.E., Asset prices in an exchange economy (1978) Econometrica, 46 (6), pp. 1429-1445; Lund, J., Engsted, T., GMM and present value tests of the C-CAPM: Evidence from the Danish, German, Swedish and UK stock markets (1996) Journal of International Money and Finance, 15 (4), pp. 497-521; Mankiw, N.G., Zeldes, S.P., The consumption of stockholders and nonstockholders (1991) Journal of Financial Economics, 29 (1), pp. 97-112; Mehra, R., The equity premium: Why is it a puzzle? (2003) Financial Analysts Journal, 59 (1), pp. 54-69; Mehra, R., Prescott, E.C., The equity premium: A puzzle (1985) Journal of Monetary Economics, 15 (2), pp. 145-161; Mor\u00e9no, M., (2003) Weather Derivatives Hedging and Swap Illiquidity, , http:\/\/michael.moreno.free.fr\/Documents\/WDOH.ppt, Weather Risk Management Association; Newey, W.K., West, K.D., A simple, positive semi-definite, heteroskedasticity and autocorrelation consistent covariance matrix (1987) Econometrica, 55 (3), pp. 703-708; Newey, W.K., West, K.D., Automatic lag selection in covariance matrix estimation (1994) Review of Economic Studies, 61 (4), pp. 631-653; Richards, T.J., Manfredo, M.R., Sanders, D.R., Pricing weather derivatives (2004) American Journal of Agricultural Economics, 86 (4), pp. 1005-1017; Roustant, O., Une Application de Deux Mod\u00e8les Econom\u00e9triques de Temp\u00e9rature \u00e0 la Gestion des Risques Climatiques (1\u00e8re partie) (2002) Banque & March\u00e9s, 58, pp. 22-29; Roustant, O., Une Application de Deux Mod\u00e8les Econom\u00e9triques de Temp\u00e9rature \u00e0 la Gestion des Risques Climatiques (2\u00e8me partie) (2002) Banque & March\u00e9s, 59, pp. 36-44"}
{"Authors":"Lee R.S.T.","Author(s) ID":"57209821688;","Title":"Chaotic Interval Type-2 Fuzzy Neuro-oscillatory Network (CIT2-FNON) for Worldwide 129 Financial Products Prediction","Year":2019,"Source title":"International Journal of Fuzzy Systems","Volume":null,"Issue":null,"Art. No.":null,"Page start":null,"Page end":null,"Page count":null,"Cited by":null,"DOI":"10.1007\/s40815-019-00688-w","Affiliations":"Division of Science and Technology, BNU-HKBU United International College, Zhuhai, Guangdong, China","Document Type":"Article","Access Type":null,"Source":"Scopus","EID":"2-s2.0-85068864101","Abstract":"We present a methodology for volatile time series forecasting using deep learning. We use a three-step methodology in order to remove trend and nonlinearities from data before applying two parallel deep neural networks to forecast two main features from processed data: absolute value and sign. The proposal is successfully applied to a volatile exchange rate time series problem. \u00a9 Springer International Publishing AG 2017.","Author Keywords":null,"Index Keywords":"Computation theory; Finance; Forecasting; Intelligent computing; Time series; Absolute values; Exchange rate forecasting; Exchange rates; Time series forecasting; Deep neural networks","References":"Brockwell, P.J., (2000) Time Series: Theory and Methods, , Springer, Heidelberg; Engel, R., Autoregressive conditional heteroscedasticity with estimates of the variance of United Kingdom inflation (1982) Econometrica, 1 (50), pp. 987-1007; Figueroa-Garc\u00eda, J.C., Soriano, J.J., A comparison of ANFIS, ANN and DBR systems on volatile time series identification (2007) Annual Meeting of the North American Fuzzy Information Processing Society, 26, pp. 321-326; Figueroa-Garc\u00eda, J.C., An evolutive interval type-2 TSK fuzzy logic system for volatile time series identification (2009) Conference on Systems, Man and Cybernetics, pp. 1-6; Bengio, Y., Lamblin, P., Popovici, D., Larochelle, H., (2006) Greedy Layer-Wise Training of Deep Networks; Bengio, Y., (2009) Learning Deep Architectures for AI; Ciresan, D., Meier, U., Masci, J., Schmidhuber, J., Multi-column deep neural network for traffic sign classification (2012) Neural Netw, 32 (1), pp. 333-338; Deng, L., Yu, D., Deep learning: Methods and applications (2014) Found. Trends Sig. Process., 7 (34), pp. 197-387; Schmidhuber, J., Deep learning in neural networks: An overview (2015) Neural Netw, 61, pp. 85-117; Hinton, G.E., Learning multiple layers of representation (2007) Trends Cogn. Sci., 11 (1), pp. 428-434; Hinton, G.E., Deep belief networks (2009) Scholarpedia, 4 (5), p. 5947; Hinton, G.E., Osindero, S., Teh, Y.W., A fast learning algorithm for deep belief nets (2006) Neural Comput, 18 (7), pp. 1527-1554; Bengio, Y., Lecun, Y., Hinton, G., Deep learning (2015) Nature, 521, pp. 436-444; Deng, L., Abdel-Hamid, O., Yu, D., (2013) A Deep Convolutional Neural Network Using Heterogeneous Pooling for Trading Acoustic Invariance with Phonetic Confusion; Lee, H., Grosse, R., Ranganath, R., Ng, A.Y., Convolutional deep belief networks for scalable unsupervised learning of hierarchical representations (2009) ICML Trans. ACM, 1, pp. 609-616; Panchal, G., Ganatra, A., Kosta, Y., Panchal, D., Behaviour analysis of multilayer perceptrons with multiple hidden neurons and hidden layers (2011) Int. J. Comput. Theor. Eng., 3 (2), pp. 332-337; Kalenatic, D., Figueroa-Garc\u00eda, J.C., Lopez, C.A., A neuro-evolutive interval type-2 TSK fuzzy system for volatile weather forecasting (2010) ICIC 2010. LNCS, 6215, pp. 142-149. , Huang, D.-S., Zhao, Z., Bevilacqua, V., Figueroa, J.C. (eds.), Springer, Heidelberg; Figueroa-Garc\u00eda, J.C., Kalenatic, D., L\u00f3pez-Bello, C.A., An evolutionary approach for imputing missing data in time series (2010) J. Syst. Circ. Comput., 19 (1), p. 107; Figueroa-Garc\u00eda, J.C., Kalenatic, D., L\u00f3pez-Bello, C.A., Missing data imputation in multivariate data by evolutionary algorithms (2011) Comput. Hum. Behav., 27 (5), pp. 1468-1474; Connor, J., Martin, R., Atlas, L., Recurring neural networks and robust time series prediction (1994) IEEE Trans. Neural Netw., 5 (2), pp. 240-254; Huang, G.B., Zhu, Q.Y., Siew, C.K., Extreme learning machine: Theory and applications (2005) Neurocomputing, 704 (1), pp. 489-501; Ni\u00f1o Pe\u00f1a, J.N., Hern\u00e1ndez-P\u00e9rez, G., Price direction prediction on high frequency data using deep belief networks. Commun. Comput (2016) Inf. Sci, 657 (1), pp. 69-79; Ar\u00e9valo, A., Ni\u00f1o, J., Hern\u00e1ndez, G., Sandoval, J., High-frequency trading strategy based on deep neural networks (2016) ICIC 2016. LNCS, 9773, pp. 424-436. , Huang, D.-S., Han, K., Hussain, A. (eds.), Springer, Cham"}
{"Authors":"Fu X., Zhang S., Chen J., Ouyang T., Wu J.","Author(s) ID":"36614138900;57203165289;55925522600;57209774396;55714034400;","Title":"A Sentiment-Aware Trading Volume Prediction Model for P2P Market Using LSTM","Year":2019,"Source title":"IEEE Access","Volume":"7","Issue":null,"Art. No.":" 8740855","Page start":81934.0,"Page end":81944.0,"Page count":null,"Cited by":null,"DOI":"10.1109\/ACCESS.2019.2923637","Affiliations":"School of Software Engineering, Beijing University of Posts and Telecommunications, Beijing, 100876, China; Department of Electronic Engineering, Tsinghua University, Beijing, 100084, China; Key Laboratory of Trustworthy Distributed Computing and Service, Ministry of Education, Beijing University of Posts and Telecommunications, Beijing, 100876, China","Document Type":"Article","Access Type":"Open Access","Source":"Scopus","EID":"2-s2.0-85068690385","Abstract":"Long short-term memory (LSTM) networks are a state-of-the-art technique for sequence learning. They are less commonly applied to financial time series predictions, yet inherently suitable for this domain. We deploy LSTM networks for predicting out-of-sample directional movements for the constituent stocks of the S&P 500 from 1992 until 2015. With daily returns of 0.46 percent and a Sharpe ratio of 5.8 prior to transaction costs, we find LSTM networks to outperform memory-free classification methods, i.e., a random forest (RAF), a deep neural net (DNN), and a logistic regression classifier (LOG). The outperformance relative to the general market is very clear from 1992 to 2009, but as of 2010, excess returns seem to have been arbitraged away with LSTM profitability fluctuating around zero after transaction costs. We further unveil sources of profitability, thereby shedding light into the black box of artificial neural networks. Specifically, we find one common pattern among the stocks selected for trading \u2013 they exhibit high volatility and a short-term reversal return profile. Leveraging these findings, we are able to formalize a rules-based short-term reversal strategy that yields 0.23 percent prior to transaction costs. Further regression analysis unveils low exposure of the LSTM returns to common sources of systematic risk \u2013 also compared to the three benchmark models. \u00a9 2017 Elsevier B.V.","Author Keywords":"Deep learning; Finance; LSTM; Machine learning; Statistical arbitrage","Index Keywords":"Brain; Commerce; Costs; Decision trees; Deep learning; Deep neural networks; Electronic trading; Finance; Financial markets; Forecasting; Learning systems; Profitability; Regression analysis; Risk assessment; Classification methods; Directional movements; Financial time series predictions; Logistic regression classifier; LSTM; Market prediction; State-of-the-art techniques; Statistical arbitrage; Long short-term memory","References":"Abadi, M., Agarwal, A., Barham, P., Brevdo, E., Chen, Z., Citro, C., http:\/\/tensorflow.org\/, (2015). TensorFlow: Large-scale machine learning on heterogeneous systems. Software available from tensorflow.org; Atsalakis, G.S., Valavanis, K.P., Surveying stock market forecasting techniques \u2013 Part II: Soft computing methods (2009) Expert Systems with Applications, 36 (3), pp. 5932-5941; Avellaneda, M., Lee, J.-H., Statistical arbitrage in the US equities market (2010) Quantitative Finance, 10 (7), pp. 761-782; Baker, M., Bradley, B., Wurgler, J., Benchmarks as limits to arbitrage: Understanding the low-volatility anomaly (2011) Financial Analysts Journal, 67 (1), pp. 40-54; Bali, T.G., Cakici, N., Whitelaw, R.F., Maxing out: Stocks as lotteries and the cross-section of expected returns (2011) Journal of Financial Economics, 99 (2), pp. 427-446; Bogomolov, T., Pairs trading based on statistical variability of the spread process (2013) Quantitative Finance, 13 (9), pp. 1411-1430; Boyer, B., Mitton, T., Vorkink, K., Expected idiosyncratic skewness (2010) Review of Financial Studies, 23 (1), pp. 169-202; Breiman, L., Random forests (2001) Machine learning, 45 (1), pp. 5-32; Britz, D., (2015), http:\/\/www.wildml.com\/2015\/10\/recurrent-neural-network-tutorial-part-4-implementing-a-grulstm-rnn-with-python-and-theano\/, Recurrent neural network tutorial, part 4 \u2013 Implementing a GRU\/LSTM RNN with Python and Theano; Carhart, M.M., On persistence in mutual fund performance (1997) The Journal of Finance, 52 (1), p. 57; Chollet, F., (2016), https:\/\/github.com\/fchollet\/keras, Keras; Clegg, M., Krauss, C., Pairs trading with partial cointegration (2018) Quantitative Finance, 18 (1), pp. 121-138; Conrad, J., Kaul, G., Mean reversion in short-horizon expected returns (1989) Review of Financial Studies, 2 (2), pp. 225-240; Diebold, F.X., Mariano, R.S., Comparing predictive accuracy (1995) Journal of Business & Economic Statistics, 13 (3), pp. 253-263; Dixon, M., Klabjan, D., Bang, J.H., Implementing deep neural networks for financial market prediction on the Intel Xeon Phi (2015) Proceedings of the eighth workshop on high performance computational finance, pp. 1-6; Engelberg, J., Reed, A.V., Ringgenberg, M., Short selling risk (2017) Journal of Finance, , (forthcoming); Fama, E.F., Efficient capital markets: A review of theory and empirical work (1970) The Journal of Finance, 25 (2), pp. 383-417; Fama, E.F., French, K.R., Multifactor explanations of asset pricing anomalies (1996) The Journal of Finance, 51 (1), pp. 55-84; Frazzini, A., Pedersen, L.H., Betting against beta (2014) Journal of Financial Economics, 111 (1), pp. 1-25; Gal, Y., Ghahramani, Z., A theoretically grounded application of dropout in recurrent neural networks (2016) Proceedings of the 2016 advances in neural information processing systems, pp. 1019-1027; Gatev, E., Goetzmann, W.N., Rouwenhorst, K.G., Pairs trading: Performance of a relative-value arbitrage rule (2006) Review of Financial Studies, 19 (3), pp. 797-827; Gers, F.A., Schmidhuber, J., Cummins, F., Learning to forget: Continual prediction with LSTM (2000) Neural Computation, 12 (10), pp. 2451-2471; Giles, C.L., Lawrence, S., Tsoi, A.C., Noisy time series prediction using recurrent neural networks and grammatical inference (2001) Machine Learning, 44 (1), pp. 161-183; Goodfellow, I., Warde-Farley, D., Mirza, M., Courville, A., Bengio, Y., Maxout networks (2013) Proceedings of the 30th International Conference on Machine Learning, pp. 1319-1327; Granger, C.W., Strategies for modelling nonlinear time-series relationships (1993) Economic Record, 69 (3), pp. 233-238; Graves, A., (2013), Generating sequences with recurrent neural networks. CoRR, arXiv preprint arXiv 1308.0850; Graves, A., Liwicki, M., Fern\u00e1ndez, S., Bertolami, R., Bunke, H., Schmidhuber, J., A novel connectionist system for unconstrained handwriting recognition (2009) IEEE Transactions on Pattern Analysis and Machine Intelligence, 31 (5), pp. 855-868; Graves, A., Mohamed, A.-R., Hinton, G., Speech recognition with deep recurrent neural networks (2013) Proceedings of the 2013 IEEE international conference on acoustics, speech and signal processing, pp. 6645-6649. , IEEE; Graves, A., Schmidhuber, J., Framewise phoneme classification with bidirectional LSTM and other neural network architectures (2005) Neural Networks, 18 (5), pp. 602-610; Green, J., Hand, J.R.M., Zhang, X.F., The characteristics that provide independent information about average U.S. monthly stock returns (2017) The Review of Financial Studies, 30 (12), pp. 4389-4436; Green, J., Hand, J.R.M., Zhang, X.F., The supraview of return predictive signals (2013) Review of Accounting Studies, 18 (3), pp. 692-730; Gregoriou, G.N., Handbook of short selling (2012), Academic Press Amsterdam and Boston, MA; (2016), http:\/\/h2o.ai\/docs, H2O documentation. http:\/\/h2o-release.s3.amazonaws.com\/h2o\/rel-tukey\/4\/docs-website\/h2o-docs\/index.html; Ho, T.K., Random decision forests (1995) Proceedings of the third international conference on document analysis and recognition, 1, pp. 278-282. , IEEE; Hochreiter, S., Schmidhuber, J., Long short-term memory (1997) Neural computation, 9 (8), pp. 1735-1780; Hong, H., Sraer, D.A., Speculative betas (2016) The Journal of Finance, 71 (5), pp. 2095-2144; Huck, N., Pairs selection and outranking: An application to the S&P 100 index (2009) European Journal of Operational Research, 196 (2), pp. 819-825; Huck, N., Pairs trading and outranking: The multi-step-ahead forecasting case (2010) European Journal of Operational Research, 207 (3), pp. 1702-1716; Jacobs, H., What explains the dynamics of 100 anomalies? (2015) Journal of Banking & Finance, 57, pp. 65-85; Jacobs, H., Weber, M., On the determinants of pairs trading profitability (2015) Journal of Financial Markets, 23, pp. 75-97; Jegadeesh, N., Evidence of predictable behavior of security returns (1990) The Journal of Finance, 45 (3), pp. 881-898; Jegadeesh, N., Titman, S., Returns to buying winners and selling losers: Implications for stock market efficiency (1993) The Journal of Finance, 48 (1), pp. 65-91; Jegadeesh, N., Titman, S., Overreaction, delayed reaction, and contrarian profits (1995) Review of Financial Studies, 8 (4), pp. 973-993; Jha, V., Timing equity quant positions with short-horizon alphas (2016) The Journal of Trading, 11 (3), pp. 53-59; Karpathy, A., (2015), http:\/\/karpathy.github.io\/2015\/05\/21\/rnn-effectiveness\/, The unreasonable effectiveness of recurrent neural networks; Krauss, C., Do, X.A., Huck, N., Deep neural networks, gradient-boosted trees, random forests: Statistical arbitrage on the S&P 500 (2017) European Journal of Operational Research, 259 (2), pp. 689-702; Kumar, A., Who gambles in the stock market? (2009) The Journal of Finance, 64 (4), pp. 1889-1933; LeBaron, B., Some relations between volatility and serial correlations in stock market returns (1992) The Journal of Business, 65 (2), pp. 199-219; LeCun, Y., Bengio, Y., Hinton, G., Deep learning (2015) Nature, 521 (7553), pp. 436-444; Lee, D.D., Chan, H., Faff, R.W., Kalev, P.S., Short-term contrarian investing \u2013 Is it profitable?.. Yes and No (2003) Journal of Multinational Financial Management, 13 (4), pp. 385-404; Lehmann, B.N., Fads, martingales, and market efficiency (1990) The Quarterly Journal of Economics, 105 (1), p. 1; Lo, A.W., MacKinlay, A.C., When are contrarian profits due to stock market overreaction? (1990) Review of Financial Studies, 3 (2), pp. 175-205; Maechler, M., (2016), https:\/\/cran.r-project.org\/package=Rmpfr, Rmpfr: R MPFR \u2013 multiple precision floating-point reliable. R package; Malkiel, B.G., A random walk down Wall Street: The time-tested strategy for successful investing (2007), WW Norton & Company; McKinney, W., Data structures for statistical computing in Python (2010) Proceedings of the ninth Python in science conference, 445, pp. 51-56; Medsker, L., Recurrent neural networks: Design and applications (2000) International series on computational intelligence, , CRC-Press; Moritz, B., Zimmermann, T., Deep conditional portfolio sorts: The relation between past and future stock returns (2014) Working paper, , LMU Munich and Harvard University; Olah, C., (2015), http:\/\/colah.github.io\/posts\/2015-08-Understanding-LSTMs\/, Understanding LSTM Networks; Pedregosa, F., Varoquaux, G., Gramfort, A., Michel, V., Thirion, B., Grisel, O., Scikit-learn: Machine learning in python (2011) Journal of Machine Learning Research, 12, pp. 2825-2830; Peterson, B.G., Carl, P., (2014), http:\/\/CRAN.R-project.org\/package=PerformanceAnalytics, PerformanceAnalytics: Econometric tools for performance and risk analysis. R package; (2016), https:\/\/docs.python.org\/3.5\/, Python 3.5.2 documentation. Available at; (2016), http:\/\/www.R-project.org\/, R: A language and environment for statistical computing; Rad, H., Low, R.K.Y., Faff, R., The profitability of pairs trading strategies: Distance, cointegration and copula methods (2016) Quantitative Finance, 16 (10), pp. 1541-1558; Sak, H., Senior, A.W., Beaufays, F., (2014), Long short-term memory based recurrent neural network architectures for large vocabulary speech recognition. CoRR, arXiv preprint arXiv 1402.1128; Schmidhuber, J., Deep learning in neural networks: An overview (2015) Neural Networks, 61, pp. 85-117; Sermpinis, G., Theofilatos, K., Karathanasopoulos, A., Georgopoulos, E.F., Dunis, C., Forecasting foreign exchange rates with adaptive neural networks using radial-basis functions and particle swarm optimization (2013) European Journal of Operational Research, 225 (3), pp. 528-540; Siah, K.W., Myers, P., (2016), http:\/\/kienwei.mit.edu\/sites\/default\/files\/images\/stock-market-prediction.pdf, Stock market prediction through technical and public sentiment analysis; Takeuchi, L., Lee, Y.-Y., (2013), Applying deep learning to enhance momentum trading strategies in stocks. Working paper, Stanford University; Tieleman, T., Hinton, G., Lecture 6.5-rmsprop: Divide the gradient by a running average of its recent magnitude (2012) COURSERA: Neural Networks for Machine Learning, 4 (2), pp. 26-30; Van Der Walt, S., Colbert, S.C., Varoquaux, G., The numpy array: a structure for efficient numerical computation (2011) Computing in Science & Engineering, 13 (2), pp. 22-30; Xiong, R., Nichols, E.P., Shen, Y., (2015), Deep learning stock volatility with Google domestic trends. arXiv e-prints arXiv 1512.04916"}
{"Authors":"Sirignano J., Cont R.","Author(s) ID":"35753895800;6602945666;","Title":"Universal features of price formation in financial markets: perspectives from deep learning","Year":2019,"Source title":"Quantitative Finance","Volume":"19","Issue":"9","Art. No.":null,"Page start":1449.0,"Page end":1459.0,"Page count":null,"Cited by":null,"DOI":"10.1080\/14697688.2019.1622295","Affiliations":"Industrial and Systems Engineering, University of Illinois at Urbana-Champaign, Urbana, IL, United States; Mathematical Institute, University of Oxford, Oxford, United Kingdom","Document Type":"Article","Access Type":null,"Source":"Scopus","EID":"2-s2.0-85068677237","Abstract":"With the development of Internet lending, the use of peer-to-peer (P2P) as a new financial credit model has been increasing in China. However, this rapid development has led to a major potential risk. A few P2P enterprises operate well in the beginning but close within a short period because of the suspension of business, fraud, illegal fundraising, and blind expansion. Effective supervision of the P2P industry is an urgent problem. Trading volume reflects the operation stability of P2P platforms. Hence, predicting the volume of the P2P market is an important research topic. This paper first analyzes the trading data of a P2P platform. It is found that the sentiment of investor comments is related to the trading volume of the P2P platform. Then, we use the TextCNN model to classify the sentiment of investor comments and obtain the time series of changes in sentiment. It is verified that the time series of change in sentiment and the P2P volume index has statistical causality and a strong correlation. This paper proposes a model that uses the trend of change in investor sentiment to predict P2P trading volume. This model uses the historical time series change in investor sentiment, the P2P volume index, and WeekDay characteristics to predict future P2P trading volume. The experimental results show that the proposed model is better than a few existing baseline methods. Compared with baseline regression, the Pearson coefficient of the predicted and actual values of the proposed model is increased by 13.26%, the mean squared error is decreased by 27.62%, and the R-squared value is increased by 28.48%. \u00a9 2013 IEEE.","Author Keywords":"long short-term memory (LSTM); Peer-to-peer lending; sentiment tracking; trading prediction","Index Keywords":"Commerce; Crime; Forecasting; Investments; Long short-term memory; Mean square error; Time series; Baseline methods; Financial credits; Investor sentiments; Mean squared error; Operation stability; Pearson coefficient; Peer-to-peer lending; Strong correlation; Tellurium compounds","References":"Bachmann, A., Becker, A., Buerckner, D., Hilker, M., Kock, F., Lehmann, M., Tiburtius, P., Funk, B., Online peer-to-peer lending - A literature review (2011) J. Internet Banking Commerce, 16 (2), pp. 1-18; Bollen, J., Mao, H., Zeng, X., Twitter mood predicts the stock market (2011) J. Comput. Sci., 2 (1), pp. 1-8. , Mar; Si, J., Mukherjee, A., Liu, B., Li, Q., Li, H., Deng, X., Exploiting topic based Twitter sentiment for stock prediction (2013) Proc. 51st Annu. Meeting Assoc. Comput. Linguistics, 2, pp. 24-29; Zhou, Z.K., Zhao, J.C., Ke, X., Can online emotions predict the stock market in China? (2016) Proc. 17th Int. Conf. Web Inf. Syst. Eng. (WISE), pp. 328-342. , 10041 Shanghai, China: Springer; Emekter, R., Tu, Y., Jirasakuldech, B., Lu, M., Evaluating credit risk and loan performance in online peer-to-peer (P2P) lending (2015) Appl. Econ., 47 (1-3), pp. 54-70; Ge, R., Feng, J., Gu, B., Zhang, P., Predicting and deterring default with social media information in peer-to-peer lending (2017) J. Manage. Inf. Syst., 34 (2), pp. 401-424; Chen, X., Huang, B., Ye, D., The role of punctuation in P2P lending: Evidence from China (2018) Econ. Model., 68, pp. 634-643. , Jan; Malekipirbazari, M., Aksakalli, V., Risk assessment in social lending via random forests (2015) Expert Syst. Appl., 42 (10), pp. 4621-4631. , Jun; Lin, X., Li, X., Zhong, Z., Evaluating borrower's default risk in peerto- peer lending: Evidence from a lending platform in China (2017) Appl. Econ., 49 (35), pp. 3538-3545; Xia, Y., Liu, C., Liu, N., Cost-sensitive boosted tree for loan evaluation in peer-to-peer lending (2017) Electron. Commerce Res. Appl., 24, pp. 30-49. , Jul.\/Aug; Byanjankar, A., Heikkil\u00e4, M., Mezei, J., Predicting credit risk in peerto- peer lending: A neural network approach (2015) Proc. IEEE Symp. Ser. Comput. Intell., pp. 719-725. , Cape Town, South Africa, Dec; Li, L.-H., Lin, C.-T., Chen, S.-F., Micro-lending default awareness using artificial neural network (2017) Proc. 2nd Int. Conf. Multimedia Syst. Signal Process., pp. 56-60; Aleum, K., Cho, S.-B., An ensemble semi-supervised learning method for predicting defaults in social lending (2019) Eng. Appl. Artif. Intell., 81, pp. 193-199. , May; Duan, J., Financial system modeling using deep neural networks (DNNs) for effective risk assessment and prediction (2019) J. Franklin Inst.-Eng. Appl. Math., 356 (8), pp. 4716-4731. , May; Yoon, Y., Li, Y., Feng, Y., Factors affecting platform default risk in online peer-to-peer (P2P) lending business: An empirical study using Chinese online P2P platform data (2019) Electron. Commerce Res., 19 (1), pp. 131-158. , Mar; Yang, J., Luo, D., The P2P risk assessment model based on the improved AdaBoost-SVM algorithm (2017) J. Financial Risk Manage., 6 (2), pp. 201-209; Liu, P., Li, H., Sun, G., P2P lending platform risk observing method based on short-time multi-source regression algorithm (2018) Comput. Sci., 45 (5), pp. 97-101; Adebiyi, A.A., Adewumi, A.O., Ayo, C.K., Comparison of ARIMA and artificial neural networks models for stock price prediction (2014) J. Appl. Math., 2014. , Mar; G\u00f6\u00e7ken, M., \u00d6z\u00e7alici, M., Boru, A., Dosdogru, A.T., Integrating metaheuristics and artificial neural networks for improved stock price prediction (2016) Expert Syst. Appl., 44, pp. 320-331. , Feb; Laboissiere, L.A., Fernandes, R.A.S., Lage, G.G., Maximum and minimum stock price forecasting of Brazilian power distribution companies based on artificial neural networks (2015) Appl. Soft Comput., 35, pp. 66-74. , Oct; Ding, X., Zhang, Y., Liu, T., Duan, J., Deep learning for event-driven stock prediction (2015) Proc. 24th Int. Joint Conf. Artif. Intell. (IJCAI), pp. 2327-2333. , Buenos Aires, Argentina; Ding, X., Zhang, Y., Liu, T., Duan, J., Knowledge-driven event embedding for stock prediction (2016) Proc. 26th Int. Conf. Comput. Linguistics, Tech. Papers (COLING), pp. 2133-2142. , Osaka, Japan, Dec; Gers, F.A., Schmidhuber, J., Cummins, F., Learning to forget: Continual prediction with LSTM (2000) Neural Comput., 12 (10), pp. 2451-2471. , Oct; Chen, K., Zhou, Y., Dai, F., A LSTM-based method for stock returns prediction: A case study of China stock market (2015) Proc. IEEE Int. Conf. Big Data, pp. 2823-2824. , Santa Clara, CA, USA, Oct.\/Nov; Oliveira, N., Cortez, P., Areal, N., The impact of microblogging data for stock market prediction: Using Twitter to predict returns, volatility, trading volume and survey sentiment indices (2017) Expert Syst. Appl., 73, pp. 125-144. , May; Li, X., Xie, H., Chen, L., Wang, J., Deng, X., News impact on stock price return via sentiment analysis (2014) Knowl.-Based Syst., 69, pp. 14-23. , Oct; Kim, Y., (2014) Convolutional Neural Networks for Sentence Classification, , https:\/\/arxiv.org\/abs\/1408.5882, [Online]; Mikolov, T., Chen, K., Corrado, G., Dean, J., (2013) Efficient Estimation of Word Representations in Vector Space, , https:\/\/arxiv.org\/abs\/1301.3781, [Online]; Zhang, X., Zhao, J., LeCun, Y., Character-level convolutional networks for text classification (2016) Proc. 29th Annu. Conf. Neural Inf. Process. Syst. (NIPS), pp. 649-657. , Montreal, QC, Canada, Dec; Granger, C.W.J., Investigating causal relations by econometric models and cross-spectral methods (1969) Econometrica, 37 (3), pp. 424-438. , Aug; Sims, C.A., Macroeconomics and reality (1980) Econometrica, 48 (1), pp. 1-48"}
{"Authors":"Miura R., Pichl L., Kaizoji T.","Author(s) ID":"57209745684;6701314709;6603679407;","Title":"Artificial Neural Networks for Realized Volatility Prediction in Cryptocurrency Time Series","Year":2019,"Source title":"Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)","Volume":"11554 LNCS","Issue":null,"Art. No.":null,"Page start":165.0,"Page end":172.0,"Page count":null,"Cited by":null,"DOI":"10.1007\/978-3-030-22796-8_18","Affiliations":"International Christian University, Osawa 3-10-2, Mitaka, Tokyo  181-8585, Japan","Document Type":"Conference Paper","Access Type":null,"Source":"Scopus","EID":"2-s2.0-85068615399","Abstract":"Accurate prediction of exchange rates is critical for devising robust monetary policies. Machine learning methods such as shallow neural networks have higher predictive accuracy than time series models when trained on input features carefully crafted by domain knowledge experts. This suggests that deep neural networks, with their ability to learn abstract features from raw data, may provide improved predictive accuracy with raw exchange rates as inputs. The preponderance of research focuses on developed currency markets. The paucity of research in emerging currency markets, and the crucial role that stable currencies play in such economies, motivates us to investigate the effectiveness of deep networks for exchange rate prediction in emerging markets. Literature suggests that the Efficient Market Hypothesis, which posits that asset prices reflect all relevant information, may not hold in such markets because of extraneous factors such as political instability and governmental interventions. This motivates our hypothesis that inclusion of carefully chosen macroeconomic factors as input features may improve the predictive accuracy of deep networks in emerging currency markets. This position paper proposes novel input features based on currency clusters and presents our method for investigating the hypothesis using exchange rates from developed as well as emerging currency markets. \u00a9 2017 by SCITEPRESS - Science and Technology Publications, Lda.","Author Keywords":"Convolution Networks; Deep Learning; Emerging Markets; Exchange Rate Prediction; Neural Networks","Index Keywords":"Artificial intelligence; Commerce; Deep learning; Electronic trading; Financial markets; Forecasting; Neural networks; Accurate prediction; Efficient market hypothesis; Emerging markets; Exchange rates; Governmental intervention; Machine learning methods; Political instability; Predictive accuracy; Deep neural networks","References":"Box, G.E.P., Jenkins, G.M., Reinsel, G.C., Ljung, G.M., (2015) Time Series Analysis: Forecasting and Control, 5th Edition, , Wiley; Busseti, E., Osband, I., Wong, S., (2012) Deep Learning for Time Series Modeling, , CS 229 Final Project Report; Chao, J., Shen, F., Zhao, J., Forecasting exchange rate with deep belief networks (2011) Proceedings of International Joint Conference on Neural Networks, , San Jose, California, USA; Dornbusch, R., Exchange rate expectations and monetary policy (1976) Journal of International Economics, 6 (3), pp. 231-244; Dunis, C.L., Laws, J., Sermpinis, G., Higher order and recurrent neural architectures for trading the EUR\/USD exchange rate (2011) Quantitative Finance, 11 (4), pp. 615-629; Engel, C., Exchange rates and interest parity (2013) National Bureau of Economic Research, 77; Fleming, J.M., Domestic financial policies under fixed and floating exchange rates (1962) IMF Staff Papers, 9, pp. 369-379; Galeshchuk, S., Neural networks performance in exchange rate prediction (2016) Neurocomputing, 172, pp. 446-452; Galeshchuk, S., Neural-based method of measuring exchange-rate impact on international companies' revenue (2014) Distributed Computing and Artificial Intelligence, 11th International Conference, pp. 529-536. , Springer International Publishing; Galeshchuk, S., Mukherjee, S., Deep networks for predicting direction of change in foreign exchange rates (2016) Intelligent Systems in Accounting, Finance and Management: Early View Papers; Graves, A., Mohamed, A.R., Hinton, G., Speech recognition with deep recurrent neural networks (2013) 2013 IEEE International Conference on Acoustics, Speech and Signal Processing, pp. 6645-6649. , IEEE, May; Hinton, G.E., Training products of experts by minimizing contrastive divergence (2002) Neural Comput, 14, pp. 1771-1800; Hinton, G.E., Osindero, S., The, Y., A fast learning algorithm for deep belief nets (2006) Neural Computations, 18, pp. 1527-1554; Hinton, G.E., Salakhutdinov, R., Reducing the dimensionality of data with neural networks (2006) Science, 313 (5786), pp. 504-507; Hyndman, R.J., Khandakar, Y., Automatic time series forecasting: The forecast package for R (2008) Journal of Statistical Software, 26 (3), pp. 1-22. , http:\/\/ideas.repec.org\/a\/jss\/jstsof\/27i03.html, 2008; Kingma, D.P., Ba, J.L., Adam: A method for stochastic optimization (2015) International Conference on Learning Representations, pp. 1-13; Lai, A., Li, M.K., Pong, F.W., Forecasting Trade Direction and Size of Future Contracts Using Deep Belief Network, , Stanford University; Langkvist, M., Karlsson, L., Loutfi, A., A review of unsupervised feature learning and deep learning for time-series modeling (2014) Pattern Recognition Letters, 42, pp. 11-24; Larochelle, H., Bengio, Y., Louradour, P.L., Exploring strategies for training deep neural networks (2009) The Journal of Machine Learning Research, 10, pp. 1-40; LeCun, Y., Bengio, Y., Hinton, G., Deep learning (2015) Nature, 521, pp. 436-444; LeCun, Y., Bottou, L., Bengio, Y., Haffner, P., Gradient-based learning applied to document recognition (1998) Proc. IEEE., 86 (11), pp. 2278-2324; Lee, H., Largman, Y., Pham, P., Ng, A., Unsupervised feature learning for audio classification using convolutional deep belief networks (2009) Advances in Neural Information Processing Systems, 22; Lukas, M., Taylor, M., The obstinate passion of foreign exchange professionals: Technical analysis (2007) Journal of Economic Literature, 45 (4), pp. 936-972; Masci, J., Meier, U., Ciresan, D., Schmidhuber, J., Stacked convolutional auto-encoders for hierarchical feature extraction Lecture Notes in Computer Science, 6791, pp. 52-59; Meese, R., Rogoff, K., The out-of-sample failure of empirical exchange rate models: Sampling error or misspecification? NBER Chapters (1983) Exchange Rates and International Macroeconomics, pp. 67-112; Mundell, R.A., Capital mobility and stabilization policy under fixed and flexible exchange rates (1963) Canadian Journal of Economic and Political Science, 29 (4), pp. 475-485; Nag, A., Forecasting daily foreign exchange rates using genetically optimized neural networks (2002) Journal of Forecasting, 21 (7), pp. 501-511; Neely, C., Sarno, L., (2002) How Well Do Monetary Fundamentals Forecast Exchange Rates?, , Federal Reserve Bank of St. Louis Working Paper Series: 2002-2007; Osadchy, M., LeCun, Y., Miller, M., Synergistic face detection and pose estimation with energybased models (2013) Journal of Machine Learning Research, 8, pp. 1197-1215; (2013) Triennial Central Bank Survey, , http:\/\/www.bis.org\/publ\/rpfx13fx.pdf, Report on global foreign exchange market activity in 2013. April, Basel, Switzerland: Bank for International Settlements; Ribeiro, B., Noel, L., Deep belief networks for financial prediction Proceedings of ICONIP 2011, Part III, LNCS, 7064, pp. 766-773; Schmidhuber, J., Deep learning in neural networks: An overview (2005) Neural Networks, pp. 85-117; Simard, P.Y., Steinkraus, D., Platt, J.C., (2003) Best; Sukittanon, S., Surendran, A.C., Platt, J.C., Burges, C.J., Convolutional networks for speech detection (2004) Interspeech, pp. 1077-1080; Thinyane, H., Millin, J., An investigation into the use of intelligent systems for currency trading (2011) Computational Economics, 37 (4), pp. 363-374; Vincent, P., Larochelle, H., Bengio, Y., Manzagol, P., Extracting and composing robust features with denoising autoencoders Proceedings of the 25th International Conference on Machine Learning (ICML 08), pp. 1096-1103; Wagner, N., Michalewicz, Z., Khouja, M., McGregor, R.R., Time series forecasting for dynamic environments: The DyFor genetic program model (2007) Trans. Evol. Comp., 11 (4), pp. 433-452; Xiao, R., (2014) Deepnet: Deep Learning Toolkit in R. R Package Version 0.2, , http:\/\/CRAN.Rproject.org\/package=deepnet; Yeh, S.-H., Wang, C.J., Tsai, M.F., (2014) Corporate Default Prediction Via Deep Learning, , ISF"}
{"Authors":"Lu M.","Author(s) ID":"57209638825;","Title":"A monetary policy prediction model based on deep learning","Year":2019,"Source title":"Neural Computing and Applications","Volume":null,"Issue":null,"Art. No.":null,"Page start":null,"Page end":null,"Page count":null,"Cited by":null,"DOI":"10.1007\/s00521-019-04319-1","Affiliations":"School of Accounting, Fujian Jiangxia University, Fuzhou, Fujian Province  350108, China","Document Type":"Article","Access Type":null,"Source":"Scopus","EID":"2-s2.0-85068321387","Abstract":"This paper considers the prediction of noisy time series data, specifically, the prediction of financial signals. A novel Dynamic Ridge Polynomial Neural Network (DRPNN) for financial time series prediction is presented which combines the properties of both higher order and recurrent neural network. In an attempt to overcome the stability and convergence problems in the proposed DRPNN, the stability convergence of DRPNN is derived to ensure that the network posses a unique equilibrium state. In order to provide a more accurate comparative evaluation in terms of profit earning, empirical testing used in this work encompass not only on the more traditional criteria of NMSE, which concerned at how good the forecasts fit their target, but also on financial metrics where the objective is to use the networks predictions to generate profit. Extensive simulations for the prediction of one and five steps ahead of stationary and non-stationary time series were performed. The resulting forecast made by DRPNN shows substantial profits on financial historical signals when compared to various neural networks; the Pi-Sigma Neural Network, the Functional Link Neural Network, the feedforward Ridge Polynomial Neural Network, and the Multilayer Perceptron. Simulation results indicate that DRPNN in most cases demonstrated advantages in capturing chaotic movement in the financial signals with an improvement in the profit return and rapid convergence over other network models. \u00a9 2010 Elsevier Ltd. All rights reserved.","Author Keywords":"Dynamic Ridge Polynomial Neural Network; Financial signals; Higher order neural network; Time series prediction","Index Keywords":"Comparative evaluations; Empirical testing; Equilibrium state; Extensive simulations; Feed-Forward; Financial metrics; Financial signal; Financial time series predictions; Functional link neural network; Higher order; Higher order neural network; Multi layer perceptron; Network models; Non-stationary time series; Nonstationary; Polynomial neural networks; Profit earning; Rapid convergence; Simulation result; Stability and convergence; Time series prediction; Time-series data; Univariate; Feedforward neural networks; Finance; Financial data processing; Forecasting; Multilayer neural networks; Polynomials; Profitability; Recurrent neural networks; Time series; Computer simulation","References":"Artyomov, E., Pecht, O.Y., Modified high-order neural network for pattern recognition (2004) Pattern Recognition Letters; Atiya, A.F., Learning on a general network (1988) Proceedings of the IEEE Conference on Neural Information Processing Systems; Beale, R., Jackson, T., (1990) Neural Computing: An Introduction, , Hilger Bristol; Cao, L.J., Tay, F.E.H., Support vector machine with adaptive parameters in financial time series forecasting (2003) IEEE Transactions on Neural Networks, 14 (6), pp. 1506-1518; Cass, R., Radl, B., Adaptive process optimization using Functional-Link Networks and Evolutionary Algorithm (1996) Control Engineering Practice, 4 (11), pp. 1579-1584; Chen, A.S., Leung, M.T., Performance evaluation of neural network architectures: The case of predicting foreign exchange correlations (2005) Journal of Forecasting, 24, pp. 403-420; Cheng, W., Wagner, L., Lin, C.H., (1996) Forecasting the 30-year US Treasury Bond with A System of Neural Networks, , Finance & Technology Publishing, Inc. USA; Dunis, C.L., Williams, M., Modeling and trading the UER\/USD exchange rate: Do neural network models perform better? (2002) In Derivatives Use, Trading and Regulation, 3 (8), pp. 211-239; Ghosh, J., Shin, Y., Efficient higher-order neural networks for function approximation and classification (1992) International Journal of Neural Systems, 3 (4), pp. 323-350; Giles, C.L., Maxwell, T., Learning, invariance, and generalization in high-order neural networks (1987) Applied Optics, 26 (23), pp. 4972-4978; Haykin, S., Neural networks (1999) A Comprehensive Foundation, , 2nd ed. Prentice-Hall, Inc. New Jersey; Hussain, A.J., Liatsis, P., Recurrent pi-sigma networks for DPCM image coding (2002) Neurocomputing, 55, pp. 363-382; Hyndman, R.J., Time Series Data Library, , http:\/\/www-personal.buseco.monash.edu.au\/~hyndman\/TSDL\/, (n.d.) Originalsourcefrom:McCleary&Hay, AppliedTimeSeriesAnalysisfortheSocialSciences,1980,SagePublications; Jordan, M.I., (1986) Serial Order: A Parallel Distributed Processing Approach, , San Diego: Institute for Cognitive Science report 8604, Institute for Cognitive Science, University of California; Leung, M.T., Chen, A.S., Daouk, H., Forecasting exchange rates using general regression neural networks (2000) Computers and Operations Research, 27, pp. 1093-1110; Mirea, L., Marcu, T., System identification using Functional-Link Neural Networks with dynamic structure (2002) 15th Triennial World Congress, , Barcelona, Spain; Patra, J.C., Bos, A.V.D., Modeling of an intelligent pressure sensor using functional link artificial neural networks (2000) ISA Transactions, 39, pp. 15-27; Shin, Y., Ghosh, J., The pi-sigma networks: An efficient higher-order neural network for pattern classification and function approximation (1991) Proceedings of International Joint Conference on Neural Networks, 1, pp. 13-018. , Seattle, Washington; Shin, Y., Ghosh, J., Ridge polynomial networks (1995) IEEE Transactions on Neural Networks, 6 (3), pp. 610-622; Tawfik, H., Liatsis, P., Prediction of non-linear time-series using higher-order neural networks (1997) Proceeding IWSSIP'97 Conference, , Poznan, Poland; Thomason, M., The practitioner method and tools (1999) Journal of Computational Intelligence in Finance, 7 (3), pp. 36-45; Williams, R.J., Zipser, D., A learning algorithm for continually running fully recurrent neural networks (1989) Neural Computation, 1, pp. 270-280; Yao, J., Tan, C.L., A case study on neural networks to perform technical forecasting of forex (2000) Neurocomputing, 34, pp. 79-98; Yumlu, S., Gurgen, F.S., Okay, N., A comparison of global, recurrent and smoothed-piecewise neural models for Istanbul stock exchange (ISE) prediction (2005) Pattern Recognition Letters, 26, pp. 2093-2103"}
{"Authors":"Yang X., Mao S., Gao H., Duan Y., Zou Q.","Author(s) ID":"57189699603;57092455700;36442463200;56328556200;57209332513;","Title":"Novel financial capital flow forecast framework using time series theory and deep learning: A case study analysis of Yu'e Bao transaction data","Year":2019,"Source title":"IEEE Access","Volume":"7","Issue":null,"Art. No.":" 8723033","Page start":70662.0,"Page end":70672.0,"Page count":null,"Cited by":null,"DOI":"10.1109\/ACCESS.2019.2919189","Affiliations":"School of Computer and Information Engineering, Shanghai Polytechnic University, Shanghai, 201209, China; Computing Center, Shanghai University, Shanghai, 200444, China; College of Information Science and Technology, Hainan University, Haikou, 570100, China; Shanghai Shangda Hairun Information System Co., Ltd., Shanghai, 200444, China","Document Type":"Article","Access Type":"Open Access","Source":"Scopus","EID":"2-s2.0-85067398528","Abstract":"Time series based model has been widely applied to estimate the future stock price, and aids investors' decisions and trades. However, due to high rate of volatility and non-linearity of time series, affecting stock market forecasting. To address this, artificial neural network (ANN) and deep neural network (DNN) have been applied in the area of stock price forecasting by various researchers. However, existing model use ANN and DNN with back propagation fails to provide flexible linear or nonlinear relationship among variables and they are difficult to train. The objective of this work is to present a modified back propagation neural network (MBNN) model that can handle huge density of nonlinear data, their relationship and give an optimal strategy for computationally hard problem. Experiments are conducted to evaluate performance of proposed MBNN over existing model in terms RMSE and MAPE. The outcome shows significant performance improvement by MBNN over state-of-art approach. \u00a9 2018 IEEE.","Author Keywords":"Artificial neural network; Data mining; Deep learning; machine learning; prediction system; time series","Index Keywords":"Backpropagation; Commerce; Data mining; Deep learning; Deep neural networks; Financial markets; Forecasting; Investments; Learning systems; Mechanics; Neural networks; Time series; Back propagation neural networks; Modified backpropagation; Non-linear relationships; Optimal strategies; Prediction systems; Stock forecasting; Stock market forecasting; Stock price forecasting; Electronic trading","References":"Selmi, N., Chaabene, S., Hachicha, N., (2015) Forecasting Returns on A Stock Market Using Artificial Neural Networks and GARCH Family Models: Evidence of Stock Market S & P 500, 4 (2), pp. 203-210; Rajput, V., Bobde, S., Stock market prediction using hybrid approach (2016) 2016 International Conference on Computing, Communication and Automation (ICCCA), pp. 82-86. , Noida; Yetis, Y., Kaplan, H., Jamshidi, M., Stock market prediction by using artificial neural network (2014) 2014 World Automation Congress (WAC), pp. 718-722. , Waikoloa, HI; Shen, S., Jiang, H., Zhang, T., (2016) Stock Market Forecasting Using Machine Learning Algorithms, , http:\/\/citeseerx.ist.psu.edu\/viewdoc\/summarydoi=10.1.1.278.6139; Usmani, M., Adil, S.H., Raza, K., Ali, S.S.A., Stock market prediction using machine learning techniques (2016) 2016 3rd International Conference on Computer and Information Sciences (ICCOINS), pp. 322-327. , Kuala Lumpur; Yan, D., Zhou, G., Zhao, X., Tian, Y., Yang, F., Predicting stock using microblog moods (2016) China Communications, 13 (8), pp. 244-257. , Aug; Sun, T., Wang, J., Zhang, P., Cao, Y., Liu, B., Wang, D., Predicting stock price returns using microblog sentiment for Chinese stock market (2017) 3rd International Conference on Big Data Computing and Communications (BIGCOM), pp. 87-96. , Chengdu, 2017; Shi, X., Multiple disease risk assessment with uniform model based on medical clinical notes (2016) IEEE Access, 4, pp. 7074-7083; Samarawickrama, A.J.P., Fernando, T.G.I., A recurrent neural network approach in predicting daily stock prices an application to the sri lankan stock market (2017) IEEE International Conference on Industrial and Information Systems (ICIIS), pp. 1-6. , Peradeniya, 2017; Shahzad, W., (2016) Efficient Machine Learning Techniques for Stock Market Prediction, , http:\/\/www.academia.edu\/26331482, last accessed; Moghaddama, A.H., Moghaddam, M.H., Esfandyari, M., (2016) Stock Market Index Prediction Using Artificial Neural Network, 21 (41), pp. 89-93; Bishop, C.M., (2006) Pattern Recognition and Machine Learning, , Springer; Guidi, G., Pettenati, M.C., Melillo, P., Iadanza, E., A machine learning system to improve heart failure patient assistance (2014) IEEE Journal of Biomedical and Health Informatics, 18 (6), pp. 1750-1756. , Nov; (2018) Yahoo Historical Prices of NASDAQ, , https:\/\/finance.yahoo.com\/, Retrieved May 5; Gurav, U., Sidnal, N., Predict stock market behavior: Role of machine learning algorithms (2018) Intelligent Computing and Information and Communication. Advances in Intelligent Systems and Computing, 673. , Bhalla S., Bhateja V., Chandavale A., Hiwale A., Satapathy S. (eds). Springer, Singapore"}
{"Authors":"Siddiqui S.A., Mercier D., Munir M., Dengel A., Ahmed S.","Author(s) ID":"57200439899;57197827803;57201250579;6603764314;54410250600;","Title":"TSViz: Demystification of Deep Learning Models for Time-Series Analysis","Year":2019,"Source title":"IEEE Access","Volume":"7","Issue":null,"Art. No.":" 8695734","Page start":67027.0,"Page end":67040.0,"Page count":null,"Cited by":null,"DOI":"10.1109\/ACCESS.2019.2912823","Affiliations":"German Research Center for Artificial Intelligence (DFKI), Kaiserslautern, Germany; Technische Universitaet Kaiserslautern, Kaiserslautern, 67663, Germany","Document Type":"Article","Access Type":"Open Access","Source":"Scopus","EID":"2-s2.0-85067255101","Abstract":"This paper presents a recurrent neural network (RNN) which is improved by using an efficient discrete wavelet transform (DWT) for predicting a high-frequency time series. In the combined DWT-RNN model, first, a multiresolution based on B-spline wavelet of high order d (BSd) is used to decompose the time series into several smooth data sets. Therefore, an approximation data set (with low-frequency) and several detail data sets (with high-frequency), with small wave amplitude, are obtained. Then, all decomposed components are used as RNN inputs. The proposed BSd-RNN model can approximate smooth patterns with satisfactory accuracy, and because of the local properties, BSd is a better choice than other common DWT such as Haar and Daubechies of order n (dbn), for preprocessing the high-frequency time series. According to results of performance metrics for predicting four different stock indices, the BSd-RNN model outperforms other common DWT-RNN model such as Haar-RNN and dbn-RNN. Also, the results show the BSd-RNN model outperforms other common artificial neural network (ANN) model such as multilayer feed-forward neural network (FFNN). Finally, The results show that BS3-RNN predicting model has better predictive ability than other compared models which use other wavelets or other ANNs. \u00a9 2019","Author Keywords":"Artificial neural networks; B-spline wavelets multiresolution; Discrete wavelet transform; Financial time series forecasting; Return volatility","Index Keywords":"Discrete wavelet transforms; Financial data processing; Forecasting; Interpolation; Multilayer neural networks; Neural networks; Recurrent neural networks; Signal reconstruction; Time series; Artificial neural network models; Financial time series forecasting; High frequency time series; Multilayer feedforward neural networks; Multiresolution; Predictive abilities; Recurrent neural network (RNN); Return volatilities; Feedforward neural networks","References":"Adelson, E.H., Simoncelli, E., Hingorani, R., Orthogonal pyramid transforms for image coding (1987) Visual Communications and Image processing II, 845, pp. 50-59; Alderson, T., Mahdavi-Amiri, A., Samavati, F.F., Offsetting spherical curves in vector and raster form (2018) The Visual Computer, 34 (6-8), pp. 973-984; Alderson, T., Samavati, F., Optimizing line-of-sight using simplified regular terrains (2014) The Visual Computer, 31 (4), pp. 407-421; Altunkaynak, A., Ozger, M., Comparison of discrete and continuous wavelet-multilayer perceptron methods for daily precipitation (2016) Journal of Hydrologic Engineering, 21 (7), p. 04016014; Bahrammirzaee, A., A comparative survey of artificial intelligence applications in finance: Artificial neural networks, expert system and hybrid intelligent systems (2010) Neural Computing and Applications, 19 (8), pp. 1165-1195; Bartels, R.H., Samavati, F.F., Reversing subdivision rules: local linear conditions and observations on inner products (2000) Journal of Computational and Applied Mathematics, 119, pp. 21-67; Bartels, R.H., Samavati, F.F., Multiresolutions numerically from subdivisions (2011) Computers and Graphics, 35 (2), pp. 185-197; Bento, P.M.R., Pombo, J.A.N., Calado, M.R.A., Mariano, S.J.P.S., A bat optimized neural network and wavelet transform approach for short-term price forecasting (2018) Applied Energy, 210, pp. 88-97; Bildirici, M., Ersin, O., Forecasting oil prices: Smooth transition and neural network augmented GARCH family models (2013) Journal of Petroleum Science and Engineering, 109, pp. 230-240; Bollerslev, T., Generalized autoregressive conditional heteroskedasticity (1986) Journal of Econometrics, 31 (3), pp. 307-327; Box, G.E., Jenkins, G.M., Reinsel, G.C., Ljung, G.M., Time series analysis: Forecasting and control (2015), John Wiley & Sons; Brunn, M., Sousa, M.C., Samavati, F.F., Capturing and reusing artistic styles with reverse subdivision based multiresolution methods (2007) International Journal of Image and Graphics, 7 (4), pp. 593-615; Chandar, S.K., Sumathi, M., Sivanandam, S.N., Prediction of stock market price using hybrid of wavelet transform and artificial neural network (2016) Indian journal of Science and Technology, 9 (8), pp. 1-5; Conejo, A.J., Plazas, M.A., Espinola, R., Molina, A.B., Day-ahead electricity price forecasting using the wavelet transform and ARIMA models (2005) IEEE Transactions on Power Systems, 20 (2), pp. 1035-1042; Daubechies, I., Ten lectures on wavelets (1992), Society for Industrial and Applied mathematics Philadelphia; Donaldson, G., Kamstra, M., An artificial neural network-GARCH model for international stock return volatility (1997) Journal of Empirical Finance, 4 (1), pp. 17-46; Doucoure, B., Agbossou, K., Cardenas, A., Time series prediction using artificial wavelet neural network and multi-resolution analysis: Application to wind speed data (2016) Renewable Energy, 92, pp. 202-211; Elman, J.L., Finding structure in time (1990) Cognitive science, 14 (2), pp. 179-211; Engle, R.F., Autoregressive conditional heteroscedasticity with estimates of the variance of United Kingdom inflation (1982) Econometrica: Journal of the Econometric Society, 50, pp. 987-1008; Finkelstein, A., Salesin, D.H., Multiresolution curves of SIGGRAPH (1994) Computer graphics, annual conference series; Grossmann, A., Morlet, J., Decomposition of hardy functions into square integrable wavelets of constant shape (1984) SIAM Journal on Mathematical Analysis, 15 (4), pp. 723-736; Haar, A., Results in mathematics (1985), Springer 8 (2), 194\u2013196; Homayouni, N., Amiri, A., Stock price prediction using a fusion model of wavelet, fuzzy logic, and ANN (2011) International conference on e-business, management and economics, 25, pp. 277-281. , Singapore; Hsieh, T.J., Hsiao, H.F., Yeh, W.C., Forecasting stock markets using wavelet transforms and recurrent neural networks: An integrated system based on artificial bee colony algorithm (2011) Applied soft computing, 11 (2), pp. 2510-2525; Huang, L., Wang, J., Forecasting energy fluctuation model by wavelet decomposition and stochastic recurrent wavelet neural network (2018) Neurocomputing; Jothimani, D., Shankar, R., Yadav, S.S., Discrete wavelet transform-based prediction of stock index: A study on national stock exchange fifty index (2015) Journal of Financial Management and Analysis, 28 (2), pp. 35-49; Kazemi, A., Shakouri, H.G., Menhaj, M.B., Mehregan, M.R., Neshat, N.A., Hierarchical artificial neural network for transport energy demand forecast: Iran case study (2010) Neural Network World, 20 (6), p. 761; Khuat, T.T., Le, Q.C., Nguyen, B.L., Le, M.H., Forecasting stock price using wavelet neural network optimized by directed artificial bee colony algorithm (2016) Journal of Telecommunications and Information Technology, pp. 43-52; Kim, H.Y., Won, C.H., Forecasting the volatility of stock price index: A hybrid model integrating LSTM with multiple GARCH-type models (2018) Expert Systems with Applications, 103, pp. 25-37; Krishnaprasad, S., Pati, C., Analysis and synthesis of feed-forward neural networks using discrete affine wavelet transformations (1993) IEEE Transactions on Neural Networks, 4 (1), pp. 73-85; Kristjanpoller, W., Hernndez, E., Volatility of main metals forecasted by a hybrid ANN-GARCH model with regressors (2017) Expert Systems with Applications, 84, pp. 290-300; Kristjanpoller, W., Minutolo, M.C., Forecasting volatility of oil price using an artificial neural network-GARCH model (2016) Expert Systems with Applications, 65, pp. 233-241; Lahmiri, S., Wavelet low and high frequency components as features for predicting stock prices with back propagation neural networks (2014) Journal of King Saud University Computer and Information Sciences, 26 (2), pp. 218-237; Li, Y., Li, X., Wang, H., Based on multiple scales forecasting stock price with a hybrid forecasting system (2016) American Journal of Industrial and Business Management, 6, pp. 1102-1112; Luo, R., Zhang, W., Xu, X., Wang, J., A neural stochastic volatility model (2018) Thirty-second AAAI conference on artificial intelligence; Mallat, S., A wavelet tour of signal processing (1999), Elsevier; Mandal, Haque, Meng, J., Srivastava, Martinez, R., A novel hybrid approach using wavelet, firefly algorithm, and fuzzy ARTMAP for day-ahead electricity price forecasting (2013) IEEE Transactions on Power Systems, 28 (2), pp. 1041-1051; Meyer, Y., Wavelets and applications (1992), 31. , Masson Paris; Mishra, N., Soni, H.K., Sharma, S., Upadhyay a.k. development and analysis of artificial neural network models for rainfall prediction by using time-series data (2018) International Journal of Intelligent Systems and Applications, 10 (1), pp. 16-23; Moller, M.F., A scaled conjugate gradient algorithm for fast supervised learning (1993) Neural Networks, 6 (4), pp. 525-533; Moltaji, A., Runions, A., Samavati, F.F., Subdivision and multiresolution for pups (2017) Computers & Graphics, 62, pp. 53-66; Nguyen, T., He, T.X., Wavelet analysis and applications in economics and finance (2015) Research & Reviews: Journal of Statistics and Mathematical Sciences, 1 (1), pp. 22-37; Olsen, L., Samavati, F.F., A discrete approach to multiresolution curves and surfaces (2008) International conference on computational science and its applications (ICCSA), pp. 468-477. , IEEE Computer Society; Qu, Z., Mao, W., Zhang, K., Zhang, W., Li, Z., Multi-step wind speed forecasting based on a hybrid decomposition technique and an improved back-propagation neural network (2019) Renewable Energy, 133, pp. 919-929; Samavati, F.F., Mahdavi-Amiri, N., Bartels, R.H., Multiresolution representation of surface with arbitrary topology by reversing do subdivision (2002) Computer Graphic Forum, 21 (2), pp. 121-136; Samavati, F.F., Bartels, R.H., Multiresolution curve and surface representation by reversing subdivision rules (1999) Computer Graphics Forum, 18 (2), pp. 97-119; Samavati, F.F., Bartels, R.H., Olsen, L., Local b-spline multiresolution with examples in iris synthesis and volumetric rendering, image pattern recognition: Synthesis and analysis in biometrics (2007) Series in Machine Perception and Artificial Intelligence, pp. 65-101; Shaghaghi, S., Bonakdari, H., Gholami, A., Ebtehaj, I., Zeinolabedini, M., Comparative analysis of GMDH neural network based on genetic algorithm and particle swarm optimization in stable channel design (2017) Applied Mathematics and Computation, 313, pp. 271-286; Shi, B., Wang, P., Jiang, J., Liu, R., Applying high-frequency surrogate measurements and a wavelet-ANN model to provide early warnings of rapid surface water quality anomalies (2018) Science of the Total Environment, 610, pp. 1390-1399; Stromberg, J., A modified Haar system and higher order spline systems (1981) Conference on Harmonic Analysis in Honor of Antoni Zygmund, pp. 475-493; Stollnitz, E.J., Derose, A.D., Salesin, D.H., Wavelets for computer graphics: Theory and applications (1996), The Morgan Kaufmann Publishers; Taha, S.M., Taha, Z.K., EEG signals classification based on autoregressive and inherently quantum recurrent neural network (2018) International Journal of Computer Applications in Technology, 58 (4), pp. 340-351; Unser, M., Ten good reasons for using spline wavelets (1997) SPIE conf. wavelet applications in signal and image processing v, 3169, pp. 422-431. , USA; Vaisla, K.S., Stock market forecasting using artificial neural network and statistical technique: A comparison report (2010) International Journal of Computer and Network Security, 2 (8), pp. 50-55; Wang, J.Z., Wang, J.J., Zhang, Z.G., Guo, S.P., Forecasting stock indices with back propagation neural network (2011) Expert Systems with Applications, 38 (11), pp. 14346-14355; Wang, L., Zou, H., Su, J., Li, L., Chaudhry, S., An ARIMA-ANN hybrid model for time series forecasting (2013) Systems Research and Behavioral Science, 30 (3), pp. 244-259; Wecker, L., Samavati, F., Gavrilova, M.A., Multiresolution approach to iris synthesis (2010) Computers and Graphics, 34 (4), pp. 468-478; Willmott, J., Matsuura, K., Advantages of the mean absolute error (MAE) over the root mean square error (RMSE) in assessing average model performance (2005) Climate Research, 30 (1), pp. 79-82; Xing, F.Z., Cambria, E., Zhang, Y., Sentiment-aware volatility forecasting (2019) Knowledge-Based Systems, 176, pp. 68-76; Zhang, Q., Benveniste, A., Wavelet networks (1992) IEEE Transactions on neural networks, 3 (6), pp. 889-898"}
{"Authors":"Ni L., Li Y., Wang X., Zhang J., Yu J., Qi C.","Author(s) ID":"7102681459;57201377077;57201523676;52164985200;57194244903;24081271700;","Title":"Forecasting of Forex Time Series Data Based on Deep Learning","Year":2019,"Source title":"Procedia Computer Science","Volume":"147","Issue":null,"Art. No.":null,"Page start":647.0,"Page end":652.0,"Page count":null,"Cited by":null,"DOI":"10.1016\/j.procs.2019.01.189","Affiliations":"College of Computer Science and Engineering, Shandong University of Science and Technology, Qingdao, 266590, China; Shandong Province Key Laboratory of Wisdom Mine Information Technology, Shandong University of Science and Technology, Qingdao, 266590, China; Key Laboratory of Embedded System and Service Computing, Ministry of Education, Tongji University, Shanghai, 200092, China; Qilu University of Technology (Shandong Academy of Sciences), Jinan Shandong, 250014, China; Shandong Computer Science Center (National Supercomputer Center in Jinan), Jinan Shandong, 250014, China; Beijing Union University, Beijing, 100101, China","Document Type":"Conference Paper","Access Type":"Open Access","Source":"Scopus","EID":"2-s2.0-85066033657","Abstract":"The forecasting of time series is a common problem in different domains. Especially the financial sector that relies heavily on algorithmic trading, employs intelligent systems for this purpose. With technological advances in the domain of intelligent systems those forecasts tend to become more and more precise. However, using such black box methods often lacks the understanding, whether the underlying time series characteristics like stationarity or chaos are caught by the corresponding algorithm and what particular external factors like dataset size influence the outcome. In addition to that the knowledge base is lacking a systematic overview of available algorithms and their application on different time series. We aim to contribute to the knowledge base by (1) conducting a literature review and descriptive analysis revealing dependencies between characteristics and algorithm use and (2) evaluating the impact of influence factors like dataset size and prediction window on the performance of Deep Learning Systems (DLS) in the context of crude oil price prediction, considering two common tasks: a trend and an exact value prediction problem. \u00a9 2018 Association for Information Systems. All rights reserved.","Author Keywords":"Crude oil; Deep learning; Intelligent systems; Prediction; Time series","Index Keywords":"Crude oil; Deep learning; Information use; Intelligent systems; Knowledge based systems; Petroleum analysis; Time series; Algorithmic trading; Crude oil price prediction; Descriptive analysis; Financial sectors; Literature reviews; Technological advances; Time series characteristic; Time series prediction; Forecasting","References":"Agarwal, R., Dhar, V., Editorial - Big data, data science, and analytics: The opportunity and challenge for IS research (2014) Information Systems Research, 25 (3), pp. 443-448. , https:\/\/doi.org\/10.1287\/isre.2014.0546; Akpanta, A.C., Okorie, I.E., Application of box-jenkins techniques in modelling and forecasting Nigeria crude oil prices (2014) International Journal of Statistics and Applications, 4 (6), pp. 283-291; Arel, I., Rose, D.C., Karnowski, T.P., Deep machine learning - A new frontier in artificial intelligence research [Research frontier] (2010) IEEE Computational Intelligence Magazine, 5 (4), pp. 13-18; Brockwell, P.J., Davis, R.A., (2016) Introduction to Time Series and Forecasting, , \/\/www.springer.com\/de\/book\/9783319298528, (3rd ed.), Springer Texts in Statistics, Springer International Publishing; Busseti, E., Osband, I., Wong, S., Deep learning for time series modeling (2012) Technical Report, Stanford University; Cao, H., Li, J., Wang, R., (2016) Trends and Applications in Knowledge Discovery and Data Mining: PAKDD 2016 Workshops, , BDM, MLSDA, PACC, WDMBF, Auckland, New Zealand, April 19, 2016, Revised Selected Papers, Springer; Chen, H., Chiang, R.H.L., Storey, V.C., Business intelligence and analytics: From big data to big impact (2012) MIS Q, 36 (4), pp. 1165-1188; Chen, Y., He, K., Tso, G.K.F., Forecasting crude oil prices: A deep learning based model (2017) Procedia Computer Science (122), 5th International Conference on Information Technology and Quantitative Management, ITQM 2017, pp. 300-307. , https:\/\/doi.org\/10.1016\/j.procs.2017.11.373; Cox, D.R., Stuart, A., Some quick sign tests for trend in location and dispersion (1955) Biometrika, 42 (1-2), pp. 80-95. , https:\/\/doi.org\/10.1093\/biomet\/42.1-2.80; Deng, L., Long-term memory properties in oil future market and its fluctuation (2012) Advances in Computer Science and Engineering, Advances in Intelligent and Soft Computing, pp. 635-640. , https:\/\/doi.org\/10.1007\/978-3-642-27948-5_84, Springer, Berlin, Heidelberg; Dorffner, G., Neural networks for time series processing (1996) Neural Network World, , http:\/\/citeseerx.ist.psu.edu\/viewdoc\/summary?doi=10.1.1.45.5697; Elenberg, E., Dimakis, A.G., Feldman, M., Karbasi, A., Streaming weak submodularity: Interpreting neural networks on the fly (2017) Advances in Neural Information Processing Systems, 30, pp. 4044-4054. , http:\/\/papers.nips.cc\/paper\/6993-streaming-weak-submodularity-interpreting-neural-networks-on-the-fly.pdf, I. Guyon, U. V. Luxburg, S. Bengio, H. Wallach, R. Fergus, S. Vishwanathan, and R. Garnett (eds.), Curran Associates, Inc; Farmer, J.D., Sidorowich, J.J., Predicting chaotic time series (1987) Physical Review Letters, 59 (8), p. 845; Fettke, P., State-of-the-art des state-of-the-art - Eine untersuchung der forschungsmethode review innerhalb der wirtschaftsinformatik (2006) Wirtschaftsinformatik, 48 (4), pp. 257-266; Franses, P.H., Van Dijk, D., Forecasting stock market volatility using (Nonlinear) GARCH models (1996) Journal of Forecasting, pp. 229-235; Gordon, S., Blake, R., Shankaranarayanan, G., Case-based research in information systems: Gaps and trends (2013) JITTA: Journal of Information Technology Theory and Application, 14 (2), p. 47; Gottwald, G.A., Melbourne, I., A new test for chaos in deterministic systems (2004) Proceedings of the Royal Society of London A: Mathematical, Physical and Engineering Sciences, 460 (2042), pp. 603-611. , https:\/\/doi.org\/10.1098\/rspa.2003.1183; Gregor, S., Building {Theory} in the {Sciences} of the {Artificial} (2009) Proceedings of the 4th {International} {Conference} on {Design} {Science} {Research} in {Information} {Systems} and {Technology}, {DESRIST} '09, pp. 41-410. , https:\/\/doi.org\/10.1145\/1555619.1555625, New York, NY, USA: ACM; Gupta, R., Wohar, M., Forecasting oil and stock returns with a qual VAR using over 150years off data (2017) Energy Economics, (62), pp. 181-186. , https:\/\/doi.org\/10.1016\/j.eneco.2017.01.001; Hamzacebi, C., Diyar, Kutay, F., Comparison of direct and iterative artificial neural network forecast approaches in multi-periodic time series forecasting (2009) Expert Systems with Applications, 36 (2), pp. 3839-3844; Khaidem, L., Saha, S., Dey, S.R., (2016) Predicting the Direction of Stock Market Prices Using Random Forest; Lahmiri, S., A study on chaos in crude oil markets before and after 2008 international financial crisis (2017) Physica A: Statistical Mechanics and its Applications, (466), pp. 389-395. , https:\/\/doi.org\/10.1016\/j.physa.2016.09.031; L\u00e4ngkvist, M., Lars, Loutfi, A., A review of unsupervised feature learning and deep learning for time-series modeling (2014) Pattern Recognition Letters, (42), pp. 11-24; Larochelle, H., Erhan, D., Courville, A., Bergstra, J., Bengio, Y., An empirical evaluation of deep architectures on problems with many factors of variation (2007) Proceedings of the 24th International Conference on Machine Learning, pp. 473-480. , ACM; Moshiri, S., Foroutan, F., Forecasting nonlinear crude oil futures prices (2006) The Energy Journal, 27 (4), pp. 81-95; M\u00fcller, O., Junglas, I., Vom Brocke, J., Debortoli, S., Utilizing big data analytics for information systems research: Challenges, promises and guidelines (2016) European Journal of Information Systems, 25 (4), pp. 289-302; Papageorgiou, E.I., Poczet, K., A two-stage model for time series prediction based on fuzzy cognitive maps and neural networks (2017) Neurocomputing, 232 (SI), pp. 113-121; Rapach, D.E., Wohar, M.E., In-sample vs. Out-of-sample tests of stock return predictability in the context of data mining (2006) Journal of Empirical Finance, 13 (2), pp. 231-247. , https:\/\/doi.org\/10.1016\/j.jempfin.2005.08.001; Sharma, R., Mithas, S., Kankanhalli, A., Transforming decision-making processes: A research agenda for understanding the impact of business analytics on organisations (2014) European Journal of Information Systems, 23 (4), pp. 433-441. , https:\/\/doi.org\/10.1057\/ejis.2014.17; Shen, F., Chao, J., Zhao, J., Forecasting exchange rate using deep belief networks and conjugate gradient method (2015) Neurocomput., 167 (C), pp. 243-253. , https:\/\/doi.org\/10.1016\/j.neucom.2015.04.071; Shmueli, G., Koppius, O.R., Predictive analytics in information systems research (2011) Mis Quarterly, pp. 553-572; Tk\u00e1\u010d, M., Verner, R., Artificial neural networks in business: Two decades of research (2016) Applied Soft Computing, (38), pp. 788-804; Tzeng, F.Y., Ma, K.L., Opening the black box - Data driven visualization of neural networks (2005) VIS 05. IEEE Visualization, pp. 383-390. , https:\/\/doi.org\/10.1109\/VISUAL.2005.1532820, 2005., October; Webster, J., Watson, R.T., Analyzing the past to prepare for the future: Writing a (2002) MIS Quarterly, 26 (2), pp. 13-23; Yi, S., Ju, J., Yoon, M.-K., Choi, J., (2017) Grouped Convolutional Neural Networks for Multivariate Time Series, , http:\/\/arxiv.org\/abs\/1703.09938"}
{"Authors":"Bhowmick A., Rahman A., Rahman R.M.","Author(s) ID":"57208836861;20535568700;57202814494;","Title":"Performance analysis of different recurrent neural network architectures and classical statistical model for financial forecasting: A case study on dhaka stock exchange","Year":2019,"Source title":"Advances in Intelligent Systems and Computing","Volume":"985","Issue":null,"Art. No.":null,"Page start":277.0,"Page end":286.0,"Page count":null,"Cited by":null,"DOI":"10.1007\/978-3-030-19810-7_27","Affiliations":"Department of Electrical and Computer Engineering, North South University, Plot-15, Block-B, Bashundhara Residential Area, Dhaka, Bangladesh","Document Type":"Conference Paper","Access Type":null,"Source":"Scopus","EID":"2-s2.0-85065917523","Abstract":"Forecasting has always been of interest. Whether one's field is finance, health or seismology, being able to predict future values based on previously gathered data proves to be invaluable when taking decisions concerning the future. In this paper, we research machine learning techniques for predictions on time series and choose the best models that fit our use case, Smart Farms, in which we distributedly analyze time series received from farm-monitoring sensors. On time series with short term dependencies, like temperature or pressure, we make predictions with Hidden Markov Models, whilst for those with long range dependencies, like ground wind speeds orprecipitations, we use Recurrent Neural Networks with Long Short-Term Memory architecture. \u00a9 2015 IEEE.","Author Keywords":"Hidden Markov Model; Long Short-Term Memory; Recurrent Neural Networks; Simultaneous Temporal and Contextual Splits","Index Keywords":"Artificial intelligence; Brain; Forecasting; Learning systems; Markov processes; Memory architecture; Recurrent neural networks; Time series; Trellis codes; Best model; Forecasting techniques; Long short term memory; Long-range dependencies; Machine learning techniques; Monitoring sensors; Sensor data; Simultaneous Temporal and Contextual Splits; Hidden Markov models","References":"Baggenstoss, P.M., A modified baum-welch algorithm for hidden markov models with multiple observation spaces (2001) Speech and Audio Processing, IEEE Transactions on, 9 (4), pp. 411-416; Condie, T., Conway, N., Alvaro, P., Hellerstein, J.M., Elmeleegy, K., Sears, R., Mapreduce online (2010) NSDI, 10, p. 20; David Forney, G., Jr., The viterbi algorithm (1973) Proceedings of the IEEE, 61 (3), pp. 268-278; Hochreiter, S., Schmidhuber, J., Long short-term memory (1997) Neural Comput., 9 (8), pp. 1735-1780. , November; Jun Yoon, B., Vaidyanathan, P.P., Context-sensitive hidden markov models for modeling long-range dependencies in symbol sequences (2006) IEEE Trans. Signal Processing, 54, pp. 4169-4184; Martens, J., Sutskever, I., Learning recurrent neural networks with hessian-free optimization (2011) ICML, pp. 1033-1040. , In Lise Getoor and Tobias Scheffer, editors Omnipress; Rabiner, L.R., Juang, B.H., An introduction to hidden markov models (1986) IEEE ASSp Magazine; Shannon, M., Zen, H., Byrne, W., Autoregressive models for statistical parametric speech synthesis (2013) Audio, Speech, and Language Processing, IEEE Transactions on, 21 (3), pp. 587-597. , March; Visser, I., Maartje, E., Raijmakers, J., Van Der Han Maas, L.J., Hidden markov models for individual time series (2009) Dynamic Process Methodology in the Social and Developmental Sciences, pp. 269-289. , In Jaan Valsiner, Peter C. M. Molenaar, Maria C. D. P. Lyra, and Nandita Chaudhary, editors. Springer US; Zhang, Y., (2004) Prediction of Financial Time Series with Hidden Markov Models; Zikopoulos, P., Eaton, C., (2011) Understanding Big Data: Analytics for Enterprise Class Hadoop and Streaming Data, , McGraw-Hill Osborne Media"}
{"Authors":"Hsu E.-Y., Liu C.-L., Tseng V.S.","Author(s) ID":"57208527341;57129735000;6507335623;","Title":"Multivariate time series early classification with interpretability using deep learning and attention mechanism","Year":2019,"Source title":"Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)","Volume":"11441 LNAI","Issue":null,"Art. No.":null,"Page start":541.0,"Page end":553.0,"Page count":null,"Cited by":null,"DOI":"10.1007\/978-3-030-16142-2_42","Affiliations":"Department of Computer Science, National Chiao Tung University, 1001 University Road, Hsinchu, 300, Taiwan; Department of Industrial Engineering and Management, National Chiao Tung University, 1001 University Road, Hsinchu, 300, Taiwan","Document Type":"Conference Paper","Access Type":null,"Source":"Scopus","EID":"2-s2.0-85065043935","Abstract":"In this paper, we propose a novel stock price prediction model based on deep learning. With the success of deep learning algorithms in the field of Artificial Neural Network (ANN), we choose to solve the regression based problems (stock price prediction in our case). Stock price prediction is a challenging problem due to its random movement. This hybrid model is a combination of two well-known networks, Long Short Term Memory (LSTM) and Gated Recurrent Unit (GRU). We choose the SP 500 historical time series data and use significant evaluation metrics such as mean squared error, mean absolute percentage error etc., that conventional approaches have used. In experiment section, we have described the effectiveness of each of the component of our model along with its performance gain over the state-of-the-art approach. Our prediction model provides less error by considering this random nature (change) for a large scale of data. \u00a9 2018 IEEE.","Author Keywords":"DNN; GRU; Hybrid-network; LSTM; Stock price prediction","Index Keywords":"Electronic trading; Errors; Financial markets; Forecasting; Learning algorithms; Long short-term memory; Mean square error; Conventional approach; Evaluation metrics; Hybrid network; LSTM; Mean absolute percentage error; Mean squared error; State-of-the-art approach; Stock price prediction; Deep learning","References":"Di Persio, L., Honchar, O., Artificial neural networks architectures for stock price prediction: Comparisons and applications (2016) International Journal of Circuits, Systems and Signal Processing, 10, pp. 403-413; Medsker, L., Jain, L., Recurrent neural networks (2001) Design and Applications, 5; Hochreiter, S., The vanishing gradient problem during learning recurrent neural nets and problem solutions (1998) International Journal of Uncertainty, Fuzziness and Knowledge-Based Systems, 6 (2), pp. 107-116; Hochreiter, S., Schmidhuber, J., Long short-term memory (1997) Neural Computation, 9 (8), pp. 1735-1780; Cho, K., Van Merri\u00ebnboer, B., Gulcehre, C., Bahdanau, D., Bougares, F., Schwenk, H., Bengio, Y., (2014) Learning Phrase Representations Using Rnn Encoder-decoder for Statistical Machine Translation; Guresen, E., Kayakutlu, G., Daim, T.U., Using artificial neural network models in stock market index prediction (2011) Expert Systems with Applications, 38 (8), pp. 10389-10397; Ruck, D.W., Rogers, S.K., Kabrisky, M., Oxley, M.E., Suter, B.W., The multilayer perceptron as an approximation to a bayes optimal discriminant function (1990) IEEE Transactions on Neural Networks, 1 (4), pp. 296-298; Ghiassi, M., Saidane, H., Zimbra, D., A dynamic artificial neural network model for forecasting time series events (2005) International Journal of Forecasting, 21 (2), pp. 341-362; Medsker, L., Design and development of hybrid neural network and expert systems (1994) Neural Networks, 1994. IEEE World Congress on Computational Intelligence., 1994 IEEE International Conference on, 3, pp. 1470-1474. , IEEE; Adebiyi, A., Ayo, C., Adebiyi, M.O., Otokiti, S., Stock price prediction using neural network with hybridized market indicators (2012) Journal of Emerging Trends in Computing and Information Sciences, 3 (1), pp. 1-9; Fujieda, S., Takayama, K., Hachisuka, T., (2018) Wavelet Convolutional Neural Networks; Baek, Y.-H., Byun, O.-S., Moon, S.-R., Image edge detection using adaptive morphology meyer wavelet-cnn (2003) Neural Networks, 2003. Proceedings of the International Joint Conference on, 2, pp. 1219-1222. , IEEE; Huynh, H.D., Dang, L.M., Duong, D., A new model for stock price movements prediction using deep neural network (2017) Proceedings of the Eighth International Symposium on Information and Communication Technology. ACM, pp. 57-62; http:\/\/www.stratio.com\/blog\/deep-learning-3-recurrent-neural-networkslstm\/; https:\/\/pythonmachinelearning.pro\/advanced-recurrent-neural-networks\/; Chollet, F., (2015) Keras: Deep Learning Library for Theano and Tensorflow, 7, p. 8. , https:\/\/keras.io\/k; Kingma, D.P., Ba, J., (2014) Adam: A Method for Stochastic Optimization; Al Shalabi, L., Shaaban, Z., Kasasbeh, B., Data mining: A preprocessing engine (2006) Journal of Computer Science, 2 (9), pp. 735-739; LeCun, Y., Bengio, Y., Hinton, G., Deep learning (2015) Nature, 521 (7553), p. 436"}
{"Authors":"Au Yeung J.F.K., Wei Z.-K., Chan K.Y., Lau H.Y.K., Yiu K.-F.C.","Author(s) ID":"57208441553;57200795560;55647800400;7201497761;24802813000;","Title":"Jump detection in financial time series using machine learning algorithms","Year":2019,"Source title":"Soft Computing","Volume":null,"Issue":null,"Art. No.":null,"Page start":null,"Page end":null,"Page count":null,"Cited by":null,"DOI":"10.1007\/s00500-019-04006-2","Affiliations":"Department of Industrial and Manufacturing Systems Engineering, The University of Hong Kong, Pokfulam, Hong Kong; Department of Applied Mathematics, The Hong Kong Polytechnic University, Hung Hom, Kowloon, Hong Kong; School of Electrical Engineering, Computing and Mathematical Sciences, Curtin University, Perth, Australia","Document Type":"Article","Access Type":null,"Source":"Scopus","EID":"2-s2.0-85064841438","Abstract":"This study presents an integrated system where wavelet transforms and recurrent neural network (RNN) based on artificial bee colony (abc) algorithm (called ABC-RNN) are combined for stock price forecasting. The system comprises three stages. First, the wavelet transform using the Haar wavelet is applied to decompose the stock price time series and thus eliminate noise. Second, the RNN, which has a simple architecture and uses numerous fundamental and technical indicators, is applied to construct the input features chosen via Stepwise Regression-Correlation Selection (SRCS). Third, the Artificial Bee Colony algorithm (ABC) is utilized to optimize the RNN weights and biases under a parameter space design. For illustration and evaluation purposes, this study refers to the simulation results of several international stock markets, including the Dow Jones Industrial Average Index (DJIA), London FTSE-100 Index (FTSE), Tokyo Nikkei-225 Index (Nikkei), and Taiwan Stock Exchange Capitalization Weighted Stock Index (TAIEX). As these simulation results demonstrate, the proposed system is highly promising and can be implemented in a real-time trading system for forecasting stock prices and maximizing profits. \u00a9 2010 Published by Elsevier B.V. All rights reserved.","Author Keywords":"Artificial bee colony algorithm (ABC); Recurrent neural network (RNN); Stepwise regression-correlation selection (SRCS); Wavelet transform","Index Keywords":"Artificial bee colonies; Dow Jones Industrial averages; Haar wavelets; Input features; Integrated systems; International stock markets; Parameter spaces; Real-time trading; Simulation result; Stepwise regression; Stock exchange; Stock indices; Stock market; Stock price; Stock price forecasting; Technical indicator; Three stages; Algorithms; Commerce; Feature extraction; Finance; Forecasting; Integrated control; Integrated optics; Optimization; Profitability; Recurrent neural networks; Regression analysis; Reinforcement learning; Time series; Wavelet transforms","References":"Abu-Mostafa, Y.S., Atiya, A.F., Introduction to financial forecasting (1996) Applied Intelligence, pp. 205-213; Refenes, A.N., Zapranis, A., Francis, G., Stock performance modeling using neural networks: A comparative study with regression models (1994) Neural Networks, pp. 375-388; Yoo, Y.N., Swales, G., Margavio, T.M., A comparison of discriminate analysis versus artificial neural networks (1993) Journal of the Operations Research Society, pp. 51-60; Zhang, Y.Q., Akkaladevi, S., Vachtsevanos, G., Lin, T.Y., Granular neural Web agents for stock prediction (2002) Soft Computing Journal, pp. 406-413; Chang, P.C., Wang, Y.W., Yang, W.N., An investigation of the hybrid forecasting models for stock price variation in Taiwan (2004) Journal of the Chinese Institute of Industrial Engineers, pp. 358-368; Chen, A.S., Leung, M.T., Daouk, H., Application of neural networks to an emerging financial market: Forecasting and trading the Taiwan stock index (2003) Computers and Operations Research, pp. 901-923; Parasuraman, K., Elshorbagy, A., Wavelet networks: An alternative to classical neural networks (2005) IEEE International Joint Conference on Neural Networks, pp. 2674-2679; Zadeh, L.A., The role of fuzzy logic in modeling, identification and control (1994) Modeling Identification and Control, pp. 191-203; Marmer, V., Nonlinearity, nonstationarity, and spurious forecasts (2008) Journal of Econometrics, pp. 1-27; Basturk, B., Karaboga, D., An artificial bee colony (abc) algorithm for numeric function optimization (2006) IEEE Swarm Intelligence Symposium, , Indianapolis, Indiana, USA, May; Cohen, A., Daubechies, I., Vial, P., Wavelets on the interval and fast wavelet transform (1993) Applied and Computational Harmonic, pp. 54-81; Ramsey, J.B., Zhang, Z., The analysis of foreign exchange data using waveform dictionaries (1997) Journal of Empirical Finance, pp. 341-372; Popoola, A., Ahmad, K., Testing the suitability of wavelet preprocessing for TSK fuzzy models (2006) Proceeding of FUZZ-IEEE: International Conference Fuzzy System Networks, pp. 1305-1309; Genay, R., Selcuk, F., Whitcher, B., Differentiating intraday seasonalities through wavelet multi-scaling (2001) Physica A, pp. 543-556; Ramsey, J.B., The contribution of wavelets to the analysis of economic and financial data (1999) Philosophical Transactions of the Royal Society of London Series A-Mathematical Physical and Engineering Sciences, pp. 2593-2606; Papagiannaki, K., Taft, N., Zhang, Z.-L., Diot, C., Long-term forecasting of internet backbone traffic (2005) IEEE Transactions on Neural Networks, pp. 1110-1124; Kim, Y., Street, W.N., An intelligent system for customer targeting: A data mining approach (2004) Decision Support System, pp. 215-228; Abramovich, F., Besbeas, P., Sapatinas, T., Bayes approach to block wavelet function estimation (2002) Computational Statistics and Data Analysis, pp. 435-451; Gencay, R., Selcuk, F., Whitcher, B., (2002) An Introduction to Wavelets and Other Filtering Methods in Finance and Economics, , Academic Press New York; Ramsey, J.B., Lampart, C., The decomposition of economic relationships by time scale using wavelets: Expenditure and income (1998) Nonlinear Dynamics and Econometrics, pp. 23-42; Adel, S., Martin, C., Heather, J.R., Jose, A.M., The reaction of stock markets to crashes and events: A comparison study between emerging and mature markets using wavelet transforms (2006) Physica A, pp. 511-521; Chang, P.C., Liu, C.H., Wang, Y.W., A hybrid model by clustering and evolving fuzzy rules for sale forecasting in printed circuit board industry (2006) Decision Support System, pp. 1715-1729; Elman, J.L., Finding structure in time (1990) Cognitive Science, 14, pp. 179-211; Karaboga, D., Basturk, B., A powerful and efficient algorithm for numerical function optimization: Artificial bee colony (abc) algorithm (2007) Journal of Global Optimization, pp. 459-471; Karaboga, D., Basturk, B., On the performance of artificial bee colony (abc) algorithm (2008) Applied Soft Computing, pp. 687-697; Karaboga, D., Akay, B., A comparative study of artificial bee colony algorithm (2009) Applied Mathematics and Computation, pp. 108-132; Karaboga, D., Ozturk, C., Neural networks training by artificial bee colony algorithm on pattern classification (2009) Neural Network World, pp. 279-292; Chen, S.M., Forecasting enrollments based on fuzzy time-series (1996) Fuzzy Sets Systems, pp. 11-319; Yu, H.K., Weighted fuzzy time-series models for TAIEX forecasting (2005) Physica A, pp. 609-624; Cheng, C.H., Wei, L.Y., Chen, Y.S., Fusion ANFIS models based on multi-stock volatility causality for TAIEX forecasting (2009) Neurocomputing, pp. 3462-3468; Chen, S.H., (2002) Genetic Algorithms and Genetic Programming in Computational Finance, , Kluwer Academic Publishers Dordrecht; Engle, R., GARCH 101: The use of ARCH\/GARCH models in applied econometrics (2001) The Journal of Economic Perspectives, pp. 157-168; Patterson, D.W., (1996) Artificial Neural Networks: Theory and Applications, , Prentice Hall"}
{"Authors":"Yu P., Yan X.","Author(s) ID":"57208402963;23391007200;","Title":"Stock price prediction based on deep neural networks","Year":2019,"Source title":"Neural Computing and Applications","Volume":null,"Issue":null,"Art. No.":null,"Page start":null,"Page end":null,"Page count":null,"Cited by":null,"DOI":"10.1007\/s00521-019-04212-x","Affiliations":"School of Computer Science, China University of Geosciences, Wuhan, Hubei  430074, China; Hubei Key Laboratary of Intelligent Geo-Information Processing, Wuhan, Hubei  430074, China","Document Type":"Article","Access Type":null,"Source":"Scopus","EID":"2-s2.0-85064689405","Abstract":"Multivariate time-series early classification is an emerging topic in data mining fields with wide applications like biomedicine, finance, manufacturing, etc. Despite of some recent studies on this topic that delivered promising developments, few relevant works can provide good interpretability. In this work, we consider simultaneously the important issues of model performance, earliness, and interpretability to propose a deep-learning framework based on the attention mechanism for multivariate time-series early classification. In the proposed model, we used a deep-learning method to extract the features among multiple variables and capture the temporal relation that exists in multivariate time-series data. Additionally, the proposed method uses the attention mechanism to identify the critical segments related to model performance, providing a base to facilitate the better understanding of the model for further decision making. We conducted experiments on three real datasets and compared with several alternatives. While the proposed method can achieve comparable performance results and earliness compared to other alternatives, more importantly, it can provide interpretability by highlighting the important parts of the original data, rendering it easier for users to understand how the prediction is induced from the data. \u00a9 Springer Nature Switzerland AG 2019.","Author Keywords":"Attention; Deep neural network; Early classification on time-series","Index Keywords":"Decision making; Deep neural networks; Time series; Attention; Attention mechanisms; Critical segments; Learning frameworks; Learning methods; Model performance; Multivariate time series; Temporal relation; Data mining","References":"Chen, Y., Zhao, D., Lv, L., Li, C., A visual attention based convolutional neural network for image classification (2016) 2016 12Th World Congress on Intelligent Control and Automation (WCICA), pp. 764-769. , pp., IEEE; Cui, Z., Chen, W., Chen, Y., (2016) Multi-Scale Convolutional Neural Networks for Time Series Classification, , arXiv preprint arXiv; Ding, H., Trajcevski, G., Scheuermann, P., Wang, X., Keogh, E., Querying and mining of time series data: Experimental comparison of representations and distance measures (2008) Proc. VLDB Endow., 1 (2), pp. 1542-1552; Ghalwash, M.F., Ramljak, D., Obradovi\u0107, Z., Early classification of multivariate time series using a hybrid HMM\/SVM model (2012) 2012 IEEE International Conference on Bioinformatics and Biomedicine (BIBM), pp. 1-6. , pp., IEEE; Grabocka, J., Schilling, N., Wistuba, M., Schmidt-Thieme, L., Learning time-series shapelets (2014) Proceedings of the 20Th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, pp. 392-401. , pp., ACM; He, Q., Dong, Z., Zhuang, F., Shang, T., Shi, Z., Fast time series classification based on infrequent shapelets (2012) 2012 11Th International Conference on Machine Learning and Applications (ICMLA), 1, pp. 215-219. , vol., pp., IEEE; Huang, H.S., Liu, C.L., Tseng, V.S., Multivariate time series early classification using multi-domain deep neural network (2018) 2018 IEEE International Conference on Data Science and Advanced Analytics (DSAA); H\u00fcbner, R., Steinhauser, M., Lehle, C., A dual-stage two-phase model of selective attention (2010) Psychol. Rev., 117 (3), p. 759; Kadous, M.W., Temporal Classification: Extending The Classification Paradigm to Multivariate Time Series (2002) University of New South Wales, Kensington; Lin, Y.-F., Chen, H.-H., Tseng, V.S., Pei, J., Reliable early classification on multivariate time series with numerical and categorical attributes (2015) PAKDD 2015. LNCS (LNAI), 9077, pp. 199-211. , https:\/\/doi.org\/10.1007\/978-3-319-18038-0_16, Cao, T., Lim, E.-P., Zhou, Z.-H., Ho, T.-B., Cheung, D., Motoda, H. (eds.), pp., Springer, Cham; Lipton, Z.C., (2016) The Mythos of Model Interpretability, , arXiv preprint arXiv; Liu, Q., Yu, F., Wu, S., Wang, L., Mining significant microblogs for misinformation identification: An attention-based approach (2018) ACM Trans. Intell. Syst. Technol., 9 (5), pp. 50:1\u201350:20. , https:\/\/doi.org\/10.1145\/3173458; Qin, Y., Song, D., Chen, H., Cheng, W., Jiang, G., Cottrell, G., (2017) A Dual-Stage Attention-Based Recurrent Neural Network for Time Series Prediction, , arXiv preprint arXiv; Ribeiro, M.T., Singh, S., Guestrin, C., Why should i trust you? Explaining the predictions of any classifier (2016) Proceedings of the 22Nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, pp. 1135-1144. , pp., ACM; Wang, W., Chen, C., Wang, W., Rai, P., Carin, L., (2016) Earliness-Aware Deep Convolutional Networks for Early Time Series Classification, , arXiv preprint arXiv; Xing, Z., Pei, J., Dong, G., Yu, P.S., Mining sequence classifiers for early prediction (2008) Proceedings of the 2008 SIAM International Conference on Data Mining, pp. 644-655. , pp., SIAM; Xing, Z., Pei, J., Philip, S.Y., Early prediction on time series: A nearest neighbor approach (2009) IJCAI, pp. 1297-1302. , pp., Morgan Kaufmann; Xing, Z., Pei, J., Philip, S.Y., Early classification on time series (2012) Knowl. Inf. Syst., 31 (1), pp. 105-127; Xing, Z., Pei, J., Yu, P.S., Wang, K., Extracting interpretable features for early classification on time series (2011) Proceedings of the 2011 SIAM International Conference on Data Mining, pp. 247-258. , pp., SIAM; Ye, L., Keogh, E., Time series shapelets: A new primitive for data mining (2009) Proceedings of the 15Th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, pp. 947-956. , pp., ACM; Zheng, Y., Liu, Q., Chen, E., Ge, Y., Zhao, J.L., Time series classification using multi-channels deep convolutional neural networks (2014) WAIM 2014. LNCS, 8485, pp. 298-310. , https:\/\/doi.org\/10.1007\/978-3-319-08010-9_33, Li, F., Li, G., Hwang, S., Yao, B., Zhang, Z. (eds.), pp., Springer, Cham"}
{"Authors":"De Stefani J., Caelen O., Hattab D., Le\u00c2\u00a0Borgne Y.-A., Bontempi G.","Author(s) ID":"57196261818;15623146800;57196257647;57207980297;6603615974;","Title":"A multivariate and multi-step ahead machine learning approach to traditional and cryptocurrencies volatility forecasting","Year":2019,"Source title":"Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)","Volume":"11054 LNAI","Issue":null,"Art. No.":null,"Page start":7.0,"Page end":22.0,"Page count":null,"Cited by":null,"DOI":"10.1007\/978-3-030-13463-1_1","Affiliations":"MLG, Departement d\u2019Informatique, Universit\u00e9 Libre de Bruxelles, Boulevard du Triomphe CP212, Brussels, 1050, Belgium; Worldline SA\/NV R&D, Brussels, Belgium; Equens Worldline R&D, Lille, Seclin, France","Document Type":"Conference Paper","Access Type":null,"Source":"Scopus","EID":"2-s2.0-85063442106","Abstract":"Early classification on multivariate time series is an important research topic in data mining with wide applications to various domains like medical diagnosis, motion detection and financial prediction, etc. Shapelet is probably one of the most commonly used approaches to tackle early classification problem, but one drawback of shaplet is its inefficiency. More importantly, the extracted shapelets may not be applicable to every test case at any time point. This work focuses on early classification of multivariate time series and proposes a novel framework named Multi-Domain Deep Neural Network (MDDNN), in which convolutional neural network (CNN) and long-short term memory (LSTM) are incorporated to learn feature representation and relationship embedding in the long sequences with long time lags. The proposed model can make predictions at any time point of a multivariate time series with the help of a truncation process. We conducted experiments on four real datasets and compared with state-of-the-art algorithms. The experimental results indicate that the proposed method outperforms the alternatives significantly on both of earliness and accuracy. Detailed analysis about the proposed model is also provided in this work. To the best of our knowledge, this is the first work that incorporates deep neural network methods (CNN and LSTM) and multi-domain approach to boost the problem of early classification on multivariate time series. \u00a9 2018 IEEE.","Author Keywords":"Convolutional Neural Networks; Early Classification; LSTM; Multi-domain Inputs; Time Series Analysis","Index Keywords":"Advanced Analytics; Computer aided diagnosis; Convolution; Data mining; Deep neural networks; Long short-term memory; Medical computing; Convolutional neural network; Feature representation; LSTM; Multi domains; Multivariate time series; Neural network method; Relationship embedding; State-of-the-art algorithms; Time series analysis","References":"Ealto, M., Va\u015cak, M., Baoti\u0107, M., Matu\u015cko, J., Horvath, K., Neuralnetwork-based ultra-short-term wind forecasting (2014) European Wind Energy Association 2014 Annual Event (EWEA 2014); Breg\u00f3n, A., Sim\u00f3n, M.A., Rodr\u00edguez, J.J., Alonso, C., Pulido, B., Moro, I., Early fault classification in dynamic systems using casebased reasoning (2005) Conference of the Spanish Association for Artificial Intelligence, pp. 211-220. , Springer, Springer; Cooley, J.W., Tukey, J.W., An algorithm for the machine calculation of complex fourier series (1965) Mathematics of Computation, 19 (90), pp. 297-301; Cui, Z., Chen, W., Chen, Y., (2016) Multi-scale Convolutional Neural Networks for Time Series Classification, , arXiv preprint arXiv:1603.06995; Ding, H., Trajcevski, G., Scheuermann, P., Wang, X., Keogh, E., Querying and mining of time series data: Experimental comparison of representations and distance measures (2008) Proceedings of the VLDB Endowment, 1 (2), pp. 1542-1552; Filonov, P., Lavrentyev, A., Vorontsov, A., (2016) Multivariate Industrial Time Series with Cyber-attack Simulation: Fault Detection Using An Lstm-based Predictive Data Model, , arXiv preprint arXiv:1612.06676; Ghalwash, M.F., Obradovic, Z., Early classification of multivariate temporal observations by extraction of interpretable shapelets (2012) BMC Bioinformatics, 13 (1), p. 195; Ghalwash, M.F., Radosavljevic, V., Obradovic, Z., Extraction of interpretable multivariate patterns for early diagnostics (2013) Data Mining (ICDM), 2013 IEEE 13th International Conference on, pp. 201-210. , IEEE; Ghalwash, M.F., Ramljak, D., Obradovi\u0107, Z., Early classification of multivariate time series using a hybrid hmm\/SVM model (2012) Bioinformatics and Biomedicine (BIBM), 2012 IEEE International Conference on, pp. 1-6. , IEEE; Grabocka, J., Schilling, N., Wistuba, M., Schmidt-Thieme, L., Learning time-series shapelets (2014) Proceedings of the 20th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, pp. 392-401. , ACM; He, K., Zhang, X., Ren, S., Sun, J., Deep residual learning for image recognition (2016) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 770-778; He, Q., Dong, Z., Zhuang, F., Shang, T., Shi, Z., Fast time series classification based on infrequent shapelets (2012) Machine Learning and Applications (ICMLA), 2012 11th International Conference on, 1, pp. 215-219. , IEEE; Hochreiter, S., Schmidhuber, J., Long short-term memory (1997) Neural Computation, 9 (8), pp. 1735-1780; Howbert, J.J., Patterson, E.E., Stead, S.M., Brinkmann, B., Vasoli, V., Crepeau, D., Vite, C.H., Mavoori, J., Forecasting seizures in dogs with naturally occurring epilepsy (2014) PloS One, 9 (1), p. e81920; Ioffe, S., Szegedy, C., Batch normalization: Accelerating deep network training by reducing internal covariate shift (2015) International Conference on Machine Learning, pp. 448-456; Kadous, M.W., (2002) Temporal Classification: Extending the Classification Paradigm to Multivariate Time Series, , University of New South Wales; Kingma, D.P., Ba, J., (2014) Adam: A Method for Stochastic Optimization, , arXiv preprint arXiv:1412.6980; Krizhevsky, A., Sutskever, I., Hinton, G.E., Imagenet classification with deep convolutional neural networks (2012) Advances in Neural Information Processing Systems, pp. 1097-1105; Lecun, Y., Bottou, L., Bengio, Y., Haffner, P., Gradient-based learning applied to document recognition (1998) Proceedings of the IEEE, pp. 2278-2324; Lin, J., Keogh, E., Lonardi, S., Chiu, B., A symbolic representation of time series, with implications for streaming algorithms (2003) Proceedings of the 8th ACM SIGMOD Workshop on Research Issues in Data Mining and Knowledge Discovery, pp. 2-11. , ACM; Lin, Y.-F., Chen, H.-H., Tseng, V.S., Pei, J., Reliable early classification on multivariate time series with numerical and categorical attributes (2015) Pacific-Asia Conference on Knowledge Discovery and Data Mining, pp. 199-211. , Springer; Lines, J., Davis, L.M., Hills, J., Bagnall, A., A shapelet transform for time series classification (2012) Proceedings of the 18th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, pp. 289-297. , ACM; Malhotra, P., Vig, L., Shroff, G., Agarwal, P., Long short term memory networks for anomaly detection in time series (2015) Proceedings, p. 89. , Presses universitaires de Louvain; Nair, V., Hinton, G.E., Rectified linear units improve restricted boltzmann machines (2010) Proceedings of the 27th International Conference on Machine Learning (ICML-10), pp. 807-814; Rakthanmanon, T., Keogh, E., Fast shapelets: A scalable algorithm for discovering time series shapelets (2013) Proceedings of the 2013 SIAM International Conference on Data Mining, pp. 668-676. , SIAM; Rodr\u00edguez, J.J., Alonso, C.J., Bostr\u00f6m, H., Boosting interval based literals (2001) Intelligent Data Analysis, 5 (3), pp. 245-262; Srivastava, N., Hinton, G., Krizhevsky, A., Sutskever, I., Salakhutdinov, R., Dropout: A simple way to prevent neural networks from overfitting (2014) The Journal of Machine Learning Research, 15 (1), pp. 1929-1958; Szegedy, C., Ioffe, S., Vanhoucke, V., Alemi, A.A., Inception-v4, inception-resnet and the impact of residual connections on learning (2017) AAAI, 4, p. 12; Wang, W., Chen, C., Wang, W., Rai, P., Carin, L., (2016) Earliness-aware Deep Convolutional Networks for Early Time Series Classification, , arXiv preprint arXiv:1611.04578; Xi, X., Keogh, E., Shelton, C., Wei, L., Ratanamahatana, C.A., Fast time series classification using numerosity reduction (2006) Proceedings of the 23rd International Conference on Machine Learning, pp. 1033-1040. , ACM, ACM New York; Xing, Z., Pei, J., Dong, G., Yu, P.S., Mining sequence classifiers for early prediction (2008) Proceedings of the 2008 SIAM International Conference on Data Mining, pp. 644-655. , SIAM; Xing, Z., Pei, J., Philip, S.Y., Early prediction on time series: A nearest neighbor approach (2009) IJCAI, pp. 1297-1302. , Morgan Kaufmann; Xing, Z., Pei, J., Yu, P.S., Wang, K., Extracting interpretable features for early classification on time series (2011) Proceedings of the 2011 SIAM International Conference on Data Mining, pp. 247-258. , SIAM; Yang, J., Nguyen, M.N., San, P.P., Li, X., Krishnaswamy, S., Deep convolutional neural networks on multichannel time series for human activity recognition (2015) IJCAI, pp. 3995-4001; Ye, L., Keogh, E., Time series shapelets: A new primitive for data mining (2009) Proceedings of the 15th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, pp. 947-956. , ACM; Zheng, Y., Liu, Q., Chen, E., Ge, Y., Zhao, J.L., Time series classification using multi-channels deep convolutional neural networks (2014) International Conference on Web-Age Information Management, pp. 298-310. , Springer"}
{"Authors":"Wen M., Li P., Zhang L., Chen Y.","Author(s) ID":"57207925743;57193136585;57207942564;56928458300;","Title":"Stock market trend prediction using high-order information of time series","Year":2019,"Source title":"IEEE Access","Volume":"7","Issue":null,"Art. No.":" 8653278","Page start":28299.0,"Page end":28308.0,"Page count":null,"Cited by":null,"DOI":"10.1109\/ACCESS.2019.2901842","Affiliations":"School of Computer Science, Southwest Petroleum University, Chengdu, 610500, China; Corporate IT Department, Nomura Securities Corporation, Tokyo, 103-8011, Japan","Document Type":"Article","Access Type":"Open Access","Source":"Scopus","EID":"2-s2.0-85063269215","Abstract":"This paper presents a novel type of recurrent neural network, the regularized dynamic self-organized neural network inspired by the immune algorithm. The regularization technique is used with the dynamic self-organized multilayer perceptrons network that is inspired by the immune algorithm. The regularization has been addressed to improve the generalization and to solve the over-fitting problem. In this work, the average values of 30 simulations generated from 10 financial time series are examined. The results of the proposed network were compared with the standard dynamic self-organized multilayer perceptrons network inspired by the immune algorithm, the regularized multilayer neural networks and the regularized self-organized neural network inspired by the immune algorithm. The simulation results indicated that the proposed network showed average improvement using the annualized return for all signals of 0.491, 8.1899 and 1.0072 in comparison to the benchmarked networks, respectively. \u00a9 2015 Elsevier B.V.","Author Keywords":"Dynamic neural network; Exchange rate time series; Financial time series prediction","Index Keywords":"Algorithms; Cybernetics; Finance; Financial data processing; Multilayers; Neural networks; Recurrent neural networks; Time series; Dynamic neural networks; Exchange rates; Financial time series; Financial time series predictions; Immune algorithms; Over fitting problem; Regularization technique; Self-organized neural networks; Multilayer neural networks; algorithm; Article; artificial neural network; controlled study; dynamic self-organized neural network; financial information system; financial time series prediction; intermethod comparison; mathematical parameters; prediction; priority journal; quality control; regularized multilayer neural network; regularized self-organized neural network; signal noise ratio; simulation","References":"Kamruzzaman, J., ANN-based forecasting of foreign currency exchange rates (2004) Neural Inf. Process. - Lett. Rev., 3 (2), pp. 49-58; Espinoza, R., Lombardi, M.J., Fornari, F., (2009) The Role of Financial Variables in Predicting Economic Activity, 1108. , ECB Working Paper Series, Germany; Leondes, C.T., Intelligent Knowledge-Based Systems: Business and Technology in the New Millennium (2005), http:\/\/dx.doi.org\/10.1007\/978-1-4020-7829-3, Springer-Verlag, US; Kamruzzaman, J., Sarker, R., Forecasting of currency exchange rates using ANN: a case study (2003), 1, pp. 793-797. , Proceedings of the Conference on Neural Networks and Signal Processing, Nanjing, China; Krollner, B., (2011) Risk management in the australian stockmarket using artificial neural networks, , (Ph.D. thesis); Tan, T.Z., Quek, C., Ng, G.S., Brain-inspired genetic complementary learning for stock market prediction (2005) IEEE Congr. Evol. Comput., 3, pp. 2653-2660; Ahmadifard, M., Sadenejad, F., Mohammadi, I., Aramesh, K., Forecasting stock market return using ANFIS: the case of Tehran stock exchange (2013) Int. J. Adv. Stud. Humanit. Soc. Sci., 1 (5), pp. 452-459; Ahangar, R.G., Yahyazadehfar, M., Pournaghshband, H., The comparison of methods artificial neural network with linear regression using specific variables for prediction stock price in Tehran stock exchange (2010) Int. J. Comput. Sci. Inf. Secur., 7 (2), pp. 38-46; Agrawal, G., Srivastav, A.K., Srivastava, A., A study of exchange rates movement and stock market volatility (2010) Int. J. Bus. Manag., 5 (12), pp. 62-73; Yao, J., Poh, H., Jasic, T., Foreign exchange rates forecasting with neural networks (1996) Proceedings of the International Conference on Neural Information Processing, pp. 754-759. , Hong Kong; Ghazali, R., (2007) Higher Order Neural Networks for Financial Time Series Prediction (Ph.D. thesis), , Liverpool John Moores University, United Kingdom; Schwaerzel, R., Bylander, T., Predicting currency exchange rates by genetic programming with trigonometric functions and high-order statistics (2006) Proceedings of the 8th Annual Conference on Genetic and Evolutionary Computation, 1, pp. 955-956; Zhang, G.P., Patuwo, B.E., Hu, M.Y., A simulation study of artificial neural networks for nonlinear time-series forecasting (2001) Comput. Oper. Res., 28 (4), pp. 381-396; Zekic, M., Neural network applications in stock market predictions: a methodology analysis (1998) Proceedings of the 9th International Conference on Information and Intelligent Systems, pp. 255-263; Bansal, A., Kauffman, R.J., Weitz, R.R., Comparing the performance of regression and neural networks a data quality varies: a business value approach (1993) J. Manag. Inf. Syst., 10 (10), pp. 11-32; Vojinovic, Z., Kecman, V., Seidel, R., A data mining approach to financial time series modelling and forecasting (2001) Intell. Syst. Account. Finance Manag., 239 (4), pp. 225-239; Dunis, C.L., Williams, M., Modelling and Trading the EUR\/USD exchange rate: do neural network models perform better? (2002) Trading Regul., 8 (3), pp. 1-24; Dunis, C.L., Williams, M., (2003) Applications of Advanced Regression Analysis for Trading and Investment, , John Wiley & Sons, England; Pissarenko, D., (2002) Neural networks for financial time series prediction: overview over recent research, , (BSc thesis), University of Derby, Austria; Aryal, D.R., Yao-wu, W., Neural network forecasting of the production level of Chinese construction industry (2003) J. Comp. Int. Manag., 6 (2), pp. 45-64; Bagherifard, K., Nilashi, M., Ibrahim, O., Janahmadi, N., Ebrahim, L., Comparative study of artificial neural network and ARIMA models in predicting exchange rate (2012) Res. J. Appl. Sci. Eng. Technol., 4 (21), pp. 4397-4403; Steurer, E., Nonlinear modelling of the DEM\/USD exchange rate (1993), pp. 199-211. , (Ed.) Apostolos-Paul Refenes, Neural Networks in the Capital Markets, Wiley; New York; Walczak, S., An empirical analysis of data requirements for financial forecasting with neural networks (2001) J. Manag. Inf. Syst., 17 (4), pp. 203-222; Widrow, B., Rumelhart, D.E., Lehr, M.A., Neural networks: applications in industry, business and science (1994) Commun. ACM, 37 (3), pp. 93-105; Hammerstrom, D., Neural networks at work (1993) IEEE Spectr., 30 (6), pp. 26-32; Lin, T.W., Yu, C.C., Forecasting stock market with neural networks (2009) SSRN Electron. J.; Guresen, E., Kayakutlu, G., Daim, T.U., Using artificial neural network models in stock market index prediction (2011) Expert Syst. Appl., 38 (8), pp. 10389-10397; Giles, C.L., Lawrence, S., Tsoi, A.C., Noisy time series prediction using a recurrent neural network and grammatical inference (2001) Mach. Learn., 44 (1-2), pp. 161-183; Yao, J., Tan, C.L., A case study on using neural networks to perform technical forecasting of forex (2000) Neurocomputing, 34 (1-4), pp. 79-98; Chen, A.-S., Leung, M.T., Performance evaluation of neural network architectures: the case of predicting foreign exchange correlations (2005) J. Forecast., 24 (6), pp. 403-420; Ghazali, R., Hussain, A., Nawi, N., Mohamad, B., Non-stationary and stationary prediction of financial time series using dynamic ridge polynomial neural network (2009) Neurocomputing, 72 (10-12), pp. 2359-2367; Pacifici, F., (2010) Novel Neural Network-based Algorithms for Urban Classification and Change Detection from Satellite Imagery (Ph.D. thesis), , Tor Vergata University, Rome, Italy; Herrera, J., (1999) TimE Series Prediction Using Inductive Reasoning Techniques (Ph.D. thesis), , Instituto de Organizacion y Control de Sistemas Industriales, Universitat Polit\u00e8cnica de Catalunya, BarcelonaTech, Spain; Zhang, X., Liu, Y., Yang, M., Zhang, T., Young, A., Li, X., Comparative study of four time series methods in forecasting typhoid fever incidence in China (2013) PloS One, 8 (5); Pedersen, M., (1997) Optimization of Recurrent Neural Networks for Time Series Modelling (Ph.D. thesis), , Technical University of Denmark, Denmark; Mahdi, A., (2010) The Application of Neural Network in Financial Time Series Analysis and Prediction Using Immune System (M.Phil. thesis), , Liverpool John Moores University, UK; Mahdi, A., Hussain, A., Al-Jumeily, D., The prediction of non-stationary physical time series using the application of regularization technique in self-organised multilayer perceptrons inspired by the immune algorithm (2010) Proceedings of the Development of E-systems Engineering Conference, pp. 213-218; Widyanto, M.R., Nobuhara, H., Kawamoto, K., Hirota, K., Kusumoputro, B., Improving recognition and generalization capability of back-propagation NN using self-organized network inspired by immune algorithm (2005) Appl. Soft Comput., 6, pp. 72-84; Shen, X., Gao, X.Z., Bie, R., Artificial immune networks: model and application (2008) Int. J. Comput. Intell. Syst., 1 (2), pp. 168-176; Jordan, M.I., Attractor dynamics and parallelism in a connectionist sequential machine (1990), pp. 112-127. , (Ed.) Joachim Diederich, Artificial neural networks, IEEE Press Piscataway; NJ, USA; Voegtlin, T., Recursive self-organizing maps (2002) Neural Netw., 15 (8-9), pp. 979-991; Siwek, K., Osowski, S., Regularization of neural networks for improved load forecasting in power system (2001) Proceedings of the 8th IEEE International Conference on Electronics, Circuits and Systems, pp. 1255-1258. , ICECS; Bishop, C.M., (1995) Neural Networks for Pattern Recognition, , Cambridge, UK; Larsen, J., Svarer, C., Andersen, L.N., Hansen, L.K., (1998) Adaptive Regularization in Neural Network Modelling, Neural Networks: Tricks of the Trade, pp. 113-132. , Springer Berlin, Heidelberg; Mahdi, A., Hussain, A., Lisbo, P., Al-Jumeily, D., The Application of the neural network model inspired by the immune system in financial time series prediction (2009) Proceedings of the Development of E-Systems Engineering conference, pp. 370-376; Hussain, A.J., Al-jumeily, D., How good is the backpropogation neural network using a self-organised network inspired by immune algorithm (SONIA) when used for multi-step financial time series prediction? (2007) Proceedings of the 4th International Symposium on Neural Networks, 4492 (2), pp. 921-930. , ISNN; Huang, Y., Lai, W., Nakamori, K.K., Forecasting foreign exchange rates with artificial neural networks: a review (2004) Int. J. Inf. Technol. Decis. Mak., 3 (1), pp. 145-165; Alexandridis, A., Livanis, E., Forecasting crude oil prices using wavelet neural networks (2008) Proceedings of the 5th FSDET Conference, pp. 1-8. , Athens, Greece; Thomason, M., The practitioner method and tools (1999) J. Comput. Intell. Finance, 7 (3), pp. 36-45; Sundareshan, M., Wong, Y.C., Condarcure, T., Training algorithems for recurrent neural nets thet eliminate the need for computation of error gradients with application to trajectory production problem (1999) Recurrent Neural Networks: Design and Applications, , CRC Press, Boca Raton, London, New York, Washington, DC, L.C.J. Larry Medsker (Ed.); Tay, F.E.H., Cao, L.J., Modified support vector machines in financial time series forecasting (2002) Neurocomputing, 48, pp. 847-861; Cao, L.J., Tay, F.E.H., Support vector machine with adaptive parameters in financial time series forecasting (2003) IEEE Trans. Neural Netw., 14 (6), pp. 1506-1518; Huang, D.S., The local minima free condition of feedforward neural networks for outer-supervised learning (1998) IEEE Trans. Syst. Man Cybern., 28B (3), pp. 477-480; Huang, D.S., A constructive approach for finding arbitrary roots of polynomials by neural networks (2004) IEEE Trans. Neural Netw., 15 (2), pp. 477-491; Montgomery, D.C., Runger, G.C., (1999) Applied Statistics and Probability for Engineers, , Wiley, New York; Huang, D.S., Radial basis probabilistic neural networks: model and application (1999) Int. J. Pattern Recognit. Artif. Intell., 13 (7), pp. 1083-1101"}
{"Authors":"Liu F., Cai M., Wang L., Lu Y.","Author(s) ID":"16039764100;57207691663;54397764100;57207696983;","Title":"An Ensemble Model Based on Adaptive Noise Reducer and Over-Fitting Prevention LSTM for Multivariate Time Series Forecasting","Year":2019,"Source title":"IEEE Access","Volume":"7","Issue":null,"Art. No.":" 8648338","Page start":26102.0,"Page end":26115.0,"Page count":null,"Cited by":1.0,"DOI":"10.1109\/ACCESS.2019.2900371","Affiliations":"School of Computer Science and Engineering, South China University of Technology, Guangzhou, 510006, China; School of Software Engineering, South China University of Technology, Guangzhou, 510006, China","Document Type":"Article","Access Type":"Open Access","Source":"Scopus","EID":"2-s2.0-85062693213","Abstract":"Time series analysis is a fundamental subject that has been addressed widely in different fields. It has been exploited and used in different scientific fields for example, natural, biomedical, economic and industrial data as well as financial time series. In this paper, we consider the application of a novel neural network architecture inspired by the immune algorithm and the recurrent links for the prediction of Lorenz and earthquake time series by exploiting the inherent temporal capabilities of the recurrent neural model. The performance of this network is benchmarked against \"traditional\", rate-encoded, neural networks; a Multi-Layer Perceptron network, a Jordan and an Elman neural network as well as the self organized neural network inspired by the immune algorithm. The results indicate that the inherent temporal characteristics of the recurrent links network make it extremely well suited to the processing of time series based data. \u00a9 2014 Springer International Publishing Switzerland.","Author Keywords":"and physical time series prediction; Recurrent neural network; self organised neural network","Index Keywords":"Algorithms; Financial data processing; Intelligent systems; Network architecture; Recurrent neural networks; Time series analysis; Dynamic neural networks; Elman neural network; Financial time series; Multi-layer perceptron networks; Physical time; Self-organised; Self-organized neural networks; Temporal characteristics; Forecasting","References":"Roverso, D., Multivariate temporal classification by windowed wavelet decomposition and recurrent neural networks (2000) Proceedings of the 3rd ANS International Topical Meeting on Nuclear Plant Instrumentation, pp. 527-538. , Washington, DC, USA, Control and Human-Machine Interface Technologies; Mirea, L., Marcu, T., (2002) System Identification Using Functional-Link Neural Networks with Dynamic Structure, , In: 15th Triennial World Congress Barcelona Spain; Herrera, J.L., (1999) Time Series Prediction Using Inductive Reasoning Techniques., , Instituto de Organizacion y Control de Sistemas Industriales; Ghazali, R., Hussain, A., Nawi, N., Mohamad, B., Non-stationary and stationary prediction of financial time series using dynamic ridge polynomial neural network (2009) Neurocomputing, 72 (10-12), pp. 2359-2367; Y\u00fcml\u00fc, S., G\u00fcrgen, F.S., Okay, N., A comparison of global, recurrent and smoothedpiecewise neural models for Istanbul stock exchange (ISE) prediction (2005) Pattern Recognition Letters, 26 (13), pp. 2093-2103; Mengistu, S.G., Quick, C.G., Creed, I.F., Nutrient export from catchments on forested landscapes reveals complex nonstationary and stationary climate signals (2013) Water Resources Research, 49 (6), pp. 3863-3880. , http:\/\/doi.wiley.com\/10.1002\/wrcr.20302, accessed October 2013; Aamodt, R., (2010) Using Artificial Neural Networks to Forecast Financial Time Series, , Unpublished Master'sthesis. Norwegian University of Science and Technology; Widyanto, M.R., Nobuhara, H., Kawamoto, K., Hirota, K., Kusumoputro, B., Improving recognition and generalization capability of back-propagation NN using a self-organized network inspired by immune algorithm (SONIA) (2005) Applied Soft Computing, 6 (1), pp. 72-84; Jordan, M.I., Attractor dynamics and parallelism in a connectionist sequential machine (1990) Artificial Neural Networks, pp. 112-127. , IEEE Press, Piscataway; Mahdi, A.A., Hussain, A.J., Al-Jumeily, D., The prediction of non-stationary physical time series using the application of regularization technique in self-organised multilayer perceptrons inspired by the immune algorithm (2010) 2010 Developments in Esystems Engineering, pp. 213-218. , http:\/\/ieeexplore.ieee.org\/lpdocs\/epic03\/wrapper.htm?arnumber=5633838, accessed February 11, 2014; Montgomery, D.C., Runger, G.C., (1999) Applied Statistics and Probability for Engineers, , Wiley New York; Jordan, M.I., Attractor dynamics and parallelism in a connectionist sequential machine (1990) Artificial Neural Networks, pp. 112-127. , IEEE Press, Piscataway; Elman, L.J., Finding structure in time (1990) Cognitive Science, 14, pp. 179-211; Al-Jumeily, D., Hussain, A., Alaskar, H., Recurrent neural networks inspired by artificial immune algorithm for time series prediction (2013) International Joint Conference on Neural Networks, Dallas, USA, , August 3-9 ISBN: 978-1-4673-6128-6; Voegtlin, T., Context quantization and contextual self-organizing maps (2000) Proc. Int. Joint Conf. on Neural Networks, 5, pp. 20-25; Lorenz, E.N., The statistical prediction of solutions of dynamics equations (1962) Proceedings International Symposium on Numerical Weather Prediction, pp. 629-635. , Meteorological Society Japan; Dunis, C.L., Williams, M., Modelling and trading the EUR\/USD exchange rate: Do neural network models perform better (2002) Derivatives Use Trading and Regulation, 8 (3), pp. 211-239; Hellstrom, T., Holmstrom, K., Predicting the stock market (1998) Technical Report IMa-TOM-1997-07, , Center of Mathematical Modeling, Department of Mathematics and Physis, M\u00e4lardalen University, V\u00e4steras, Sweden, August"}
{"Authors":"Berradi Z., Lazaar M.","Author(s) ID":"57207622928;57200595982;","Title":"Integration of Principal Component Analysis and Recurrent Neural Network to Forecast the Stock Price of Casablanca Stock Exchange","Year":2019,"Source title":"Procedia Computer Science","Volume":"148","Issue":null,"Art. No.":null,"Page start":55.0,"Page end":61.0,"Page count":null,"Cited by":null,"DOI":"10.1016\/j.procs.2019.01.008","Affiliations":"National School of Applied Sciences, Abdelmalek Essaadi University, Tetouan, Morocco","Document Type":"Conference Paper","Access Type":"Open Access","Source":"Scopus","EID":"2-s2.0-85062668948","Abstract":"Illegal insider trading of stocks is based on releasing non-public information (e.g., new product launch, quarterly financial report, acquisition or merger plan) before the information is made public. Detecting illegal insider trading is difficult due to the complex, nonlinear, and non-stationary nature of the stock market. In this work, we present an approach that detects and predicts illegal insider trading proactively from large heterogeneous sources of structured and unstructured data using a deep-learning based approach combined with discrete signal processing on the time series data. In addition, we use a tree-based approach that visualizes events and actions to aid analysts in their understanding of large amounts of unstructured data. Using existing data, we have discovered that our approach has a good success rate in detecting illegal insider trading patterns. \u00a9 2018 IEEE.","Author Keywords":"Illegal Insider Trading;; Natural Language Processing; Neural Network; Stock Market; Time Series Prediction","Index Keywords":"Big data; Commerce; Crime; Deep learning; Financial markets; Learning algorithms; Natural language processing systems; Neural networks; Signal processing; Time series; Trees (mathematics); Heterogeneous sources; Insider trading; Learning-based approach; NAtural language processing; Pro-active approach; Public information; Time series prediction; Tree-based approach; Electronic trading","References":"Golmohammadi, K., Zaiane, O.R., D\u00edaz, D., Detecting stock market manipulation using supervised learning algorithms (2014) Data Science and Advanced Analytics (DSAA). 2014, pp. 435-441. , IEEE; (2010) Financial Crimes Report 2007, , https:\/\/www.fbi.gov\/stats-services\/Publications\/fcsReport2007, May. [Online]; Jeng, L.A., Metrick, A., Zeckhauser, R., Estimating the returns to insider trading: A performance-evaluation perspective (2003) Review of Economics and Statistics, 85 (2), pp. 453-471; Golmohammadi, K., Zaiane, O.R., Time series contextual anomaly detection for detecting market manipulation in stock market (2015) Data Science and Advanced Analytics (DSAA). 2015. 36678 2015, pp. 1-10. , IEEE; Diaz, D., Theodoulidis, B., Sampaio, P., Analysis of stock market manipulations using knowledge discovery techniques applied to intraday trade prices (2011) Expert Systems with Applications, 38 (10), pp. 12757-12771; Allen, F., Gale, D., Stock-price manipulation (1992) The Review of Financial Studies, 5 (3), pp. 503-529; Cao, Y., Li, Y., Coleman, S.A., Belatreche, A., McGinnity, T.M., Adaptive hidden markov model with anomaly states for price manipulation detection (2015) IEEE Trans. Neural Netw. Learning Syst., 26 (2), pp. 318-330; Cumming, D., Johan, S., Li, D., Exchange trading rules and stock market liquidity (2011) Journal of Financial Economics, 99 (3), pp. 651-671; Jia, H., (2016) Investigation Into the Effectiveness Of Long Short Term Memory Networks For Stock Price Prediction, , arXiv preprint arXiv: 1603.07893; Song, Y., Cao, L., Wu, X., Wei, G., Ye, W., Ding, W., Coupled behavior analysis for capturing coupling relationships in group-based market manipulations (2012) Proceedings of the 18th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, pp. 976-984. , ACM; Ali, M.M.Z., Theodoulidis, B., Analyzing stock market fraud cases using a linguistics-based text mining approach (2014) WaSABi-FEOSW@ ESWC; Mantere, M., Stock market manipulation using cyberattacks together with misinformation disseminated through social media (2013) 2013 International Conference on Social Computing, pp. 950-954. , IEEE; Ahern, K.R., Information networks: Evidence from illegal insider trading tips (2017) Journal of Financial Economics, 125 (1), pp. 26-47; (2018) Yahoo Finance-Business Finance, Stock Market, Quotes, News, , https:\/\/finance.yahoo.com, Accessed on 07\/27; (2018) Sec.Gov-Litigation Releases, , https:\/\/www.sec.gov\/litigation\/litreleases.shtml, Accessed on 07\/27; (2018) Sec Enforcement Actions: Insider Trading Cases, , https:\/\/www.sec.gov\/spotlight\/insidertrading\/cases.shtml, Accessed on 07\/27; (2018) Financial Crimes Report 2010-2011 fbi, , https:\/\/www.fbi.gov\/stats-services\/Publications\/financial-crimes-Report-2010-2011, Accessed on 07\/27; Geurts, P., Ernst, D., Wehenkel, L., Extremely randomized trees (2006) Machine Learning, 63 (1), pp. 3-42; Islam, S.R., Eberle, W., Ghafoor, S.K., Credit default mining using combined machine learning and heuristic approach (2018) Proceedings of the 2018 International Conference on Data Science (ICDATA), pp. 16-22. , ACSE; Islam, S.R., (2018) An Efficient Technique For Mining Bad Credit Accounts From Both Olap And Oltp, , Ph.D. dissertation, Tennessee Technological University"}
{"Authors":"Brando A., Rodr\u00edguez-Serrano J.A., Ciprian M., Maestre R., Vitri\u00e0 J.","Author(s) ID":"57205697622;26538208800;57205694376;57204770846;7003477071;","Title":"Uncertainty modelling in deep networks: Forecasting short and noisy series","Year":2019,"Source title":"Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)","Volume":"11053 LNAI","Issue":null,"Art. No.":null,"Page start":325.0,"Page end":340.0,"Page count":null,"Cited by":null,"DOI":"10.1007\/978-3-030-10997-4_20","Affiliations":"BBVA Data and Analytics, Barcelona, Spain; BBVA Data and Analytics, Madrid, Spain; Departament de Matem\u00e0tiques i Inform\u00e0tica, Universitat de Barcelona, Barcelona, Spain","Document Type":"Conference Paper","Access Type":null,"Source":"Scopus","EID":"2-s2.0-85061131265","Abstract":"The advent of Data Science has led to data being evermore useful for an increasing number of organizations who want to extract knowledge from it for financial and research purposes. This has triggered data to be mined at an even faster pace causing the rise of Data Centers that host over thousands of machines together with thousands of jobs running in each of those machines. The growing complexities associated with managing such a huge infrastructure has caused the scheduling management systems to be inefficient at resource allocation across these machines. Hence, resource usage forecasting of machines in data centers is a growing area for research. This study focuses on the Time Series forecasting of CPU usage of machines in data centers using Long Short-Term Memory (LSTM) Network and evaluating it against the widely used and traditional autoregressive integrated moving average (ARIMA) models for forecasting. The final LSTM model had a forecasting error in the range of 17-23% compared to ARIMA model's 3742%. The results clearly show that LSTM models performed more consistently due to their ability to learn non-linear data much better than ARIMA models. \u00a9 2017 Infonomics Society.","Author Keywords":"ARIMA Model; CPU Usage forecasting; Data Center; LSTM Network","Index Keywords":"Forecasting; Scheduling; ARIMA modeling; Autoregressive integrated moving average models; Data centers; Forecasting error; Research purpose; Resource usage; Scheduling management system; Time series forecasting; Long short-term memory","References":"Reiss, C., Towards understanding heterogeneous clouds at scale: Google trace analysis (2012) Intel Science and Technology Center for Cloud Computing, , Tech. Rep 84; Big Data and Data Center Fun Facts-AIS, , http:\/\/www.americanis.net\/2014\/big-data-data-center-fun-facts, Accessed on 09\/30\/2017; Derrick Kondo, S.D.I., Cirne, W., Host load prediction in a google compute cloud with a Bayesian model (2012) Proceedings of the International Conference On High Performance Computing, Networking, Storage and Analysis, p. 21. , IEEE Computer Society Press; Ismaeel, S., Miri, A., Using elm techniques to predict data centre vm requests (2015) Cyber Security and Cloud Computing (CSCloud) 2015 IEEE 2nd International Conference On, pp. 80-86. , IEEE; Cao, J., Cpu load prediction for cloud environment based on a dynamic ensemble model (2014) Software: Practice and Experience, 44 (7), pp. 793-804; Duggan, M., A network aware approach for the scheduling of virtual machine migration during peak loads (2017) Cluster Computing, pp. 1-12; Duggan, M., An autonomous network aware vm migration strategy in cloud data centres (2016) Cloud and Autonomic Computing (ICCAC), 2016 International Conference On, pp. 24-32. , IEEE; Barrett, E., Howley, E., Duggan, J., Applying reinforcement learning towards automating resource allocation and application scalability in the cloud (2013) Concurrency and Computation: Practice and Experience, 25 (12), pp. 1656-1674; Duggan, M., A reinforcement learning approach for the scheduling of live migration from under utilised hosts (2016) Memetic Computing, pp. 1-11; Barrett, E., Howley, E., Duggan, J., A learning architecture for scheduling workflow applications in the cloud (2011) Web Services (ECOWS), 2011 Ninth IEEE European Conference On, pp. 83-90. , IEEE; Schlittgen, R., Robert h. Shumway and david s. Stoffer: Time series analysis and its applications with r examples, 2nd edn.\" in (2008) AStA Advances in Statistical Analysis, 92 (2), pp. 233-234; Nau, R., Statistical forecasting: Notes on regression and time series analysis (2015) Durham: Fuqua School of Business, , Duke University; Understanding LSTM Networks-colah's Blog, , http:\/\/colah.github.io\/posts\/2015-08-Understanding-LSTMs, Accessed on 09\/30\/2017; Liu, Y., (2000) Overfitting and Forecasting: Linear Versus Nonlinear Time Series Models"}
{"Authors":"Sethia A., Raut P.","Author(s) ID":"57205209102;57203153335;","Title":"Application of LSTM, GRU and ICA for stock price prediction","Year":2019,"Source title":"Smart Innovation, Systems and Technologies","Volume":"107","Issue":null,"Art. No.":null,"Page start":479.0,"Page end":487.0,"Page count":null,"Cited by":1.0,"DOI":"10.1007\/978-981-13-1747-7_46","Affiliations":"Dwarkadas J. Sanghvi College of Engineering, Mumbai, India","Document Type":"Conference Paper","Access Type":null,"Source":"Scopus","EID":"2-s2.0-85059063545","Abstract":"Stock price time series are extremely nonlinear in nature and hence, accurate stock price forecasting has been a challenge. Accurate prediction of stock prices and the direction of stock price movement is also essential for a stock trader\/investor in order to trade profitably. A deep learning approach to stock price forecasting is presented in this study. A total of fourteen different deep learning models based on Long-Short Term Memory (LSTM), Gated Recurring Unit (GRU), Convolutional Neural Networks (CNN) and Extreme Learning Machines (ELM) are designed and empirically evaluated on all stocks in the S&P BSE-BANKEX index for their ability to generate one-step ahead and four-step ahead forecasts. Performance of the proposed systems is evaluated in terms of the Root Mean Squared Error (RMSE), Directional Accuracy (DA) and the Median Absolute Percentage Error (MdAPE). Results indicate that deep learning models proposed in this study are capable of generating highly accurate stock price forecasts. \u00a9 2018 The Authors. Published by Elsevier B.V.","Author Keywords":"CNN; Deep learning; ELM; Financial time-series; GRU; LSTM","Index Keywords":"Commerce; Electronic trading; Financial markets; Forecasting; Long short-term memory; Mean square error; Time series; Convolutional Neural Networks (CNN); Extreme learning machine; Financial time series; LSTM; Root mean squared errors; Stock price forecasting; Stock price forecasts; Stock price movements; Deep learning","References":"Cowles, A., III, Can stock market forecasters forecast? (1933) Econometrica: Journal of The Econometric Society, pp. 309-324; Cowles, A., Stock market forecasting (1944) Econometrica, Journal of The Econometric Society, pp. 206-214; Fama, E.F., The behavior of stock-market prices (1965) The Journal of Business, 38 (1), pp. 34-105; Fama, E.F., Random walks in stock market prices (1995) Financial Analysts Journal, 51 (1), pp. 75-80; Nair, B.B., Kumar, P.S., Sakthivel, N., Vipin, U., Clustering stock price time series data to generate stock trading recommendations: An empirical study (2017) Expert Systems with Applications, 70, pp. 20-36; Nair, B.B., Mohandas, V., Artificial intelligence applications in financial forecasting-a survey and some empirical results (2015) Intelligent Decision Technologies, 9 (2), pp. 99-140; Nair, B.B., Mohandas, V., An intelligent recommender system for stock trading (2015) Intelligent Decision Technologies, 9 (3), pp. 243-269; Nair, B.B., Mohandas, V., Nayanar, N., Teja, E., Vigneshwari, S., Teja, K., A stock trading recommender system based on temporal association rule mining (2015) SAGE Open, 5 (2); Huang, G., Liu, Z., Weinberger, K.Q., Van Der Maaten, L., Densely connected convolutional networks (2017) Proceedings of The IEEE Conference on Computer Vision and Pattern Recognition, 1, p. 3; He, K., Zhang, X., Ren, S., Sun, J., Deep residual learning for image recognition (2016) Proceedings of The IEEE Conference on Computer Vision and Pattern Recognition, pp. 770-778; (2018) Index Reach - S&P Bse Bankex, , https:\/\/www.bseindia.com\/indices\/indiceswatch.aspx?index_Code=53&iname=BANKEX#about, accessed: April 12; Yahoo Finance - Business Finance, Stock Market, , https:\/\/in.finance.yahoo.com\/, quotes, news, accessed: April 12, 2018. URL; Chung, J., Gulcehre, C., Cho, K., Bengio, Y., Empirical Evaluation of Gated Recurrent Neural Networks on Sequence Modeling, , arXiv preprint; Malhotra, P., Vig, L., Shroff, G., Agarwal, P., Long short term memory networks for anomaly detection in time series (2015) Proceedings, Presses Universitaires De Louvain, p. 89; Laptev, N., Yosinski, J., Li, L.E., Smyl, S., Time-series extreme event forecasting with neural networks at uber (2017) International Conference on Machine Learning; Che, Z., Purushotham, S., Cho, K., Sontag, D., Liu, Y., Recurrent neural networks for multivariate time series with missing values (2018) Scientific Reports, 8 (1), p. 6085; Bandara, K., Bergmeir, C., Smyl, S., Forecasting Across Time Series Databases Using Long Short-Term Memory Networks on Groups of Similar Series, , arXiv preprint; Suryani, D., Convolutional Neural Network; Dalto, M., Matu\u0161ko, J., Va\u0161ak, M., Deep neural networks for ultra-short-term wind forecasting (2015) Industrial Technology (ICIT), 2015 IEEE International Conference on, pp. 1657-1663. , IEEE; Huang, G.-B., Zhu, Q.-Y., Siew, C.-K., Extreme learning machine: A new learning scheme of feedforward neural networks (2004) Neural Networks, 2004. Proceedings. 2004 IEEE International Joint Conference on, 2, pp. 985-990. , IEEE; Huang, G.-B., Zhu, Q.-Y., Siew, C.-K., Extreme learning machine: Theory and applications (2006) Neurocomputing, 70 (1-3), pp. 489-501; Huang, G.-B., Zhou, H., Ding, X., Zhang, R., Extreme learning machine for regression and multiclass classification (2012) IEEE Transactions on Systems, Man, and Cybernetics, Part B (Cybernetics), 42 (2), pp. 513-529; Huang, G.-B., An insight into extreme learning machines: Random neurons, random features and kernels (2014) Cognitive Computation, 6 (3), pp. 376-390; Balaji, A.J., Ram, D.H., Nair, B.B., Machine learning approaches to electricity consumption forecasting in automated metering infrastructure (ami) systems: An empirical study (2017) Computer Science On-Line Conference, pp. 254-263. , Springer; De Gooijer, J.G., Hyndman, R.J., 25 years of time series forecasting (2006) International Journal of Forecasting, 22 (3), pp. 443-473; Wang, J.-J., Wang, J.-Z., Zhang, Z.-G., Guo, S.-P., Stock index forecasting based on a hybrid model (2012) Omega, 40 (6), pp. 758-766"}
{"Authors":"Pawar K., Jalem R.S., Tiwari V.","Author(s) ID":"57204828764;57204832113;56496391800;","Title":"Stock Market Price Prediction Using LSTM RNN","Year":2019,"Source title":"Advances in Intelligent Systems and Computing","Volume":"841","Issue":null,"Art. No.":null,"Page start":493.0,"Page end":503.0,"Page count":null,"Cited by":null,"DOI":"10.1007\/978-981-13-2285-3_58","Affiliations":"DSPM IIIT, Naya Raipur, India","Document Type":"Conference Paper","Access Type":null,"Source":"Scopus","EID":"2-s2.0-85057427978","Abstract":"Over recent decades, globalization has resulted in a steady increase in cross-border financial flows around the world. To build an abstract representation of a real-world financial market situation, we structure the fundamental influences among homogeneous and heterogeneous markets with three types of correlations: The inner-domain correlation between homogeneous markets in various countries, the cross-domain correlation between heterogeneous markets, and the time-series correlation between current and past markets. Such types of correlations in global finance challenge traditional machine learning approaches due to model complexity and nonlinearity. In this paper, we propose a novel cross-domain deep learning approach (Cd-DLA) to learn real-world complex correlations for multiple financial market prediction. Based on recurrent neural networks, which capture the time-series interactions in financial data, our model utilizes the attention mechanism to analyze the inner-domain and cross-domain correlations, and then aggregates all of them for financial forecasting. Experiment results on ten-year financial data on currency and stock markets from three countries prove the performance of our approach over other baselines. \u00a9 2018 IEEE.","Author Keywords":"attention neural network; deep learning; financial analysis","Index Keywords":"Commerce; Complex networks; Electronic trading; Financial markets; Forecasting; Recurrent neural networks; Time series; Abstract representation; Attention mechanisms; Complex correlation; Financial analysis; Financial forecasting; Heterogeneous markets; Machine learning approaches; Market prediction; Deep learning","References":"Cavalcante, R.C., Brasileiro, R.C., Souza, V.L., Nobrega, J.P., Oliveira, A.L., Computational intelligence and financial markets: A survey and future directions (2016) Expert Systems with Applications, 55, pp. 194-211; Laitinen, E.K., Laitinen, T., Bankruptcy prediction: Application of the taylor's expansion in logistic regression (2000) International Review of Financial Analysis, 9 (4), pp. 327-349; Foreman, R.D., A logistic analysis of bankruptcy within the us local telecommunications industry (2003) Journal of Economics and Business, 55 (2), pp. 135-166; Hassan, M.R., Nath, B., Stock market forecasting using hidden markov model: A new approach (2005) Intelligent Systems Design and Applications, 2005. ISDA'05. Proceedings. 5th International Conference On. IEEE, pp. 192-196; Guresen, E., Kayakutlu, G., Daim, T.U., Using artificial neural network models in stock market index prediction (2011) Expert Systems with Applications, 38 (8), pp. 10389-10397; Ding, X., Zhang, Y., Liu, T., Duan, J., Deep learning for event-driven stock prediction (2015) Ijcai, pp. 2327-2333; Fischer, T., Krauss, C., Deep learning with long short-term memory networks for financial market predictions (2017) European Journal of Operational Research; Deng, Y., Bao, F., Kong, Y., Ren, Z., Dai, Q., Deep direct reinforcement learning for financial signal representation and trading (2017) IEEE Transactions on Neural Networks and Learning Systems, 28 (3), pp. 653-664; Di Persio, L., Honchar, O., Recurrent neural networks approach to the financial forecast of google assets (2017) International Journal of Mathematics and Computers in Simulation, 11; Bengio, Y., Deep learning of representations for unsupervised and transfer learning (2012) Proceedings of ICML Workshop on Unsupervised and Transfer Learning, pp. 17-36; McCallum, A.K., Learning to use selective attention and shortterm memory in sequential tasks (1996) From Animals to Animats 4: Proceedings of the Fourth International Conference on Simulation of Adaptive Behavior, 4, p. 315. , MIT Press; Bahdanau, D., Cho, K., Bengio, Y., (2014) Neural Machine Translation by Jointly Learning to Align and Translate; Li, Y., Ma, W., Applications of artificial neural networks in financial economics: A survey (2010) Computational Intelligence and Design (ISCID), 2010 International Symposium on, 1, pp. 211-214. , IEEE; Chen, K., Zhou, Y., Dai, F., A lstm-based method for stock returns prediction: A case study of China stock market (2015) Big Data (Big Data), 2015 IEEE International Conference On. IEEE, pp. 2823-2824; Wang, C., Pan, S., Long, G., Zhu, X., Jiang, J., Mgae: Marginalized graph autoencoder for graph clustering (2017) Proceedings of the 2017 ACM on Conference on Information and Knowledge Management. ACM, pp. 889-898; Pan, S., Wu, J., Zhu, X., Zhang, C., Wang, Y., Tri-party deep network representation (2016) Network, 11 (9), p. 12; Pan, S., Hu, R., Long, G., Jiang, J., Yao, L., Zhang, C., (2018) Adversarially Regularized Graph Autoencoder; Takeuchi, L., Lee, Y.-Y.A., (2013) Applying Deep Learning to Enhance Momentum Trading Strategies in Stocks, , Technical Report. Stanford University; Tino, P., Schittenkopf, C., Dorffner, G., Financial volatility trading using recurrent neural networks (2001) IEEE Transactions on Neural Networks, 12 (4), pp. 865-874; Sutskever, I., Vinyals, O., Le, Q.V., Sequence to sequence learning with neural networks (2014) Advances in Neural Information Processing Systems, pp. 3104-3112; Chung, J., Gulcehre, C., Cho, K., Bengio, Y., (2014) Empirical Evaluation of Gated Recurrent Neural Networks on Sequence Modeling; Pan, S., Wu, J., Zhu, X., Long, G., Zhang, C., Task sensitive feature exploration and learning for multitask graph classification (2017) IEEE Transactions on Cybernetics, 47 (3), pp. 744-758; Caruana, R., Multitask learning (1998) Learning to Learn, pp. 95-133. , Springer; Pan, S., Wu, J., Zhu, X., Zhang, C., Philip, S.Y., Joint structure feature exploration and regularization for multi-task graph classification (2016) IEEE Transactions on Knowledge and Data Engineering, 28 (3), pp. 715-728; Ngiam, J., Khosla, A., Kim, M., Nam, J., Lee, H., Ng, A.Y., Multimodal deep learning (2011) Proceedings of the 28th International Conference on Machine Learning (ICML-11), pp. 689-696; LeCun, Y., Bengio, Y., Hinton, G., Deep learning (2015) Nature, 521 (7553), p. 436; Sukhbaatar, S., Weston, J., Fergus, R., End-to-end memory networks (2015) Advances in Neural Information Processing Systems, pp. 2440-2448; Hermann, K.M., Kocisky, T., Grefenstette, E., Espeholt, L., Kay, W., Suleyman, M., Blunsom, P., Teaching machines to read and comprehend (2015) Advances in Neural Information Processing Systems, pp. 1693-1701; Yang, Z., He, X., Gao, J., Deng, L., Smola, A., Stacked attention networks for image question answering (2016) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 21-29; Fawcett, T., An introduction to roc analysis (2006) Pattern Recognition Letters, 27 (8), pp. 861-874"}
{"Authors":"Ni\u00f1o J., Hernandez G., Ar\u00e9valo A., Leon D., Sandoval J.","Author(s) ID":"57190225431;35897064300;57190281278;57195350225;56311250400;","Title":"CNN with limit order book data for stock price prediction","Year":2019,"Source title":"Advances in Intelligent Systems and Computing","Volume":"880","Issue":null,"Art. No.":null,"Page start":444.0,"Page end":457.0,"Page count":null,"Cited by":null,"DOI":"10.1007\/978-3-030-02686-8_34","Affiliations":"Universidad Nacional de Colombia, Bogot\u00e1, Colombia; Universidad Externado de Colombia, Bogot\u00e1, Colombia","Document Type":"Conference Paper","Access Type":null,"Source":"Scopus","EID":"2-s2.0-85055911654","Abstract":"The scope of this manuscript is to present a new short-term financial forecasting and trading tool: the Gene Expression Programming (GEP) Trader Tool. It is based on the gene expression programming algorithm. This algorithm is based on a genetic programming approach, and provides supreme statistical and trading performance when used for modelling and trading financial time series. The GEP Trader Tool is offered through a user-friendly standalone Java interface. This paper applies the GEP Trader Tool to the task of forecasting and trading the future contracts of FTSE100, DAX30 and SandP500 daily closing prices from 2000 to 2015. It is the first time that gene expression programming has been used in such massive datasets. The model\u2019s performance is benchmarked against linear and nonlinear models such as random walk model, a movingaverage convergence divergence model, an autoregressive moving average model, a genetic programming algorithm, a multilayer perceptron neural network, a recurrent neural network a higher order neural network. To gauge the accuracy of all models, both statistical and trading performances are measured. Experimental results indicate that the proposed approach outperforms all the others in the in-sample and out-of-sample periods by producing superior empirical results. Furthermore, the trading performances are improved further when trading strategies are imposed on each of the models. \u00a9 2016 John Wiley and Sons, Ltd.","Author Keywords":"Gene expression; Genetic algorithm; Trading; Transaction","Index Keywords":null,"References":"Alavi, A.H., Gandomi, A.H., A robust data mining approach for formulation of geotechnical engineering systems (2011) Engineering Computations, 28 (3), pp. 242-274; Alghieth, M., Yang, Y., Chiclana, F., Development of 2D curve-fitting genetic\/gene-expression programming technique for efficient timeseries financial forecasting (2015) 2015 International Symposium on Innovations in Intelligent Systems and Applications (INISTA), p. 106. , IEEE: Piscataway, NJ; Alvarez-D\u00edaz, M., Alvarez, A., Genetic multi-model composite forecast for non-linear prediction of exchange rates (2005) Empirical Economics, 30 (3), pp. 643-663; Chen, H.H., Yang, C.B., Peng, Y.H., The trading on the mutual funds by gene expression programming with Sortino ratio (2014) Applied Soft Computing, 15, pp. 219-230; Diebold, F.X., Mariano, R.S., Comparing predictive accuracy (1995) The Journal of Business and Economic Studies, 13, pp. 253-265; Dehuri, S., Cho, S.B., Multi-objective classification rule mining using gene expression (2008) Third International Conference on Convergence and Hybrid Information Technology, 2008 (ICCIT\u201908), 2, p. 754. , IEEE Computer Society: Washington, DC; Divsalar, M., Firouzabadi, A.K., Sadeghi, M., Behrooz, A.H., Alavi, A.H., Towards the prediction of business failure via computational intelligence techniques (2011) Expert Systems, 28 (3), pp. 209-226; Divsalar, M., Roodsaz, H., Vahdatinia, F., Norouzzadeh, G., Behrooz, A.H., A robust data-mining approach to bankruptcy prediction (2012) Journal of Forecasting, 31, pp. 504-523; Esfahanipour, A., Mousavi, S., A genetic programming model to generate risk-adjusted technical trading rules in stock markets (2011) Expert Systems with Applications, 38 (7), pp. 8438-8445; Ferreira, C., Gene expression programming: A new adaptive algorithm for solving problems (2001) Computing Systems, 13, pp. 87-129; Ferreira, C., (2006) Gene Expression Programming: Mathematical Modelling by an Artificial Intelligence, , 2nd ed.). Springer: San Francisco, CA; Gandomi, A.H., Alavi, A.H., Multi-stage genetic programming: A new strategy to nonlinear system modeling (2011) Information Sciences, 181 (23), pp. 5227-5239; Gandomi, A.H., Alavi, A.H., Mirzahosseini, M.R., Moghadas, N.F., Nonlinear genetic-based models for prediction of flow number of asphalt mixtures (2011) Journal of Materials in Civil Engineering, ASCE, 23 (3), p. 248; Gandomi, A.H., Yang, X., Talatahari, S., Alavi, A.H., (2013) Metaheuristic Applications in Structures and Infrastructures, , Waltham, MA: Elsevier; Kaboudan, M.A., Genetic programming prediction of stock prices (2000) Computational Economics, 16, pp. 207-236; Karathanasopoulos, A., Laws, J., Sermpinis, G., Dunis, C., Forecasting and trading the EUR\/USD exchange rate with gene expression and psi sigma neural networks (2012) Expert Systems with Applications, 39 (10), pp. 8865-8877; Karathanasopoulos, A., Vasilakis, G., Theofilatos, K., Georgopoulos, E., Likothanassi, S., A genetic programming approach for EUR\/ USD exchange rate forecasting and trading (2013) Computational Economics, 42 (4), pp. 415-431; Karathanasopoulos, A., Sermpinis, G., Fountouli, A., Theofilatos, K., Gene expression programming and trading strategies (2013) Artificial Intelligence Applications and Innovations, p. 497. , H. Papadopoulos, A. S. Andreou, L. Iliadis, and I. Maglogiannis (Eds.), Berlin: Springer; Karathanasopoulos, A., Sermpinis, G., Laws, J., Dunis, C., Modelling and trading the Greek stock market with gene expression and genetic programing algorithms (2014) Journal of Forecasting, 33 (8), pp. 596-610; Koza, J.R., (1992) Genetic Programming: On the Programming of Computers by means of Natural Selection, , Cambridge, MA: MIT Press; Koza, J.R., Genetic programming (1998) Encyclopedia of Computer Science and Technology, 39, p. 29. , J. G. Williams, and A. Kent (Eds.), New York: Marcel Dekker.Supplement 24; Lee, C.H., Yang, C.B., Chen, H.H., Taiwan stock investment with gene expression programming (2014) Procedia Computer Science, 35, p. 137; Lee, Y., Tong, L., Forecasting time series using a methodology based on autoregressive integrated moving average and genetic programming (2011) Knowledge-Based Systems, 24 (1), pp. 66-72; Lopez, H.S., Weinert, W.R., An enhanced gene expression programming approach for symbolic regression problems (2004) International Journal of Applied Mathematics and Computer Science, 14, pp. 375-384; Manahov, V., Hudson, R., Hoque, H., Return predictability and the \u2018wisdom of crowds\u2019: Genetic programming trading algorithms, the marginal trader hypothesis and the Hayek hypothesis (2015) Journal of International Financial Markets Institutions and Money, 37, pp. 85-98; Pesaran, M.H., Timmermann, A., Predictability of stock returns: Robustness and economic significance (1995) The Journal of Finance, 50 (4), pp. 1201-1228; Shapiro, A.F., A hitchhiker\u2019s guide to the techniques of adaptive nonlinear models. Insurance (2000) Mathematics and Economics, 26 (2), pp. 119-132; Smith, V.L., Markets as economizers of information: Experimental examination of the \u2018Hayek hypothesis\u2019 (1982) Economic Inquiry, 20 (2), pp. 165-179; Yaghouby, F., Ayatollahi, A., Bahramali, R., Yaghouby, M., Alavi, A.H., Towards automatic detection of atrial fibrillation: A hybrid computational approach (2010) Computers in Biology and Medicine, 40 (11), pp. 919-930; Yang, X.S., Gandomi, A.H., Talatahari, S., Alavi, A.H., (2012) Metaheuristics in Water Resources, , Elsevier, Waltham, MA: Geotechnical and Transportation Engineering; Zargari, S.A., Zabihi, S., Alavi, A.H., Gandomi, A.H., A computational intelligence based approach for short-term traffic flow prediction (2012) Expert Systems, 29 (2), pp. 124-142; Zhang, G.P., Neural networks for time-series forecasting (2012) Handbook of Natural Computing, p. 461. , G. Rozenberg, T. B\u00e4ck, and J. N. Kok (Eds.), Berlin: Springer"}
{"Authors":"Althelaya K.A., El-Alfy E.-S.M., Mohammed S.","Author(s) ID":"57202503786;7003943902;7102894386;","Title":"Stock Market Forecast Using Multivariate Analysis with Bidirectional and Stacked (LSTM, GRU)","Year":2018,"Source title":"21st Saudi Computer Society National Computer Conference, NCC 2018","Volume":null,"Issue":null,"Art. No.":" 8593076","Page start":null,"Page end":null,"Page count":null,"Cited by":null,"DOI":"10.1109\/NCG.2018.8593076","Affiliations":"Department of Information and Computer Science, College of Computer Sciences and Engineering, King Fahd University of Petroleum and Minerals, Dhahran, 31261, Saudi Arabia","Document Type":"Conference Paper","Access Type":null,"Source":"Scopus","EID":"2-s2.0-85061485605","Abstract":"The variation and dependency on different parameters of stock market makes prediction a complex process. Artificial neural Networks have been proven to be useful in such cases to predict the stock values. The parameters involved and the commonly used algorithms are discussed and compared in this paper. In case of backpropagation algorithm, a feed forward network is present and weights are modified by back propagating the error. Similarly, significant modification is introduced in Sup-port Vector Machines Algorithm(SVMA) which results in higher accuracy rates. Presence of kernel and other parameters make it more flexible. Long Short-Term Memory(LSTM), another commonly used time series forecasting algorithm, is a special type of Recurrent Neural Network(RNN) that uses gradient descent algorithm. This paper provides a comparative analysis between these algorithms on the basis of accuracy, variation and time required for different number of epochs. The T-test hypothesis test was used for further analysis to test the reliability of each algorithm. \u00a9 2019 IEEE.","Author Keywords":"Artificial Neural Network(ANN); Back-propgation; Long Short-Term Memory(LSTM); Recurrent Neural Netwrok(RNN); Support Vector Machines(SVM); T-tests","Index Keywords":"Backpropagation algorithms; Brain; Commerce; Electronic trading; Financial markets; Forecasting; Neural networks; Reliability analysis; Support vector machines; Back-propgation; Feed-forward network; Gradient descent algorithms; Predictive algorithms; Recurrent neural network (RNN); Recurrent Neural Netwrok(RNN); T-tests; Time series forecasting; Long short-term memory","References":"Zheng, A., Jin, J., (2017) Using Ai to Make Predictions on Stock Market, , Stanford University, Tech. Rep; Hegazy, O., Soliman, O.S., Abdul Salam, M., A machine learning model for stock market prediction (2013) International Journal of Computer Science and Telecommunications, 4, pp. 17-23. , Dec; Xia, Y., Liu, Y., Chen, Z., Support vector regression for prediction of stock trend (2013) Information Management, Innovation Management and Industrial Engineering (ICIII), 2013 6th International Conference on, 2, pp. 123-126. , IEEE; Rhoads, R.M.N., Predicting market data with a kalman filter (2010) Technical Analysis of Stocks and Commodities, , January; (2018), https:\/\/brilliant.org\/wiki\/backpropagation\/, Brilliant. org; Madge, S., (2015) Predicting Stock Price Direction Using Support Vector Ma-chines, , Princeton University, Independent Work Report; Hearst, M.A., Dumais, S.T., Osuna, E., Platt, J., Scholkopf, B., Sup-port vector machines (1998) IEEE Intelligent Systems and Their Applications, 13 (4), pp. 18-28. , July; Olah, C., (2015) Understanding Lstm Networks, , http:\/\/colah.github.io\/posts\/2015-08-Understanding-LSTMs, Aug; Moawad, A., (2018) The Magic of Lstm Neu-Ral Networks, , https:\/\/medium.com\/datathings\/the-magicof-lstm-neural-networks-6775e8b540cd, Feb; Bonde, G., Khaled, R., Extracting the best features for predicting stock prices using machine learning (2012) Proceedings on the Inter-national Conference on Artificial Intelligence (ICAI). The Steering Committee of the World Congress in Computer Science, Computer, p. 1; Pedregosa, F., Varoquaux, G., Gramfort, A., Michel, V., Thirion, B., Grisel, O., Blondel, M., Dubourg, V., Scikit-learn: Machine learning in python (2011) Journal of Machine Learning Research, 12, pp. 2825-2830. , Oct; Smola, A.J., Scholkopf, B., A tutorial on support vector regression (2004) Statistics and Computing, 14 (3), pp. 199-222; Brownlee, J., (2016) How to Implement the Backpropagation Algorithm from Scratch Inpython, , https:\/\/machinelearningmastery.com\/time-seriesprediction-lstm-recurrent-neural-networks-python-keras\/, Jul; Brownlee, J., (2016) Time Series Prediction Withlstm Recurrent Neural Networks in Python with Keras, , https:\/\/machinelearningmastery.com\/time-seriesprediction-lstm-recurrent-neural-networks-python-keras\/, Jul; Ku, C., (2017) Beating the Naive Model in the Stock Market, , https:\/\/medium.com\/@CalvinJKu\/beating-the-naive-model-inthe-stock-market-62ec54436cf3, May; Teow, J., (2017) Understanding Kalman Filters with Python, , https:\/\/medium.com\/@jaems33\/understanding-kalman-filters-with-python-2310e87b8f48, May; Xu, Y., Zhang, G., Application of kalman filter in the prediction of stock price (2015) International Symposium on Knowledge Acquisition and Modeling (KAM), pp. 197-198. , Atlantis press; Lacey, T., Tutorial: The kalman filter Computer Vision; http:\/\/www.cc.gatech.edu\/classes\/cs732298\/spring\/PS\/kf1.p"}
{"Authors":"Baek Y., Kim H.Y.","Author(s) ID":"57202960071;57200074208;","Title":"ModAugNet: A new forecasting framework for stock market index value with an overfitting prevention LSTM module and a prediction LSTM module","Year":2018,"Source title":"Expert Systems with Applications","Volume":"113","Issue":null,"Art. No.":null,"Page start":457.0,"Page end":480.0,"Page count":null,"Cited by":2.0,"DOI":"10.1016\/j.eswa.2018.07.019","Affiliations":"Department of Financial Engineering, Ajou University, Worldcupro 206, Yeongtong-gu, Suwon, 16499, South Korea; Department of Data Science, Ajou University, Worldcupro 206, Yeongtong-gu, Suwon, 16499, South Korea","Document Type":"Article","Access Type":null,"Source":"Scopus","EID":"2-s2.0-85049969159","Abstract":"In this paper, a survey on the efficacy of neural network models in predicting market trends is performed by presenting a detailed taxonomy of a few recently proposed models. After surveying the results presented, it is demonstrated that neural networks can be superior when applied to trading simulation, and have greater potential to model noisy financial data compared to traditional classifier approaches. \u00a9 2017 IEEE.","Author Keywords":"Deep Learning; Financial Time Series; Machine Learning; Neural Networks; Trend Analysis","Index Keywords":"Commerce; Deep learning; Financial data processing; Learning systems; Neural networks; Surveys; Financial data; Financial time series; Market trends; Neural network model; Neural network techniques; Trend analysis; Time series analysis","References":"Brock, V., Khan, H.U., Big data analytics: Does organizational factor matters impact technology acceptance ? (2017) J. Big Data; Bekirev, A.S., Klimov, V.V., Kuzin, M.V., Shchukin B, A., Payment card fraud detection using neural network committee and clustering (2015) Opt. Mem. Neural Networks, 24 (3), pp. 193-200; Fama, E.F., Random walks in stock market prices (1995) Financ. Anal. J., 51 (1), pp. 75-80; Publishing, B., International economic (2010) Rev. Lit. Arts Am., 1 (2), pp. 79-106; Lee, A., Wu, M.-C., Chen, A.-P., Treand behavior research by pattern analysis in financial big data-a case study of Taiwan index futures market (2016) 2016 7th International Conference on Cloud Computing and Big Data (CCBD), pp. 162-165; Chen, J., Chen, W., Huang, C., (2016) Financial Time-series Data Analysis Using Deep Convolutional Neural Networks, pp. 99-104; Chen, Y., Yang, B., Dong, J., Abraham, A., Time-series forecasting using flexible neural tree model (2005) Inf. Sci. (Ny)., 174 (3-4), pp. 219-235; Yao, X., Liu, Y., A new evolutionary system for evolving artificial neural networks (1997) IEEE Trans. Neural Netw., 8 (3), pp. 694-713; Yao, X., Evolving artificial neural networks (1999) Proc. IEEE, 87 (9), pp. 1423-1447; Giacomel, F., Galante, R., Pereira, A., An algorithmic trading agent based on a neural network ensemble: A case of study in north American and brazilian stock markets (2015) 2015 IEEE\/WIC\/ACM Int. Conf. Web Intell. Intell. Agent Technol., pp. 230-233; Sharma, V., Rai, S., Dev, A., A comprehensive study of artificial neural networks (2012) Int. J. Adv. Res. Comput. Sci. Softw. Eng., 2 (10), pp. 278-284; Poria, S., Cambria, E., Gelbukh, A., Aspect extraction for opinion miningwith a deep convolutional neural network (2016) Knowledge-Based Syst., pp. 1-8; Lecun, Y., Bengio, Y., Hinton, G., Deep learning (2015) Nature, 521 (7553), pp. 436-444; Kotzias, D., (2015) From Group to Individual Labels Using Deep Features, pp. 597-606; Sirat, J.N.J.A., Neural trees: A new tool for classification (1990) Network, 11, pp. 423-438; Gul, Z., Uzair, A., Arshad, A., Pattern recognition through perceptually important points in financial time series (2004) Int. Conf. Fuzzy Sets Soft Comput. Econ. Financ., 1, pp. 89-97; Wang, Z., Oates, T., Imaging time-series to improve classification and imputation (2015) IJCAI Int. Jt. Conf. Artif. Intell., 2015, pp. 3939-3945. , January Ijcai; Chung, F.L., Fu, T.C., Ng, V., Luk, R.W.P., An evolutionary approach to pattern-based time series segmentation (2004) IEEE Trans. Evol. Comput., 8 (5), pp. 471-489"}
{"Authors":"Wang Y., Liu Y., Wang M., Liu R.","Author(s) ID":"57205507649;57205509553;55561302000;36606572600;","Title":"LSTM Model Optimization on Stock Price Forecasting","Year":2018,"Source title":"Proceedings - 2018 17th International Symposium on Distributed Computing and Applications for Business Engineering and Science, DCABES 2018","Volume":null,"Issue":null,"Art. No.":" 8572550","Page start":173.0,"Page end":177.0,"Page count":null,"Cited by":null,"DOI":"10.1109\/DCABES.2018.00052","Affiliations":"College of Mathematics and Computer Science, Fuzhou University, Fuzhou, 350116, China","Document Type":"Conference Paper","Access Type":null,"Source":"Scopus","EID":"2-s2.0-85060291651","Abstract":"The paper presents aspects related to developing methods for financial time series forecasting using deep learning in relation to multi-agent stock trading system, called A-Trader. On the basis of this model, an investment strategies in A-Trader system can be build. The first part of the paper briefly discusses a problem of financial time series on FOREX market. Classical neural networks and deep learning models are outlined, their performances are analyzed. The final part presents deployment and evaluation of a deep learning model implemented using H20 library as an agent of A-Trader system. \u00a9 2017 PTI.","Author Keywords":null,"Index Keywords":"Commerce; Deep learning; Finance; Financial data processing; Information systems; Multi agent systems; Time series; Water; Classical neural networks; Financial time series; Financial time series forecasting; Forex markets; Investment strategy; Learning models; Multi agent; Stock trading system; Electronic trading","References":"Mendes, L., Godinho, P., Dias, J., A forex trading system based on a genetic algorithm (2012) Journal of Heuristics, 18 (4), pp. 627-656; Westerhoff, F.H., Multi-asset market dynamics (2011) Macroeconomic Dynamics, 8, pp. 596-616. , 2011; Thompson, J.R., Wilson, J.R., Fitts, E.P., Analysis of market returns using multifractal time series and agent-based simulation Proceedings of the Winter Simulation Conference (WSC '12). Winter Simulation Conference, 323, p. 2012. , Article; Kirkpatric, C.D., Dahlquist, J., Technical analysis: The complete resource for financial market technicians (2006) Financial Times Press; Lento, C., A combined signal approach to technical analysis on the S&P 500 (2008) Journal of Business & Economics Research, 6 (8), pp. 41-51; Badawy, O., Almotwaly, A., Combining neural network knowledge in a mobile collaborating multi-agent system (2004) Electrical, Electronic and Computer Engineering, ICEEC '04, pp. 325-328; Kaltwasser, P.R., Uncertainty about fundamentals and herding behavior in the FOREX market (2010) Physica A: Statistical Mechanics and Its Applications, 389 (6), pp. 1215-1222. , March; Aladag, H.C., Yolco, U., Egrioglu, E., A new time invariant fuzzy time series forecasting model based on particle swarm optimization (2012) Applied Soft Computing, 12 (10), pp. 3291-3299; Singh, P., Borah, B., Forecasting stock index price based on M-factors fuzzy time series and particle swarm optimization (2014) International Journal of Approximate Reasoning, 55 (3), pp. 812-833; Aloud, M., Tsang, E.P.K., Olsen, R., Modelling the FX market traders' behaviour: An agent-based approach (2012) Simulation in Computational Finance and Economics: Tools and Emerging Applications, pp. 202-228. , B. Alexandrova-Kabadjova, S. Martinez-Jaramillo, A. L. Garcia-Almanza and E. Tsang (eds.) IGI Global; Glattfelder, J.B., Dupuis, A., Olsen, R., Patterns in highfrequency FX data: Discovery of 12 empirical scaling laws (2011) Quantitative Finance, 11 (4), pp. 599-614; Barbosa, R.P., Belo, O., Multi-agent forex trading system (2010) Agent and Multi-agent Technology for Internet and Enterprise Systems, Studies in Computational Intelligence, 289, pp. 91-118; Batres-Estrada, G., Deep learning for multivariate financial time series (2015) Thesis of KTH Royal Institute of Technology, , Stockholm; Busseti, E., Osband, I., Wong, S., (2012) Deep Learning for Time Series Modeling, , http:\/\/cs229.stanford.edu\/proj2012\/BussetiOsbandWong-DeepLearningForTimeSeriesModeling.pdf; Bengio, Y., Learning deep architectures for AI (2009) Foundations and Trends in Machine Learning, 2, p. 1; Takeuchi, L., Ying, L.Y., (2013) Applying Deep Learning to Enhance Momentum Trading Strategies in Stocks, , http:\/\/cs229.stanford.edu\/proj2013\/TakeuchiLee-ApplyingDeepLearningToEnhanceMomentumTradingStrategies.InStocks.pdf; Hinton, G.E., Osindero, S., Teh, Y.W., A fast learning algorithm for deep belief nets Neural Computation, 18 (7), pp. 1527-1554; Kuremoto, T., Kimura, S., Kobayashi, K., Obayashi, M., Time series forecasting using a deep belief network with restricted boltzmann machines (2014) Neurocomputing, 137, pp. 47-56. , 2014; Korczak, J., Hernes, M., Bac, M., Fuzzy logic as agents' knowledge representation in a-trader system Information Technology for Management (2016) Lecture Notes in Business Information Processing, 243, pp. 109-124. , E. Ziemba (ed.) Springer International Publishing; Korczak, J., Hernes, M., Bac, M., Performance evaluation of decision-making agents' in the multi-agent system (2014) Proceedings of Federated Conference Computer Science and Information Systems (FedCSIS), pp. 1171-1180. , Warszawa; Korczak, J., Hernes, M., Bac, M., Fundamental analysis in the multi-agent trading system (2016) Proceedings of Federated Conference Computer Science and Information Systems (FedCSIS), pp. 1171-1180. , Gdask; Hernes, M., Nguyen, N.T., Deriving consensus for hierarchical incomplete ordered partitions and coverings (2007) Journal of Universal Computer Science, 13 (2), pp. 317-328; Hernes, M., Sobieska-Karpiska, J., Application of the consensus method in a multi-agent financial decision support system Information Systems and E-Business Management, 14 (1), p. 2016. , Springer Berlin Heidelberg; McNelis, P.D., Neural networks in finance: Gaining predictive edge in the market (2004) Advanced Finance Series, , Academic Press Academic Press, Inc., Orlando; Kondratenko, V.V., Kuperin, Y., (2003) Using Recurrent Neural Networks to Forecasting of Forex, , arXiv:cond-mat\/0304469 [cond-mat.disnn]; Persio L, D.I., Honchar, O., Artificial neural networks approach to the forecast of stock market price movements (2016) International Journal of Economics and Management Systems, 1, pp. 158-162; Arnold, L., Rebecchi, S., Chevallier, S., Paugam-Moisy, H., (2011) An Introduction to Deep Learning, , ESANN; Glorot, X., Bengio, Y., Understanding the difficulty of training deep feedforward neural networks (2010) Proceedings of the 13th International Conference On Artificial Intelligence and Statistics, 9, pp. 249-256; Lu, H., Li, B., Zhu, J., Li, Y., Li, Y., Xu, X., He, L., Serikawa, S., Wound intensity correction and segmentation with convolutional neural networks Concurrency and Computation: Practice and Experience, 29, p. 2017; Cha, Y.J., Choi, W., Buy\u00fck\u00f6zt\u00fcrk, O., Deep learning-based crack damage detection using convolutional neural networks (2017) Computer-Aided Civil and Infrastructure Engineering, 32, pp. 361-378; Larochelle, H., Bengio, Y., Exploring strategies for training deep neural networks (2009) Journal of Machine Learning Research, 1, pp. 1-40; Hall, P., How Is Deep Learning Different from Multilayer Perceptron, , https:\/\/www.quora.com\/How-is-deep-learningdifferent-from-multilayer-perceptron, [access: 01.05.2017]; https:\/\/github.com\/h2oait, access: 01.05.2017; Candel, A., Parmar, V., LeDell, E., Arora, A., (2015) Deep Learning with h2o, , https:\/\/h2orelease.s3.amazonaws.com\/h2o\/rel-slater\/9\/docs-website\/h2odocs\/booklets\/DeepLearning_Vignette.pdf"}
{"Authors":"Gurav U., Sidnal N.","Author(s) ID":"36052794200;24462689600;","Title":"Adaptive Stock Forecasting Model using Modified Backpropagation Neural Network (MBNN)","Year":2018,"Source title":"Proceedings of the International Conference on Computational Techniques, Electronics and Mechanical Systems, CTEMS 2018","Volume":null,"Issue":null,"Art. No.":" 8769290","Page start":380.0,"Page end":385.0,"Page count":null,"Cited by":null,"DOI":"10.1109\/CTEMS.2018.8769290","Affiliations":"Dept. of Information Technology, KIT's College of Engineering, Kolhapur, India; CSE Board, India","Document Type":"Conference Paper","Access Type":null,"Source":"Scopus","EID":"2-s2.0-85070385176","Abstract":"Predicting stock market is not an easy task as it is a chaotic system i.e. whose dynamics are sensitive to arbitrarily small differences in initial conditions. Any small changes in the system can produce compound errors in predicting the future behavior of the system. Over the last few years, many machine learning algorithms have been used in an attempt to forecast stock prices. This paper evaluates the effectiveness of a type of Recurrent Neural Network known as Long Short Term Memory (LSTM) to implement technical analysis for making predictions about stock prices of AAPL ticker from NASDAQ exchange. Performance with three popular output activation layers is tested with Adam optimizer as back-propagation algorithm. The performance is compared using Root Mean Square Deviation. The model had an average RMSE value of 12.483 with linear output activation scaled to range (0,1) and 3.258 for the same scaled to a range of (-1,1), 21.769 with sigmoid output activation scaled to range (0,1) and 21.738 with tanh output activation scaled to a range of (-1,1). \u00a9 2018 IEEE.","Author Keywords":"Adam Optimizer; Long short term memory; Recurrent neural networks; Stock market prediction; Technical Analysis; Time series analysis","Index Keywords":"Backpropagation algorithms; Brain; Chaotic systems; Chemical activation; Commerce; Costs; Electronic trading; Financial markets; Forecasting; Learning algorithms; Machine learning; Recurrent neural networks; Time series analysis; Activation layer; Initial conditions; Nasdaq Exchange; Optimizers; Root mean square deviations; Short-term forecasting; Stock market prediction; Technical analysis; Long short-term memory","References":"Fama, E.F., The behavior of stock-market prices (1965) The Journal of Business, 38 (1), pp. 34-105. , http:\/\/www.jstor.org\/stable\/2350752; Lui, Y., Mole, D., The use of fundamental and technical analyses by foreign exchange dealers: Hong Kong evidence (1998) Journal of International Money and Finance, 17 (3), pp. 535-545. , https:\/\/doi.org\/10.1016\/S0261-5606(98)00011-4, http: \/\/www. sciencedirect. com\/science\/article\/pii\/S0261560 698000114; Krollner, B., Vanstone, B., Finnie, G., Financial time series forecasting with machine learning techniques: A survey (2010) Paper Presen at the European Symposium on Artificial Neural Networks: Computational and Machine Learning, , Bruges, Belgium; Hochreiter, S., Schmidhuber, J., Long short-term memory (1997) Neural Computation, 9 (8), pp. 1735-1780; Graves, A., Mohamed, A.R., Hinton, G., Speech recognition with deep recurrent neural networks (2013) 2013 IEEE International Conference on Acoustics, Speech and Signal Processing, pp. 6645-6649. , Vancouver, BC; Kingma, D.P., Lei Ba, J., Adam: A method for Stochastic Optimization (2015) Published at ICLR 2015; Srivastava, N., Hinton, G., Krizhevsky, A., Sutskever, I., Salakhutdinov, R., Dropout: A simple way to prevent neural networks from overfitting (2014) Journal of Machine Learning Research, 15; Majumder, M., Hussian, A., Forecasting of Indian stock market index using artificial neural network (2010) For National Stock Exchange of India Limited; Di Persio, L., Honchar, O., Artificial neural networks approach to the forecast of stock market price movements (2016) International Journal of Economics and Management Systems, 1"}
{"Authors":"Kumar S., Ningombam D.","Author(s) ID":"57209548409;57200762188;","Title":"Short-Term Forecasting of Stock Prices Using Long Short Term Memory","Year":2018,"Source title":"Proceedings - 2018 International Conference on Information Technology, ICIT 2018","Volume":null,"Issue":null,"Art. No.":" 8724351","Page start":182.0,"Page end":186.0,"Page count":null,"Cited by":null,"DOI":"10.1109\/ICIT.2018.00046","Affiliations":"Department of Computer Science and Engineering, Sikkim Manipal Institute of Technology, Rangpo, 737136, India","Document Type":"Conference Paper","Access Type":null,"Source":"Scopus","EID":"2-s2.0-85067436089","Abstract":"Credit products are a crucial part of business of banks and other financial institutions. A novel approach based on time series of customer's data representation for predicting willingness to take a personal loan is shown. Proposed testing procedure based on moving window allows detection of complex, sequential, time based dependencies between particular transactions. Moreover, this approach reduces noise by eliminating irrelevant dependencies that would occur due to the lack of time dimension analysis. The system for identifying customers interested in credit products, based on classification with random forests and deep neural networks is proposed. The promising results of empirical studies prove that the system is able to extract significant patterns from customers historical transfer and transactional data and predict credit purchase likelihood. Our approach, including the testing method, is not limited to banking sector and can be easily transferred and implemented as a general purpose direct marketing campaign system. \u00a9 2019 Elsevier Ltd","Author Keywords":"Boruta algorithm; Consumer credit; Data mining; Database marketing; Deep belief networks; Deep learning; Direct marketing; Feature selection; Marketing campaigns; Random forest; Retail banking; Time series","Index Keywords":"Commerce; Decision trees; Deep learning; Deep neural networks; Feature extraction; Sales; Testing; Time series; Consumer credits; Database marketing; Deep belief networks; Direct marketing; Marketing campaign; Random forests; Retail banking; Data mining","References":"ApacheSpark, Apache spark framework (2018), http:\/\/spark.apache.org\/; Bose, I., Chen, X., Quantitative models for direct marketing: A review from systems perspective (2009) European Journal of Operational Research, 195 (1), pp. 1-16; Breiman, L., Classification and regression trees (2017), Routledge; Changchien, S.W., Lee, C.-F., Hsu, Y.-J., On-line personalized sales promotion in electronic commerce (2004) Expert Systems with Applications, 27 (1), pp. 35-52; Friedman, J., Hastie, T., Tibshirani, R., The elements of statistical learning (2001), 1. , Springer series in statistics New York, NY, USA:; H2O.ai, H2O Framework (2018), https:\/\/www.h2o.ai\/; Hinton, G.E., Osindero, S., Teh, Y.-W., A fast learning algorithm for deep belief nets (2006) Neural Computation, 18 (7), pp. 1527-1554; (2008), Hossein Javaheri, S. Response modeling in direct marketing: a data mining based approach for target selection; Hughes, G., On the mean accuracy of statistical pattern recognizers (1968) IEEE Transactions on Information Theory, 14 (1), pp. 55-63; Kaefer, F., Heilman, C.M., Ramenofsky, S.D., A neural network application to consumer classification to improve the timing of direct marketing activities (2005) Computers & Operations Research, 32 (10), pp. 2595-2615; Kim, E., Kim, W., Lee, Y., Combination of multiple classifiers for the customer's purchase behavior prediction (2003) Decision Support Systems, 34 (2), pp. 167-175; Kim, Y., Street, W.N., An intelligent system for customer targeting: A data mining approach (2004) Decision Support Systems, 37 (2), pp. 215-228; Kursa, M.B., Rudnicki, W.R., Feature selection with the Boruta package (2010) Journal Statistics Software, 36 (11), pp. 1-13; Liao, S.-H., Chen, Y.-J., Mining customer knowledge for electronic catalog marketing (2004) Expert Systems with Applications, 27 (4), pp. 521-532; Min, S.-H., Han, I., Detection of the customer time-variant pattern for improving recommender systems (2005) Expert Systems with Applications, 28 (2), pp. 189-199; Nilsson, R., Pe\u00f1a, J.M., Bj\u00f6rkegren, J., Tegn\u00e9r, J., Consistent feature selection for pattern recognition in polynomial time (2007) Journal of Machine Learning Research, 8 (Mar), pp. 589-612; Piersma, N., Jonker, J.-J., Determining the optimal direct mailing frequency (2004) European Journal of Operational Research, 158 (1), pp. 173-182; Rossi, P.E., McCulloch, R.E., Allenby, G.M., The value of purchase history data in target marketing (1996) Marketing Science, 15 (4), pp. 321-340; Sing'oei, L., Wang, J., Data mining framework for direct marketing: A case study of bank marketing (2013) International Journal of Computer Science Issues (IJCSI), 10 (2), p. 198; Tang, J., Alelyani, S., Liu, H., Feature selection for classification: A review (2014) Data Classification: Algorithms and Applications, p. 37; Trunk, G.V., A problem of dimensionality: A simple example (1979) IEEE Transactions on Pattern Analysis and Machine Intelligence, (3), pp. 306-307; Weng, S.-S., Liu, M.-J., Feature-based recommendations for one-to-one marketing (2004) Expert Systems with Applications, 26 (4), pp. 493-508; Zaharia, M., An architecture for fast and general data processing on large clusters (2016), Morgan & Claypool"}
{"Authors":"Manurung A.H., Budiharto W., Prabowo H.","Author(s) ID":"57207622302;36069151100;57210847043;","Title":"Algorithm and modeling of stock prices forecasting based on long short-term memory (LSTM)","Year":2018,"Source title":"ICIC Express Letters","Volume":"12","Issue":"12","Art. No.":null,"Page start":1277.0,"Page end":1283.0,"Page count":null,"Cited by":null,"DOI":"10.24507\/icicel.12.12.1277","Affiliations":"Management Department, BINUS Business School, Bina Nusantara University, Jl. K. H. Syahdan No. 9, DKI, Jakarta, 11480, Indonesia; Computer Science Department, School of Computer Science, Bina Nusantara University, Jl. K. H. Syahdan No. 9, DKI, Jakarta, 11480, Indonesia; Computer Science Department, Bina Nusantara University, Jl. K. H. Syahdan No. 9, DKI, Jakarta, 11480, Indonesia","Document Type":"Article","Access Type":null,"Source":"Scopus","EID":"2-s2.0-85062649597","Abstract":"Stock price movement is typically affected by a lot of hidden factors. Predicting stock price direction, especially short-term direction, is very challenging and consistently attracts researches. Deep recurrent neural networks, such as Long Short-Term Memory, typically outperform statistical time series models and traditional machine learning approaches with their mechanisms of learning to vectorize historical information. However, encoding entire history into a vector may unavoidably causes information loss regardless of memory learning and updating mechanisms, especially for those tasks where decisions need to be made on the current time point and similar historical time points are of great references to the decision making. In this paper, we propose a new deep architecture called Recurrent Embedding Kernel (REK) that can learn to make optimal decisions by referring to the entire history instead of just current memory vectors. Experimental results on multiple stock ETFs with different long-term trends show that REK outperforms RNN, LSTM, and GRU, on predicting daily price direction. \u00a9 2018 IEEE.","Author Keywords":"deep learning; recurrent architecture; recurrent embedding kernel; stock prediction; time series","Index Keywords":"Big data; Decision making; Deep learning; Embeddings; Financial markets; Forecasting; Memory architecture; Network architecture; Time series; Deep architectures; Historical information; Machine learning approaches; Optimal decisions; recurrent embedding kernel; Stock predictions; Stock price movements; Time series models; Long short-term memory","References":"Adhikari, R., Agrawal, R., A combination of artificial neural network and random walk models for financial time series forecasting (2014) Neural Computing and Applications, 24 (6), pp. 1441-1449; Liew, J.K.-S., Mayster, B., (2017) Forecasting Etfs with Machine Learning Algorithms; Qian, X.-Y., (2017) Financial Series Prediction: Comparison between Precision of Time Series Models and Machine Learning Methods, , arXiv preprint arXiv:1706 00948; Fischer, T., Krauss, C., Deep learning with long short-term memory networks for financial market predictions (2018) European Journal of Operational Research, 270 (2), pp. 654-669; Fi\u010dura, M., (2017) Forecasting Foreign Exchange Rate Movements with Knearest-neighbour, Ridge Regression and Feed-forward Neural Networks; Nelson, D.M., Pereira, A.C., De Oliveira, R.A., Stock market\ufffds price movement prediction with lstm neural networks Neural Networks (IJCNN 2017 International Joint Conference on, 2017, pp. 1419-1426. , IEEE; Shen, G., Tan, Q., Zhang, H., Zeng, P., Xu, J., Deep learning with gated recurrent unit networks for financial sequence predictions (2018) Procedia Computer Science, 131, pp. 895-903; Hamilton, J.D., (1994) Time Series Analysis. Princeton, 2. , university press Princeton, NJ; Cortes, C., Vapnik, V., Support vector machine (1995) Machine Learning, 20 (3), pp. 273-297; Liaw, A., Wiener, M., Classification and regression by randomforest (2002) R News, 2 (3), pp. 18-22; Kruse, R., Borgelt, C., Klawonn, F., Moewes, C., Steinbrecher, M., Held, P., Multi-layer perceptrons (2013) Computational Intelligence, pp. 47-81. , Springer; Funahashi, K.-I., Nakamura, Y., Approximation of dynamical systems by continuous time recurrent neural networks (1993) Neural Networks, 6 (6), pp. 801-806; Hochreiter, S., Schmidhuber, J., Long short-term memory (1997) Neural Computation, 9 (8), pp. 1735-1780; Chung, J., Gulcehre, C., Cho, K., Bengio, Y., (2014) Empirical Evaluation of Gated Recurrent Neural Networks on Sequence Modeling, , arXiv preprint arXiv:1412 3555; Hao, J., Xie, Y., Priestley, J., Deep kernel: Learning kernel function from data using deep neural network (2016) 2016 IEEE\/ACM 3rd International Conference on Big Data Computing Applications and Technologies (BDCAT, pp. 1-7. , Dec; Xie, Y., Hao, J., Unsupervised deep kernel for high dimensional data (2017) Neural Networks (IJCNN 2017 International Joint Conference on, pp. 294-299. , IEEE; Bergstra, J., Breuleux, O., Bastien, F., Lamblin, P., Pascanu, R., Desjardins, G., Turian, J., Bengio, Y., Theano: A cpu and GPU math compiler in python (2010) Proc. 9th Python in Science Conf, pp. 1-7; Hunter, J.D., Matplotlib: A 2d graphics environment (2007) Computing in Science & Engineering, 9 (3), pp. 90-95"}
{"Authors":"Tsang G., Deng J., Xie X.","Author(s) ID":"57205363535;55922714500;7402761335;","Title":"Recurrent Neural Networks for Financial Time-Series Modelling","Year":2018,"Source title":"Proceedings - International Conference on Pattern Recognition","Volume":"2018-August","Issue":null,"Art. No.":" 8545666","Page start":892.0,"Page end":897.0,"Page count":null,"Cited by":null,"DOI":"10.1109\/ICPR.2018.8545666","Affiliations":"Computer Science Department, Swansea University, United Kingdom","Document Type":"Conference Paper","Access Type":null,"Source":"Scopus","EID":"2-s2.0-85059781356","Abstract":"In this paper, the author proposes an innovative Chaotic Interval Type-2 Fuzzy Neuro-oscillatory Network (CIT2-FNON) for worldwide financial prediction. Inspired by the author\u2019s original work on Lee-oscillator\u2014a chaotic discrete-time neural oscillator with profound transient-chaotic property, CIT2-FNON provides: (1) effective modeling of Interval Type-2 Fuzzy Logic with Chaotic Transient-Fuzzy Membership Function (CTFMF); and (2) time-series recurrent neural network training and prediction with Chaotic Bifurcation Transfer Function (CBTF). Different from the contemporary research on Type-2 Fuzzy Logic Systems (T2FLS) which mainly focus on the R&D of the Interval Type-2 Fuzzy Logic (IT2FL)\u2014a simplified version of T2FLS due to its computational complexity, the main innovation of this paper include: (1) the Chaotic Type-2 Transient-Fuzzy Logic (CT2TFL) proposed in this paper provides a truly T2FLS with remarkable chaotic transient-fuzzy property to resolve the computational complexity problem; and (2) different from contemporary fuzzy-neuro systems which focus on the integration of fuzzy logic and neural networks as separated functional modules, the CIT2-FNON introduced in this paper is constructed by Lee-oscillators which serves as \u201ctransient-fuzzy input neurons\u201d of the recurrent network and effectively converts it into CT2TFL system. In other words, the chaotic transient-fuzzification process is actually part of the neural model of the CIT2-FNON. From the implementation perspective, CIT2-FNON is integrated with 2048-trading day time-series financial data and Top-10 major financial signals as financial fuzzy signals (FFS) for the real-time prediction of 129 worldwide financial products. \u00a9 2019, Taiwan Fuzzy Systems Association.","Author Keywords":"Chaotic bifurcation transfer function; Chaotic neural oscillatory network; Chaotic transient-fuzzy membership function; Financial prediction; Interval type-2 fuzzy logic; Lee-oscillator","Index Keywords":"Bifurcation (mathematics); Complex networks; Computational complexity; Computer circuits; Finance; Forecasting; Fuzzy inference; Fuzzy neural networks; Membership functions; Recurrent neural networks; Time series; Transfer functions; Chaotic bifurcation; Financial prediction; Fuzzy membership function; Interval type-2 fuzzy logic; Oscillatory networks; Fuzzy logic","References":"Bai, C., Shi, B., Liu, F., Sarkis, J., Banking credit worthiness: evaluating the complex relationships (2019) Omega, 83, pp. 26-38; Baklouti, N., Abraham, A., Alimi, A.M., A Beta basis function interval type-2 fuzzy neural network for time series applications (2018) Eng. Appl. Artif. Intell., 71, pp. 259-274; Bhattacharya, D., Konar, A., Self-adaptive type-1\/type-2 hybrid fuzzy reasoning techniques for two-factored stock index time-series prediction (2018) Soft. Comput., 22 (18), pp. 6229-6246; Borden, C., (2018) Fibonacci Trading: How to Master the Time and Price Advantage, , McGraw-Hill Education, New York; Brown, C., (2012) Elliot Wave Principle: Elementary Concepts, Wave Patterns, and Practice Exercises, , Bloomberg Press, New York; Bulkowski, T.N., (2005) Encyclopedia of Chart Patterns, , Wiley, Hoboken; Chai, N., Wu, B., Yang, W., Shi, B., A multicriteria approach for modeling small enterprise credit rating: evidence from China (2019) Emerg. Mark. Financ. Trade, 55 (11), pp. 1-21; Chang, P.C., Wang, D., Zhou, C., A novel model by evolving partially connected neural network for stock price trend forecasting (2012) Expert Syst. Appl., 39 (1), pp. 611-620; Chen, L., Aihara, K., Chaotic stimulated annealing by a neural model with transient chaos (1995) Neural Netw., 8 (6), pp. 915-930; Dabhi, V.K., Chaudhary, S., Financial time-series modeling and prediction using postfix-GP (2016) Comput. Econ., 47 (2), pp. 219-253; Dai, W., Wu, J., Lu, Y., Combining nonlinear independent component analysis and neural network for the prediction of Asian stock market indexes (2012) Expert Syst. Appl., 39 (4), pp. 4444-4452; Gonzalez, J.A.R., Solis, J.F., Huacuja, H.J.F., Barbosa, J.J.G., Rangel, R., Fuzzy GA-SVR for Mexican stock exchange\u2019s financial time-series forecast with online parameter tuning (2019) Int. J. Comb. Optim. Prob. Inf., 10 (1), pp. 41-50; http:\/\/www.metatrader4.com; http:\/\/qffc.org; http:\/\/Forex.com; http:\/\/AvaTrader.com; Han, M., Zhong, K., Han, B., Interval type-2 fuzzy neural networks for chaotic time-series prediction: a concise overview (2018) IEEE Trans. Cybern., 99, pp. 1-12; Henrique, B.M., Sobreiro, V.A., Kimura, H., Stock price prediction using support vector regression on daily and up to the minute prices (2018) J. Financ. Data Sci., 4 (3), pp. 183-201; Hermann, H., Patricio, F.V., Fuzzy hybrid system for forecasting financial time-series (2015) Aestimatio, 11, pp. 78-91; Jiang, An interval type-2 fuzzy logic system for stock index forecasting based on fuzzy time series and a fuzzy logical relationship map (2018) IEEE Access, 6, pp. 69107-69119; Lee, R.S.T., A transient-chaotic auto-associative network (TCAN) based on LEE-oscillators (2004) IEEE Trans. Neural Netw., 15 (5), pp. 1228-1243; Lee, R.S.T., iJADE stock advisor: an intelligent agent based stock prediction system using hybrid RBF recurrent network (2004) IEEE Trans. Syst. Man Cybern. (Part A), 34 (3), pp. 421-428; Lee, R.S.T., LEE-Associator\u2014a transient chaotic autoassociative network for progressive memory recalling (2006) Neural Netw., 19 (5), pp. 644-666; Lee, R.S.T., (2006) Fuzzy-Neuro Approach to Agent Applications (From the AI Perspective to Modern Ontology), , Springer-Verlag, Germany; Lee, R.S.T., Liu, J.N.K., Scene analysis using an integrated composite neural oscillatory elastic graph matching model (2002) Pattern Recogn., 35, pp. 1835-1846; Lee, R.S.T., Advanced Paradigms in artificial intelligence from neural oscillators, chaos theory to chaotic neural networks (2005) Aust. Adv. Knowl. Int., 55 (11), pp. 303-380; Ling, P.W., The stock price forecasting comparative research of the use of fractal theory at Taiwan traditional industry and technology industry (2003) Appl. Mech. Mater., 274, pp. 53-56; Liu, F., Quek, C., Ng, G.S., Neural network model for time-series prediction by reinforcement learning (2005) 2005 IEEE International Joint Conference on Neural Networks, 2, pp. 809-814; Liu, J., Wu, C., Wang, Z., Wu, L., Reliable filter design for sensor networks using type-2 fuzzy framework (2017) IEEE Trans. Ind. Inf., 13 (4), pp. 1742-1752; Murphy, J.J., (1999) Technical Analysis of the Financial Markets: A Comprehensive Guide to Trading Methods and Application, , New York Institute of Finance, New York; Nahil, A., Lyhyaoui, A., Short-term stock price forecasting using kernel principal component analysis and support vector machines: the case of Casablanca stock exchange (2018) Procedia Comput. Sci., 127, pp. 161-169; Ouahilal, M., Mohajir, M.E., Chahhou, M., Eddine, E.M., A novel hybrid model based on Hodrick\u2013Prescott filter and support vector regression algorithm for optimizing stock market price prediction (2017) J. Big Data, 4 (1), pp. 1-22; Pulido, M., Melin, P., Optimization of ensemble neural networks with type-1 and type-2 fuzzy integration for Prediction of the Taiwan stock exchange (2018) Stud. Fuzziness Soft Comput., 361, pp. 151-164; Pulido, M., Melin, P., Castillo, O., Particle swarm optimization of ensemble neural networks with Fuzzy aggregation for time series prediction of the Mexican Stock Exchange (2014) Inf. Sci., 280, pp. 188-204; Rubio, A., Berm\u00fadez, J.D., Vercher, E., Improving stock index forecasts by using a new weighted fuzzy-trend time-series method (2017) Expert Syst. Appl., 76, pp. 12-20; Sadaei, H.J.S., Enayatifar, R., Guimaraes, F.G., Mahmud, M., Alzamil, Z.A., Combining ARFIMA models and fuzzy time-series for the forecast of long memory time-series (2016) Neurocomputing, 175, pp. 782-796; Sanz, J.A., Bernardo, D., Herrera, F., Bustince, H., Hagras, H., A compact evolutionary interval-valued fuzzy rule-based classification system for the modeling and prediction of real-world financial applications with imbalanced data (2015) IEEE Trans. Fuzzy Syst., 23 (4), pp. 973-990; Singh, R., Srivastava, S., Stock prediction using deep learning (2017) Multimed. Tools Appl., 76 (18), pp. 18569-18584; Sumati, V., Patvardhan, C., Interval type-2 mutual subsethood fuzzy neural inference system (IT2MSFuNIS) (2018) IEEE Trans. Fuzzy Syst., 26 (1), pp. 203-215; Sun, G., Xu, S., Li, Z., Finite-time fuzzy sampled-data control for nonlinear flexible spacecraft with stochastic actuator failures (2017) IEEE Trans. Ind. Electron., 64 (5), pp. 3851-3861; Wang, X., Period-doublings to chaos in a simple neural network: an analytic proof (1991) Complex Syst., 5, pp. 425-441; Wong, M.H.Y., Lee, R.S.T., Liu, J.N.K., Wind shear forecasting by chaotic oscillatory-based neural networks (CONN) with Lee-Oscillator (Retrograde Signaling) Model (2008) International Joint Conference on Neural Networks (IJCNN), pp. 2040-2047; Xu, S., Sun, G., Ma, Z., Li, X., Fractional-order fuzzy sliding mode control for the deployment of tethered satellite system under input saturation (2018) IEEE Trans. Aerosp. Electron. Syst., 55 (11), p. 1; Ye, F., Zhang, L., Zhang, D., Fujita, H., Gong, Z., A novel forecasting method based on multi-order fuzzy time-series and technical analysis (2016) Inf. Sci., 367-368, pp. 41-57; Yolcu, O.C., Yolcu, U., Egrioglu, E., Aladag, C.H., High order fuzzy time-series forecasting method based on an intersection operation (2016) Appl. Math. Model., 40, pp. 8750-8765"}
{"Authors":"Day M.-Y., Lin J.-T., Chen Y.-C.","Author(s) ID":"14031006200;57204820145;57204820974;","Title":"Artificial intelligence for conversational robo-advisor","Year":2018,"Source title":"Proceedings of the 2018 IEEE\/ACM International Conference on Advances in Social Networks Analysis and Mining, ASONAM 2018","Volume":null,"Issue":null,"Art. No.":" 8508269","Page start":1057.0,"Page end":1064.0,"Page count":null,"Cited by":null,"DOI":"10.1109\/ASONAM.2018.8508269","Affiliations":"Department of Information Management, Tamkang University, Taiwan, Taiwan","Document Type":"Conference Paper","Access Type":null,"Source":"Scopus","EID":"2-s2.0-85057319854","Abstract":"This paper aims at developing a new method by which to build a data-driven portfolio featuring a target risk\u2013return. We first present a comparative study of recurrent neural network models (RNNs), including a simple RNN, long short-term memory (LSTM), and gated recurrent unit. The models are applied to the investment universe consisted of 10 stocks in the S& P500. The experimental results show that the LSTM-based prediction model outperforms the others in terms of hit ratio of 1-month-ahead forecasts. We then build predictive threshold-based portfolios (TBPs) that are subsets of the universe satisfying given threshold criteria for the LSTM-based return forecasts. The TBPs are rebalanced monthly to restore equal weight to the constituents of the TBPs. We find that the risk and return profile of the realized TBP represents a monotonically increasing frontier on the risk\u2013return plane, where the equally weighted universe portfolio plays a role in the lower bound of TBPs. This shows the availability of TBPs in targeting specific risk\u2013return levels, and the EWP of an universe plays a role in the reference portfolio of the TBPs. In the process, thresholds play dominant roles in characterizing risk, return, and the prediction accuracy of the TBPs. The TBP is more data-driven in designing portfolio return and risk than existing ones, in the sense that it requires no prior knowledge of finance such as financial assumptions, financial mathematics, or expert insights. For practical uses, we present a multiperiod TBP management method and also discuss the application of TBP to mean\u2013variance portfolios to reduce estimation risk. \u00a9 2018, Springer Science+Business Media, LLC, part of Springer Nature.","Author Keywords":"Efficient frontier; Financial time series; Portfolio management; Recurrent neural networks","Index Keywords":"Financial data processing; Financial markets; Forecasting; Investments; Recurrent neural networks; Risk perception; Comparative studies; Efficient frontier; Financial mathematics; Financial time series; Management method; Portfolio managements; Prediction accuracy; Recurrent neural network model; Long short-term memory","References":"Atsalakis, G.S., Valavanis, K.P., Surveying stock market forecasting techniques\u2014Part II: soft computing methods (2009) Expert Syst Appl, 36 (3), pp. 5932-5941; Dixon, M., Klabjan, D., Bang, J.H., (2015) Implementing Deep Neural Networks for Financial Market Prediction on the Intel Xeon Phi, , https:\/\/ssrn.com\/abstract=2627258; Huck, N., Pairs selection and outranking: an application to the S&P100 index (2009) J Oper Res, 196 (2), pp. 819-825; Huck, N., Pairs trading and outranking: the multi-step-ahead forecasting case (2010) J Oper Res, 207 (3), pp. 1702-1716; Krauss, C., Do, X.A., Huck, N., Deep neural networks, gradient-boosted trees, random forests: statistical arbitrage on the S&P500 (2017) Eur J Oper Res, 259 (2), pp. 689-702; Moritz, B., Zimmermann, T., (2014) Deep Conditional Portfolio Sorts: The Relation between past and Future Stock Returns, , Working paper; Sermpinis, G., Theofilatos, K.A., Karathanasopoulos, A.S., Georgopoulos, E.F., Dunis, C.L., Forecasting foreign exchange rates with adaptive neural networks using radial-basis functions and particle swarm optimization (2013) Eur J Oper Res, 225 (3), pp. 528-540; Takeuchi, L., Lee, Y.-Y., (2013) Applying Deep Learning to Enhance Momentum Trading Strategies in Stocks, , Working paper; Cavalcante, R.C., Brasileiro, R.C., Souza, V.L.F., Nbrega, J.P., Oliveira, A.L.I., Computational intelligence and financial markets: a survey and future directions (2016) Expert Syst Appl, 55, pp. 194-211; Aggarwal, S., Aggarwal, S., Deep investment in financial markets using deep learning models (2017) Int J Comput Appl, 162 (2), pp. 40-43; Gao, T., Li, X., Chai, Y., Tang, Y., Deep learning with stock indicators and two-dimensional principal component analysis for closing price prediction system (2016) 7Th IEEE International Conference on Software Engineering and Service Science (ICSESS), 2016. IEEE; Zhang, Y., (2015) Using financial reports to predict stock market trends with machine learning techniques, , Oxford University, Oxford; Fischer, T., Krauss, C., Deep learning with long short-term memory networks for financial market predictions (2017) FAU Discussion Papers in Economics 11\/2017, , http:\/\/hdl.handle.net\/10419\/157808, Erlangen; Pang, X., Zhou, Y., Wang, P., An innovative neural network approach for stock market prediction (2018) J Supercomput; Hu, Z., Liu, W., Bian, J., Liu, X., Liu, T.-Y., Listening to chaotic whispers: A deep learning framework for news-oriented stock trend prediction (2018) Proceedings of the Eleventh ACM International Conference on Web Search and Data Mining, pp. 261-269; Singh, R., Srivastava, S., Stock prediction using deep learning, multimedia tools and application (2017) Multimed Tools Appl, 76 (18), pp. 18569-18584; Markowitz, H., Portfolio selection (1952) J Finance, 17 (1), pp. 77-91; Fama, E., French, K., The cross-section of expected stock returns (1992) Expert Syst Appl, 47, pp. 427-465; Black, F., Litterman, R., Global portfolio optimization (1992) Financ Anal J, 48 (5), pp. 28-43; Michaud, R., (1998) Efficient asset management: a practical guide to stock portfolio optimization and asset allocation, , Harvard Business School Press, Boston; Haugen, R., Baker, N., Pairs selection and outranking: an application to the S&P100 index (1991) J Oper Res, 17 (3), pp. 35-40; Choueifaty, Y., Coignard, Y., Toward maximum diversification (2008) J Portf Manag, 35 (1), pp. 40-51; Qian, E., (2005) Risk Parity Portfolios: Efficient Portfolios through True Diversification, , https:\/\/www.panagora.com\/assets\/PanAgora-Risk-Parity-Portfolios-Efficient-Portfolios-Through-True-Diversification.pdf, Research paper; Qian, E., (2005) Risk Parity Portfolios: The Next Generation, , https:\/\/www.panagora.com\/assets\/PanAgora-Risk-Parity-The-Next-Generation.pdf, Research paper; Faber, M.T., A quantitative approach to tactical asset allocation (2014) J Wealth Manag, 9 (4), pp. 69-79; Keller, W.J., Keuning, J.W., (2014) Momentum, Markowitz, and Smart Beta: A Tactical, Analytical and Practical Look at Modern Portfolio Theory, , https:\/\/ssrn.com\/abstract=2759734orhttps:\/\/doi.org\/10.2139\/ssrn.2759734; Keller, W.J., Bulter, A., (2014) A Century of Generalized Momentum; from Flexible Asset Allocations (FAA) to Elastic Asset Allocation (EAA), , https:\/\/ssrn.com\/abstract=2543979, https:\/\/doi.org\/10.2139\/ssrn.2543979; Keller, W.J., Keuning, J.W., Protective asset allocation (PAA): a simple momentum-based alternative for term deposits (2009) Expert Syst Appl, 36 (3), pp. 5932-5941; Campbell, J.Y., Sanford, J.G., Jiang, W., Trading volume and serial correlation in stock returns (1993) Q J Econ, 108, pp. 905-939; Choueifaty, Y., Coignard, Y., Trading volume and cross-autocorrelations in stock returns (2000) J Finance, 55, pp. 913-935; Bao, W., Yue, J., Rao, Y., A deep learning framework for financial time series using stacked autoencoders and long-short term memory (2017) PLoS ONE, 12 (7); Freitas, F.D., De Souza, A.F., De Almeida, A.R., Prediction-based portfolio optimization model using neural networks (2009) Neurocomputing, 72, pp. 2155-2170; Mishra, S.K., Panda, G., Majhi, B., Prediction based mean-variance model for constrained portfolio assets selection using multiobjective evolutionary algorithms (2016) Swarm Evol Comput, 28, pp. 117-130; Ganeshapillai, G., Guttag, J., Lo, A., Learning connections in financial time series (2013) Proceedings of the 30Th International Conference on Machine Learning (ICML13), pp. 109-117; Elman, J., Finding structure in time (1990) Cogn Sci, 14, pp. 179-211; Bengio, Y., Simard, P., Frasconi, P., Learning long-term dependencies with gradient descent is difficult (1994) IEEE Trans Neural Netw, 5 (2), pp. 157-166; Hochreiter, S., Schmidhuber, J., Long short-term memory (1997) Neural Comput, 9 (8), pp. 1735-1780; Cho, K., Merrienboer, B., G\u00fcl\u00e7ehre, C., Bougares, F., Schwenk, H., Bengio, Y., (2014) Learning Phrase Representations Using RNN Encoder-Decoder for Statistical Machine Translation, , CoRR; Diederik, P.K., Jimmy, B., (2014) Adam: A Method for Stochastic Optimization.; Chollet, F., (2016) Keras: Deep Learning Library for Theano and Tensorflow, , https:\/\/keras.io; Jegadeesh, N., Titman, S., Profitability of momentum strategies: an evaluation of alternative explanations (2001) J Finance, 56, pp. 699-720; Plyakha, Y., Uppal, R., Vilkov, G., (2012) Why Does an Equal-Weighted Portfolio Outperform Value-And Price-Weighted Portfolios?, , https:\/\/ssrn.com\/abstract=2724535, https:\/\/doi.org\/10.2139\/ssrn.2724535; Merton, R.C., On estimating the expected return on the market: an explanatory investigation (1980) J Financ Econ, 8, pp. 323-361; Jorion, P., International portfolio diversification with estimation risk (1985) J Bus, 58 (3), pp. 259-278; Best, M., Grauer, R., Positively weighted minimum-variance portfolios and the structure of asset expected returns (1992) J Financ Quant Anal, 27 (4), pp. 513-537; Broadie, M., Computing efficient frontiers using estimated parameters (1993) Ann Oper Res, 45, pp. 21-58"}
{"Authors":"Machado E.J., Pereira A.C.M.","Author(s) ID":"57192673413;35579191200;","Title":"Proposal and implementation of machine learning models for stock markets using web data","Year":2018,"Source title":"WebMedia 2018 - Proceedings of the 24th Brazilian Symposium on Multimedia and the Web","Volume":null,"Issue":null,"Art. No.":null,"Page start":61.0,"Page end":64.0,"Page count":null,"Cited by":null,"DOI":"10.1145\/3243082.3264663","Affiliations":"Federal Center for Tech. Education of MG, Belo Horizonte, Minas Gerais, Brazil; Federal University of Minas Gerais (UFMG), Belo Horizonte, Minas Gerais, Brazil","Document Type":"Conference Paper","Access Type":null,"Source":"Scopus","EID":"2-s2.0-85056713060","Abstract":"Stock market prediction has attracted much attention from academia as well as business. However, it is a challenging research topic, in which many advanced computational methods have been proposed, but not yet attained a desirable and reliable performance. This study proposes a new method for stock market prediction, which adopts the Long Short-Term Memory (LSTM) neural network and incorporates investor sentiment and market factors to improve forecasting performance. By extracting investor sentiment from forum posts using Na\u00efve Bayes, this paper makes it possible to analyze the irrational component of stock price. Our empirical study on CSI300 index proves that our prediction method provides better prediction performance. It gives a prediction accuracy of 87.86%, outperforming other benchmark models by at least 6%. Furthermore, our empirical study reveals evidence that helps to better understand investor sentiment and stock behaviors. Finally, this work shows the potential of deep learning financial time series in the presence of strong noises. \u00a9 2017 IEEE.","Author Keywords":"Deep learning; Investor sentiment; Stock market prediction","Index Keywords":"Commerce; Deep learning; Finance; Financial data processing; Financial markets; Forecasting; Long short-term memory; Financial time series; Forecasting performance; Investor sentiments; Prediction accuracy; Prediction methods; Prediction performance; Reliable performance; Stock market prediction; Investments","References":"Fama, E.F., The adjustment of stock prices to new information (1969) International Economic Review, 10 (1), pp. 1-21; Fama, E.F., Efficient capital markets: II (1991) The Journal of Finance, 46 (5), pp. 1575-1617; Cootner, P.H., (1964) The Random Character of Stock Market Prices; Fama, E.F., The behavior of stock-market prices (1965) The Journal of Business, 38 (1), pp. 34-105; Qian, B., Rasheed, K., Stock market prediction with multiple classifiers (2007) Applied Intelligence, 26 (1), pp. 25-33; Malkiel, B.G., The efficient market hypothesis and its critics (2003) The Journal of Economic Perspectives, 17 (1), pp. 59-82; Robert, R.J.P., (2002) The Wave Principle of Human Social Behavior and the New Science of Socionomics, , New Classics Library, GA; Prechter, R.R., Jr., Parker, W.D., The financial\/economic dichotomy in social behavioral dynamics: The socionomic perspective (2007) The Journal of Behavioral Finance, 8 (2), pp. 84-108; Smith, V.L., Constructivist and ecological rationality in economics (2003) The American Economic Review, 93 (3), pp. 465-508; Nofsinger, J.R., Social mood and financial economics (2005) The Journal of Behavioral Finance, 6 (3), pp. 144-160; Butler, K.C., Jamal Malaikah, S., Efficiency and inefficiency in thinly traded stock markets: Kuwait and Saudi Arabia (1992) Journal of Banking & Finance, 16 (1), pp. 197-210; Kavussanos, M.G., Dockery, E., A multivariate test for stock market efficiency: The case of ASE (2001) Applied Financial Economics, 11 (5), pp. 573-579; Gallagher, L.A., Taylor, M.P., Permanent and temporary components of stock prices: Evidence from assessing macroeconomic shocks (2002) Southern Economic Journal, pp. 345-362; De Long, J.B., Noise trader risk in financial markets (1990) Journal of Political Economy, 98 (4), pp. 703-738; Shleifer, A., Vishny, R.W., The limits of arbitrage (1997) The Journal of Finance, 52 (1), pp. 35-55; Li, F., (2006) Do Stock Market Investors Understand the Risk Sentiment of Corporate Annual Reports?; Schumaker, R.P., Evaluating sentiment in financial news articles (2012) Decision Support Systems, 53 (3), pp. 458-464; Tetlock, P.C., Giving content to investor sentiment: The role of media in the stock market (2007) The Journal of Finance, 62 (3), pp. 1139-1168; Tetlock, P.C., Saar-Tsechansky, M., Macskassy, S., More than words: Quantifying language to measure firms' fundamentals (2008) The Journal of Finance, 63 (3), pp. 1437-1467; Chen, H., Customers as advisors: The role of social media in financial (2012) Management Science, 54 (3), pp. 477-491; Antweiler, W., Frank, M.Z., Is all that talk just noise? The information content of internet stock message boards (2004) The Journal of Finance, 59 (3), pp. 1259-1294; Hornik, K., Stinchcombe, M., White, H., Multilayer feedforward networks are universal approximators (1989) Neural Networks, 2 (5), pp. 359-366; Kamijo, K.-I., Tanigawa, T., Stock price pattern recognition - A recurrent neural network approach (1990) Neural Networks, 1990, , 1990 IJCNN International Joint Conference on. IEEE; Hamid, S.A., Iqbal, Z., Using neural networks for forecasting volatility of S & P 500 index futures prices (2004) Journal of Business Research, 57 (10), pp. 1116-1125; Bollen, J., Mao, H., Zeng, X., Twitter mood predicts the stock market (2011) Journal of Computational Science, 2 (1), pp. 1-8; Hochreiter, S., Schmidhuber, J., Long short-term memory (1997) Neural Computation, 9 (8), pp. 1735-1780; Graves, A., (2013) Generating Sequences With Recurrent Neural Networks, , arXiv preprint arXiv:1308.0850; Sundermeyer, M., Schl\u00fcter, R., Ney, H., LSTM neural networks for language modeling (2012) Interspeech; Graves, A., Mohamed, A.-R., Hinton, G., Speech recognition with deep recurrent neural networks (2013) Acoustics, Speech and Signal Processing (icassp), 2013 Ieee International Conference On. IEEE; Lee, W.Y., Jiang, C.X., Indro, D.C., Stock market volatility, excess returns, and the role of investor sentiment (2002) Journal of Banking & Finance, 26 (12), pp. 2277-2299; Baker, M., Wurgler, J., Investor sentiment and the cross-section of stock returns (2006) The Journal of Finance, 61 (4), pp. 1645-1680; Brown, G.W., Cliff, M.T., Investor sentiment and the near-term stock market (2004) Journal of Empirical Finance, 11 (1), pp. 1-27; Schumaker, R.P., Chen, H., Textual analysis of stock market prediction using breaking financial news: The AZFin text system (2009) ACM Transactions on Information Systems (TOIS), 27 (2), p. 12; Xiong, R., Nichols, E.P., Shen, Y., (2015) Deep Learning Stock Volatility With Google Domestic Trends, , arXiv preprint arXiv:1512.04916; Lewis, D.D., Naive (Bayes) at forty: The independence assumption in information retrieval (1998) European Conference on Machine Learning, , Springer Berlin Heidelberg; Lai, T.L., Xing, H., (2008) Statistical Models and Methods for Financial Markets, , New York: Springer; Chollet, F., (2015) Keras, , https:\/\/github\/fchollet\/keras, GitHub Repository; Srivastava, N., Dropout: A simple way to prevent neural networks from overfitting (2014) Journal of Machine Learning Research, 15 (1), pp. 1929-1958; Glorot, X., Bengio, Y., Understanding the difficulty of training deep feedforward neural networks (2010) Aistats, 9; Bu, H., Pi, L., Does investor sentiment predict stock returns? The evidence from Chinese stock market (2014) Journal of Systems Science and Complexity, 27 (1), pp. 130-143"}
{"Authors":"Fischer T., Krauss C.","Author(s) ID":"55757780995;57189242463;","Title":"Deep learning with long short-term memory networks for financial market predictions","Year":2018,"Source title":"European Journal of Operational Research","Volume":"270","Issue":"2","Art. No.":null,"Page start":654.0,"Page end":669.0,"Page count":null,"Cited by":49.0,"DOI":"10.1016\/j.ejor.2017.11.054","Affiliations":"Department of Statistics and Econometrics, University of Erlangen-N\u00fcrnberg, Lange Gasse 20, N\u00fcrnberg, 90403, Germany","Document Type":"Article","Access Type":null,"Source":"Scopus","EID":"2-s2.0-85039970639","Abstract":"Trend forecasting is considered a difficult task, especially for China stock market due to its highly uncertainty. The study compares six forecasting models, i.e., Support Vector Machine (SVM), Naive Bayes, Decision Tree, Multilayer perceptron (MLP), Recurrent neural network (RNN), and Long Short-Term Memory (LSTM). 9 features combinations are selected based on 23 technical indicators which are commonly used in stock market analysis, and trainsets of 12 different records numbers are chosen to compare the performance of the models under different scenarios. Evaluation is carried out on 8 years of historical data from 2008 to 2015 of the listed company (000592) in China stock market. Experimental results show that the performance of deep learning models MLP, RNN, LSTM is better than other models with respect to the index of accuracy. MLP is 20.75% higher than Decision Tree, Decision Tree is better than others under f-measure, and Decision Tree is 40.02% higher than Naive Bayes. Experimental results also show that in the imbalanced stock market data, the performance of models RNN and Decision Tree is better than others. \u00a9 2017 IEEE.","Author Keywords":"Deep learning; Stock market; Trend forecasting","Index Keywords":"Classifiers; Commerce; Decision trees; Deep learning; Financial markets; Forecasting; Mobile devices; Support vector machines; Trees (mathematics); China stock markets; Comparative studies; Forecasting models; Multi layer perceptron; Recurrent neural network (RNN); Stock market analysis; Technical indicator; Trend forecasting; Long short-term memory","References":"Huang, W., Nakamori, Y., Wang, S.-Y., Wang, forecasting stock market movement direction with support vector machine (2015) Computers& Operations Research, 32 (10), pp. 2513-2522; Hassan, M.-R., Nath, B., Kirley, M., A fusion model of hmm, ann and ga for stock market forecasting (2007) Expert Systems with Applications, 33 (1), pp. 171-180; Patel, J., Shah, S., Thakkar, P., Kotecha, K., Predicting stock and stock price index movement using trend deterministic data preparation and machine learning techniques (2015) Expert Systems with Applications, 42 (1), pp. 259-268; Nair, B.B., Mohandas, V.P., Sakthivel, N.R., A decision tree-rough set hybrid system for stock market trend prediction (2010) International Journal of Computer Applications, 6 (9), pp. 1-6; Wang, J.-L., Chan, S.-H., Stock market trading rule discovery using two-layer bias decision tree (2006) Expert Systems with Applications, 30 (4), pp. 605-611; Lai, R.K., Fan, C.Y., Huang, W.H., Chang, P.C., Evolving and clustering fuzzy decision tree for financial time series data forecasting (2009) Expert Systems with Applications An International Journal, 36 (2), pp. 3761-3773; Wang, J.H., Leu, J.Y., Stock market trend prediction using arima-based neural networks (1996) IEEE International Conference on Neural Networks, pp. 2160-2165; Saad, E.-W., Prokhorov, D.V., Comparative study of stock trend prediction using time delay, recurrent and probabilistic neural networks (1998) IEEE Transactions on Neural Networks, 9 (6), pp. 1456-1470; Nair, B.B., Sai, S.G., Naveen, A.N., Lakshmi, A., Venkatesh, G.S., Mohandas, V.-P., (2011) A OA-Artificial Neural Network Hybrid System for Financial Time Series Forecasting, , Springer Berlin Heidelberg; Ebrahimpour, R., Nikoo, H., Masoudnia, S., Yousefi, M.R., Ghaemi, M.S., Mixture of mlp-experts for trend forecasting of time series: A case study of the Tehran stock exchange (2011) International Journal of Forecasting, 27 (3), pp. 804-816; Tiifekci, P., Classification-based prediction models for stock price index movement (2016) Intelligent Data Analysis, 20 (2), pp. 357-376; Hsieh, T.-J., Hsiao, H.F., Yeh, W.-C., Forecasting stock markets using wavelet transforms and recurrent neural networks: An integrated system based on artificial bee colony algorithm (2011) Applied Soft Computing, 11 (2), pp. 2510-2525; Yoshihara, A., Fujikawa, K., Seki, K., Uehara, K., (2014) Predicting Stock Market Trends by Recurrent Deep Neural Networks, , Springer International Publishing; Chen, K., Zhou, Y., Dai, F., A lstm-based method for stock returns prediction: A case study of China stock market (2015) IEEE International Conference on Big Data, pp. 2823-2824; Duan, J., Liu, H., Zeng, J., Posterior probability model for stock return prediction based on analyst's recommendation behavior (2013) Knowledge-Based Systems, 50, pp. 151-158; Ding, X., Zhang, Y., Liu, T., Duan, J., Deep learning for event-driven stock prediction (2015) International Conference on Artificial Intelligence, pp. 2327-2333; Akita, R., Yoshihara, A., Matsubara, T., Uehara, K., Deep learning for stock prediction using numerical and textual information (2016) IEEE\/ACIS International Conference on Computer and Information Science, pp. 1-6; Sak, H., Senior, A., Beaufays, F., Long short-Term memory recurrent neural network architectures for large scale acoustic modeling (2014) Computer Science, pp. 338-342"}
{"Authors":"Pereira D.F.R., Junior N.N.D.M., Caloba L.P.","Author(s) ID":"57204639812;57204645429;24282923400;","Title":"Financial Time Series Forecasting Using Non-Linear Methods and Stacked Autoencoders","Year":2018,"Source title":"Proceedings of the International Joint Conference on Neural Networks","Volume":"2018-July","Issue":null,"Art. No.":" 8489425","Page start":null,"Page end":null,"Page count":null,"Cited by":null,"DOI":"10.1109\/IJCNN.2018.8489425","Affiliations":"Signal Processing Laboratory, Polytechnical School-Federal University of Rio de Janeiro, Rio de Janeiro, RJ, Brazil","Document Type":"Conference Paper","Access Type":null,"Source":"Scopus","EID":"2-s2.0-85056525695","Abstract":"In this study, we consider the relationship between oil and gas prices, the Dow Jones index, the US dollar index and their volatility indicators. Application of wavelet analysis allows to reveal regularities of dynamics of selected time series at different periods. The Wavelet approach makes it possible to determine how these variables interact at different frequencies, and how this interaction evolves over time on different frequency scales. Common revenue movements of the studied time series characterize the behavior of the relevant markets. The levels of high volatility at similar intervals explain that there is a link between the changes in these markets, and the global economy is vulnerable to oil and gas prices, the value of the dollar index and the Dow Jones index. At the next stage of the research, a comparison of the predictive capabilities of Long Short Term Memory and Wavelet based Back Propagation neural networks for co-movement leaders is made. \u00a9 2019 CEUR-WS. All rights reserved.","Author Keywords":"Neural networks; Volatility; Wavelet analysis; Wavelet coherence; Wavelet multiple correlation and cross correlation","Index Keywords":"Backpropagation; Commerce; Costs; Financial markets; Industrial research; Knowledge management; Neural networks; Time series; Time series analysis; Wavelet analysis; Back propagation neural networks; Cross correlations; Different frequency; Oil and gas prices; Predictive capabilities; Us dollar indices; Volatility; Wavelet coherences; Motion estimation","References":"Shah, A., Deo, M., Integration of the indian stock market: At the angle of Time-Frequency (2016) Journal of Economic Integration, 31 (1), pp. 183-205. , http:\/\/dx.doi.org\/10.11130\/jei.2016.31.1.183; Crowley, P., (2005) An Intuitive Guide to Wavelets for Economists, , Working Paper, Bank of Finland; Rua, A., Nunes, L., International comovement of stock market returns: A wavelet analysis (2009) Journal of Empirical Finance, 16, pp. 632-639; Alou, C., Hkiri, B., Co-movements of GCC emerging stock markets: New evidence from wavelet coherence analysis (2014) Economic Modelling, 36, pp. 421-431; Loh, L., Co-movement of Asia-Pacific with european and US stock market returns: A cross-time-frequency analysis (2013) Research in International Business and Finance, 29, pp. 1-13; Madaleno, M., Pinho, C., International stock market indices comovements: A new look (2012) International Journal of Finance and Economics, 17, pp. 89-102; Vacha, L., Barunik, J., Co-movement of energy commodities revisited: Evidence from wavelet coherence analysis (2012) Energy Economics, 34 (1), pp. 241-247; Tiwari, A., Mutascu, M., Albulescu, C., The influence of the international oil prices on the real effective exchange rate in Romania in a wavelet transform framework (2013) Energy Economics, 40, pp. 714-733; Akoum, I., Graham, M., Kivihaho, J., Nikkinen, J., Omran, M., Co-movement of oil and stock prices in the GCC region: A wavelet analysis (2012) Quarterly Review of Economics and Finance, 52, pp. 385-394; Ramsey, J., Lampart, C., Decomposition of economic relationships by timescale using wavelet (1998) Macroeconomic Dynamics, 2, pp. 49-71; Gen\u00e7ay, R., Sel\u00e7uk, F., Whitcher, B., (2002) An Introduction To Wavelets and Other Filtering Methods in Finance and Economics, , Academic Press, San Diego, CA; Percival, D., Walden, A., (2000) Wavelet Methods for Time Series Analysis, , Cambridge University Press; Gallegati, M., Semmler, W., (2014) Wavelet Application in Economics and Finance, , NY: Springer; Fern\u00e1ndez-Macho, J., Wavelet multiple correlation and cross-correlation: A multiscale analysis of euro zone stock markets (2012) Physica A, 391 (4), pp. 1097-1104; Dajcman, S., Kavkler, A., Wavelet analysis of stock return energy decomposition and return comovement- a case of some central european and developed european stock markets (2014) E A M: Ekonomie A Management, 17 (1), pp. 104-120; Dar, A., Bhanja, N., Samantaraya, A., Tiwari, A., Export led growth or growth led export hypothesis in india: Evidence based on time-frequency approach (2013) Asian Economic and Financial Review, 3 (7), pp. 869-880; Gallegati, M., Wavelet analysis of stock returns and aggregate economic activity (2008) Computational Statistics & Data Analysis, 52, pp. 3061-3074; Abid, F., Kaffel, B., Time\u2013frequency wavelet analysis of the interrelationship between the global macro assets and the fear indexes (2018) Physica A, 490, pp. 1028-1045; Husain, A., Arezki, R., Breuer, P., Haksar, V., (2015) Global Implications of Lower Oil Prices, , International Monetary Fund; Gadanecz, B., Jayaram, K., Measures of financial stability \u2013 a review. Bank of international settlements (2009) IFC Bulletin, 31, pp. 365-382; Azar, A., The relation of the US dollar with oil prices, gold prices, and the US stock market (2015) Research in World Economy, 6 (1), pp. 159-171; Malliaris, G., Malliaris, M., Are oil, gold and the euro inter-related? time series and neural network analysis (2013) Review of Quantitative Finance and Accounting, 40 (1), pp. 1-14; Yoshino, N., Taghizade-Hesary, F., Monetary policy and oil price fluctuations following the subprime crisis (2014) International Journal Monetary Economics and Finance, 7 (3), pp. 157-174; Aguiar-Conraria, L., Soares, J., The continuous wavelet transform: Moving beyond uni and bivariate analysis (2014) J. Econ. Surv., 28 (2), pp. 344-375; Chen, L., Qiao, Z., Wang, M., Wang, C., Du, R., Stanley, H., Which artificial intelligence algorithm better predicts the chinese stock market? (2018) IEEEAccess, 6, pp. 48625-48633; Daubechies, I., (1992) Ten Lectures on Wavelets, , SIAM: Society for Industrial and Applied Mathematics; Torrence, C., Compo, G., A practical guide to wavelet analysis (1998) Bulletin of the American Meteorological Society, 79 (1), pp. 61-78; Fern\u00e1ndez-Macho, J., Time-localized wavelet multiple regression and correlation (2017) Physica A, 490, pp. 1126-1236; Jerome, T., Douglas, R., Atlas, L., Recurrent neural networks and robust time series prediction (1994) IEEE Transactions on Neural Networks, 5 (2), pp. 240-254; LeCun, Y., Bengio, Y., Hinton, G., Deep learning (2015) Nature, 521, pp. 436-444; Chong, E., Han, C., Park, F., Deep learning networks for stock market analysis and prediction: Methodology, data representations, and case studies (2017) Expert Syst. Appl., 83, pp. 187-205; Jin, W., Li, Z., Wei, L., Zhen, H., The improvements of BP neural network learning algorithm (2000) Proc. WCCC ICSP, pp. 1647-1649; Eynard, J., Grieu, S., Polit, M., Wavelet-based multi-resolution analysis and artificial neural networks for forecasting temperature and thermal power consumption (2011) Engineering Applications of Artificial Intelligence, Elsevier, 24 (3), pp. 501-516"}
{"Authors":"Jiang X., Pan S., Jiang J., Long G.","Author(s) ID":"57013726600;55522732400;55731807500;55522990400;","Title":"Cross-Domain Deep Learning Approach for Multiple Financial Market Prediction","Year":2018,"Source title":"Proceedings of the International Joint Conference on Neural Networks","Volume":"2018-July","Issue":null,"Art. No.":" 8489360","Page start":null,"Page end":null,"Page count":null,"Cited by":null,"DOI":"10.1109\/IJCNN.2018.8489360","Affiliations":"Centre for Artificial Intelligence, School of Software Faculty of Engineering and Information Technology, University of Technology, Sydney, Australia","Document Type":"Conference Paper","Access Type":null,"Source":"Scopus","EID":"2-s2.0-85056490365","Abstract":"In this paper, we introduce a model based on Convolutional Neural Network for forecasting foreign exchange rates. Additionally, a method of transforming exchange rates data from 1D structure to 2D structure is proposed. The transaction of the foreign exchange market has periodic characteristics, however, due to the technical limitations, these characteristics cannot be utilized by existing time series forecasting models. In this paper, we propose a model which can process 2D structure exchange rates data and put these characteristics to good use. Exchange rates Euro against US dollar, US dollar against Japanese yen and British Pound Sterling against US dollar are researched in this paper. Our experimental results show that, when compared with Artificial Neural Network, Support Vector Regression and Gated Recurrent Unit, the proposed model can effectively improve the accuracy of long-term forecasting. \u00a9 2017, Springer Science+Business Media New York.","Author Keywords":"Adaptive gradient algorithm; Convolutional neural network; Foreign exchange rates forecasting; Long-term forecasting","Index Keywords":"Convolution; Finance; Forecasting; Metadata; Neural networks; Convolutional neural network; Foreign exchange rates; Gradient algorithm; Long-term forecasting; Model-based OPC; Support vector regression (SVR); Technical limitations; Time series forecasting models; Electronic trading","References":"Zhang, Y., Zhao, D., Sun, J., Zou, G., Li, W., Adaptive convolutional neural network and its application in face recognition (2016) Neural Process Lett, 43 (2), pp. 389-399; Abdel-Hamid, O., Mohamed, A., Jiang, H., (2012) IEEE international conference on acoustics, speech and signal processing (ICASSP), pp 4277\u20134280, , Penn G (2012) Applying convolutional neural networks concepts to hybrid nn-hmm model for speech recognition. In; Shelhamer, E., Long, J., Darrell, T., Fully convolutional networks for semantic segmentation (2017) IEEE Trans Pattern Anal Mach Intell, 39 (4), pp. 640-651; Gao, Z.K., Cai, Q., Yang, Y.X., Dang, W.D., Zhang, S.S., Multiscale limited penetrable horizontal visibility graph for analyzing nonlinear time series (2016) Sci Rep, 6, p. 35622; Gao, Z.K., Jin, N.D., A directed weighted complex network for characterizing chaotic dynamics from time series (2012) Nonlinear Anal Real World Appl, 13 (2), pp. 947-952; Gao, Z.K., Cai, Q., Yang, Y.X., Dong, N., Zhang, S.S., Visibility graph from adaptive optimal kernel time-frequency representation for classification of epileptiform eeg (2016) Int J Neural Syst, 27 (4), p. 1750005; Gao, Z.K., Fang, P.C., Ding, M.S., Jin, N.D., Multivariate weighted complex network analysis for characterizing nonlinear dynamic behavior in two-phase flow (2015) Exp Therm Fluid Sci, 60, pp. 157-164; Gao, Z.K., Yang, Y.X., Fang, P.C., Zou, Y., Xia, C.Y., Du, M., Multiscale complex network for analyzing experimental multivariate time series (2015) Eur Lett, 109, p. 30005. , http:\/\/stacks.iop.org\/0295-5075\/109\/i=3\/a=30005; Hu, W., Yan, L., Liu, K., Wang, H., A short-term traffic flow forecasting method based on the hybrid pso-svr (2016) Neural Process Lett, 43 (1), pp. 155-172; Hu, W., Yan, L., Wang, H., Du, B., Tao, D., Real-time traffic jams prediction inspired by biham, middleton and levine (bml) model (2017) Inf Sci, 381, pp. 209-228; Galeshchuk, S., Neural networks performance in exchange rate prediction (2016) Neurocomputing, 172, pp. 446-452; Sermpinis, G., Stasinakis, C., Theofilatos, K., Karathanasopoulos, A., Modeling, forecasting and trading the EUR exchange rates with hybrid rolling genetic algorithms support vector regression forecast combinations (2015) Eur J Op Res, 247 (3), pp. 831-846; Box, G.E.P., Jenkins, G.M., Reinsel, G.C., (2008) Linear stationary models. pp 47\u201391; Box, G.E.P., Jenkins, G.M., Reinsel, G.C., (2008) Linear nonstationary models. pp 93\u2013136; Ferreira, T.A.E., Vasconcelos, G.C., Adeodato, P.J.L., A new intelligent system methodology for time series forecasting with artificial neural networks (2008) Neural Process Lett, 28 (2), pp. 113-129; Elman, J.L., Finding structure in time (1990) Cogn Sci, 14 (2), pp. 179-211; Hochreiter, S., Schmidhuber, J., Long short-term memory (1997) Neural Comput, 9 (8), pp. 1735-1780; Cho, K., van Merrienboer, B., Bahdanau, D., Bengio, Y., On the properties of neural machine translation: encoder-decoder approaches (2014) CoRR, , http:\/\/arxiv.org\/abs\/1409.1259; Bech, M.L., Sobrun, J., Fx market trends before, between and beyond triennial surveys (2013) BIS Q Rev, , http:\/\/www.bis.org\/publ\/qtrpdf\/r_qt1312f.htm; Deng, S., Yoshiyama, K., Mitsubuchi, T., Sakurai, A., Hybrid method of multiple kernel learning and genetic algorithm for forecasting short-term foreign exchange rates (2015) Comput Econ, 45 (1), pp. 49-89; Chiarella, C., Peat, M., Stevenson, M., Detecting and modelling nonlinearity in flexible exchange rate time series (1994) Asia Pac J Manag, 11 (2), pp. 159-186; Brooks, C., Testing for non-linearity in daily sterling exchange rates (1996) Appl Financ Econ, 6 (4), pp. 307-317; Abdel-Hamid, O., Li, D., Dong Y (2013) Exploring convolutional neural network structures and optimization techniques for speech recognition, p. 2013. , In, Interspeech; Samek, D., Varacha, P., Time series prediction using artificial neural networks: single and multi-dimensional data (2013) Int J Math Models Methods Appl Sci, 7 (1), pp. 38-46; Hubel, D.H., Wiesel, T.N., Receptive fields, binocular interaction and functional architecture in the cat\u2019s visual cortex (1962) J physiol, 160 (1), pp. 106-154; Fukushima, K., A neural network for visual pattern recognition (1988) Computer, 21 (3), pp. 65-75; LeCun, Y., Bengio, Y., Arbib, M.A., Convolutional networks for images, speech, and time series (1998) The handbook of brain theory and neural networks, pp. 255-258. , MIT Press, Cambridge, MA; Lecun, Y., Bottou, L., Bengio, Y., Haffner, P., Gradient-based learning applied to document recognition (1998) Proc IEEE, 86 (11), pp. 2278-2324; Duchi, J., Hazan, E., Singer, Y., Adaptive subgradient methods for online learning and stochastic optimization (2011) J Mach Learn Res, 12, pp. 2121-2159; Dean, J., Corrado, G.S., Monga, R., Chen, K., Devin, M., Le, Q.V., Mao, M.Z., Yang, K., Ng AY (2012) Large scale distributed deep networks Proceedings of the 25th international conference on neural information processing systems, MIT Press, pp. 1223-1231. , Cambridge, MA: USA; Srivastava, N., Hinton, G., Krizhevsky, A., Sutskever, I., Salakhutdinov, R., Dropout: a simple way to prevent neural networks from overfitting (2014) J Mach Learn Res, 15 (1), pp. 1929-1958; Wang, L., Qiao, Y., (2015) IEEE conference on computer vision and pattern recognition (CVPR), pp 4305\u20134314, , Tang X (2015) Action recognition with trajectory-pooled deep-convolutional descriptors. In; Ji, Y., Hao, J., Reyhani, N., Lendasse, A., (2005) Direct and recursive prediction of time series using mutual information selection, pp 1010\u20131017; Page, E.S., Continuous inspection schemes (1954) Biometrika, 41, pp. 100-115; Abadi, M., Agarwal, A., Barham, P., Brevdo, E., Chen, Z., Citro, C., Corrado, G.S., (2015) TensorFlow: large-scale machine learning on heterogeneous systems., software available from tensorflow.org, , http:\/\/tensorflow.org\/, Davis A, Dean J, Devin M, Ghemawat S, Goodfellow I, Harp A, Irving G, Isard M, Jia Y, Jozefowicz R, Kaiser L, Kudlur M, Levenberg J, Man\u00e9 D, Monga R, Moore S, Murray D, Olah C, Schuster M, Shlens J, Steiner B, Sutskever I, Talwar K, Tucker P, Vanhoucke V, Vasudevan V, Vi\u00e9gas F, Vinyals O, Warden P, Wattenberg M, Wicke M, Yu Y, Zheng X"}
{"Authors":"Yao S., Luo L., Peng H.","Author(s) ID":"57204428087;17345995600;9732506800;","Title":"High-frequency stock trend forecast using LSTM model","Year":2018,"Source title":"13th International Conference on Computer Science and Education, ICCSE 2018","Volume":null,"Issue":null,"Art. No.":" 8468703","Page start":293.0,"Page end":296.0,"Page count":null,"Cited by":null,"DOI":"10.1109\/ICCSE.2018.8468703","Affiliations":"Xiamen University, Department of Automation, Xiamen, China","Document Type":"Conference Paper","Access Type":null,"Source":"Scopus","EID":"2-s2.0-85055483678","Abstract":"Multivariate time series forecasting recently has received extensive attention with its wide application in finance, transportation, environment, and so on. However, few of the currently developed models have considered the impact of noise on prediction. Since multivariate time series contains multiple subsequences with strong nonlinear fluctuations, it is also difficult to obtain satisfactory prediction results. In this paper, aiming at improving prediction performance, we have proposed a novel ensemble three-phase model called adaptive noise reducer-stacked auto-encoder-validating-AdaBoost-based long short-term memory (ANR-SAE-VALSTM). We start with an introduction of a novel ANR for time series noise elimination. The SAEs are then used to extract features from the de-noised multivariate time series. Finally, we feed the de-noised features into the VALSTM to train an ensemble over-fitting prevention predictor. The proposed model is employed on the Beijing PM2.5 dataset and GEFCom2014 Electricity Price dataset. Compared with other popular models, the proposed model has achieved the best prediction performance in all prediction horizons. In addition, a careful ablation study is conducted to demonstrate the efficiency of our model design. \u00a9 2013 IEEE.","Author Keywords":"adaptive noise reducer; long short-term memory; Multivariate time series forecasting; stacked auto-encoders; validating AdaBoost algorithm","Index Keywords":"Adaptive boosting; Brain; Forecasting; Learning systems; Signal encoding; Spurious signal noise; Time series; AdaBoost algorithm; Adaptive noise; Auto encoders; Electricity prices; Multivariate time series; Prediction horizon; Prediction performance; Satisfactory predictions; Long short-term memory","References":"Wang, B., Huang, H., Wang, X., A novel text mining approach to financial time series forecasting (2012) Neurocomputing, 83, pp. 136-145. , Apr; Rather, A.M., Agarwal, A., Sastry, V.N., Recurrent neural network and a hybrid model for prediction of stock returns (2015) Expert Syst. Appl., 42 (6), pp. 3234-3241; Gautam, A., Singh, V., A novel approach for decomposition of financial time series (2017) Proc. Int. Conf. IEEE Recent Innov. Signal Process. Embedded Syst. (RISE), pp. 537-542. , Oct; Liu, H., Mi, X.-W., Li, Y.-F., Wind speed forecasting method based on deep learning strategy using empirical wavelet transform, long short term memory neural network and elman neural network (2018) Energy Convers. Manage., 156, pp. 498-514. , Jan; Wang, F., Yu, Y., Zhang, Z., Li, J., Zhen, Z., Li, K., Wavelet decomposition and convolutional LSTM networks based improved deep learning model for solar irradiance forecasting (2018) Appl. Sci., 8 (8), p. 1286; Cirstea, R.-G., Micu, D.-V., Muresan, G.-M., Guo, C., Yang, B., (2018) Correlated Time Series Forecasting Using Deep Neural Networks: A Summary of Results, , https:\/\/arxiv.org\/abs\/1808.09794; Hassani, H., Dionisio, A., Ghodsi, M., The effect of noise reduction in measuring the linear and nonlinear dependency of financial markets (2010) Nonlinear Anal., Real World Appl., 11 (1), pp. 492-502; Gao, J., Sultan, H., Hu, J., Tung, W.-W., Denoising nonlinear time series by adaptive filtering and wavelet shrinkage: A comparison (2010) IEEE Signal Process. Lett., 17 (3), pp. 237-240. , Mar; Bao, W., Yue, J., Rao, Y., A deep learning framework for financial time series using stacked autoencoders and long-short term memory (2017) PLoS ONE, 12 (7); Xu, M., Han, M., Lin, H., Wavelet-denoising multiple echo state networks for multivariate time series prediction (2018) Inf. Sci., 465, pp. 439-458. , Oct; Farahmand, S., Sobayo, T., Mogul, D.J., Noise-assisted multivariate EMD-based mean-phase coherence analysis to evaluate phase-synchrony dynamics in epilepsy patients (2018) IEEE Trans. Neural Syst. Rehabil. Eng., 26 (12), pp. 2270-2279. , Dec; Abdalla, F.Y., Zhao, Y., Wu, L., Denoising ECG signal by complete EEMD adaptive noise (2017) Proc. IEEE Int. Symp. Signal Process. Inf. Technol. (ISSPIT), pp. 337-342. , Dec; Bai, L., Han, Z., Li, Y., Ning, S., A hybrid de-noising algorithm for the gear transmission system based on CEEMDAN-PE-TFPF (2018) Entropy, 20 (5), p. 361; Fadlallah, B., Chen, B., Keil, A., Pr\u00edncipe, J., Weighted-permutation entropy: A complexity measure for time series incorporating amplitude information (2013) Phys. Rev. E, Stat. Phys. Plasmas Fluids Relat. Interdiscip. Top., 87 (2); Lin, S.-Y., Chiang, C.-C., Li, J.-B., Hung, Z.-S., Chao, K.-M., Dynamic fine-tuning stacked auto-encoder neural network for weather forecast (2018) Future Gener. Comput. Syst., 89, pp. 446-454. , Dec; Pak, U., Kim, C., Ryu, U., Sok, K., Pak, S., Ahybrid model based on convolutional neural networks and long short-term memory for ozone concentration prediction (2018) Air Qual., Atmos. Health, 11 (8), pp. 883-895; Pang, N., Yin, F., Zhang, X., Zhao, X., A robust approach for multivariate time series forecasting (2017) Proc. 8th Int. Symp. Inf. Commun. Technol., pp. 106-113; Chen, K., Hu, J., He, J., A framework for automatically extracting overvoltage features based on sparse autoencoder (2018) IEEE Trans. Smart Grid, 9 (2), pp. 594-604. , Mar; Lv, F., Wen, C., Liu, M., Bao, Z., Weighted time series fault diagnosis based on a stacked sparse autoencoder (2017) J. Chemometrics, 31 (9), p. e2912; Zhou, T., Agree AdaBoost stacked autoencoder for shortterm traffic flow forecasting (2017) Neurocomputing, 247, pp. 31-38. , Jul; Kim, H.Y., Won, C.H., Forecasting the volatility of stock price index: A hybrid model integrating LSTM with multiple GARCH-type models (2018) Expert Syst. Appl., 103, pp. 25-37. , Aug; Hu, Y.-L., Chen, L., A nonlinear hybrid wind speed forecasting model using LSTM network, hysteretic ELM and differential evolution algorithm (2018) Energy Convers. Manage., 173, pp. 123-142. , Oct; Hochreiter, S., Schmidhuber, J., Long short-term memory (1997) Neural Comput., 9 (8), pp. 1735-1780; Xiao, J., Li, Y., Xie, L., Liu, D., Huang, J., A hybrid model based on selective ensemble for energy consumption forecasting in China (2018) Energy, 159, pp. 534-546. , Sep; Wu, Y., Gao, J., AdaBoost-based long short-term memory ensemble learning approach for financial time series forecasting (2018) Current Sci., 115 (1), pp. 159-165; Xiao, L., Dong, Y., Dong, Y., An improved combination approach based on AdaBoost algorithm for wind speed time series forecasting (2018) Energy Convers. Manage., 160, pp. 273-288. , Mar; Box, G.E.P., Pierce, D.A., Distribution of residual autocorrelations in autoregressive-integrated moving average time series models (1970) J. Amer. Statist. Assoc., 65 (332), pp. 1509-1526. , Apr; Hamilton, J.D., (1994) Time Series Analysis, 2. , Princeton, NJ, USA: Princeton Univ. Press; Qiu, H., Xu, S., Han, F., Liu, H., Caffo, B., Robust estimation of transition matrices in high dimensional heavy-tailed vector autoregressive processes (2015) Proc. Int. Conf. Mach. Learn., 37, p. 1843; Melnyk, I., Banerjee, A., Estimating structured vector autoregressive models (2016) Proc. Int. Conf. Mach. Learn., pp. 830-839; You, Y., Demmel, J., Hsieh, C.-J., Vuduc, R., (2018) Accurate, Fast and Scalable Kernel Ridge Regression on Parallel and Distributed Systems, , https:\/\/arxiv.org\/abs\/1805.00569; Smola, A.J., Sch\u00f6lkopf, B., A tutorial on support vector regression (2004) Statist. Comput., 14 (3), pp. 199-222. , Aug; Yang, H., Huang, K., King, I., Lyu, M.R., Localized support vector regression for time series prediction (2009) Neurocomputing, 72 (10-12), pp. 2659-2669; Tobar, F., Castro, I., Silva, J., Orchard, M., Improving battery voltage prediction in an electric bicycle using altitude measurements and kernel adaptive filters (2018) Pattern Recognit. Lett., 105, pp. 200-206. , Apr; Jun, L., Qiu-Li, W., Short-term traffic flow online forecasting based on kernel adaptive filter (2018) J. Meas. Sci. Instrum., 9 (4), pp. 326-334; Roberts, S., Osborne, M., Ebden, M., Reece, S., Gibson, N., Aigrain, S., Gaussian processes for time-series modelling (2013) Philos. Trans. Roy. Soc. A, Math., Phys. Eng. Sci., 371 (1984); Dasgupta, S., Osogami, T., Nonlinear dynamic boltzmann machines for time-series prediction (2017) Proc. AAAI, pp. 1833-1839; Qin, Y., Song, D., Chen, H., Cheng, W., Jiang, G., Cottrell, G., (2017) A Dual-stage Attention-based Recurrent Neural Network for Time Series Prediction, , https:\/\/arxiv.org\/abs\/1704.02971; Bengio, Y., Simard, P., Frasconi, P., Learning long-term dependencies with gradient descent is difficult (1994) IEEE Trans. Neural Netw., 5 (2), pp. 157-166. , Mar; Wang, F., Yu, Y., Zhang, Z., Li, J., Zhen, Z., Li, K., Wavelet decomposition and convolutional LSTM networks based improved deep learning model for solar irradiance forecasting (2018) Appl. Sci., 8 (8), p. 1286; Chang, Y.-Y., Sun, F.-Y., Wu, Y.-H., Lin, S.-D., (2018) A Memorynetwork Based Solution for Multivariate Time-series Forecasting, , https:\/\/arxiv.org\/abs\/1809.02105; Torres, M.E., Colominas, M.A., Schlotthauer, G., Flandrin, P., A complete ensemble empirical mode decomposition with adaptive noise (2011) Proc. IEEE Int. Conf. Acoust., Speech Signal Process. (ICASSP), pp. 4144-4147. , May; Bandt, C., Pompe, B., Permutation entropy: A natural complexity measure for time series (2002) Phys. Rev. Lett., 88 (17); Liang, X., Assessing Beijing's PM2:5 pollution: Severity, weather impact, APEC and winter heating (2015) Proc. Roy. Soc. A, Math., Phys. Eng. Sci., 471 (2182); Hong, T., Pinson, P., Fan, S., Zareipour, H., Troccoli, A., Hyndman, R.J., Probabilistic energy forecasting: Global energy forecasting competition 2014 and beyond (2016) Int. J. Forecasting, 32 (3), pp. 896-913"}
{"Authors":"Chen Y., Wu J., Bu H.","Author(s) ID":"57204076092;57204072042;57204073569;","Title":"Stock Market Embedding and Prediction: A Deep Learning Method","Year":2018,"Source title":"2018 15th International Conference on Service Systems and Service Management, ICSSSM 2018","Volume":null,"Issue":null,"Art. No.":" 8464968","Page start":null,"Page end":null,"Page count":null,"Cited by":null,"DOI":"10.1109\/ICSSSM.2018.8464968","Affiliations":"School of Economics and Management, Beihang University, Beijing, China; Beijing Key Laboratory of Emergency Support, Simulation Technologies for City Operations, Beijing, China; Beijing Advanced Innovation Center for Big Data and Brain Computing, Beihang University, Beijing, China","Document Type":"Conference Paper","Access Type":null,"Source":"Scopus","EID":"2-s2.0-85054354418","Abstract":"Stock price modeling and prediction have been challenging objectives for researchers and speculators because of noisy and non-stationary characteristics of samples. With the growth in deep learning, the task of feature learning can be performed more effectively by purposely designed network. In this paper, we propose a novel end-to-end model named multi-filters neural network (MFNN) specifically for feature extraction on financial time series samples and price movement prediction task. Both convolutional and recurrent neurons are integrated to build the multi-filters structure, so that the information from different feature spaces and market views can be obtained. We apply our MFNN for extreme market prediction and signal-based trading simulation tasks on Chinese stock market index CSI 300. Experimental results show that our network outperforms traditional machine learning models, statistical models, and single-structure(convolutional, recurrent, and LSTM) networks in terms of the accuracy, profitability, and stability. \u00a9 2018 Elsevier B.V.","Author Keywords":"Deep learning; Feature engineering; Stock price prediction","Index Keywords":"Commerce; Convolution; Electronic trading; Financial markets; Forecasting; Long short-term memory; Motion estimation; Chinese stock market; Feature engineerings; Financial time series; Machine learning models; Market prediction; Non stationary characteristics; Stock price movement predictions; Stock price prediction; Deep learning","References":"Kim, K.J., Han, I., Genetic algorithms approach to feature discretization in artificial neural networks for the prediction of stock price index (2000) Expert Syst. Appl., 19 (2), pp. 125-132; Gunduz, H., Yaslan, Y., Cataltepe, Z., Intraday prediction of borsa istanbul using convolutional neural networks and feature correlations (2017) Knowl.-Based Syst., 137, pp. 138-148; Hagenau, M., Liebmann, M., Neumann, D., Automated news reading: stock price prediction based on financial news using context-capturing features (2013) Decis. Support Syst., 55 (3), pp. 685-697; Ding, X., Zhang, Y., Liu, T., Duan, J., Deep learning for event-driven stock prediction (2015) Proceedings of the 24th International Conference on Artificial Intelligence, pp. 2327-2333. , AAAI Press; Shynkevich, Y., McGinnity, T., Coleman, S., Belatreche, A., Li, Y., Forecasting price movements using technical indicators: investigating the impact of varying input window length (2017) Neurocomputing; Patel, J., Shah, S., Thakkar, P., Kotecha, K., Predicting stock and stock price index movement using trend deterministic data preparation and machine learning techniques (2015) Expert Syst. Appl., 42 (1), pp. 259-268; Sen, J., Chaudhuri, T.D., A robust predictive model for stock price forecasting (2017) International Conference on Business Analytics and Intelligence; Atsalakis, G.S., Valavanis, K.P., Surveying stock market forecasting techniques part ii: soft computing methods (2009) Expert Syst. Appl., 36 (3), pp. 5932-5941; Pan, Y., Xiao, Z., Wang, X., Yang, D., A multiple support vector machine approach to stock index forecasting with mixed frequency sampling (2017) Knowl.-Based Syst., 122, pp. 90-102; Xiong, T., Li, C., Bao, Y., Hu, Z., Zhang, L., A combination method for interval forecasting of agricultural commodity futures prices (2015) Knowl.-Based Syst., 77 (100), pp. 92-102; Shen, F., Chao, J., Zhao, J., Forecasting exchange rate using deep belief networks and conjugate gradient method (2015) Neurocomputing, 167, pp. 243-253; Singh, R., Srivastava, S., Stock prediction using deep learning (2017) Multimedia Tools Appl., 76 (18), pp. 18569-18584; Chen, K., Zhou, Y., Dai, F., A lstm-based method for stock returns prediction: a case study of china stock market (2015) Big Data (Big Data), 2015 IEEE International Conference on, pp. 2823-2824. , IEEE; Deng, Y., Bao, F., Kong, Y., Ren, Z., Dai, Q., Deep direct reinforcement learning for financial signal representation and trading (2017) IEEE Trans. Neural Netw. Learn. Syst., 28 (3), p. 653; Sirignano, J., Deep learning for limit order books arXiv preprint (2016); Taylor, M.P., Allen, H., The use of technical analysis in the foreign exchange market (1992) J. Int. Money Finance, 11 (3), pp. 304-314; Gunasekarage, A., Power, D.M., The profitability of moving average trading rules in south asian stock markets (2001) Emerg. Mark. Rev., 2 (1), pp. 17-33; Lee, C., Swaminathan, B., Price momentum and trading volume (2000) J. Finance, 55 (5), pp. 2017-2069; Lento, C., Gradojevic, N., Wright, C., Investment information content in bollinger bands? (2007) Appl. Financ. Econ. Lett., 3 (4), pp. 263-267; Back, A.D., Weigend, A.S., A first application of independent component analysis to extracting structure from stock returns (1997) Int. J. Neural Syst., 8 (4), pp. 473-484; Roweis, S.T., Saul, L.K., Nonlinear dimensionality reduction by locally linear embedding (2000) Science, 290 (5500), pp. 2323-2326; Hambly, B., Lyons, T., Uniqueness for the signature of a path of bounded variation and the reduced path group (2010) Ann. of Math., pp. 109-167; Boedihardjo, H., Geng, X., Lyons, T., Yang, D., The signature of a rough path: uniqueness (2016) Adv. Math., 293, pp. 720-737; Lyons, T., Rough paths, signatures and the modelling of functions on streams arXiv preprint (2014); Kocak, C., Arma(p,q) type high order fuzzy time series forecast method based on fuzzy logic relations (2017) Appl. Soft Comput.; Zumbach, G., Fernndez, L., Option pricing with realistic arch processes (2014) Quant. Finance, 14 (1), pp. 143-170; Lin, Z., Modelling and forecasting the stock market volatility of sse composite index using garch models (2017) Future Gener. Comput. Syst.; lk, N., Kuruppuarachchi, D., Kuzmicheva, O., Stock market's response to real output shocks in eastern european frontier markets: A varwal model (2017) Emerg. Mark. Rev.; Valiant, L.G., A theory of the learnable (1984) Commun. ACM, 27 (11), pp. 1134-1142; Rivest, R.L., Learning decision lists (1987) Mach. Learn., 2 (3), pp. 229-246; Zhou, T., Gao, S., Wang, J., Chu, C., Todo, Y., Tang, Z., Financial time series prediction using a dendritic neuron model (2016) Knowl.-Based Syst., 105 (100), pp. 214-224; Zhou, L., Si, Y.W., Fujita, H., Predicting the listing statuses of chinese-listed companies using decision trees combined with an improved filter feature selection method (2017) Knowl.-Based Syst., 128; Krizhevsky, A., Sutskever, I., Hinton, G.E., Imagenet classification with deep convolutional neural networks (2012) Advances in Neural Information Processing Systems, pp. 1097-1105; Graves, A., Mohamed, A.-R., Hinton, G., Speech recognition with deep recurrent neural networks (2013) Acoustics, Speech and Signal Processing (icassp), 2013 IEEE International Conference on, pp. 6645-6649. , IEEE; Yang, W., Jin, L., Ni, H., Lyons, T., Rotation-free online handwritten character recognition using dyadic path signature features, hanging normalization, and deep neural network (2016) Pattern Recognition (ICPR), 2016 23rd International Conference on, pp. 4083-4088. , IEEE; Lcun, Y., Bottou, L., Bengio, Y., Haffner, P., Gradient-based learning applied to document recognition (1998) Proc. IEEE, 86 (11), pp. 2278-2324; Williams, R.J., Zipser, D., A Learning Algorithm for Continually Running Fully Recurrent Neural Networks (1989), pp. 270-280. , MIT Press; Cho, K., Van Merrienboer, B., Bahdanau, D., Bengio, Y., On the properties of neural machine translation: encoder-decoder approaches (2014) Comput. Sci.; Hochreiter, S., Schmidhuber, J., Long short-term memory (1997) Neural Comput., 9 (8), pp. 1735-1780; Szegedy, C., Liu, W., Jia, Y., Sermanet, P., Reed, S., Anguelov, D., Erhan, D., Rabinovich, A., Going deeper with convolutions (2015) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 1-9; Cui, Y., Chen, Z., Wei, S., Wang, S., Liu, T., Hu, G., Attention-over-attention neural networks for reading comprehension arXiv preprint (2016); Han, K.J., Hahm, S., Kim, B.H., Kim, J., Lane, I., Deep learning-based telephony speech recognition in the wild (2017) Proc. Interspeech, pp. 1323-1327; Girshick, R., Donahue, J., Darrell, T., Malik, J., Rich feature hierarchies for accurate object detection and semantic segmentation (2014) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 580-587; Hochreiter, S., The vanishing gradient problem during learning recurrent neural nets and problem solutions (1998) Internat. J. Uncertain. Fuzziness Knowledge-Based Systems, 6 (2), pp. 107-116; Bengio, Y., Simard, P., Frasconi, P., Learning long-term dependencies with gradient descent is difficult (2002) IEEE Trans. Neural Netw., 5 (2), pp. 157-166; Pascanu, R., Mikolov, T., Bengio, Y., On the difficulty of training recurrent neural networks (2013) International Conference on Machine Learning, pp. 1310-1318; Srivastava, N., Hinton, G.E., Krizhevsky, A., Sutskever, I., Salakhutdinov, R., Dropout: a simple way to prevent neural networks from overfitting (2014) J. Mach. Learn. Res., 15 (1), pp. 1929-1958; Ioffe, S., Szegedy, C., Batch normalization: accelerating deep network training by reducing internal covariate shift (2015) International Conference on Machine Learning, pp. 448-456; He, K., Zhang, X., Ren, S., Sun, J., Deep residual learning for image recognition (2016) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 770-778; Dixon, M., Sequence classification of the limit order book using recurrent neural networks (2017) J. Comput. Sci., , http:\/\/www.sciencedirect.com\/science\/article\/pii\/S1877750317309675, URL; Rimer, M., Martinez, T., Softprop: softmax neural network backpropagation learning (2004) Neural Networks, 2004. Proceedings. 2004 IEEE International Joint Conference on, Vol. 2, pp. 979-983. , IEEE; HechtNielsen, Theory of the backpropagation neural network (1988) Neural Netw., 1 (1). , 445\u2013445; Andrychowicz, M., Denil, M., Gomez, S., Hoffman, M.W., Pfau, D., Schaul, T., Shillingford, B., De Freitas, N., Learning to learn by gradient descent by gradient descent (2016) Advances in Neural Information Processing Systems, pp. 3981-3989; Dem\u0161ar, J., Statistical comparisons of classifiers over multiple data sets (2006) J. Mach. Learn. Res., 7 (Jan), pp. 1-30; Markowitz, H., Portfolio selection (1952) J. Finance, 7 (1), pp. 77-91; Ledoit, O., Wolf, M., Robust performance hypothesis testing with the sharpe ratio (2008) J. Empir. Finance, 15 (5), pp. 850-859"}
{"Authors":"Sezer O.B., Ozbayoglu A.M.","Author(s) ID":"57207586168;6505999525;","Title":"Algorithmic financial trading with deep convolutional neural networks: Time series to image conversion approach","Year":2018,"Source title":"Applied Soft Computing Journal","Volume":"70","Issue":null,"Art. No.":null,"Page start":525.0,"Page end":538.0,"Page count":null,"Cited by":7.0,"DOI":"10.1016\/j.asoc.2018.04.024","Affiliations":"TOBB University of Economics and Technology, Ankara, 06560, Turkey","Document Type":"Article","Access Type":null,"Source":"Scopus","EID":"2-s2.0-85048331794","Abstract":"Applying neural network and error t-value test, this study trains and analyzes 28 interest rate changes of China\u2019s macro-monetary policy and the mutual influences between reserve adjustments and financial markets for 51 times from 2000 to 2018 according to the data correlation between financial market and monetary policy. Through the principal component analysis, the bilateral financial risk system and data set are established, and the data set pre-process and dimensionality reduction are carried out to extract the most informative features. Six training cases are designed with processed features, and then the cases are input to each neural network model for combined prediction. Firstly, based on backpropagation neural network (BP), the forecasting model of monetary policy is established. Then, considering the importance characteristics of financial index data, expert weights based on BP, are introduced to propose weights backpropagation (WBP) model. On the basis of the timing characteristics of financial market, the WBP model is improved and the timing weights backpropagation (TWBP) model is proposed. Experiments show that different training cases bring out various effects. The accuracy rate of interest rate and reserve change value is lower than the original value after training. The mutation after data processing affects the learning of neural network. At the same time, the WBP and TWBP models improve according to the importance and timing characteristics of financial indicators have less errors in results, and the TWBP model has higher accuracy. When the number of hidden layers is 3, good results can be obtained, but in manifold training of the timing cycle, the efficiency of that is not as good as the WBP model. \u00a9 2019, Springer-Verlag London Ltd., part of Springer Nature.","Author Keywords":"Financial risks; Monetary policy; Neural network; Time series","Index Keywords":"Backpropagation; Commerce; Data handling; Electronic trading; Financial markets; Forecasting; Neural networks; Principal component analysis; Risk assessment; Time series; Back-propagation neural networks; Dimensionality reduction; Financial indicator; Financial risks; Forecasting modeling; Monetary policies; Neural network model; Timing characteristics; Deep learning","References":"Black, S.E., Devereux, P.J., Lundborg, P., On the origins of risk-taking in financial markets (2017) J Financ, 72 (5), pp. 100-105; Riccioni, J., Cerqueti, R., Regular paths in financial markets: investigating the benford\u2019s law (2018) Chaos Solitons Fractals, 107, pp. 186-194; Lin, E.M.H., Sun, E.W., Yu, M.T., Systemic risk, financial markets, and performance of financial institutions (2018) Ann Oper Res, 262 (2), pp. 579-603; Lengnick, M., Wohltmann, H.W., Optimal monetary policy in a new Keynesian model with animal spirits and financial markets (2016) J Econ Dyn Control, 64, pp. 148-165; Dafermos, Y., Nikolaidi, M., Galanis, G., Climate change, financial stability and monetary policy (2018) Ecol Econ, 152, pp. 219-234; Platen, E., Rebolledo, R., Principles for modelling financial markets (1996) J Appl Probab, 33 (3), pp. 601-613; Li, K., Tang, X., Li, K., Energy-efficient stochastic task scheduling on heterogeneous computing systems (2014) IEEE Trans Parallel Distrib Syst, 25 (11), pp. 2867-2876; Antipov, A., Meade, N., Forecasting call frequency at a financial services call centre (2002) J Oper Res Soc, 53 (9), pp. 953-960; Li, C., Chiang, T.W., Complex neurofuzzy arima forecasting\u2013a new approach using complex fuzzy sets (2013) IEEE Trans Fuzzy Syst, 21 (3), pp. 567-584; Kayalar, D.E., K\u00fc\u00e7\u00fck\u00f6zmen, C.C., Selcuk-Kestel, A.S., The impact of crude oil prices on financial market indicators: copula approach (2017) Energy Econ, 61, pp. 162-173; Yuming, X., Li, K., Jingtong, H., Li, K., A genetic algorithm for task scheduling on heterogeneous computing systems using multiple priority queues (2014) Inf Sci, 270, pp. 255-287; Ganda, F., The environmental impacts of financial development in oecd countries: a panel gmm approach (2019) Environ Sci Pollut Res, 5, pp. 11-15; Jian, Z.H., Zhu, B.S., Shuang, L.I., (2012) Dynamic Inflation Target, Money Supply Mechanism and China\u2019s Economic Fluctuation: A Dsge-Based Analysis, , Chin J Manag Sci; Yuming, X., Li, K., He, L., Zhang, L., Li, K., A hybrid chemical reaction optimization scheme for task scheduling on heterogeneous computing systems (2015) IEEE Trans Parallel Distrib Syst, 26 (12), pp. 3208-3222; Chen, J., Li, K., Bilal, K., Metwally, A.A., Li, K., Yu, P.S., Parallel protein community detection in large-scale ppi networks based on multi-source learning (2018) IEEE\/ACM Trans Comput Biol Bioinf, , (,),.,., https:\/\/doi.org\/10.1109\/TCBB.2018.2868088; Chen, C., Tiao, G.C., Random level-shift time series models, arima approximations, and level-shift detection (1990) J Bus Econ Stat, 8 (1), pp. 83-97; Einav, L., Levin, J., Economics in the age of big data (2014) Science, 346 (6210), pp. 124-130; Zhang, X.P.S., Wang, F., Signal processing for finance, economics, and marketing: concepts, framework, and big data applications (2017) IEEE Signal Process Mag, 34 (3), pp. 14-35; Ara\u00fajo, R.D.A., A morphological perceptron with gradient-based learning for Brazilian stock market forecasting (2012) Neural Netw, 28, pp. 61-81; Chung, H., Shin, K.S., Genetic algorithm-optimized long short-term memory network for stock market prediction (2010) Sustainability, 10, p. 3765; Li, K., Yang, W., Li, K., Performance analysis and optimization for spmv on gpu using probabilistic modeling (2015) IEEE Trans Parallel Distrib Syst, 26 (1), pp. 196-205; Chen, J., Li, K., Tang, Z., Yu, S., Li, K., A parallel random forest algorithm for big data in spark cloud computing environment (2017) IEEE Trans Parallel Distrib Syst, 28 (4), pp. 919-933; Lazer, D., Kennedy, R., King, G., Big data. the parable of google flu: traps in big data analysis (2014) Science, 343 (6176), p. 1203; Chiu, M.C., Pun, C.S., Wong, H.Y., Big data challenges of high-dimensional continuous-time mean-variance portfolio selection and a remedy (2017) Risk Analysis, 37 (8), p. 1532; Chen, J., Li, K., Deng, Q., Li, K., Yu, P.S., Distributed deep learning model for intelligent video surveillance systems with edge computing (2019) IEEE Trans Ind Inf, , (,),.,., https:\/\/doi.org\/10.1109\/TII.2019.2909473; Yu, L., Chen, H., Wang, S., Evolving least squares support vector machines for stock market trend mining (2009) IEEE Trans Evol Comput, 13 (1), pp. 87-102; Ebrahimpour, R., Nikoo, H., Masoudnia, S., Mixture of mlp-experts for trend forecasting of time series: a case study of the tehran stock exchange (2011) Int J Forecast, 27 (3), pp. 804-816; Chen, M.Y., Chen, B.T., A hybrid fuzzy time series model based on granular computing for stock price forecasting (2015) Inf Sci, 294 (2), pp. 227-241; Chen, J., Li, K., Bilal, K., Zhou, X., Li, K., Yu, P.S., A bi-layered parallel training architecture for large-scale convolutional neural networks (2018) IEEE Trans Parallel Distrib Syst, 30 (5), pp. 965-976; Chen, J., Li, K., Huigui, R., Bilal, K., Li, K., Yu, P.S., A periodicity-based parallel time series prediction algorithm in cloud computing environments (2018) Inf Sci, , https:\/\/doi.org\/10.1016\/j.ins.2018.06.045; Bengio, Y., Delalleau, O., Justifying and generalizing contrastive divergence (2009) Neural Comput, 21 (6), p. 1601; Cao, Z., Long, C., Chao, Z., Spiking neural network-based target tracking control for autonomous mobile robots (2015) Neural Comput Appl, 26 (8), pp. 1839-1847; Dahl, G.E., Sainath, T.N., Hinton, G.E., Improving deep neural networks for LVCSR using rectified linear units and dropout (2013) IEEE International Conference on Acoustics; Qian, B., Rasheed, K., Stock market prediction with multiple classifiers (2007) Appl Intell, 26 (1), pp. 25-33; Fratianni, M., Marchionne, F., The fading stock market response to announcements of bank bailouts (2013) J Financ Stabil, 9 (1), pp. 69-89; Patwary, E.U., Lee, J.Y., Nobi, A., Changes of hierarchical network in local and world stock market (2017) J Kor Phys Soc, 71 (7), pp. 444-451; Wu, X., Lu, H., Exponential synchronization of weighted general delay coupled and non-delay coupled dynamical networks (2010) Comput Math Appl, 60 (8), pp. 2476-2487; Lecun, Y., Bengio, Y., Hinton, G., Deep learning (2015) Nature, 521 (7553), p. 436; Song, Y., Lee, J.W., Lee, J., A study on novel filtering and relationship between input-features and target-vectors in a deep learning model for stock price prediction (2018) Appl Intell, 49, pp. 897-911; Pang, X., Zhou, Y., Pan, W., An innovative neural network approach for stock market prediction (2018) J Supercomput, 1, pp. 1-21; Asadi, S., Hadavandi, E., Mehmanpazir, F., Hybridization of evolutionary levenberg-marquardt neural networks and data pre-processing for stock market prediction (2012) Knowledge-Based Syst, 35 (15), pp. 245-258; Yu-Hui, T., Wei, K., Shou-Ning, Q., Research on stock quotation based on improved rough lattice model (2010) IEEE, 3, pp. 442-445; Yoo, P.D., Kim, M.H., Jan, T., Financial forecasting: Advanced machine learning techniques in stock market analysis (2005) IEEE, pp. 1-7; O\u2019Connor, N., Madden, M.G., A neural network approach to predicting stock exchange movements using external factors (2006) Knowledge-Based Syst, 19 (5), pp. 371-378; Chen, Y., Li, K., Yang, W., Xiao, G., Xie, X., Li, T., Performance-aware model for sparse matrix-matrix multiplication on the sunway taihulight supercomputer (2019) IEEE Trans Parallel Distrib Syst, 30 (4), pp. 923-938; Maknickien\u00e9, N., Maknickas, A., Financial market prediction system with evolino neural network and delphi method (2013) Physiologia Plantarum, 14 (2), pp. 403-413; Jie, W., Wang, J., Forecasting stochastic neural network based on financial empirical mode decomposition (2017) Neural Netw, 90, pp. 8-20; Xiao, G., Li, K., Li, K., Reporting l most influential objects in uncertain databases based on probabilistic reverse top-k queries (2017) Inf Sci, 405, pp. 207-226; Desai, V.S., Bharati, R., The efficacy of neural networks in predicting returns on stock and bond indices (2010) Decis Sci, 29 (2), pp. 405-423; Xiao, G., Li, K., CASpMV: a customized and accelerative SPMV framework for the sunway TaihuLight (2019) IEEE Transactions on Parallel and Distributed Systems, p. 1. , (,),., https:\/\/doi.org\/10.1109\/TPDS.2019.2907537; Lin, A., Shang, P., Zhou, H., Cross-correlations and structures of stock markets based on multiscale MF-DXA and PCA (2014) Nonlinear Dyn, 78 (1), pp. 485-494; http:\/\/www.stats.gov.cn\/; http:\/\/www.51ifind.com\/, iFind: Hithink flush information network co., ltd. (ifind); http:\/\/www.gtarsc.com\/; Leshno, M., Lin, V.Y., Pinkus, A., Original contribution: multilayer feedforward networks with a nonpolynomial activation function can approximate any function (1991) Neural Comput, 6 (6), pp. 861-867; Mandic, D.P., Chambers, J.A., Relating the slope of the activation function and the learning rate within a recurrent neural network (1999) Neural Comput, 11 (5), pp. 1069-1077"}
{"Authors":"Yan H., Ouyang H.","Author(s) ID":"57198790516;35269370400;","Title":"Financial Time Series Prediction Based on Deep Learning","Year":2018,"Source title":"Wireless Personal Communications","Volume":"102","Issue":"2","Art. No.":null,"Page start":683.0,"Page end":700.0,"Page count":null,"Cited by":3.0,"DOI":"10.1007\/s11277-017-5086-2","Affiliations":"School of Economics, Huazhong University of Science and Technology, 1037 Luoyu Road, Wuhan, Hubei, China","Document Type":"Article","Access Type":null,"Source":"Scopus","EID":"2-s2.0-85037095689","Abstract":"Recurrent neural network are a type of deep learning units that are well studied to extract features from sequential samples. They have been extensively applied in forecasting univariate financial time series, however their application to high frequency multivariate sequences has been merely considered. This paper solves a classification problem in which recurrent units are extended to deep architecture to extract features from multi-variance market data in 1-minutes frequency and extreme market are subsequently predicted for trading signals. Our results demonstrate the abilities of deep recurrent architecture to capture the relationship between the historical behavior and future movement of high frequency samples. The deep RNN is compared with other models, including SVM, random forest, logistic regression, using CSI300 1-minutes data over the test period. The result demonstrates that the capability of deep RNN generating trading signal based on extreme movement prediction support more efficient market decision making and enhance the profitability. \u00a9 Springer International Publishing AG, part of Springer Nature 2018.","Author Keywords":"Deep learning; Financial time series; High frequency trading; Recurrent neural networks","Index Keywords":"Commerce; Decision making; Decision trees; Deep learning; Deep neural networks; Electronic trading; Forecasting; Motion estimation; Network architecture; Time series; Deep architectures; Financial time series; High frequency HF; High-frequency trading; Logistic regressions; Market prediction; Movement prediction; Random forests; Recurrent neural networks","References":"Bhattacharya, A., Parlos, A.G., Atiya, A.F., Prediction of MPEG-coded video source traffic using recurrent neural networks (2002) IEEE Trans. Signal Process., 51 (8), pp. 2177-2190; Cheng, W., Wagner, L., Lin, C.H., Forecasting the 30-year us treasury bond with a system of neural networks (1996) Neuroizest J, 4, pp. 10-16; Dauphin, Y., Yao, K., Bengio, Y., Deng, L., Hakkani-Tur, D., He, X., Heck, L., Zweig, G., Using recurrent neural networks for slot filling in spoken language understanding (2015) IEEE\/ACM Trans. Audio Speech Lang. Process., 23 (3), pp. 530-539; Emam, A., Optimal artificial neural network topology for foreign exchange forecasting (2008) Proceedings of the 46Th Annual Southeast Regional Conference on XX, pp. 63-68. , ACM; Graves, A., Mohamed, A., Hinton, G., Speech recognition with deep recurrent neural networks (2013) 2013 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), pp. 6645-6649. , IEEE; Ioffe, S., Szegedy, C., Batch normalization: Accelerating deep network training by reducing internal covariate shift (2015) International Conference on Machine Learning, pp. 448-456; Kim, Y., (2014) Convolutional Neural Networks for Sentence Classification; Kingma, D., Ba, J., (2014) Adam: A method for stochastic optimization, , arXiv preprint arXiv; Krizhevsky, A., Sutskever, I., Hinton, G.E., Imagenet classification with deep convolutional neural networks (2012) Advances in Neural Information Processing Systems, pp. 1097-1105; Mikolov, T., Karafit, M., Burget, L., Cernock, J., Khudanpur, S., Recurrent neural network based language model (2010) INTERSPEECH 2010, Conference of the International Speech Communication Association, pp. 1045-1048; Nag, A.K., Mitra, A., Forecasting daily foreign exchange rates using genetically optimized neural networks (2002) J. Forecast., 21 (7), pp. 501-511; Panda, C., Narasimhan, V., Forecasting exchange rate better with artificial neural network (2007) J. Policy Model., 29 (2), pp. 227-236; Sharda, R., Patil, R.B., Connectionist approach to time series prediction: An empirical test (1992) J. Intell. Manuf., 3 (5), pp. 317-323; Srivastava, N., Hinton, G.E., Krizhevsky, A., Sutskever, I., Salakhutdinov, R., Dropout: A simple way to prevent neural networks from overfitting (2014) J. Mach. Learn. Res., 15 (1), pp. 1929-1958; Szegedy, C., Liu, W., Jia, Y., Sermanet, P., Reed, S., Anguelov, D., Erhan, D., Rabinovich, A., Going deeper with convolutions (2015) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 1-9; van Eyden, R.J., (1996) The Application of Neural Networks in the Forecasting of Share Prices; Weigend, A.S., Predicting sunspots and exchange rates with connectionist networks (1992) Nonlinear Modeling and Forecasting, pp. 395-432; Weigend, A.S., Rumelhart, D.E., Huberman, B.A., Generalization by weight-elimination with application to forecasting (1991) Advances in Neural Information Processing Systems, pp. 875-882; White, H., Economic prediction using neural networks: The case of IBM daily stock returns (1988) IEEE International Conference on Neural Networks, 2, pp. 451-458; Williams, R.J., Zipser, D., A Learning Algorithm for Continually Running Fully Recurrent Neural Networks (1989) MIT Press, Cambridge"}
{"Authors":"Alkhoshi E., Belkasim S.","Author(s) ID":"57205116311;6603864907;","Title":"Stable stock market prediction using NARX algorithm","Year":2018,"Source title":"ACM International Conference Proceeding Series","Volume":null,"Issue":null,"Art. No.":null,"Page start":62.0,"Page end":66.0,"Page count":null,"Cited by":null,"DOI":"10.1145\/3277104.3277120","Affiliations":"Department of Computer Science, Georgia State University, Atlanta, GA, United States","Document Type":"Conference Paper","Access Type":null,"Source":"Scopus","EID":"2-s2.0-85058627874","Abstract":"In this paper, we show that the recent integration of statistical models with deep recurrent neural networks provides a new way of formulating volatility (the degree of variation of time series) models that have been widely used in time series analysis and prediction in finance. The model comprises a pair of complementary stochastic recurrent neural networks: the generative network models the joint distribution of the stochastic volatility process; the inference network approximates the conditional distribution of the latent variables given the observables. Our focus here is on the formulation of temporal dynamics of volatility over time under a stochastic recurrent neural network framework. Experiments on real-world stock price datasets demonstrate that the proposed model generates a better volatility estimation and prediction that outperforms mainstream methods, e.g., deterministic models such as GARCH and its variants, and stochastic models namely the MCMC-based stochvol as well as the Gaussian-process-based, on average negative log-likelihood. Copyright \u00a9 2018, Association for the Advancement of Artificial Intelligence (www.aaai.org). All rights reserved.","Author Keywords":null,"Index Keywords":"Economic analysis; Electronic trading; Recurrent neural networks; Stochastic systems; Time series analysis; Conditional distribution; Deterministic models; Gaussian Processes; Joint distributions; Stochastic recurrent neural network; Stochastic volatility; Stochastic Volatility Model; Volatility estimations; Stochastic models","References":"Andersen, T.G., Bollerslev, T., Answering the skeptics: Yes, standard volatility models do provide accurate forecasts (1998) International Economic Review, pp. 885-905; Bahdanau, D., Cho, K., Bengio, Y., Neural machine translation by jointly learning to align and translate (2014) CoRR, , abs\/1409.0473; Bollerslev, T., Engle, R.F., Nelson, D.B., Arch models (1994) Handbook of Econometrics, 4, pp. 2959-3038; Bollerslev, T., Generalized autoregressive conditional heteroskedasticity (1986) Journal of Econometrics, 31 (3), pp. 307-327; Cho, K., Van Merrienboer, B., G\u00fcl\u00e7ehre, \u00c7., Bahdanau, D., Bougares, F., Schwenk, H., Bengio, Y., Learning phrase representations using RNN encoder-decoder for statistical machine translation (2014) Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing, EMNLP 2014, pp. 1724-1734. , Moschitti, A.; Pang, B.; and Daelemans, W., eds, October 25-29, 2014, Doha, Qatar, A meeting of SIGDAT, a Special Interest Group of the ACL, ACL; Chorowski, J., Bahdanau, D., Serdyuk, D., Cho, K., Bengio, Y., Attention-based models for speech recognition (2015) Cortes Et Al, pp. 577-585. , 2015; Chung, J., Kastner, K., Dinh, L., Goel, K., Courville, A.C., Bengio, Y., A recurrent latent variable model for sequential data (2015) Cortes Et Al, pp. 2980-2988. , 2015; Cortes, C., Lawrence, N.D., Lee, D.D., Sugiyama, M., Garnett, R., (2015) Advances in Neural Information Processing Systems 28: Annual Conference on Neural Information Processing Systems 2015, , eds. December 7-12, 2015, Montreal, Quebec, Canada; Engle, R.F., Kroner, K.F., Multivariate simultaneous generalized arch (1995) Econometric Theory, 11, pp. 122-150. , 01; Engle, R.F., Autoregressive conditional heteroscedasticity with estimates of the variance of United Kingdom inflation (1982) Econometrica: Journal of the Econometric Society, pp. 987-1007; Fraccaro, M., S\u00f8nderby, S.K., Paquet, U., Winther, O., Sequential neural models with stochastic layers (2016) Advances in Neural Information Processing Systems 29: Annual Conference on Neural Information Processing Systems 2016, pp. 2199-2207. , Lee, D. D.; Sugiyama, M.; von Luxburg, U.; Guyon, I.; and Garnett, R., eds, December 5-10, 2016, Barcelona, Spain; Glosten, L.R., Jagannathan, R., Runkle, D.E., On the relation between the expected value and the volatility of the nominal excess return on stocks (1993) The Journal of Finance, 48 (5), pp. 1779-1801; Heston, S.L., A closed-form solution for options with stochastic volatility with applications to bond and currency options (1993) Review of Financial Studies, 6 (2), pp. 327-343; Hochreiter, S., Schmidhuber, J., Long short-term memory (1997) Neural Computation, 9 (8), pp. 1735-1780; Hull, J., White, A., The pricing of options on assets with stochastic volatilities (1987) The Journal of Finance, 42 (2), pp. 281-300; Hull, J.C., (2006) Options, Futures, and Other Derivatives, , Pearson Education India; Jacquier, E., Polson, N.G., Rossi, P.E., Bayesian analysis of stochastic volatility models (2002) Journal of Business & Economic Statistics, 20 (1), pp. 69-87; Kastner, G., Fr\u00fchwirth-Schnatter, S., Ancillarity-sufficiency interweaving strategy (ASIS) for boosting MCMC estimation of stochastic volatility models (2014) Computational Statistics & Data Analysis, 76, pp. 408-423; Kim, S., Shephard, N., Chib, S., Stochastic volatility: Likelihood inference and comparison with arch models (1998) The Review of Economic Studies, 65 (3), pp. 361-393; Kingma, D.P., Ba, J., ADaM: A method for stochastic optimization (2014) CoRR, , abs\/1412.6980; Kingma, D.P., Welling, M., Auto-encoding variational bayes (2013) CoRR, , abs\/1312.6114; Krizhevsky, A., Sutskever, I., Hinton, G.E., Imagenet classification with deep convolutional neural networks (2012) Advances in Neural Information Processing Systems 25: 26th Annual Conference on Neural Information Processing Systems 2012. Proceedings of a Meeting Held December 3-6, pp. 1106-1114. , Bartlett, L.; Pereira, F. C. N.; Burges, C. J. C.; Bottou, L.; and Weinberger, K. Q., eds, 2012, Lake Tahoe, Nevada, United States; LeCun, Y., Bengio, Y., Hinton, G.E., Deep learning (2015) Nature, 521 (7553), pp. 436-444; Little, R.J., Rubin, D.B., (2014) Statistical Analysis with Missing Data, , John Wiley & Sons; Nelson, D.B., Conditional heteroskedasticity in asset returns: A new approach (1991) Econometrica: Journal of the Econometric Society, pp. 347-370; Poon, S.-H., Granger, C.W., Forecasting volatility in financial markets: A review (2003) Journal of Economic Literature, 41 (2), pp. 478-539; Rezende, D.J., Mohamed, S., Wierstra, D., Stochastic backpropagation and approximate inference in deep generative models (2014) Proceedings of the 31th International Conference on Machine Learning, ICML 2014, 32, pp. 1278-1286. , Beijing, China, 21-26 June 2014, of JMLR Workshop and Conference Proceedings, JMLR.org; Schmidhuber, J., Deep learning in neural networks: An overview (2015) Neural Networks, 61, pp. 85-117; Schuster, M., Paliwal, K.K., Bidirectional recurrent neural networks (1997) IEEE Trans. Signal Processing, 45 (11), pp. 2673-2681; Srivastava, N., Hinton, G.E., Krizhevsky, A., Sutskever, I., Salakhutdinov, R., Dropout: A simple way to prevent neural networks from overfitting (2014) Journal of Machine Learning Research, 15 (1), pp. 1929-1958; Van Den Oord, A., Kalchbrenner, N., Kavukcuoglu, K., Pixel recurrent neural networks (2016) Proceedings of the 33nd International Conference on Machine Learning, ICML 2016, pp. 1747-1756. , Balcan, M., and Weinberger, K. Q., eds, New York City, NY, USA, June 19-24, 2016, 48 of JMLR Workshop and Conference Proceedings, JMLR.org; Wu, Y., Hern\u00e1ndez-Lobato, J.M., Ghahramani, Z., Gaussian process volatility model (2014) Advances in Neural Information Processing Systems 27: Annual Conference on Neural Information Processing Systems 2014, pp. 1044-1052. , Ghahramani, Z.; Welling, M.; Cortes, C.; Lawrence, N. D.; and Weinberger, K. Q., eds, December 8-13 2014, Montreal, Quebec, Canada; Xu, K., Ba, J., Kiros, R., Cho, K., Courville, A.C., Salakhutdinov, R., Zemel, R.S., Bengio, Y., Show, attend and tell: Neural image caption generation with visual attention (2015) Proceedings of the 32nd International Conference on Machine Learning, ICML 2015, Lille, France, pp. 2048-2057. , Bach, F. R., and Blei, D. M., eds, 11 July 2015, 37 of JMLR Workshop and Conference Proceedings, JMLR.org; Zakoian, J.-M., Threshold heteroskedastic models (1994) Journal of Economic Dynamics and Control, 18 (5), pp. 931-955"}
{"Authors":"Chiong R., Adam M.T.P., Fan Z., Lutz B., Hu Z., Neumann D.","Author(s) ID":"23395951300;44061092000;57007544300;57190262132;55838947300;7202067244;","Title":"A sentiment analysis-based machine learning approach for financial market prediction via news disclosures","Year":2018,"Source title":"GECCO 2018 Companion - Proceedings of the 2018 Genetic and Evolutionary Computation Conference Companion","Volume":null,"Issue":null,"Art. No.":null,"Page start":278.0,"Page end":279.0,"Page count":null,"Cited by":6.0,"DOI":"10.1145\/3205651.3205682","Affiliations":"University of Newcastle, Callaghan, NSW  2308, Australia; University of Freiburg, Freiburg, 79085, Germany; Wuhan University, Wuhan, 430072, China","Document Type":"Conference Paper","Access Type":null,"Source":"Scopus","EID":"2-s2.0-85051531626","Abstract":"The investment market has been growing every day, performing an important role in the lives of individuals and corporations. Therefore, there is a need to better understand the situations that occur in the capital market, by means of strategies and indicators that can assist in pattern recognition, analisys and investiment decisions. This work performs a study of characterization and analysis of a historical time series data of 10 asset codes (i.e., BBAS3, USIM5, PETR4, JBSS3, KROT3, LAME4, MRVE4, NATU3, RADL3 e TIMP3) of the Bovespa index and sentiment analysis of polarity news and Twitter data with the proposal of evaluating a prediction model. It proposes the combination of deep learning and machine learning computational intelligence models for prediction, allowing the execution and cancellation of buy and sell orders. Finally, it evaluates the behavior of each proposed trading strategy by Accuracy, Percentage of Financial Return and other indicators to provide a better understanding of financial market behavior. \u00a9 2018 Copyright held by the owner\/author(s).","Author Keywords":"Data characterization; Deep learning; Financial indicators; Machine learning; Stock markets; Trading strategies; Web 2.0","Index Keywords":"Artificial intelligence; Commerce; Financial markets; Investments; Learning systems; Pattern recognition; Sentiment analysis; Time series analysis; Data characterization; Financial indicator; Financial returns; Investment market; Machine learning models; Time-series data; Trading strategies; Web 2.0; Deep learning","References":"Abdulaziz Almalaq, G.E., A review of deep learning methods applied on load forecasting (2017) IEEE International Conference on Machine Learning and Applications (ICMLA); (2016) Sobre O Terminal Bloomberg, , Bloomberg. Accessado em 2016-03-25; (2014) What Does The Stock Exchenge Do?, , Bovespa. Stock Exchenge of S\u00e3o Paulo; David, G.E.H., Ackley, H., A learning alforithm for boltzmann machine (1987) Readings in Computer Vision, pp. 522-533; George, K.P.V., Atsalakis, S., Surveying stock market forecasting techniques \u2013 Part II: Soft computing methods (2009) Expert Systems with Applications; Kevin Beyer, R.R., Goldstein, J., (1999) When Is \"Nearest Neighbor\"Meaningful?, , CiteSeerX; Mart\u00edn Iglesias Caride, L.L., Stock returns forecast: An examination by means of artificial neural networks (2017) Complex Systems: Solutions and Challenges in Economics, Management and Engineering, , A. F. B. e; Niaki, S., Hoseinzade, S., Forecasting s&p 500 index using artificial neural networks and design of experiments (2013) Journal of Industrial Engineering International, 9 (1), pp. 1-9; Paulo Henrique Kaupa, R.J.S., Rough sets: Technical computer intelligence applied to financial market (2017) International Journal of Business Innovation and Research, 13; Tiago, A.S.S., Oliveira, P., Barbar, J.S., Computer network traffic prediction: A comparison between traditional and deep learning neural networks (2016) International Journal Big Data Intelligence, 3 (1); White, H., Economic prediction using neural networks: The case of IBM daily stock returns (1988) Neural Networks, 1988., IEEE International Conf. on, pp. 451-458. , IEEE"}
{"Authors":"Du S., Li T., Horng S.-J.","Author(s) ID":"57194798613;7406372548;35585485600;","Title":"Time Series Forecasting Using Sequence-to-Sequence Deep Learning Framework","Year":2018,"Source title":"Proceedings - International Symposium on Parallel Architectures, Algorithms and Programming, PAAP","Volume":"2018-December","Issue":null,"Art. No.":" 8701741","Page start":171.0,"Page end":176.0,"Page count":null,"Cited by":null,"DOI":"10.1109\/PAAP.2018.00037","Affiliations":"School of Information Science and Technology, Southwest Jiaotong University, Chengdu, 611756, China; Department of Computer Science and Information Engineering, National Taiwan University of Science and Technology, Taiwan","Document Type":"Conference Paper","Access Type":null,"Source":"Scopus","EID":"2-s2.0-85065636375","Abstract":"Time series analysis has significance in financial analytics and market forecasting and it can be utilized in any field. For stockbrokers, understanding trends and forecasting supported by software are very important to decision making and reacting to changes in behavioral patterns. This paper proposes an algorithm and model for market forecasting in Indonesian exchange based on the Long Short-Term Memory (LSTM) and compared with ARIMA model. We use data from Bank Central Asia (BCA) from 2013-2018 obtained from Yahoo finance. In our experiments, we predict and simulate the important prices called Open, High, Low and Closing (OHLC) with various parameters. Based on the experiment, the best accurate prediction in LSTM comes from the short term (1 year) with high epoch in training phase rather than using 3 years or 5 years of training data, and our model has better result compared with popular model such as ARIMA. These results should be very useful to be used in stock exchange office. \u00a9 2018, ICIC International. All rights reserved.","Author Keywords":"ARIMA; Deep learning; Finance; Forecasting; LSTM; Stock market","Index Keywords":null,"References":"Brockwell, P.J., Davis, R.A., (2016) Introduction to Time Series and Forecasting (Springer Text in Statistics), , Springer International Publishers, Switzerland; http:\/\/www.indonesiaforeigninvestmentlaw.com\/capital-market\/indonesia-invesment-capital-market-in-indonesia\/; https:\/\/www.indonesia-investments.com\/id\/nance\/nancial-columns\/analysis-and-forecast-of-indonesias-jakarta-composite-index-ihsg\/item1278; Goodfellow, I., Bengio, Y., Courville, A., (2016) Deep Learning (Adaptive Computation and Machine Learning Series), , MIT Publisher, Cambridge, MA; Saad, E.W., Prokhorov, D.V., Wunsch, D.C., Comparative study of stock trend prediction using time delay, recurrent and probabilistic neural networks (1998) IEEE Trans. Neural Networks, 9, pp. 1456-1470; Bao, W., Yue, J., Rao, Y., A deep learning framework for financial time series using stacked autoencoders and long-short term memory (2017) Plos ONE, 12 (7), pp. 1-24; Gers, F.A., Schmidhuber, J., Cummins, F., Learning to forget: Continual prediction with LSTM (2000) Neural Computation, 12 (10), pp. 2451-2471; https:\/\/github.com\/NourozR\/Stock-Price-Prediction-LSTM; Pai, P.-F., Lin, C.-S., A hybrid ARIMA and support vector machines model in stock price fore-casting (2005) International Journal of Management Science, 33 (3), pp. 497-505; https:\/\/www.r-bloggers.com\/forecasting-stock-returns-using-arima-model\/; https:\/\/lilianweng.github.io\/lil-log\/2017\/07\/08\/predict-stock-prices-using-RNN-part-1.html; Chen, K., Zhou, Y., Dai, F., (2015) A Lstm-Based Method for Stock Returns Prediction, , A case study of China stock market, IEEE International Conference on Big Data; Cavalcante, R.C., Brasileiro, R.C., Souza, V.L.F., Nobrega, J.P., Oliveira, A.L.I., Computational intelligence and financial markets: A survey and future directions (2016) Expert Systems with Applications, 55, pp. 194-211"}
{"Authors":"Katarya R., Mahajan A.","Author(s) ID":"35810442400;57208733585;","Title":"A survey of neural network techniques in market trend analysis","Year":2018,"Source title":"Proceedings of the International Conference on Intelligent Sustainable Systems, ICISS 2017","Volume":null,"Issue":null,"Art. No.":null,"Page start":873.0,"Page end":877.0,"Page count":null,"Cited by":null,"DOI":"10.1109\/ISS1.2017.8389302","Affiliations":"Department of Information Technology, Delhi Technological University, Shahbad Daulatpur, Bawana Road, Delhi - 42, India","Document Type":"Conference Paper","Access Type":null,"Source":"Scopus","EID":"2-s2.0-85050027999","Abstract":"Realized volatility (RV) is defined as the sum of the squares of logarithmic returns on high-frequency sampling grid and aggregated over a certain time interval, typically a trading day in finance. It is not a priori clear what the aggregation period should be in case of continuously traded cryptocurrencies at online exchanges. In this work, we aggregate RV values using minute-sampled Bitcoin returns over 3-h intervals. Next, using the RV time series, we predict the future values based on the past samples using a plethora of machine learning methods, ANN (MLP, GRU, LSTM), SVM, and Ridge Regression, which are compared to the Heterogeneous Auto-Regressive Realized Volatility (HARRV) model with optimized lag parameters. It is shown that Ridge Regression performs the best, which supports the auto-regressive dynamics postulated by HARRV model. Mean Squared Error values by the neural-network based methods closely follow, whereas the SVM shows the worst performance. The present benchmarks can be used for dynamic risk hedging in algorithmic trading at cryptocurrency markets. \u00a9 2019, Springer Nature Switzerland AG.","Author Keywords":"ANN; CNN; GRU; HARRV; LSTM; MLP; Realized volatility; Ridge regression; SVM","Index Keywords":"Electronic money; Electronic trading; Learning algorithms; Learning systems; Mean square error; Regression analysis; Time series; Algorithmic trading; HARRV; High-frequency sampling; LSTM; Machine learning methods; Mean squared error; Realized volatility; Ridge regression; Long short-term memory","References":"Andersen, T.G., Bollerslev, T., Diebold, F., Labys, P., Modeling and forecasting realized volatility (2003) Econometrica, 71, pp. 579-625; Kaggle, Bitcoin Historical Data, , https:\/\/www.kaggle.com\/mczielinski\/bitcoin-historical-data, Accessed 1 Dec 2018. Released under CC BY-SA 4.0 license; Moews, B., Herrmann, J.M., Ibikunle, G., Lagged correlation-based deep learning for directional trend change prediction in financial time series (2019) Expert Syst. Appl., 120, pp. 197-206; Cao, J., Li, Z., Li, J., Financial time series forecasting model based on CEEMDAN and LSTM (2019) Phy. A: Stat. Mech. Appl., 519, pp. 127-139; Mallqui, D.C.A., Fernandes, R.A.S., Predicting the direction, maximum, minimum and closing prices of daily Bitcoin exchange rate using machine learning techniques (2019) Appl. Soft Comput., 75, pp. 596-606; Lahmiri, S., Bekiros, S., Cryptocurrency forecasting with deep learning chaotic neural networks (2019) Chaos, Solitons Fractals, 118, pp. 35-40; Nakano, M., Takahashi, A., Takahashi, S., Bitcoin technical trading with artificial neural network (2018) Phys. A: Stat. Mech. Appl., 510, pp. 587-609; Rosenblatt, F., (1961) Principles of Neurodynamics Perceptrons and the Theory of Brain Mechanisms, , Spartan Books, Washington; Lecun, Y., Back-propagation applied to handwritten zip code recognition (1989) Neural Compu, 1 (4), pp. 541-551; Hochreiter, S., Schmidhuber, J., Long short-term memory (1997) Neural Comput, 9 (8), pp. 1735-1780; Cho, K., van Merrienboer, B., Bahdanau, D., Bengio, Y., On the properties of neural machine translation: Encoder-decoder approaches (2014) 8Th Workshop on Syntax. Semantics and Structure in Statistical Translation, pp. 102-111. , pp., Association for Computational Linguistics, Doha; Vapnik, V.N., (1995) The Nature of Statistical Learning Theory, , https:\/\/doi.org\/10.1007\/978-1-4757-3264-1, Springer, Heidelberg; Hoerl, A.E., Kennard, R.W., Ridge regression: Biased estimation for nonorthogonal problems (1970) Technometrics, 12, pp. 55-67"}
{"Authors":"Zhang R., Yuan Z., Shao X.","Author(s) ID":"56402104400;57203940881;7202920566;","Title":"A New Combined CNN-RNN Model for Sector Stock Price Analysis","Year":2018,"Source title":"Proceedings - International Computer Software and Applications Conference","Volume":"2","Issue":null,"Art. No.":" 8377920","Page start":546.0,"Page end":551.0,"Page count":null,"Cited by":null,"DOI":"10.1109\/COMPSAC.2018.10292","Affiliations":"MIT Laboratory for Financial Engineering, Cambridge, MA, United States; College of Computer and Control Engineering, Nankai University, Tianjin, China","Document Type":"Conference Paper","Access Type":null,"Source":"Scopus","EID":"2-s2.0-85055477715","Abstract":"Trend change prediction in complex systems with a large number of noisy time series is a problem with many applications for real-world phenomena, with stock markets as a notoriously difficult to predict example of such systems. We approach predictions of directional trend changes via complex lagged correlations between them, excluding any information about the target series from the respective inputs to achieve predictions purely based on such correlations with other series. We propose the use of deep neural networks that employ step-wise linear regressions with exponential smoothing in the preparatory feature engineering for this task, with regression slopes as trend strength indicators for a given time interval. We apply this method to historical stock market data from 2011 to 2016 as a use case example of lagged correlations between large numbers of time series that are heavily influenced by externally arising new information as a random factor. The results demonstrate the viability of the proposed approach, with state-of-the-art accuracies and accounting for the statistical significance of the results for additional validation, as well as important implications for modern financial economics. \u00a9 2018 Elsevier Ltd","Author Keywords":"Deep learning; Lagged correlation; Stock market; Trend analysis","Index Keywords":"Commerce; Complex networks; Deep learning; Deep neural networks; Financial data processing; Financial markets; Forecasting; Time series; Change prediction; Exponential smoothing; Feature engineerings; Financial economics; Financial time series; Statistical significance; Strength indicator; Trend analysis; Real time systems","References":"Baggenstoss, P.M., Derivative-augmented features as a dynamic model for time-series (2015) Proceedings of the 23rd European signal processing conference (EUSIPCO), pp. 958-962; Batres-Estrada, B., (2015), Deep learning for multivariate financial time series. Master's thesis. KTH Royal Institute of Technology; Boyacioglu, M.A., Avci, D., An adaptive network-based fuzzy inference system (ANFIS) for the prediction of stock market return: The case of the istanbul stock exchange (2010) Expert Systems with Applications, 37 (12), pp. 7908-7912; Bradley, A.P., The use of the area under the roc curve in the evaluation of machine learning algorithms (1997) Pattern Recognition, 30 (7), pp. 1145-1159; Brown, R.G., Exponential smoothing for predicting demand (1956), Arthur D. Little Inc Cambridge, Massachusetts; Cao, L.J., Tay, F.E.H., Support vector machine with adaptive parameters in financial time series forecasting (2003) IEEE Transactions on Neural Networks and Learning Systems, 14 (6), pp. 1506-1518; Cavalcante, R.C., Brasileiro, R.C., Souza, V.L., Nobrega, J.P., Oliveira, A.L., Computational intelligence and financial markets: A survey and future directions (2016) Expert Systems with Applications, 55, pp. 194-211; Chatzis, S.P., Siakoulis, V., Petropoulos, A., Stavroulakis, E., Vlachogiannakis, N., Forecasting stock market crisis events using deep and statistical machine learning techniques (2018) Expert Systems with Applications, 112, pp. 353-371; Chen, N.-F., Roll, R., Ross, S.A., Economic forces and the stock market (1986) The Journal of Business, 59 (3), pp. 383-403; Clarke, J.P., Jandik, T., Mandelker, G., The efficient markets hypothesis (2000) Expert financial planning: Advice from industry leaders, pp. 126-141; Cootner, P., The random character of stock market prices (1964), M.I.T. Press; Darrat, A.F., Zhong, M., On testing the random-walk hypothesis: A model-comparison approach (2000) Financial Review, 35 (3), pp. 105-124; Ding, X., Zhang, Y., Liu, T., Duan, J., Deep learning for event-driven stock prediction (2015) Proceedings of the 24th international conference on artificial intelligence (IJCAI'15), pp. 2327-2333; Doran, J.S., Peterson, D.R., Wright, C., Confidence, opinions of market efficiency, and investment behavior of finance professors (2010) Journal of Financial Markets, 13 (1), pp. 174-195; Drakos, K., Terrorism-induced structural shifts in financial risk: Airline stocks in the aftermath of the September 11th terror attacks (2004) European Journal of Political Economy, 20 (2), pp. 435-446; Fama, E.F., The behaviour of stock market prices (1965) Journal of Business, 38 (1), pp. 34-105; Fama, E.F., Efficient capital markets: A review of theory and empirical work (1970) The Journal of Finance, 25 (2), pp. 383-417; Fama, E.F., French, K.R., Permanent and temporary components of stock prices (1988) Journal of Political Economy, 96 (2), pp. 246-273; Gehrig, T., Menkhoff, L., Extended evidence on the use of technical analysis in foreign exchange (2006) International Journal of Finance & Economics, 11 (4), pp. 327-338; Gen\u00e7ay, R., Sel\u00e7uk, F., Whitcher, B.J., An introduction to wavelets and other filtering methods in finance and economics (2001), 1st Amsterdam: Elsevier; Gibson, J., Segbroeck, M.V., Ortega, A., Georgiou, P.G., Narayanan, S., Spectro-temporal directional derivative features for automatic speech recognition (2013) Proceedings of the 14th annual conference of the international speech communication association (Interspeech 2013), pp. 872-875; Glorot, X., Bengio, Y., Understanding the difficulty of training deep feedforward neural networks (2010) Proceedings of the thirteenth international conference on artificial intelligence and statistics (AISTATS10), Proceedings of Machine Learning Research, 9, pp. 249-256. , Y.W. Teh M. Titterington PMLR; Grecki, T., \u0141uczak, M., Using derivatives in time series classification (2013) Data Mining and Knowledge Discovery, 26 (2), pp. 310-331; He, K., Zhang, X., Ren, S., Sun, J., Delving deep into rectifiers: Surpassing human-level performance on imagenet classification (2015) Proceedings of the 2015 IEEE international conference on computer vision (ICCV), pp. 1026-1034; Hinton, G.E., Salakhutdinov, R.R., Reducing the dimensionality of data with neural networks (2006) Science, 313 (5786), pp. 504-507; Hinton, G.E., Srivastava, N., Krizhevsky, A., Sutskever, I., Salakhutdinov, R., Improving neural networks by preventing co-adaptation of feature detectors (2012) Computing Research Repository; Ho, T.S.Y., Stoll, H.R., The dynamics of dealer markets under competition (1983) The Journal of Finance, 38 (4), pp. 1053-1074; Holt, C.C., Forecasting trends and seasonal by exponentially weighted averages (1957) Office of Naval Research memorandum, (52); Kendall, M.G., Hill, A.B., The analysis of economic time-series-part i: Prices (1953) Journal of the Royal Statistical Society. Series A (General), 116 (1), pp. 11-34; Lin, X., Yang, Z., Song, Y., Short-term stock price prediction based on echo state networks (2009) Expert Systems with Applications, 36 (1), pp. 7313-7317; Lo, A.W., The adaptive markets hypothesis: Market efficiency from an evolutionary perspective (2004) Journal of Portfolio Management, 30 (1). , 15\u20139; Lo, A.W., MacKinlay, A.C., Stock market prices do not follow random walks: Evidence from a simple specification test (1987) Working Paper, , National Bureau of Economic Research; Malagrino, L.S., Roman, N.T., Monteiro, A.M., Forecasting stock market index daily direction: A Bayesian network approach (2018) Expert Systems with Applications, 105, pp. 11-22; Malkiel, B.G., A random walk down wall street (1973), New York: W. W. Norton & Company, Inc; McGill, R., Tukey, J.W., Larsen, W.A., Variations of box plots (1978) The American Statistician, 32 (1), pp. 12-16; Menkveld, A.J., High frequency trading and the new market makers (2013) Journal of Financial Markets, 16 (4), pp. 712-740; Mierswa, I., Morik, K., Automatic feature extraction for classifying audio data (2005) Machine Learning, 58 (2), pp. 127-149; Nahmias, S., Production and operations analysis (2009), Boston and New York: McGrawHill\/Irwin Series in Operations and Decision Sciences; Najafabadi, M.M., Villanustre, F., Khoshgoftaar, T.M., Seliya, N., Muharemagic, R.W.E., Deep learning applications and challenges in big data analytics (2015) Journal of Big Data, 2 (1), pp. 1-21; Nason, G.P., von Sachs, R., Wavelets in time series analysis (1999) Catholic University of Louvain - Institute of Statistics Paper Series; Nassirtoussi, A.K., Aghabozorgi, S., Wah, T.Y., Ngo, D.C., Text mining for market prediction: A systematic review (2014) Expert Systems with Applications, 41 (16), pp. 7653-7670; Nesreen, A., Atiya, A., Gayar, N.E., El-Shishiny, H., An empricial comparison of machine learning models for time series forecasting (2010) Econometric Reviews, 29 (5-6), pp. 594-621; Ng, A., Machine learning and AI via brain simulations (2012) Lectures of the 26th annual conference on neural information processing systems (NeurIPS 2012); Perryman, A.A., Butler, F.C., Martin, J.A., Ferris, G.R., When the CEO is ill: Keeping quiet or going public? (2010) Business Horizons, 53 (1), pp. 21-29; Saad, E.W., Prokhorov, D.V., Wunsch, D.C., Comparative study of stock trend prediction using time delay, recurrent and probabilistic neural networks (1998) IEEE Transactions on Neural Networks, 9 (6), pp. 1456-1470; Seni, G., Elder, J., Ensemble methods in data mining: Improving accuracy through combining predictions (2010), Morgan & Claypool San Rafael, California; Sitte, R., Sitte, J., Neural networks approach to the random walk dilemma of financial time series (2002) Applied Intelligence, 16 (3), pp. 163-171; Skabar, A., Cloete, I., Neural networks, financial trading and the efficient markets hypothesis (2002) Proceedings of the 24th Australasian conference on computer science, pp. 241-249; Srivastava, N., Hinton, G., Krizhevsky, A., Sutskever, I., Salakhutdinov, R., Dropout: A simple way to prevent neural networks from overfitting (2014) Journal of Machine Learning Research, 15, pp. 1929-1958; Summers, L.H., Does the stock market rationally reflect fundamental values? (1986) The Journal of Finance, 41 (3), pp. 591-601; Takeuchi, L., Lee, Y., (2013), -Y. A. Applying deep learning to enhance momentum trading strategies in stocks. Working paper; Wasserstein, R.L., Lazar, N.A., The ASA's statement on p-values: Context, process, and purpose (2016) The American Statistician, 70 (2), pp. 129-133; Weng, B., Lu, L., Wang, X., Megahed, F.M., Martinez, W., Predicting short-term stock prices using ensemble methods and online data sources (2018) Expert Systems with Applications, 112, pp. 258-273; White, H., Economic prediction using neural networks: The case of IBM daily stock returns (1988) Proceedings of the IEEE 1988 International Conference On Neural Networks, 2, pp. 451-458; Zhang, G., Patuwo, B., Hu, M.Y., Forecasting with artificial neural networks: The state of the art (1997) International Journal of Forecasting, 14 (1), pp. 35-62; Zhang, G.P., Qi, M., Neural network forecasting for seasonal and trend time series (2005) European Journal of Operational Research, 160 (2), pp. 501-514; Zhang, J., Cui, S., Xu, Y., Li, Q., Li, T., A novel data-driven stock price trend prediction system (2018) Expert Systems with Applications, 97, pp. 60-69; Zhang, Y., Wu, L., Stock market prediction of S&P 500 via combination of improved bco approach and bp neural network (2009) Expert Systems with Applications, 36 (5), pp. 8849-8854"}
{"Authors":"Zhao Z., Rao R., Tu S., Shi J.","Author(s) ID":"57195064100;7403068844;57202467255;57202460505;","Title":"Time-weighted lstm model with redefined labeling for stock trend prediction","Year":2018,"Source title":"Proceedings - International Conference on Tools with Artificial Intelligence, ICTAI","Volume":"2017-November","Issue":null,"Art. No.":null,"Page start":1210.0,"Page end":1217.0,"Page count":null,"Cited by":4.0,"DOI":"10.1109\/ICTAI.2017.00184","Affiliations":"Shanghai Jiao Tong University, Shanghai, China; Shanghai Rongshi Investment Management Co Ltd, Shanghai, China","Document Type":"Conference Paper","Access Type":null,"Source":"Scopus","EID":"2-s2.0-85048469315","Abstract":"Algorithmic trading approaches based on news or social network posts claim to outperform classical methods that use only price time series and other economics values. However combining financial time series with news or posts, requires daily huge amount of relevant text which are impracticable to gather in real time, even because the online sources of news and social networks no longer allow unconditional massive download of data. These difficulties have renewed the interest in simpler methods based on financial time series. This work presents a wide experimental comparisons of the performance of 7 trading protocols applied to 27 component stocks of the Dow Jones Industrial Average (DJIA). The buy\/sell trading actions are driven by the stock value predictions performed with 3 types of neural network architectures: feed forward, recurrent and autoencoder. Each architecture types in turn has been experimented with different sizes and hyperparameters over all the multivariate time series. The combinations of trading protocols with variants of the 3 neural network types have been in turn applied to time series, varying the input variables from 4 to 17 and the training period from 8 to 16\u00a0years while the test period from 1 to 2\u00a0years. \u00a9 2019, Springer Nature Switzerland AG.","Author Keywords":"Autoencoder; Deep learning; Feed forward neural network; LSTM; Quantitative finance; Recurrent neural network; Stock market prediction; Trading","Index Keywords":"Commerce; Deep learning; Deep neural networks; Feedforward neural networks; Financial markets; Information management; Long short-term memory; Network architecture; Recurrent neural networks; Social networking (online); Time series; Auto encoders; Dow Jones Industrial averages; Experimental comparison; LSTM; Multivariate time series; Stock market prediction; Stock value prediction; Trading; Electronic trading","References":"Abe, M., Nakayama, H., (2018) Deep Learning for Forecasting Stock Returns in the Cross-Section, , arXiv preprint arXiv; Adebiyi, A.A., Adewumi, A.O., Ayo, C.K., Comparison of ARIMA and artificial neural networks models for stock price prediction (2014) J. Appl. Math., 2014, pp. 1-614342. , https:\/\/doi.org\/10.1155\/2014\/614342; Akita, R., Yoshihara, A., Matsubara, T., Uehara, K., Deep learning for stock prediction using numerical and textual information (2016) 2016 IEEE\/ACIS 15Th International Conference on Computer and Information Science (ICIS), pp. 1-6. , pp., IEEE; Atsalakis, G.S., Valavanis, K.P., Forecasting stock market short-term trends using a neuro-fuzzy based methodology (2009) Expert Syst. Appl., 36 (7), pp. 10696-10707; Atsalakis, G.S., Valavanis, K.P., Surveying stock market forecasting techniques-Part II: Soft computing methods (2009) Expert Syst. Appl., 36 (3), pp. 5932-5941; Bao, W., Yue, J., Rao, Y., A deep learning framework for financial time series using stacked autoencoders and long-short term memory (2017) PLOS One, 12 (7), pp. 1-24. , https:\/\/doi.org\/10.1371\/journal.pone.0180944; Bollen, J., Mao, H., Zeng, X., Twitter mood predicts the stock market (2011) J. Comput. Sci., 2 (1), pp. 1-8; Box, G.E.P., Jenkins, G., (1970) Time Series Analysis, , Forecasting and Control. Holden-Day, Inc., San Francisco; Cao, Q., Leggio, K.B., Schniederjans, M.J., A comparison between Fama and French\u2019s model and artificial neural networks in predicting the Chinese stock market (2005) Comput. Oper. Res., 32 (10), pp. 2499-2512; Cerroni, W., Moro, G., Pasolini, R., Ramilli, M., Decentralized detection of network attacks through P2P data clustering of SNMP data (2015) Comput. Secur., 52, pp. 1-16. , https:\/\/doi.org\/10.1016\/j.cose.2015.03.006; Cerroni, W., Moro, G., Pirini, T., Ramilli, M., Peer-to-peer data mining classifiers for decentralized detection of network attacks (2013) Proceedings of the 24Th Australasian Database Conference, ADC 2013. CRPIT, 137, pp. 101-108. , http:\/\/crpit.com\/abstracts\/CRPITV137Cerroni.html, Wang, H., Zhang, R. (eds.), vol., pp., Australian Computer Society, Inc., Darlinghurst; Cho, K., Learning phrase representations using RNN encoder-decoder for statistical machine translation Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP), pp. 1724-1734. , Association for Computational Linguistics, Doha (2014). http:\/\/www.aclweb.org\/anthology\/D14-1179; Ding, X., Zhang, Y., Liu, T., Duan, J., Deep learning for event-driven stock prediction (2015) IJCAI, pp. 2327-2333. , pp; Domeniconi, G., Masseroli, M., Moro, G., Pinoli, P., Discovering new gene functionalities from random perturbations of known gene ontological annotations (2014) KDIR 2014-Proceedings of the International Conference on Knowledge Discovery and Information Retrieval, Rome, Italy, 21\u201324 October 2014, pp. 107-116. , https:\/\/doi.org\/10.5220\/0005087801070116, SciTePress; Domeniconi, G., Masseroli, M., Moro, G., Pinoli, P., Cross-organism learning method to discover new gene functionalities (2016) Comput. Methods Programs Biomed., 126, pp. 20-34. , https:\/\/doi.org\/10.1016\/j.cmpb.2015.12.002; Domeniconi, G., Moro, G., Pagliarani, A., Pasolini, R., Cross-domain sentiment classification via polarity-driven state transitions in a Markov model (2016) IC3K 2015. CCIS, 631, pp. 118-138. , https:\/\/doi.org\/10.1007\/978-3-319-52758-1_8, Fred, A., Dietz, J.L.G., Aveiro, D., Liu, K., Filipe, J. (eds.), pp., Springer, Cham; Domeniconi, G., Moro, G., Pagliarani, A., Pasolini, R., Markov chain based method for in-domain and cross-domain sentiment classification (2015) KDIR 2015-Proceedings of the International Conference on Knowledge Discovery and Information Retrieval, Part of the 7Th International Joint Conference on Knowledge Discovery, Knowledge Engineering and Knowledge Management (IC3K 2015), Lisbon, Portugal, 1, pp. 127-137. , https:\/\/doi.org\/10.5220\/0005636001270137, SciTePress; Domeniconi, G., Moro, G., Pagliarani, A., Pasolini, R., Learning to predict the stock market Dow Jones index detecting and mining relevant tweets (2017) Proceedings of the 9Th International Joint Conference on Knowledge Discovery, Knowledge Engineering and Knowledge Management, Funchal, Madeira, Portugal, 1\u20133 November 2017, 1, pp. 165-172. , https:\/\/doi.org\/10.5220\/0006488201650172; Domeniconi, G., Moro, G., Pagliarani, A., Pasolini, R., On deep learning in cross-domain sentiment classification (2017) Proceedings of the 9Th International Joint Conference on Knowledge Discovery, Knowledge Engineering and Knowledge Management, Funchal, Madeira, Portugal, 1\u20133 November 2017, pp. 50-60. , https:\/\/doi.org\/10.5220\/0006488100500060; Domeniconi, G., Moro, G., Pasolini, R., Sartori, C., Cross-domain text classification through iterative refining of target categories representations (2014) KDIR 2014-Proceedings of the International Conference on Knowledge Discovery and Information Retrieval, Rome, Italy, 21\u201324 October 2014, pp. 31-42. , https:\/\/doi.org\/10.5220\/0005069400310042; Domeniconi, G., Moro, G., Pasolini, R., Sartori, C., Iterative refining of category profiles for nearest centroid cross-domain text classification (2015) IC3K 2014. CCIS, 553, pp. 50-67. , https:\/\/doi.org\/10.1007\/978-3-319-25840-9_4, Fred, A., Dietz, J.L.G., Aveiro, D., Liu, K., Filipe, J. (eds.), pp., Springer, Cham; Domeniconi, G., Moro, G., Pasolini, R., Sartori, C., A comparison of term weighting schemes for text classification and sentiment analysis with a supervised variant of tf.idf (2016) DATA 2015. CCIS, 584, pp. 39-58. , https:\/\/doi.org\/10.1007\/978-3-319-30162-4_4, Helfert, M., Holzinger, A., Belo, O., Francalanci, C. (eds.), vol., pp., Springer, Cham; Esteva, A., Dermatologist-level classification of skin cancer with deep neural networks (2017) Nature, 542 (7639), pp. 115-118. , https:\/\/doi.org\/10.1038\/nature21056; Fabbri, M., Moro, G., Dow Jones trading with deep learning: The unreasonable effectiveness of recurrent neural networks (2018) Proceedings of the 7Th International Conference on Data Science, Technology and Applications-Volume 1: DATA, pp. 142-153. , https:\/\/doi.org\/10.5220\/0006922101420153, pp., INSTICC, SciTePress; Fama, E.F., Efficient capital markets: A review of theory and empirical work (1970) J. Financ., 25 (2), pp. 383-417; Fischer, T., Krauss, C., Deep learning with long short-term memory networks for financial market predictions (2017) Eur. J. Oper. Res., 270, pp. 654-669; Fisher, I.E., Garnsey, M.R., Hughes, M.E., Natural language processing in accounting, auditing and finance: A synthesis of the literature with a roadmap for future research (2016) Intell. Syst. Account. Financ. Manag., 23 (3), pp. 157-214; Gers, F.A., Schmidhuber, J., Cummins, F., Learning to forget: Continual prediction with LSTM (1999) Neural Comput, 12, pp. 2451-2471; Gidofalvi, G., Elkan, C., Using news articles to predict stock price movements (2001) Department of Computer Science and Engineering, University of California, San Diego; Graves, A., (2013) Generating Sequences with Recurrent Neural Networks, , arXiv preprint arXiv; Hochreiter, S., Schmidhuber, J., Long short-term memory (1997) Neural Comput, 9 (8), pp. 1735-1780; Khashei, M., Bijari, M., Ardali, G.A.R., Improvement of auto-regressive integrated moving average models using fuzzy logic and artificial neural networks (ANNs) (2009) Neurocomputing, 72 (4-6), pp. 956-967; Khashei, M., Bijari, M., Ardali, G.A.R., Hybridization of autoregressive integrated moving average (ARIMA) with probabilistic neural networks (PNNs) (2012) Comput. Ind. Eng., 63 (1), pp. 37-45; Kingma, D.P., Ba, J., Adam: A method for stochastic optimization (2014) Corr Abs\/1412, p. 6980. , http:\/\/arxiv.org\/abs\/1412.6980; Krizhevsky, A., Sutskever, I., Hinton, G.E., ImageNet classification with deep convolutional neural networks (2012) Proceedings of the 25Th International Conference on Neural Information Processing Systems, NIPS 2012, 1, pp. 1097-1105. , http:\/\/dl.acm.org\/citation.cfm?id=2999134.2999257, pp., Curran Associates Inc., USA; Lebaron, B., Arthur, W.B., Palmer, R., Time series properties of an artificial stock market (1999) J. Econ. Dyn. Control., 23 (9-10), pp. 1487-1516; Lee, C.M., Ko, C.N., Short-term load forecasting using lifting scheme and ARIMA models (2011) Expert Syst. Appl., 38 (5), pp. 5902-5911; Di Lena, P., Domeniconi, G., Margara, L., Moro, G., GOTA: GO term annotation of biomedical literature (2015) BMC Bioinform, 16, pp. 1-346. , https:\/\/doi.org\/10.1186\/s12859-015-0777-8; Lin, M.C., Lee, A.J., Kao, R.T., Chen, K.T., Stock price movement prediction using representative prototypes of financial reports (2011) ACM Trans. Manag. Inf. Syst. (TMIS), 2 (3), p. 19; Lo, A.W., Mackinlay, A.C., Stock market prices do not follow random walks: Evidence from a simple specification test (1988) Rev. Financ. Stud., 1 (1), pp. 41-66. , https:\/\/doi.org\/10.1093\/rfs\/1.1.41; Lo, A.W., Repin, D.V., The psychophysiology of real-time financial risk processing (2002) J. Cogn. Neurosci., 14 (3), pp. 323-339; Lodi, S., Monti, G., Moro, G., Sartori, C., Peer-to-peer data clustering in self-organizing sensor networks (2009) Intelligent Techniques for Warehousing and Mining Sensor Network Data, December 2009, pp. 179-211. , http:\/\/www.igi-global.com\/chapter\/peer-peer-data-clustering-self\/39546, pp., IGI Global, Information Science Reference, Hershey; Malkiel, B.G., The efficient market hypothesis and its critics (2003) J. Econ. Perspect., 17 (1), pp. 59-82; Malkiel, B.G., (1973) A Random Walk down Wall Street, , Norton, New York; Merh, N., Saxena, V.P., Pardasani, K.R., A comparison between hybrid approaches of ann and arima for indian stock trend forecasting (2010) Bus. Intell. J., 3 (2), pp. 23-43; Mitra, S.K., Optimal combination of trading rules using neural networks (2009) Int. Bus. Res., 2 (1), p. 86; Monti, G., Moro, G., Self-organization and local learning methods for improving the applicability and efficiency of data-centric sensor networks (2009) Qshine 2009. LNIC-SSITE, 22, pp. 627-643. , https:\/\/doi.org\/10.1007\/978-3-642-10625-5_40, Bartolini, N., Nikoletseas, S., Sinha, P., Cardellini, V., Mahanti, A. (eds.), pp., Springer, Heidelberg; Moro, G., Pagliarani, A., Pasolini, R., Sartori, C., Cross-domain & in-domain sentiment analysis with memory-based deep neural networks (2018) Proceedings of the 10Th International Joint Conference on Knowledge Discovery, Knowledge Engineering and Knowledge Management-Volume 1: KDIR, pp. 127-138. , https:\/\/doi.org\/10.5220\/0007239101270138, pp., INSTICC, SciTePress; Moro, G., Pasolini, R., Domeniconi, G., Pagliarani, A., Roli, A., Prediction and trading of Dow Jones from Twitter: A boosting text mining method with relevant tweets identification (2019) IC3K 2017. CCIS, 976, pp. 26-42. , https:\/\/doi.org\/10.1007\/978-3-030-15640-4_2, Fred, A., Aveiro, D., Dietz, J.L.G., Liu, K., Bernardino, J., Salgado, A., Filipe, J. (eds.), pp., Springer, Cham; Mostafa, M.M., Forecasting stock exchange movements using neural networks: Empirical evidence from Kuwait (2010) Expert Syst. Appl., 37 (9), pp. 6302-6309; Olson, D., Mossman, C., Neural network forecasts of Canadian stock returns using accounting ratios (2003) Int. J. Forecast., 19 (3), pp. 453-465; Pagliarani, A., Moro, G., Pasolini, R., Domeniconi, G., Transfer learning in sentiment classification with deep neural networks (2019) IC3K 2017. CCIS, 976, pp. 3-25. , https:\/\/doi.org\/10.1007\/978-3-030-15640-4_1, Fred, A., Aveiro, D., Dietz, J.L.G., Liu, K., Bernardino, J., Salgado, A., Filipe, J. (eds.), pp., Springer, Cham; Schumaker, R., Chen, H., Textual analysis of stock market prediction using financial news articles (2006) AMCIS 2006 Proceedings, p. 185. , p; Schumaker, R.P., Chen, H., Textual analysis of stock market prediction using breaking financial news: The AZFin text system (2009) ACM Trans. Inf. Syst. (TOIS), 27 (2), p. 12; Soni, S., Applications of ANNs in stock market prediction: A survey (2011) Int. J. Comput. Sci. Eng. Technol., 2 (3), pp. 71-83; Srivastava, N., Mansimov, E., Salakhutdinov, R., Unsupervised learning of video representations using LSTMs (2015) Corr Abs\/1502, p. 04681. , http:\/\/arxiv.org\/abs\/1502.04681; Sterba, J., Hilovska, K., The implementation of hybrid ARIMA neural network prediction model for aggregate water consumption prediction (2010) Aplimat J. Appl. Math., 3 (3), pp. 123-131; Tetlock, P.C., Giving content to investor sentiment: The role of media in the stock market (2007) J. Financ., 62 (3), pp. 1139-1168; Wang, W., Li, Y., Huang, Y., Liu, H., Zhang, T., A method for identifying the mood states of social network users based on cyber psychometrics (2017) Future Internet, 9 (2), p. 22; (2018) Wikipedia Contributors: Financial Statement \u2013 Wikipedia, the Free Encyclopedia, , https:\/\/en.wikipedia.org\/w\/index.php?title=Financialstatement&oldid=831492885"}
{"Authors":"Tang J., Chen X.","Author(s) ID":"57204393943;35204856400;","Title":"Stock market prediction based on historic prices and news titles","Year":2018,"Source title":"ACM International Conference Proceeding Series","Volume":null,"Issue":null,"Art. No.":null,"Page start":29.0,"Page end":34.0,"Page count":null,"Cited by":null,"DOI":"10.1145\/3231884.3231887","Affiliations":"Fudan University, Shanghai, China","Document Type":"Conference Paper","Access Type":null,"Source":"Scopus","EID":"2-s2.0-85055451449","Abstract":"With technological advancements, big data can be easily generated and collected in many applications. Embedded in these big data are useful information and knowledge that can be discovered by machine learning and data mining models, techniques or algorithms. A rich source of big data is stock exchange. The ability to effectively predict future stock prices improves the economic growth and development of a country. Traditional linear approaches for prediction (e.g., Kalman filters) may not be practical in handling big data like stock prices due to highly nonlinear and chaotic nature. This lead to the exploitation of various nonlinear estimators such as the extended Kalman filters, expert systems, and various neural network architectures. Moreover, to lessen the potential shortcomings of individual algorithms, ensemble approaches have been created by averaging values across different algorithms. Existing ensemble techniques mostly basket-together a collection of sample-based algorithms that are catered to nonlinear functions. To the best of our knowledge, traditional linear estimators have not yet been incorporated into such an ensemble. Hence, in this paper, we propose a machine learning (specifically, token-based ensemble) algorithm that utilizes both linear and nonlinear estimators to predict big financial time-series data. Our ensemble consists of a traditional Kalman filter, long short-term memory (LSTM) network, and the traditional linear regression model. We also explore the adaptive properties in short-term high-risk trading in the presence of noisy data like stock prices and demonstrate the performance of our ensemble. \u00a9 2018 IEEE.","Author Keywords":"Ensemble learning; Kalman filter; Linear data; Linear regression; Long short term memory (LSTM); Nonlinear data; Stock prediction; Time-series analysis","Index Keywords":"Big data; Brain; Costs; Data mining; Economics; Electronic trading; Expert systems; Filtration; Financial markets; Forecasting; Kalman filters; Learning algorithms; Linear regression; Long short-term memory; Network architecture; Predictive analytics; Regression analysis; Time series analysis; Ensemble learning; Linear data; Linear regression models; Machine learning approaches; Nonlinear data; Stock predictions; Technological advancement; Traditional Kalman filters; Machine learning","References":"Abdullah, M.H.L.B., Ganapathy, V., Neural network ensemble for financial trend prediction (2000) Proc. Tencon, 3, pp. 157-161; Atsalakis, G.S., Valavanis, K.P., Surveying stock market forecasting techniques-Part II: Soft computing methods (2009) ESWA, 36 (3), pp. 5932-5941; Brown, J.A., A machine learning system for supporting advanced knowledge discovery from chess game data (2017) Proc. IEEE ICMLA, pp. 649-654; Brock, W., Simple technical trading rules and the stochastic properties of stock returns (1992) Journal of Finance, 47 (5), pp. 1731-1764; Brown, R.G., (1959) Statistical Forecasting for Inventory Control, , McGraw-Hill; Chalmers, G., Funk, S.H., Adjusting real-time mode transitions via genetic algorithms (2017) Proc. IEEE ICMLA, pp. 789-794; Chen, Y., Flexible neural trees ensemble for stock index modeling (2007) Neurocomputing, 70 (4-6), pp. 697-703; Delorme-Costil, A., Bezian, J.J., Forecasting domestic hot water demand in residential house using artificial neural networks (2017) Proc. IEEE ICMLA, pp. 467-472; Efficient market hypothesis (EMH) Investopedia; Faragher, R., Understanding the basis of the Kalman filter via a simple and intuitive derivation (2012) IEEE Signal Processing, 29 (5), pp. 128-132; Grewal, M.S., Kalman filtering (2011) International Encyclopedia of Statistical Science, pp. 705-708; Grewal, M.S., Andrews, A.P., Applications of kalman filtering in aerospace 1960 to the present (2010) IEEE Control Systems, 30 (3), pp. 69-78; Haleh, H., A new approach to forecasting stock price with EKF data fusion (2011) International Journal of Trade, Economics and Finance, 2 (2), pp. 109-114; Hochreiter, S., Schmidhuber, J., Long short-term memory (1997) Neural Computation, 9 (8), pp. 1735-1780; Jadid Abdulkadir, S., Hybridization of ensemble Kalman filter and non-linear auto-regressive neural network for financial forecasting (2014) Proc. MIKE 2014, pp. 72-81; Julier, S.J., Uhlmann, J.K., New extension of the Kalman filter to nonlinear systems (1997) Proc. AeroSense; Kalman, R.E., A new approach to linear filtering and prediction problems (1960) J. Basic Eng, 82 (1), pp. 35-45; Kelly, A., (1994) A 3D State Space Formulation of A Navigation Kalman Filter for Autonomous Vehicles, , Tech. report CMURI-TR-94-19; Kim, K., Financial time series forecasting using support vector machines (2003) Neurocomputing, 55 (1-2), pp. 307-319; Kuo, R.J., An intelligent stock trading decision support system through integration of genetic algorithm based fuzzy neural network and artificial neural network (2001) Fuzzy Sets and Systems, 118 (1), pp. 21-45; Liu, B., An ensembled RBF extreme learning machine to forecast road surface temperature (2017) Proc. IEEE ICMLA, pp. 977-980; Martins, L.C.B., Early prediction of college attrition using data mining (2017) Proc. IEEE ICMLA, pp. 1075-1078; Neter, J., (1996) Applied Linear Statistical Models, , 4e, McGraw-Hill; Pulido, M., Particle swarm optimization of ensemble neural networks with fuzzy aggregation for time series prediction of the Mexican stock exchange (2014) Information Sciences, 280, pp. 188-204; Tsai, C., Predicting stock returns by classifier ensembles (2011) Applied Soft Computing, 11 (2), pp. 2452-2459; White, H., Economic prediction using neural networks: The case of IBM daily stock returns (1988) Proc. IEEE ICNN; Yoo, P.D., Machine learning techniques and use of event information for stock market prediction: A survey and evaluation (2006) Proc. CIMCA-IAWTIC, 2, pp. 835-841"}
{"Authors":"Janardhanan D., Barrett E.","Author(s) ID":"57202363941;27567564400;","Title":"CPU workload forecasting of machines in data centers using LSTM recurrent neural networks and ARIMA models","Year":2018,"Source title":"2017 12th International Conference for Internet Technology and Secured Transactions, ICITST 2017","Volume":null,"Issue":null,"Art. No.":null,"Page start":55.0,"Page end":60.0,"Page count":null,"Cited by":4.0,"DOI":"10.23919\/ICITST.2017.8356346","Affiliations":"College of Engineering and Informatics, National University of Ireland, Galway, Galway City, Ireland","Document Type":"Conference Paper","Access Type":null,"Source":"Scopus","EID":"2-s2.0-85048045372","Abstract":"According to the efficient market hypothesis, financial prices are unpredictable. However, meaningful advances have been achieved on anticipating market movements using machine learning techniques. In this work, we propose a novel method to represent the input for a stock price forecaster. The forecaster is able to predict stock prices from time series and additional information from web pages. Such information is extracted as structured events and represented in a compressed concept space. By using such representation with scalable forecasters, we reduced prediction error by about 10%, when compared to the traditional auto regressive models. \u00a9 2015 ACM.","Author Keywords":"Deep learning; Natural language processing; Open information extraction; Stocks forecast","Index Keywords":"Artificial intelligence; Commerce; Costs; Forecasting; Learning algorithms; Learning systems; Natural language processing systems; Time series analysis; Websites; Auto regressive models; Concept space; Deep learning; Efficient market hypothesis; Machine learning techniques; NAtural language processing; Prediction errors; Stock forecasting; Financial markets","References":"Banko, M., Cafarella, M.J., Soderland, S., Broadhead, M., Etzioni, O., Open information extraction for the web (2007) IJCAI, 7, pp. 2670-2676; Bengio, Y., Ducharme, R., Vincent, P., Janvin, C., A neural probabilistic language model (2003) The Journal of Machine Learning Research, 3, pp. 1137-1155; Breiman, L., Random forests (2001) Machine Learning, 45 (1), pp. 5-32; Christensen, J., Soderland, S., Etzioni, O., Semantic role labeling for open information extraction (2010) Proceedings of the NAACL HLT 2010 First International Workshop on Formalisms and Methodology for Learning by Reading, pp. 52-60. , Association for Computational Linguistics; Ding, X., Zhang, Y., Liu, T., Duan, J., (2014) Using Structured Events to Predict Stock Price Movement: An Empirical Investigation; Etzioni, O., Fader, A., Christensen, J., Soderland, S., Mausam, M., Open information extraction: The second generation (2011) IJCAI, 11, pp. 3-10; Fama, E.F., The behavior of stock-market prices (1965) Journal of Business, pp. 34-105; Fu, T.-C., A review on time series data mining (2011) Engineering Applications of Artificial Intelligence, 24 (1), pp. 164-181; Hall, M., Frank, E., Holmes, G., Pfahringer, B., Reutemann, P., Witten, I.H., The weka data mining software: An update (2009) SIGKDD Explor. Newsl., 11 (1), pp. 10-18. , November; Hearst, M.A., Dumais, S.T., Osman, E., Platt, J., Scholkopf, B., Support vector machines (1998) Intelligent Systems and their Applications, 13 (4), pp. 18-28. , IEEE; Hochreiter, S., Schmidhuber, J., Long short-term memory (1997) Neural Computation, 9 (8), pp. 1735-1780; LeCun, Y., Bengio, Y., Convolutional networks for images, speech, and time series (1995) The Handbook of Brain Theory and Neural Networks, 3361 (10); Mausam, Schmitz, M., Bart, R., Soderland, S., Etzioni, O., Open language learning for information extraction (2012) Proceedings of Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning (EMNLP-CONLL); Mikolov, T., Chen, K., Corrado, G., Dean, J., (2013) Efficient Estimation of Word Representations in Vector Space, , arXiv preprint arXiv:1301.3781; Montgomery, D.C., Jennings, C.L., Kulahci, M., (2015) Introduction to Time Series Analysis and Forecasting, , John Wiley & Sons; Peng, Y., Jiang, H., (2015) Leverage Financial News to Predict Stock Price Movements Using Word Embeddings and Deep Neural Networks, , arXiv preprint arXiv:1506.07220; Williams, R.J., Zipser, D., A learning algorithm for continually running fully recurrent neural networks (1989) Neural Computation, 1 (2), pp. 270-280; Yu, S., Kak, S., (2012) A Survey of Prediction Using Social Media, , arXiv preprint arXiv:1203.1647"}
{"Authors":"Perfilieva I.","Author(s) ID":"6602820249;","Title":"Modeling with fuzzy transforms - A new tool of data mining and quantitative finance","Year":2018,"Source title":"2017 6th International Conference on Reliability, Infocom Technologies and Optimization: Trends and Future Directions, ICRITO 2017","Volume":"2018-January","Issue":null,"Art. No.":null,"Page start":16.0,"Page end":21.0,"Page count":null,"Cited by":null,"DOI":"10.1109\/ICRITO.2017.8342391","Affiliations":"Institute for Research and Applications of Fuzzy Modeling, University of Ostrava, 30. dubna 22, Ostrava 1, 701 03, Czech Republic","Document Type":"Conference Paper","Access Type":null,"Source":"Scopus","EID":"2-s2.0-85049694522","Abstract":"This paper proposes a C-RNN forecasting method for Forex time series data based on deep-Recurrent Neural Network (RNN) and deep Convolutional Neural Network (CNN), which can further improve the prediction accuracy of deep learning algorithm for the time series data of exchange rate. We fully exploit the spatio-temporal characteristics of forex time series data based on the data-driven method. On the exchange rate data of nine major foreign exchange currencies, the experimental comparison of the forecasting method shows that the C-RNN foreign exchange time series data prediction method constructed in this paper has better applicability and higher accuracy. \u00a9 2019 The Author(s).","Author Keywords":"Convolutional neural network; Deep learning; Foreign Exchange Rate; Recurrent neural network; Time series analysis","Index Keywords":"Convolution; Deep learning; Deep neural networks; Economics; Electronic trading; Finance; Forecasting; Internet of things; Learning algorithms; Recurrent neural networks; Convolutional neural network; Data-driven methods; Experimental comparison; Forecasting methods; Foreign exchange rates; Prediction accuracy; Recurrent neural network (RNN); Spatiotemporal characteristics; Time series analysis","References":"Yi, L., Location privacy leakage through sensory data (2017) Security and Communication Networks, 2017, pp. 75763071-757630712; Zhipeng, C., Xu, Z., A private and efficient mechanism for data uploading in smart cyber-physical systems (2018) IEEE Transactions on Network Science and Engineering, to Be Published; Xiang, T., Distributed deterministic broadcasting algorithms under the SINR model (2016) Proceedings INFOCOM 2016-The 35th Annual IEEE International Conference on Computer Communications, pp. 1-9; Ni, L., Resource Allocation Strategy in Fog Computing Based on Priced Timed Petri Nets (2017) IEEE Internet of Things Journal, 4 (5), pp. 1216-1228; Yu, D., Ning, L., Distributed spanner construction with physical interference: Constant stretch and linear sparse-ness (2017) IEEE\/ACM Transactions on Networking, 25 (4), pp. 2138-2151; Yu, J., Huang, B., Cheng, X., Atiquzzaman, M., Shortest link scheduling algorithms in wireless networks under the SINR model (2017) IEEE Transactions on Vehicular Technology, 66 (3), pp. 2643-2657; Zhang, J., Yuan, Y., Wang, X., RPAR: Location Privacy Preserving via Repartitioning Anonymous Region in Mobile Social Network (2018) Security and Communication Networks, pp. 68293261-682932610; Liang, Y., Deep learning based inference of private information using embedded sensors in smart devices (2018) IEEE Network, 32 (4), pp. 8-14; Zhang, L., FakeMask: A Novel Privacy Preserving Approach for Smartphones (2016) IEEE Transactions on Network and Service Management, 13 (2), pp. 335-348; Yu, J., Wan, S., Cheng, X., Yu, D., Coverage contribution area based k-coverage for wireless sensor networks (2017) Management of Environmental Quality: An International Journal, 66 (9), pp. 8510-8523; Zhang, X., Localized algorithms for Yao graph-based spanner construction in wireless networks under SINR (2017) IEEE\/ACM Transactions on Networking, 25 (4), pp. 2459-2472; Wang, G., DS-MAC: An energy efficient demand sleep mac protocol with low latency for wireless sensor networks (2015) Journal of Network and Computer Applications, 58, pp. 155-164; Yu, J., Zhang, Q., Domatic partition in homogeneous wireless sensor networks (2014) Journal of Network and Computer Applications, 37, pp. 186-193; He, Z., Latent-data privacy preserving with customized data utility for social network data (2018) IEEE Transactions on Vehicular Technology, 67 (1), pp. 665-673; Zheng, X., Data linkage in smart internet of things systems: A consideration from a privacy perspective (2018) IEEE Communications Magazine, 56 (9), pp. 55-61; Cai, Z., He, Z., Guan, X., Li, Y., Collective Data-Sanitization for Preventing Sensitive Information Inference Attacks in Social Networks (2018) IEEE Transactions on Dependable and Secure Computing, 15 (4), pp. 577-590; Ni, L., Li, C., Wang, X., DP-MCDBSCAN: Differential privacy preserving multi-core DBSCAN clustering for network user data (2018) IEEE Access, 6, pp. 21053-21063; Zheng, X., Follow but no track: Privacy preserved profile publishing in cyber-physical social systems (2017) IEEE Internet of Things Journal, 4 (6), pp. 1868-1878; He, Z., Cost-efficient strategies for restraining rumor spreading in mobile social networks (2017) IEEE Transactions on Vehicular Technology, 66 (3), pp. 2789-2800; Xu, Z., A fair mechanism for private data publication in online social networks (2018) IEEE Transactions on Network Science and Engineering, to Be Published; Moore, M., Roche, M., Less of A Puzzle: A New Look at the Forex Market (2015) Ournal of International Economics, 58 (2), pp. 387-411; Barunik, J., Kocenda, E., Vacha, L., Asymmetric volatility connectedness on the forex market (2017) KIER Working Papers, 956. , Kyoto University, Institute of Economic Research; Zheng, Y., Liu, Q., Chen, E., Time Series Classification Using Multi-Channels Deep Convolutional Neural Networks (2014) Web-Age Information Management, pp. 201-210. , Springer International Publishing 2014; Zheng, Y., Liu, Q., Chen, E., Exploiting multi-channels deep convolutional neural networks for multivariate time series classification (2016) Frontiers of Computer Science, 10 (1), pp. 96-112; Redmon, J., Divvala, S., Girshick, R., You only Look Once: Unified, Real-Time Object Detection (2016) Computer Vision and Pattern Recognition, pp. 779-788; Wei, H., A general approach based on autorreletion to determine input variables of neural networks for time series forecasting (2004) Journal of Systems Science and Complexity., 17 (3), pp. 297-305; Bengio, Y., Simard, P., Frasconi, P., Learning long-term dependencies with gradient descent is difficult (2002) IEEE Transactions on Neural Networks, 5 (2), pp. 157-166; Lecun, Y., Bengio, Y., Hinton, G., Deep learning (2015) Nature, 521 (7553), pp. 436-444; Schmidhuber, J., Deep learning in neural networks: An overview (2015) Neural Networks, 61, pp. 85-117; Rehman, M., Muhammad Khan, G., Ali Mahmud, S., Foreign Currency Exchange Rates Prediction Using CGP and Recurrent Neural Network (2014) IERI Procedia, 10, pp. 239-244; Chao, J., Zhao, J., Shen, F., Forecasting exchange rate using deep belief networks and conjugate gradient method (2015) Neurocomputing, 167 (C), pp. 243-253; Veeriah, V., Zhuang, N., Qi, G.J., Differential Recurrent Neural Networks for Action Recognition (2015) EprintArxiv, , http:\/\/arxiv.org\/abs\/1504.06678; Krizhevsky, A., Sutskever, I., Hinton, G.E., ImageNet Classification with Deep Convolutional Neural Networks (2012) Advances in Neural Information Processing Systems, 2012, pp. 1097-1105; Abdel-Hamid, O., Mohamed, A.R., Jiang, H., Convolutional Neural Networks for Speech Recognition (2014) ACM Transactions on Audio Speech & Language Processing, 22 (10), pp. 1533-1545"}
{"Authors":"Zhang Z., Shen Y., Zhang G., Song Y., Zhu Y.","Author(s) ID":"57202058986;56528648300;15077721900;57193831014;57195231359;","Title":"Short-term prediction for opening price of stock market based on self-adapting variant PSO-Elman neural network","Year":2018,"Source title":"Proceedings of the IEEE International Conference on Software Engineering and Service Sciences, ICSESS","Volume":"2017-November","Issue":null,"Art. No.":null,"Page start":225.0,"Page end":228.0,"Page count":null,"Cited by":1.0,"DOI":"10.1109\/ICSESS.2017.8342901","Affiliations":"School of Information Scienceand Engineering, Lanzhou University, Lanzhou, Gansu Province, China","Document Type":"Conference Paper","Access Type":null,"Source":"Scopus","EID":"2-s2.0-85047019329","Abstract":"This work presents a remarkable and innovative short-term forecasting method for Financial Time Series (FTS). Most of the approaches for FTS modeling work directly with prices, given the fact that transaction data is more reachable and more widely available. For this particular work, we will be using the Limit Order Book (LOB) data, which registers all trade intentions from market participants. As a result, there is more enriched data to make better predictions. We will be using Deep Convolutional Neural Networks (CNN), which are good at pattern recognition on images. In order to accomplish the proposed task we will make an image-like representation of LOB and transaction data, which will feed up into the CNN, therefore it can recognize hidden patterns to classify FTS in short-term periods. We will present step by step methodology to encode financial time series into an image-like representation. Results present an impressive performance, ranging between 63% and 66% in Directional Accuracy (DA), having advantages in reducing model parameters as well as to make inputs time invariant. \u00a9 Springer Nature Switzerland AG 2019.","Author Keywords":"Convolutional Neural Networks; Deep Learning; Limit Order Book; Pattern recognition; Short-term forecasting","Index Keywords":"Commerce; Convolution; Correlation theory; Deep learning; Deep neural networks; Financial markets; Forecasting; Neural networks; Pattern recognition; Time series; Convolutional neural network; Deep convolutional neural networks; Directional accuracy; Financial time series; Limit order book; Market participants; Short-term forecasting; Stock price prediction; Electronic trading","References":"Ar\u00e9valo, A., Nino, J., Hern\u00e1ndez, G., Sandoval, J., (2016) High-Frequency Trading Strategy Based on Deep Neural Networks, pp. 424-436. , https:\/\/doi.org\/10.1007\/978-3-319-42297-840; Arnold, L., Rebecchi, S., Chevallier, S., Paugam-Moisy, H., An introduction to deep learning (2011) ESANN, , https:\/\/www.elen.ucl.ac.be\/Proceedings\/esann\/esannpdf\/es2011-4.pdf; Chao, J., Shen, F., Zhao, J., Forecasting exchange rate with deep belief networks (2011) The 2011 International Joint Conference on Neural Networks, pp. 1259-1266. , http:\/\/ieeexplore.ieee.org\/articleDetails.jsp?arnumber=6033368, IEEE; Chen, M., Ebert, D., Hagen, H., Laramee, R.S., van Liere, R., Ma, K.L., Ribarsky, W., Silver, D., Data, information, and knowledge in visualization (2009) IEEE Comput. Graph. Appl., 29 (1), pp. 12-19; Cont, R., Stoikov, S., Talreja, R., A stochastic model for order book dynamics (2010) Oper. Res., 58, pp. 549-563; de Goijer, J., Hyndman, R., 25 years of time series forecasting (2006) J. Forecast., 22, pp. 443-473; Ding, X., Zhang, Y., Liu, T., Duan, J., Deep learning for event-driven stock prediction (2015) Proceedings of the Twenty-Fourth International Joint Conference on Artificial Intelligence (ICJAI), , http:\/\/ijcai.org\/papers15\/Papers\/IJCAI15-329.pdf; Gould, M.E.A., Limit order books (2010) Quant. Financ., 13, p. 42; Hamid, S., Habib, A., Financial forecasting with neura networks (2014) Acad. Acc. Financ. Stud. J., 18, pp. 37-56; Hinton, G.E., Osindero, S., Teh, Y.W., A fast learning algorithm for deep belief nets (2006) Neural Comput, 18 (7), pp. 1527-1554. , https:\/\/doi.org\/10.1162\/neco.2006.18.7.1527, 16764513; Huang, G.E.A., Trends in extreme learning machines: A review (2015) Neural Netw, 61, pp. 32-48; Krizhevsky, A., Sutskever, I., Hinton, G.E., Imagenet classification with deep convolutional neural networks (2012) Proceedings of the 25Th International Conference on Neural Information Processing Systems, NIPS 2012, 1, pp. 1097-1105. , http:\/\/dl.acm.org\/citation.cfm?id=2999134.2999257, Curran Associates Inc., USA; Laserson, J., From neural networks to deep learning: Zeroing in on the human brain (2011) XRDS, 18 (1), pp. 29-34. , https:\/\/doi.org\/10.1145\/2000775.2000787; Lecun, Y., Bottou, L., Bengio, Y., Haffner, P., Gradient-based learning applied to document recognition (1998) Proc. IEEE, 86 (11), pp. 2278-2324; L\u00e4ngkvist, M., Karlsson, L., Loutfi, A., A review of unsupervised feature learning and deep learning for time-series modeling (2014) Pattern Recognit. Lett., 42, pp. 11-24. , http:\/\/www.sciencedirect.com\/science\/article\/pii\/S0167865514000221; Nino, J., Hernandez, G., Price direction prediction on high frequency data using deep belief networks (2016) Applied Computer Sciences in Engineering, pp. 74-83. , Springer; Olshausen, B.A., Field, D.J., Natural image statistics and efficient coding (1996) Network Comput. Neural Syst., 7 (2), pp. 333-339. , https:\/\/doi.org\/10.1088\/0954-898X 7 2 014, 16754394; Sandoval, J., (2013) Empirical Shape Function of the Limit-Order Books of the USD\/COP Spot Market, p. 7. , https:\/\/ssrn.com\/abstract=2408087, ODEON; Sandoval, J., Nino, J., Hernandez, G., Cruz, A., Detecting informative patterns in financial market trends based on visual analysis (2016) Procedia Comput. Sci., 80, pp. 752-761. , http:\/\/www.sciencedirect.com\/science\/article\/pii\/S1877050916308407, International Conference on Computational Science 2016, ICCS 2016, 6-8 June 2016, San Diego, California, USA; Shen, F., Chao, J., Zhao, J., Forecasting exchange rate using deep belief networks and conjugate gradient method (2015) Neurocomput, 167, pp. 243-253. , https:\/\/doi.org\/10.1016\/j.neucom.2015.04.071; Takeuchi, L., Lee, Y., (2013) Applying Deep Learning to Enhance Momentum Trading Strategies in Stocks; Wang, Z., Oates, T., (2015) Encoding Time Series as Images for Visual Inspection and Classification Using Tiled Convolutional Neural Networks, , https:\/\/pdfs.semanticscholar.org\/32e7\/b2ddc781b571fa023c205753a803565543e7.pdf; Yeh, S., Wang, C., Tsai, M., (2014) Corporate Default Prediction via Deep Learning, , http:\/\/teacher.utaipei.edu.tw\/cjwang\/slides\/ISF2014.pdf"}
{"Authors":"Zhang L., Fan X., Xu C.","Author(s) ID":"57207391748;18041619200;55600419500;","Title":"A fusion financial prediction strategy based on RNN and representative pattern discovery","Year":2018,"Source title":"Parallel and Distributed Computing, Applications and Technologies, PDCAT Proceedings","Volume":"2017-December","Issue":null,"Art. No.":null,"Page start":92.0,"Page end":97.0,"Page count":null,"Cited by":null,"DOI":"10.1109\/PDCAT.2017.00024","Affiliations":"Shenzhen Institutes of Advanced Technology, Chinese Academy of Sciences, Shenzhen, China; Shenzhen College of Advanced Technology, University of Chinese Academy of Sciences, China","Document Type":"Conference Paper","Access Type":null,"Source":"Scopus","EID":"2-s2.0-85046799040","Abstract":"This work introduces how to use Limit Order Book Data (LOB) and transaction data for short-term forecasting of stock prices. LOB registers all trade intentions from market participants, as a result, it contains more market information that could enhance predictions. We will be using Deep Convolutional Neural Networks (CNN), which are good at pattern recognition on images. In order to accomplish the proposed task we will make an image-like representation of LOB and transaction data, which will feed up into the CNN, therefore it can recognize hidden patterns to classify Financial Time Series (FTS) in short-term periods. Data enclose information from 11 NYSE instruments, including stocks, ETF and ADR. We will present step by step methodology for encoding financial time series into an image-like representation. Results present an impressive performance, 74.15% in Directional Accuracy (DA). \u00a9 2018, Springer Nature Switzerland AG.","Author Keywords":"Convolutional Neural Networks; Deep Learning; Limit Order Book; Pattern recognition; Short-term forecasting","Index Keywords":"Commerce; Convolution; Correlation theory; Deep learning; Deep neural networks; Financial markets; Forecasting; Neural networks; Pattern recognition; Time series; Convolutional neural network; Deep convolutional neural networks; Directional accuracy; Financial time series; Limit order book; Market information; Market participants; Short-term forecasting; Electronic trading","References":"Ar\u00e9valo, A., Nino, J., Le\u00f3n, D., Hernandez, G., Sandoval, J., Deep learning and wavelets for high-frequency price forecasting (2018) ICCS 2018. LNCS, 10861, pp. 385-399. , Shi, Y., et al. (eds.), Springer, Cham, https:\/\/doi.org\/10.1007\/978-3-319-93701-4 29; Ar\u00e9valo, A., Ni\u00f1o, J., Hern\u00e1ndez, G., Sandoval, J., High-frequency trading strategy based on deep neural networks (2016) ICIC 2016. LNCS (LNAI), 9773, pp. 424-436. , Huang, D.-S., Han, K., Hussain, A. (eds.), Springer, Cham, https:\/\/doi.org\/10.1007\/978-3-319-42297-840; Arnold, L., Rebecchi, S., Chevallier, S., Paugam-Moisy, H., (2011) An Introduction to Deep Learning, , https:\/\/www.elen.ucl.ac.be\/Proceedings\/esann\/esannpdf\/es2011-4.pdf, ESANN; Chao, J., Shen, F., Zhao, J., Forecasting exchange rate with deep belief networks The 2011 International Joint Conference on Neural Networks, pp. 1259-1266. , IEEE, July 2011. http:\/\/ieeexplore.ieee.org\/articleDetails.jsp? arnumber=6033368ieeexplore.ieee.org\/xpls\/abs all.jsp?arnumber=6033368; Chen, M., Data, information, and knowledge in visualization (2009) IEEE Comput. Graph. Appl., 29 (1), pp. 12-19; Cont, R., Stoikov, S., Talreja, R., A stochastic model for order book dynamics (2010) Oper. Res., 58, pp. 549-563; de Goijer, J., Hyndman, R., 25 years of time series forecasting (2006) J. Forecast., 22, pp. 443-473; Ding, X., Zhang, Y., Liu, T., Duan, J., Deep learning for event-driven stock prediction (2015) Proceedings of the Twenty-Fourth International Joint Conference on Artificial Intelligence (ICJAI), , http:\/\/ijcai.org\/papers15\/Papers\/IJCAI15-329.pdf; Gould, M.D., Porter, M.A., Williams, S., McDonald, M., Fenn, D.J., Howison, S.D., Limit order books (2010) Quant. Finance, 13, p. 42; Hamid, S., Habib, A., Financial forecasting with neura networks (2014) Acad. Account. Financ. Stud. J., 18, pp. 37-56; Huang, G., Huang, G.B., Song, S., You, K., Trends in extreme learning machines: A review (2015) Neural Netw, 61, pp. 32-48; L\u00e4ngkvist, M., Karlsson, L., Loutfi, A., A review of unsupervised feature learning and deep learning for time-series modeling (2014) Pattern Recognit. Lett., 42, pp. 11-24. , http:\/\/www.sciencedirect.com\/science\/article\/pii\/S0167865514000221; Ni\u00f1o-Pe\u00f1a, J.H., Hern\u00e1ndez-P\u00e9rez, G.J., Price direction prediction on high frequency data using deep belief networks (2016) WEA 2016. CCIS, 657, pp. 74-83. , https:\/\/doi.org\/10.1007\/978-3-319-50880-1 7, Figueroa-Garc\u00eda, J.C., L\u00f3pez-Santana, E.R., Ferro-Escobar, R. (eds.), Springer, Cham; Sandoval, J., (2013) Empirical Shape Function of the Limit-Order Books of the USD\/COP Spot Market, , https:\/\/ssrn.com\/abstract=2408087, ODEON, no. 7; Sandoval, J., Nino, J., Hernandez, G., Cruz, A., Detecting informative patterns in financial market trends based on visual analysis (2016) Procedia Comput. Sci., 80, pp. 752-761. , http:\/\/www.sciencedirect.com\/science\/article\/pii\/S1877050916308407. International Conference on Computational Science 2016, ICCS 2016, 6\u20138 June 2016, San Diego, California, USA; Shen, F., Chao, J., Zhao, J., Forecasting exchange rate using deep belief networks and conjugate gradient method (2015) Neurocomput., 167 (C), pp. 243-253. , https:\/\/doi.org\/10.1016\/j.neucom.2015.04.071; Takeuchi, L., Lee, Y., (2013) Applying Deep Learning to Enhance Momentum Trading Strategies in Stocks; Wang, Z., Oates, T., (2015) Encoding Time Series as Images for Visual Inspection and Classification Using Tiled Convolutional Neural Networks, , https:\/\/pdfs. semanticscholar.org\/32e7\/b2ddc781b571fa023c205753a803565543e7.pdf; Yeh, S., Wang, C., Tsai, M., (2014) Corporate Default Prediction via Deep Learning, , http:\/\/teacher.utaipei.edu.tw\/"}
{"Authors":"Dong Y., Wang J., Guo Z.","Author(s) ID":"57194399361;56380147600;37002500800;","Title":"Research and application of local perceptron neural network in highway rectifier for time series forecasting","Year":2018,"Source title":"Applied Soft Computing Journal","Volume":"64","Issue":null,"Art. No.":null,"Page start":656.0,"Page end":673.0,"Page count":null,"Cited by":4.0,"DOI":"10.1016\/j.asoc.2017.12.022","Affiliations":"School of Mathematics and Statistics, Lanzhou University, Gansu, China; School of Statistics, Dongbei University of Finance and Economics, Dalian, 116025, China; State Key Laboratory of Numerical Modeling for Atmospheric Sciences and Geophysical Fluid Dynamics, Institute of Atmospheric Physics, Chinese Academy of Sciences, Beijing, 10029, China","Document Type":"Article","Access Type":null,"Source":"Scopus","EID":"2-s2.0-85040316827","Abstract":"We propose a wavelet neural network (neuro-wavelet) model for the short-term forecast of stock returns from high-frequency financial data. The proposed hybrid model combines the capability of wavelets and neural networks to capture non-stationary nonlinear attributes embedded in financial time series. A comparison study was performed on the predictive power of two econometric models and four recurrent neural network topologies. Several statistical measures were applied to the predictions and standard errors to evaluate the performance of all models. A Jordan net that used as input the coefficients resulting from a non-decimated wavelet-based multi-resolution decomposition of an exogenous signal showed a consistent superior forecasting performance. Reasonable forecasting accuracy for the one-, three- and five step-ahead horizons was achieved by the proposed model. The procedure used to build the neuro-wavelet model is reusable and can be applied to any high-frequency financial series to specify the model characteristics associated with that particular series. Copyright \u00a9 2013 John Wiley & Sons, Ltd. Copyright \u00a9 2013 John Wiley & Sons, Ltd.","Author Keywords":"high-frequency financial data; neuro-wavelets; recurrent neural networks; time series forecasting; wavelet multi-resolution decomposition","Index Keywords":null,"References":"Bjorn, V., Multiresolution methods for financial time series prediction (1995) Proceedings of the IEEE\/IAFE 1995 Conference on Computational Intelligence for Financial Engineering; Chenoweth, T., Obradovic, Z., A multicomponent nonlinear prediction system for the S&P 500 Index (1996) Neurocomputing, 10 (3), pp. 275-290; Dremin, I.M., Leonidov, A.V., Volatility dynamics of wavelet-filtered stock prices (2008) Bulletin of the Lebedev Physics Institute, 35 (1), pp. 1-5; Elman, J.L., Finding structure in time (1990) Cognitive Science, 14, pp. 179-211; Franses, P.H., Haldrup, N., The effects of additive outliers on test for unit root and cointegration (1994) Journal of Business and Economics, 12 (4), pp. 471-478; Garcia, R., Gencay, R., Pricing and hedging derivative securities with neural networks and homogeneity hint (2000) Journal of Econometrics, 94, pp. 93-115; Gencay, R., Optimization of technical trading strategies and the profitability in security markets (1998) Economic Letters, 59, pp. 249-254; Gencay, R., Liu, T., Nonlinear modeling and prediction with feed-forward and recurrent networks (1997) Physica D, 108, pp. 119-134; Gencay, R., Stengos, T., Moving average rules, volume and the predictability of security returns with feedforward networks (1998) Journal of Forecasting, 17, pp. 401-414; Gencay, R., Selcuk, F., Whitcher, B., (2002) An Introduction to Wavelets and Other Filtering Methods in Finance and Economics, , Academic Press: San Diego, CA; Gencay, R., Gradojevic, N., Seluk, F., Whitcher, B., Asymmetry of information flow between volatilities across time scales (2010) Quantitative Finance, 10 (8), pp. 895-915; Hogan, S., Jarrow, R., Teo, M., Warachkat, M., Testing market efficiency using statistical arbitrage with applications to momentum and value strategies (2004) Journal of Financial Economics, 73 (3), pp. 525-565; Jordan, M.I., (1986) Serial Order: A Parallel Distributed Processing, , Institute for Cognitive Science Report 8604, University of California San Diego; Maharaj, E., Alonso, A., Discrimination of locally stationary time series using wavelets (2007) Computational Statistics and Data Analysis, 52, pp. 879-895; McNelis, P.D., (2005) Neural Networks in Finance, , Elsevier Academic Press: Burlington, MA; Minerva, T., Wavelet filtering for prediction in time series analysis (2010) WAMUS'10: Proceedings of the 10th WSEAS International Conference on Wavelet Analysis and Multirate Systems, pp. 89-94. , In; Minu, K.K., Lineesh, M.C., Jessy, J.C., Wavelet neural networks for nonlinear time series analysis (2010) Applied Mathematical Sciences, 4 (50), pp. 2485-2595; Misiti, M., Misiti, Y., Oppenheim, G., Poggi, J.M., (2007) Wavelets and Their Application, , Wiley-ISTE Publishing: London; Murtagh, F., Starck, J.L., Renaud, O., On neuro-wavelet modeling (2004) Decision Support Systems, 37, pp. 475-484; Odgen, R.T., (1997) Essential Wavelets for Statistical Applications and Analysis, , Birkhauser: Boston, MA; Percival, D.B., Walden, A.T., (2006) Wavelet Methods for Time Series Analysis, , Cambridge University Press: Cambridge, UK; Renaud, O., Stark, J.L., Murtagh, F., Prediction based on a multiscale decomposition (2003) International Journal of Wavelets, Multiresolution and Information Processing, 1 (2), pp. 217-232; Soltani, S., Boichu, D., Simard, P., Canu, S., The long-term memory prediction by multiscale decomposition (2000) Signal Processing, 80 (10), pp. 2195-2205; Zekic, M., Neural network applications in stock market predictions: A methodology analysis (1998) Proceedings of the 9th International Conference on Information and Intelligent Systems '98, pp. 255-263. , In, Aurer B. Logo\u017ear R. (eds). Vara\u017edin; Zhang, G., Patuwo, B.E., Hu, M.Y., Forecasting with artificial neural networks: The state of the art (1998) International Journal of Forecasting, 14, pp. 35-62; Zhang, Q., Benveniste, A., Wavelet networks (1992) IEEE Transactions on Neural Networks, 3 (6), pp. 889-898; Zheng, G., Starck, J.L., Campbell, J.G., Murtagh, F., Multiscale transforms for filtering financial data streams (1999) Journal of Computational Intelligence in Finance, 7, pp. 18-35"}
{"Authors":"Samarawickrama A.J.P., Fernando T.G.I.","Author(s) ID":"57203114328;7004517726;","Title":"A recurrent neural network approach in predicting daily stock prices an application to the Sri Lankan stock market","Year":2018,"Source title":"2017 IEEE International Conference on Industrial and Information Systems, ICIIS 2017 - Proceedings","Volume":"2018-January","Issue":null,"Art. No.":null,"Page start":1.0,"Page end":6.0,"Page count":null,"Cited by":6.0,"DOI":"10.1109\/ICIINFS.2017.8300345","Affiliations":"Department of Computer Science, Faculty of Applied Sciences, University of Sri Jayewardenepura, Nugegoda, Sri Lanka","Document Type":"Conference Paper","Access Type":null,"Source":"Scopus","EID":"2-s2.0-85050024627","Abstract":"We propose a wavelet neural network model (neuro-wavelet) for the short-term forecast of stock returns from high-frequency financial data. The proposed hybrid model combines the inherent capability of wavelets and artificial neural networks to capture non-stationary and non-linear attributes embedded in financial time series. A comparison study was performed on the modeling and predictive power among two traditional econometric models and four different dynamic recurrent neural network architectures. Several statistical measures and tests were performed on the forecasting estimates and standard errors to evaluate the predictive performance of all models. A Jordan net which used as input to the neural network the coefficients resulting from a non-decimated Haar wavelet-based decomposition of the high and low stock prices showed consistently to have a superior modeling and predictive performance over the other models. Reasonable forecasting accuracy for one, three, and five step-ahead horizons was achieved by the Jordan neuro-wavelet model. \u00a9 2012 Newswood Limited. All rights reserved.","Author Keywords":"Dynamic neural networks; Neuro-wavelets; Time series forecasting; Wavelet decomposition","Index Keywords":"Control equipment; Electronic trading; Financial markets; Forecasting; Investments; Network architecture; Recurrent neural networks; Time series; Dynamic neural networks; Dynamic recurrent neural networks; Financial time series; Forecasting accuracy; Neuro-wavelets; Predictive performance; Time series forecasting; Wavelet neural network model; Wavelet decomposition","References":"Bjorn, V., Multiresolution methods: For: Financial time series prediction Proc. of the IEEE\/IAFE 1995 Conf. on Computational Intelligence: For Financial Engineering; Chenoweth, T., Obradovic, Z., A multicomponent nonlinear prediction system: For the S&P 500 Index (1996) Neurocomputing, 10 (3), pp. 275-290; Dremin, I.M., Leonidov, A.V., Volatility dynamics of wavelet-: Filtered stock prices (2008) Bulletin of the Lebedev Physics Institute, 35 (1), pp. 1-5; Franses, P.H., Haldrup, N., The effects of additive outliers on test: For unit root and cointegration (1994) J. of Business & Economics, 12 (4), p. 471; Gencay, R., Selcuk, F., Whitcher, B., (2002) An Introduction to Wavelets and other Filtering Methods in Finance and Economics, , San Diego, CA: Academic Press; McNelis, P.D., (2005) Neural Networks in Finance, , Burlington, MA: Elsevier Academic Press; Minu, K.K., Lineesh, M.C., John, C.J., Wavelet neural networks: For nonlinear time series analysis (2010) Applied Mathematical Sciences, 4 (50), pp. 2485-2595; Misiti, M., Misiti, Y., Oppenheim, G., Poggi, J.M., (2007) Wavelets and their Application, , London, UK: Wiley-ISTE Publishing; Murtagh, F., Starck, J.L., Renaud, O., On neuro-wavelet modeling (2004) Decision Support Systems, 37, pp. 475-484; Odgen, R.T., (1997) Essential Wavelets: For Statistical Applications and Analysis, , Boston, MA: Birkhauser; Percival, D.B., Walden, A.T., (2006) Wavelet Methods: For Time Series Analysis, , Cambridge University Press; Renaud, O., Stark, J.L., Murtagh, F., Prediction based on a multiscale decomposition (2003) Int. J. of Wavelets, Multiresolution and Information Processing, 1 (2), pp. 217-232; Soltani, S., Boichu, D., Simard, P., Canu, S., The long-term memory prediction by multiscale decomposition (2000) Signal Processing, 80 (10), pp. 2195-2205; Zekic, M., Neural network applications in stock market predictions - A methodology analysis (1998) Proc. of the 9th Int. Conf. on Information and Intelligent Systems '98, pp. 255-263; Zhang, G., Patuwo, B.E., Hu, M.Y., Forecasting with artificial neural networks: The state of the art (1998) International Journal of Forecasting, 14, pp. 35-62; Zhang, Q., Benveniste, A., Wavelet networks (1992) IEEE Transactions on Neural Networks, 3 (6), pp. 889-898; Zheng, G., Starck, J.L., Campbell, J.G., Murtagh, F., Multiscale transforms: For: Filtering: Financial data streams (1999) Journal of Computational Intelligence in Finance, 7, pp. 18-35"}
{"Authors":"Li W., Liao J.","Author(s) ID":"56177322400;57201553186;","Title":"A comparative study on trend forecasting approach for stock price time series","Year":2018,"Source title":"Proceedings of the International Conference on Anti-Counterfeiting, Security and Identification, ASID","Volume":"2017-October","Issue":null,"Art. No.":null,"Page start":74.0,"Page end":78.0,"Page count":null,"Cited by":null,"DOI":"10.1109\/ICASID.2017.8285747","Affiliations":"China Tobacco ZheJiang Industrial CO. LTD, Hangzhou, 310000, China; School of Computer Science Fudan University, Shanghai, 200433, China","Document Type":"Conference Paper","Access Type":null,"Source":"Scopus","EID":"2-s2.0-85045276426","Abstract":"Forecasting time series has several applications in various domains. The vast amount of data that are available nowadays provide the opportunity to use powerful deep learning approaches, but at the same time pose significant challenges of high-dimensionality, velocity and variety. In this paper, a novel logistic formulation of the well-known Bag-of-Features model is proposed to tackle these challenges. The proposed method is combined with deep convolutional feature extractors and is capable of accurately modeling the temporal behavior of time series, forming powerful forecasting models that can be trained in an end-to-end fashion. The proposed method was extensively evaluated using a large-scale financial time series dataset, that consists of more than 4 million limit orders, outperforming other competitive methods. \u00a9 2019 IEEE.","Author Keywords":"Limit Order Book; Temporal Bag-of-Features; Time series forecasting","Index Keywords":null,"References":"Cao, L., Eng Hock Tay, F., Support vector machine with adaptive parameters in financial time series forecasting (2003) IEEE Transactions on Neural Networks, 14 (6), pp. 1506-1518; Steinherz Hippert, H., Eduardo Pedreira, C., Castro Souza, R., Neural networks for shortterm load forecasting: A review and evaluation (2001) IEEE Transactions on Power Systems, 16 (1), pp. 44-55; Xi, X., Keogh, E., Shelton, C., Wei, L., Ann Ratanamahatana, C., Fast time series classification using numerosity reduction (2006) Proceedings of the International Conference on Machine Learning, pp. 1033-1040; Lipton, Z.C., Kale, D.C., Elkan, C., Wetzell, R., (2015) Learning to Diagnose with Lstm Recurrent Neural Networks, , preprint 1511. 03677; Cui, Z., Chen, W., Chen, Y., (2016) Multiscale Convolutional Neural Networks for Time Series Classification, , preprint arXiv:1603. 06995; Gokce Baydogan, M., Runger, G., Tuv, E., A bag-of-features framework to classify time series (2013) IEEE Transactions on Pattern Analysis and Machine Intelligence, 35 (11), pp. 2796-2802; Bailly, A., Malinowski, S., Tavenard, R., Guyet, T., Chapel, L., Bag-oftemporal-sift-words for time series classification (2015) ECML\/PKDD Workshop on Advanced Analytics and Learning on Temporal Data; Passalis, N., Tefas, A., Kanniainen, J., Gabbouj, M., Iosifidis, A., Temporal bag-of-features learning for predicting mid price movements using high frequency limit order book data (2018) IEEE Transactions on Emerging Topics in Computational Intelligence; Passalis, N., Tefas, A., Learning bagof-features pooling for deep convolutional neural networks (2017) Proceedings of the IEEE International Conference on Computer Vision; Passalis, N., Tefas, A., Training lightweight deep convolutional neural networks using bag-of-features pooling (2018) IEEE Transactions on Neural Networks and Learning Systems; Sivic, J., Zisserman, A., Video google: A text retrieval approach to object matching in videos (2003) Proceedings of the IEEE International Conference on Computer Vision, 2, pp. 1470-1477; Iosifidis, A., Tefas, A., Pitas, I., Multidimensional sequence classification based on fuzzy distances and discriminant analysis (2013) IEEE Transactions on Knowledge and Data Engineering, 25 (11), pp. 2564-2575; Passalis, N., Tefas, A., Entropy optimized feature-based bag-of-words representation for information retrieval (2016) IEEE Transactions on Knowledge and Data Engineering, 28 (7), pp. 1664-1677; Passalis, N., Tsantekidis, A., Tefas, A., Kanniainen, J., Gabbouj, M., Iosifidis, A., Time-series classification using neural bag-of-features (2017) Proceedings of the European Signal Processing Conference, pp. 301-305; Kercheval, A.N., Zhang, Y., Modelling highfrequency limit order book dynamics with support vector machines (2015) Quantitative Finance, 15 (8), pp. 1315-1329; Passalis, N., Tefas, A., Concept detection and face pose estimation using lightweight convolutional neural networks for steering drone video shooting (2017) Proceedings of the European Signal Processing Conference, pp. 71-75; Glorot, X., Bengio, Y., Understanding the difficulty of training deep feedforward neural networks (2010) Proceedings of the International Conference on Artificial Intelligence and Statistics, pp. 249-256; Kingma, D.P., Ba, J., Adam: A method for stochastic optimization (2015) Proceedings of the International Conference on Learning Representations; Thanh Tran, D., Magris, M., Kanniainen, J., Gabbouj, M., Iosifidis, A., Tensor representation in high-frequency financial data for price change prediction (2017) Proceedings of the IEEE Symposium Series on Computational Intelligence, pp. 1-7; Ntakaris, A., Kanniainen, J., Gabbouj, M., Iosifidis, A., Mid-price prediction based on machine learning methods with technical and quantitative indicators (2018) SSRN; Tomasini, E., Jaekle, U., (2011) Trading Systems, , Harriman House Limited"}
{"Authors":"Ugur Gudelek M., Arda Boluk S., Murat Ozbayoglu A.","Author(s) ID":"57201792615;57201796716;57200377068;","Title":"A deep learning based stock trading model with 2-D CNN trend detection","Year":2018,"Source title":"2017 IEEE Symposium Series on Computational Intelligence, SSCI 2017 - Proceedings","Volume":"2018-January","Issue":null,"Art. No.":null,"Page start":1.0,"Page end":8.0,"Page count":null,"Cited by":2.0,"DOI":"10.1109\/SSCI.2017.8285188","Affiliations":"TOBB University of Economics and Technology, Department of Computer Engineering, Ankara, Turkey","Document Type":"Conference Paper","Access Type":null,"Source":"Scopus","EID":"2-s2.0-85046136407","Abstract":"Financial Analysis has become a challenging aspect in today\u2019s world of valuable and better investment. This paper introduces the implementation of Recurrent Neural Network (RNN) along with Long Short-Term Memory Cells (LSTM) for Stock Market Prediction used for Portfolio Management considering the Time Series Historical Stock Data of Stocks in the Portfolio. The comparison of the model with the traditional Machine Learning Algorithms\u2014Regression, Support Vector Machine, Random Forest, Feed Forward Neural Network and Backpropagation have been performed. Various metrics and architectures of LSTM RNN model have been considered and are tested and analysed. There is discussion on how the sentiments of the customer would affect the stocks along with the changes in trends. \u00a9 2019, Springer Nature Singapore Pte Ltd.","Author Keywords":"Long short-term memory; Portfolio optimization; Recurrent neural network; Trading","Index Keywords":"Backpropagation algorithms; Brain; Commerce; Decision trees; Electronic trading; Financial markets; Information management; Investments; Learning algorithms; Recurrent neural networks; Financial analysis; Portfolio managements; Portfolio optimization; Recurrent neural network (RNN); Short term memory; Stock market prediction; Stock market prices; Trading; Long short-term memory","References":"Li, R., Fu, D., Zheng, Z., An Analysis of the Correlation between Internet Public Opinion and Stock Market (2017) 2017 4Th International Conference on Information Science and Control Engineering (ICISCE), pp. 150-153. , (pp., IEEE; Tiwari, V., Gupta, S., Tiwari, V., Association rule mining: A graph based approach for mining frequent itemsets (2010) International Conference of Networking and Information Technology (ICNIT), pp. 309-313. , (pp., IEEE; Kunal, S., Saha, A., Varma, A., Tiwari, V., Textual Dissection of Live Twitter Reviews using Naive Bayes (2018) Procedia Computer Science, 132, pp. 307-313. , Elsevier; Khaidem, L., Saha, S., Dey, S.R., (2016) Predicting the Direction of Stock Market Prices Using Random Forest, , arXiv preprint arXiv; Al-Nasseri, A., Ali, F.M., What does investors' online divergence of opinion tell us about stock returns and trading volume? (2018) Journal of Business Research, 86, pp. 166-178; Lin, Y., Guo, H., Hu, J., An SVM-based approach for stock market trend prediction (2013) The 2013 International Joint Conference On, pp. 1-7. , Neural Networks (IJCNN), (pp., IEEE; Gupta, A., Dhingra, B., Stock market prediction using hidden markov models (2012) Engineering and Systems (SCES), 2012 Students Conference On, pp. 1-4. , (pp., IEEE; Bhuriya, D., Kaushal, G., Sharma, A., Singh, U., Stock market prediction using linear regression (2017) International Conference of Electronics, Communication and Aerospace Technology (ICECA), , Coimbatore, India. IEEE; Yang, J., Rao, R., Hong, P., Ding, P., Ensemble model for stock price movement trend prediction on different investing periods (2016) Computational Intelligence and Security (CIS), 2016 12Th International Conference, pp. 358-361. , IEEE; Labiad, B., Berrado, A., Benabbou, L., Machine learning techniques for short term stock movements classification for Moroccan stock exchange (2016) Intelligent Systems: Theories and Applications (SITA), 2016 11Th International Conference, pp. 1-6. , IEEE; Mingyue, Q., Cheng, L., Yu, S., Application of the Artifical Neural Network in predicting the direction of stock market index (2016) 2016 10Th International Conference on Complex, Intelligent, and Software Intensive Systems (CISIS), pp. 219-223. , IEEE; Mithani, F., Machchhar, S., Jasdanwala, F., A modified bpn approach for stock market prediction (2016) Computational Intelligence and Computing Research (ICCIC), pp. 1-4. , 2016IEEE International Conference; Sharma, A., Bhuriya, D., Singh, U., Survey of stock market prediction using machine learning approach (2017) International Conference of Electronics, Communication and Aerospace Technology (ICECA), , Coimbatore, India. IEEE; George, S., Changat, M., Network approach for stock market data mining and portfolio analysis (2017) Networks & Advances in Computational Technologies (Netact, pp. 251-256. , 2017 International Conference on (pp., IEEE; Dewan, A., Sharma, M., Prediction of heart disease using a hybrid technique in data mining classification (2015) Computing for Sustainable Global Development (Indiacom), 2015 2Nd International Conference On, pp. 704-706. , (pp., IEEE; Sak, H., Senior, A., Beaufays, F., Long short-term memory recurrent neural network architectures for large scale acoustic modeling (2014) Fifteenth Annual Conference of the International, , speech communication association; Heaton, J., Polson, N., Witte, J., Deep learning for finance: deep portfolios (2017) Applied Stochastic Models in Business and Industry, (1), p. 33; Mrcela, L., Mercep, A., Begusic, S., Kostanjcar, Z., Portfolio optimization using preference relation based on statistical arbitrage (2017) Smart Systems and Technologies (SST, pp. 161-165. , 2017 International Conference on (pp., IEEE; Fang, J., Xiaoyun, M., Dynamic Multi-Mode Portfolio Optimization Strategy for Markovian Arrival Process (2017) Robots & Intelligent System (ICRIS, pp. 139-142. , 2017 International Conference on (pp., IEEE; Das, S., Goyal, M., Rebalancing a two-asset Markowitz portfolio: A fundamental analysis (2012) Computational Intelligence for Financial Engineering & Economics (CIFE), 2012 IEEE Conference, pp. 1-8. , IEEE; Yang, Y., Hasuike, T., Construction of Investor Sentiment Index in the Chinese Stock Market (2017) Advanced Applied Informatics (IIAI\u2013AAI), 2017 6Th IIAI International Congress On, pp. 23-28. , (pp., IEEE"}
{"Authors":"Yin Q., Zhang R., Liu Y., Shao X.","Author(s) ID":"57201996015;56402104400;57201990786;7202920566;","Title":"Forecasting of stock price trend based on CART and similar stock","Year":2018,"Source title":"2017 4th International Conference on Systems and Informatics, ICSAI 2017","Volume":"2018-January","Issue":null,"Art. No.":null,"Page start":1503.0,"Page end":1508.0,"Page count":null,"Cited by":null,"DOI":"10.1109\/ICSAI.2017.8248523","Affiliations":"College of Computer and Control Engineering., Nankai University, Tianjin, China; Laboratory for Financial Engineering, Massachusetts Institute of Technology, Cambridge, MA, United States; Fu Foundation School of Engineering and Applied Science, Columbia University, New York, NY, United States","Document Type":"Conference Paper","Access Type":null,"Source":"Scopus","EID":"2-s2.0-85046676132","Abstract":"Financial time series forecasting is considered to be one of the most challenging areas in current time series analysis theory. This complexity is caused mainly by the multitude of factors that influence the series and the volatility of this factors, which means that predicting models must adapt to a wide range of circumstances. Yet, the possibility of great financial return makes it a field of great interest for many researchers. Recently, non-linear techniques have been widely used for the construction of forecasting models, due to its ability to access higher order statistics. In particular, neural networks have shown to greatly enhance classical predicting models, and over the past years Deep Learning techniques are on the rise since computational power and data availability are becoming less of a constraint. This paper aims to compare the use of deep learning methods over shallow neural networks when predicting next day closing prices of stocks traded in the Brazilian financial market. Moreover, simulations using recent historical data are performed so that the models' profitability can be assessed and compared with the well-known strategy of Buy and Hold. \u00a9 2018 IEEE.","Author Keywords":null,"Index Keywords":"Commerce; Deep learning; Electronic trading; Finance; Forecasting; Higher order statistics; Computational power; Data availability; Financial returns; Financial time series forecasting; Forecasting models; Learning techniques; Non-linear methods; Nonlinear techniques; Time series analysis","References":"Kim, K., Kaljuvee, J., Chapter 1-overview of electronic and algorithmic trading (2007) Electronic and Algorithmic Trading Technology, Ser. Complete Technology Guides for Financial Services, pp. 1-14. , K. Kim and J. Kaljuvee, Eds. Boston: Academic Press; Atsalakis, G.S., Valavanis, K.P., Surveying stock market forecasting techniques part II: Soft computing methods (2009) Expert Systems with Applications, 36 (3), pp. 5932-5941; Aggarwal, R., Inclan, C., Leal, R., Volatility in emerging stock markets (1999) The Journal of Financial and Quantitative Analysis, 34 (3), pp. 33-55; Fama, E.F., The behaviour of stock market prices (1965) Journal of Business, pp. 34-105; Granger, C.W., Forecasting stock market prices: Lessons for forecasters (1992) International Journal of Forecasting, 8, pp. 3-13; Chaboud, A.P., Chiquoine, B., Hjalmarsson, E., Vega, C., Rise of the machines: Algorithmic trading in the foreign exchange market (2014) The Journal of Finance, 69 (5), pp. 2045-2084. , http:\/\/dx.doi.org\/10.1111\/jofi.12186; Bostrom, N., (2014) Superintelligence: Paths, Dangers, Strategy, , Oxford: Oxford University Press; Nayak, R.K., Mishra, D., Rath, A.K., A nave SVM-knn based stock market trend reversal analysis for indian benchmark indices (2015) Appl. Soft Comput., 35 (C), pp. 670-680. , oct; Weng, B., Ahmed, M.A., Megahed, F.M., Stock market oneday ahead movement prediction using disparate data sources (2017) Expert Systems with Applications, 79, pp. 153-163; Pommeranzenbaum, I.R., (2014) Redes Neurais Artificiais Na Predi\u00e7 \u00e3o das Principais S\u00e9ries Do \u00edndice Ibovespa e Suas Aplica\u00e7 \u00f5es em Sistemas Automatizados de Negocia\u00e7 \u00e3o, , Master's thesis, Instituto Alberto Luiz Coimbra de P\u00f3s-Gradua\u00e7 \u00e3o e Pesquisa de Engenharia-UFRJ, Mar; Giacomel, F.D.S., (2016) Um M\u00e9todo Algor\u00edtmico para Opera\u00e7 \u00f5es Na Bolsa de Valores Baseado em Ensembles de Redes Neurais para Modelar e Prever Os Movimentos Dos Mercados de A\u00e7 \u00f5es, , Master's thesis, Universidade Federal do Rio Grande do Sul; Zhong, X., Enke, D., Forecasting daily stock market return using dimensionality reduction (2017) Expert Systems with Applications, 67, pp. 126-139; Ding, X., Zhang, Y., Liu, T., Duan, J., Deep learning for event-driven stock prediction (2015) Proceedings of the 24th International Conference on Artificial Intelligence, Ser. IJCAI'15, pp. 2327-2333. , AAAI Press; Chong, E., Han, C., Park, F.C., Deep learning networks for stock market analysis and prediction: Methodology, data representations, and case studies (2017) Expert Systems with Applications, 83, pp. 187-205; Virili, F., Freisleben, B., Nonstationarity and data preprocessing for neural network predictions of an economic time series (2000) Proceedings of the IEEE-INNS-ENNS International Joint Conference on Neural Networks, 5, pp. 129-134; L\u00e4ngkvist, M., Karlsson, L., Loutfi, A., A review of unsupervised feature learning and deep learning for time-series modeling (2014) Pattern Recognition Letters, 42 (6); Brockwell, P.J., Davis, R.A., (1991) Time Series: Theory and Methods, , 2nd ed., ser. Springer Series in Statistics. Springer; Franses, P.H., Dijk, D.V., Opschoor, A., (2014) Time Series Models for Business and Economic Forecasting, , Cambridge University Press; Kirchg\u00e4ssner, G., Wolters, J., (2007) Introduction to Modern Time Series Analysis, , Springer-Verlag Berlin Heidelberg; Meucci, A., (2007) Risk and Asset Allocation, Ser. Springer Finance, , Springer; Hornik, K., Approximation capabilities of multilayer feedforward networks (1991) Neural Networks, 4 (2), pp. 251-257; Andayani, U., Nababan, E.B., Siregar, B., Muchtar, M.A., Nasution, T.H., Siregar, I., Optimization backpropagation algorithm based on nguyen-widrom adaptive weight and adaptive learning rate (2017) 2017 4th International Conference on Industrial Engineering and Applications (ICIEA), pp. 363-367. , April; LeCun, Y., Bengio, Y., Hinton, G., Deep learning (2015) Nature, 521; Glorot, X., Bengio, Y., Understanding the difficulty of training deep feedforward neural networks (2010) Proceedings of the Thirteenth International Conference on Artificial Intelligence and Statistics, Ser. Proceedings of Machine Learning Research, 9, pp. 249-256. , May. Sardinia, Italy: PMLR; Erhan, D., Bengio, Y., Courville, A., Manzagol, P.-A., Vincent, P., Bengio, S., Why does unsupervised pre-training help deep learning? (2010) J. Mach. Learn. Res., 11, pp. 625-660. , mar; Bengio, Y., Lamblin, P., Popovici, D., Larochelle, H., Greedy layerwise training of deep networks (2006) Proceedings of the 19th International Conference on Neural Information Processing Systems, Ser. NIPS'06, pp. 153-160. , Cambridge, MA, USA: MIT Press; Short Selling, , https:\/\/www.investopedia.com\/terms\/s\/shortselling.asp, accessed: 2018-01-25; Ae Broadcast, , http:\/\/ae.dev.tmp.br\/aebroadcast, accessed: 2018-01-23; Edwards, R., Bassetti, W., Magee, J., (2012) Technical Analysis of Stock Trends, , Tenth Edition, ser. Technical Analysis of Stock Trends. CRC Press; Boxer, H., Moving average convergence\/divergence (2014) Profitable Day and Swing Trading: Using Price\/Volume Surges and Pattern Recognition to Catch Big Moves in the Stock Market, pp. 91-102; Bollinger, J., (2001) Bollinger on Bollinger Bands, , McGraw-Hill Education; Tsang, W.W.H., Chong, T.T.L., Profitability of the on-balance volume indicator (2009) Economics Bulletin, 29, pp. 2424-2431; Chandra, P., (2017) Investment Analysis and Portfolio Management, , McGraw-Hill Education"}
{"Authors":"Yan X., Zhang W., Ma L., Liu W., Wu Q.","Author(s) ID":"57208444896;56393387800;56377428300;56303625400;57208608787;","Title":"Parsimonious quantile regression of financial asset tail dynamics via sequential learning","Year":2018,"Source title":"Advances in Neural Information Processing Systems","Volume":"2018-December","Issue":null,"Art. No.":null,"Page start":1575.0,"Page end":1585.0,"Page count":null,"Cited by":null,"DOI":null,"Affiliations":"Tencent AI Lab, United States; School of Data Science, City University of Hong Kong, Hong Kong; Department of SEEM, Chinese University of Hong Kong, Hong Kong","Document Type":"Conference Paper","Access Type":null,"Source":"Scopus","EID":"2-s2.0-85064804694","Abstract":"The theory of fuzzy (F)-transforms relates to a modern mathematical modeling. It provides a (dimensionally) reduced and robust representation of original data. It is based on a granulation of a domain (fuzzy partition) and gives a tractable image of an original data. The main characteristics with respect to input data: size reduction, noise removal, invariance to geometrical transformations, knowledge transfer from conventional mathematics, fast computation. The F-transform has been applied to: image processing, computer vision, on-line pattern recognition in big data bases, time series analysis and forecasting, mathematical finance, numerical methods for differential equations, deep learning neural networks. In this contribution, we show that the technique of F-transforms fully agrees with the technique of dimensionality reduction, based on Laplacian eigenmaps. In the application part, we give an overview of the F-transform applications to mathematical finance. \u00a9 2017 IEEE.","Author Keywords":"basic function; Black-Scholes equation; dimensionality reduction; F-transform; fuzzy partition; Laplacian eigenmaps; market volatility","Index Keywords":"Big data; Computation theory; Data mining; Deep learning; Differential equations; Finance; Image processing; Knowledge management; Laplace transforms; Numerical methods; Pattern recognition; Time series analysis; Basic functions; Black Scholes equations; Dimensionality reduction; F transforms; Fuzzy partition; Laplacian eigenmaps; Market volatility; Data reduction","References":"Belkin, M., Niyogi, P., Laplacian eigenmaps for dimensionality reduction and data representation (2003) Neural Computation, 15 (6), pp. 1373-1396; Haykin, S., (1999) Neural Networks: A Comprehensive Foundation, , Upper Saddle River, NJ: Prentice Hall; Holapek, M., Tich\u00fd, T., Nonparametric regression via higher degree F-transform for implied volatility surface estimation Proc. Mathematical Methods in Economics, 2016 Liberec, CR, pp. 277-282; Holapek, M., Tevuli\u00e1kov\u00e1, P., Perfilieva, I., F-transform method for option pricing (2016) Proc. 8th Int. Sci. Conf. Managing and Modelling of Financial Risks, , Ostrava, Czech Republic, V\u0160B, September 5-6; Holapek, M., Val\u00e1\u0161ek, R., Numerical solution of partial differential equations with the help of fuzzy transform technique (2017) Proc. IEEE International Conference on Fuzzy Systems (FUZZ-IEEE) Naples, , Italy; Khastan, A., Perfilieva, I., Alijani, Z., A new fuzzy approximation method to Cauchy problems by fuzzy transform (2016) Fuzzy Sets Systems, 288, pp. 75-89; Luce, R.D., Several possible measures of risk (1980) Theory and Decision, 12 (3), pp. 217-228; Novak, V., Perfilieva, I., Dvorak, A., (2015) Insight into Fuzzy Modeling, , John Wiley & Sons, Inc; Perfilieva, I., Fuzzy transform: Application to the Reef growth problem (2003) Fuzzy Logic in Geology, pp. 275-300. , in: R. V. Demicco, G. J. Klir (Eds.), Academic Press, Amsterdam; Perfilieva, I., Fuzzy Transform: Theory and application (2006) Fuzzy Sets and Systems, 157, pp. 993-1023; Perfilieva, I., Dankova, M., Bede, B., Towards a higher degree F-transform (2011) Fuzzy Sets Systems, 180, pp. 3-19; Perfilieva, I., \u0160tevuli\u00e1kov\u00e1, P., Val\u00e1\u0161ek, R., F-transformbased shooting method for nonlinear boundary value problems (2017) Soft Computing, 21 (13), pp. 3493-3502; Perfilieva, I., \u0160tevuli\u00e1kov\u00e1, P., Val\u00e1\u0161ek, R., F-transform for numerical solution of two-point boundary value problem (2017) Iranian Journal of Fuzzy Systems, , article in press; Scholkopf, B., Smola, A., Mulller, K.-R., Nonlinear component analysis as a kernel eigenvalue problem (1998) Neural Computation, 10 (5), pp. 1299-1319; Troiano, L., Mejuto, E., Kriplani, P., An Alternative estimation of market volatility based on fuzzy transform (2017) Proc. IFSA-SCIS 2017, , Otsu, Shiga, Japan, June 27-30"}
{"Authors":"Qiao M., Huang K.-W.","Author(s) ID":"57207454883;28367654100;","Title":"Hierarchical accounting variables forecasting by deep learning methods","Year":2018,"Source title":"International Conference on Information Systems 2018, ICIS 2018","Volume":null,"Issue":null,"Art. No.":null,"Page start":null,"Page end":null,"Page count":null,"Cited by":null,"DOI":null,"Affiliations":"Department of Information Systems, National University of Singapore, Singapore","Document Type":"Conference Paper","Access Type":null,"Source":"Scopus","EID":"2-s2.0-85062493875","Abstract":"Many real-world financial time series forecasting problems share a unique property: the focal variable of interests can be decomposed into a large number of accounting component variables. For example, company earnings are calculated from total revenue minus total costs and each variable can be further decomposed into several accounting items. This property leads to a relatively new research problem. When the dependent variable for prediction has a hierarchical structure, which level of aggregation may be the optimal choice for prediction? Is it possible to use the information from the predictions of all component variables to enhance the prediction accuracy of the focal variable of interests? To solve this problem, this paper designs a novel forecasting method-Hierarchical Stacking of LSTM (HSL)-by using various data mining techniques. Our proposed solution consists of two stages. In the first phase, by LSTM-RNN, the proposed method makes predictions of the dependent variable given different candidate decompositions. Meanwhile, we devise a method creative use of Genetic algorithm to search for the top-performing decompositions of the dependent variable. In the second stage, the ensemble learning method by Stacking is applied to aggregate several predictions from top-performing decompositions. An empirical evaluation on earning forecast of public companies illustrates that HSL can outperform other existing methods. \u00a9 International Conference on Information Systems 2018, ICIS 2018.All rights reserved.","Author Keywords":"Deep Learning; Fintech; Forecast; Hierarchical Accounting Variables","Index Keywords":"Data mining; Financial data processing; Forecasting; Genetic algorithms; Information systems; Information use; Long short-term memory; Problem solving; Dependent variables; Empirical evaluations; Financial time series forecasting; Fintech; Forecasting methods; Hierarchical Accounting Variables; Hierarchical structures; Prediction accuracy; Deep learning","References":"Baesens, B., Bapna, R., Marsden, J.R., Vanthienen, J., Zhao, J.L., Transformational issues of big data and analytics in networked business (2016) MIS Quarterly, 40 (4); Bao, Y., Datta, A., Simultaneously discovering and quantifying risk types from textual risk disclosures (2014) Management Science, 60 (6), pp. 1371-1391; Bell, E.T., Exponential polynomials (1934) Annals of Mathematics, pp. 258-277; Bengio, Y., Simard, P., Frasconi, P., Learning long-term dependencies with gradient descent is difficult (1994) IEEE Transactions on Neural Networks, 5 (2), pp. 157-166; Cao, Q., Parry, M.E., Neural network earnings per share forecasting models: A comparison of backward propagation and the genetic algorithm (2009) Decision Support Systems, 47 (1), pp. 32-41; Che, J., Optimal sub-models selection algorithm for combination forecasting model (2015) Neurocomputing, 151, pp. 364-375; Chen, H., Chiang, R.H., Storey, V.C., Business intelligence and analytics: From big data to big impact (2012) MIS Quarterly, pp. 1165-1188; Donahue, J., Anne Hendricks, L., Guadarrama, S., Rohrbach, M., Venugopalan, S., Saenko, K., Darrell, T., Long-term recurrent convolutional networks for visual recognition and description (2015) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 2625-2634; Falkenauer, E., (1998) Genetic Algorithms and Grouping Problems, , Wiley New York; Hamilton, J.D., (1994) Time Series Analysis, , Princeton university press Princeton; Harvey, D.S., Leybourne, S.J., Newbold, P., Tests for forecast encompassing (1998) Journal of Business & Economic Statistics, 16 (2), pp. 254-259; Hochreiter, S., Schmidhuber, J., Long short-term memory (1997) Neural Computation, 9 (8), pp. 1735-1780; Holland, J.H., Adaptation in natural and artificial systems (1975) An Introductory Analysis with Application to Biology, Control, and Artificial Intelligence, pp. 439-444. , Ann Arbor, MI: University of Michigan Press; Huang, A.H., Zang, A.Y., Zheng, R., Evidence on the information content of text in analyst reports (2014) The Accounting Review, 89 (6), pp. 2151-2180; Hyndman, R.J., Ahmed, R.A., Athanasopoulos, G., Shang, H.L., Optimal combination forecasts for hierarchical time series (2011) Computational Statistics & Data Analysis, 55 (9), pp. 2579-2589; Hyndman, R.J., Lee, A.J., Wang, E., Fast computation of reconciled forecasts for hierarchical and grouped time series (2016) Computational Statistics & Data Analysis, 97, pp. 16-32; Laboissiere, L.A., Fernandes, R.A., Lage, G.G., Maximum and minimum stock price forecasting of Brazilian power distribution companies based on artificial neural networks (2015) Applied Soft Computing, 35, pp. 66-74; \u00d6zsu, M.T., Valduriez, P., (2011) Principles of Distributed Database Systems, , Springer Science & Business Media; Pai, P.-F., Lin, C.-S., A hybrid ARIMA and support vector machines model in stock price forecasting (2005) Omega, 33 (6), pp. 497-505; Qiu, L., Bhattacharya, P., Phan, T., Battling diabetes through food photography: An image-based utility maximization framework for diet diagnostics (2017) International Conference of Information Systems, , Seoul, South Korea; Ruskey, F., Simple combinatorial gray codes constructed by reversing sublists (1993) International Symposium on Algorithms and Computation, pp. 201-208. , Springer; Smith, J., Wallis, K.F., A simple explanation of the forecast combination puzzle (2009) Oxford Bulletin of Economics and Statistics, 71 (3), pp. 331-355; Taieb, S.B., Yu, J., Barreto, M.N., Rajagopal, R., Regularization in hierarchical time series forecasting with application to electricity smart meter data (2017) AAAI, pp. 4474-4480; Wolpert, D.H., Stacked generalization (1992) Neural Networks, 5 (2), pp. 241-259; Zhang, W., Cao, Q., Schniederjans, M.J., Neural network earnings per share forecasting models: A comparative analysis of alternative methods (2004) Decision Sciences, 35 (2), pp. 205-237; Zhou, Z.-H., Wu, J., Tang, W., Ensembling neural networks: Many could be better than all (2002) Artificial Intelligence, 137 (1-2), pp. 239-263"}
{"Authors":"Luo R., Zhang W., Xu X., Wang J.","Author(s) ID":"57204819270;56108513500;57206642524;57206677306;","Title":"A neural stochastic volatility model","Year":2018,"Source title":"32nd AAAI Conference on Artificial Intelligence, AAAI 2018","Volume":null,"Issue":null,"Art. No.":null,"Page start":6401.0,"Page end":6408.0,"Page count":null,"Cited by":4.0,"DOI":null,"Affiliations":"University College, London, United Kingdom; Shanghai Jiao Tong University, China","Document Type":"Conference Paper","Access Type":null,"Source":"Scopus","EID":"2-s2.0-85060437096","Abstract":"Accurate time-series forecasting is vital for numerous areas of application such as transportation, energy, finance, economics, etc. However, while modern techniques are able to explore large sets of temporal data to build forecasting models, they typically neglect valuable information that is often available under the form of unstructured text. Although this data is in a radically different format, it often contains contextual explanations for many of the patterns that are observed in the temporal data. In this paper, we propose two deep learning architectures that leverage word embeddings, convolutional layers and attention mechanisms for combining text information with time-series data. We apply these approaches for the problem of taxi demand forecasting in event areas. Using publicly available taxi data from New York, we empirically show that by fusing these two complementary cross-modal sources of information, the proposed models are able to significantly reduce the error in the forecasts. \u00a9 2018 Elsevier B.V.","Author Keywords":"Cross modality learning; Data fusion; Deep learning; Special events; Taxi demand; Textual data; Time series forecasting; Urban mobility","Index Keywords":"Data fusion; Forecasting; Taxicabs; Time series; Cross modality; Special events; Taxi demand; Textual data; Time series forecasting; Urban mobility; Deep learning","References":"Krygsman, S., Dijst, M., Arentze, T., Multimodal public transport: an analysis of travel time elements and the interconnectivity ratio (2004) Transp. Policy, 11 (3), pp. 265-275; Moreira-Matias, L., Gama, J., Ferreira, M., Mendes-Moreira, J., Damas, L., Predicting taxi\u2013passenger demand using streaming data (2013) IEEE Trans. Intell. Transp. Syst., 14 (3), pp. 1393-1402; van Oort, N., Brands, T., de Romph, E., Short term ridership prediction in public transport by processing smart card data (2015) Transportation Research Board Annual Meeting, pp. 15-0773; Pereira, F.C., Rodrigues, F., Ben-Akiva, M., Using data from the web to predict public transport arrivals under special events scenarios (2015) J. Intell. Transp. Syst., 19 (3), pp. 273-288; O'Connor, B., Balasubramanyan, R., Routledge, B.R., Smith, N.A., From tweets to polls: linking text sentiment to public opinion time series. (2010) ICWSM, 11 (122-129), pp. 1-2; Tang, X., Yang, C., Zhou, J., Stock price forecasting by combining news mining and time series analysis (2009) Web Intelligence and Intelligent Agent Technologies, 2009. WI-IAT\u201909. IEEE\/WIC\/ACM International Joint Conferences on, 1, pp. 279-282. , IEEE; Si, J., Mukherjee, A., Liu, B., Li, Q., Li, H., Deng, X., Exploiting topic based twitter sentiment for stock prediction. (2013) ACL, 2013 (2), pp. 24-29; Schmidhuber, J., Deep learning in neural networks: an overview (2015) Neural Netw., 61, pp. 85-117; Zhu, L., Laptev, N., (2017), 1709.01907 Deep and confident prediction for time series at uber, arXiv; Xu, J., Rahmatizadeh, R., B\u00f6l\u00f6ni, L., Turgut, D., Real-time prediction of taxi demand using recurrent neural networks (2017) IEEE Trans. Intell. Transp. Syst.; (2017), http:\/\/www.nyc.gov\/html\/tlc\/html\/about\/trip_record_data.shtml, New York City Taxi & Limousine Commission, Taxi and limousine commission (tlc) trip record data Available; Potier, F., Bovy, P., Liaudat, C., Big events: planning, mobility management (2003) European Transp. Conference; FHWA, Planned Special Events: Checklists for Practitioners (2006) Technical Report, , Federal Highway Administration; Coutroubas, F., Karabalasis, G., Voukas, Y., Public transport planning for the greatest event - the 2004 olympic games (2003) European Transp. Conference; Pereira, F., Rodrigues, F., Polisciuc, E., Ben-Akiva, M., Why so many people? explaining nonhabitual transport overcrowding with internet data (2015) IEEE Trans. Intell. Transp. Syst., 16 (3), pp. 1370-1379; Levecq, C., Kuhn, B., Jasek, D., General Guidelines for Active Traffic Management Deployment (2011) Technical Report, , Texas Transportation Institute; Brinckerhoff, P., Synthesis of Active Traffic Management Experiences in Europe and the United States (2010) Technical Report, , Federal Highway Administration; Kuppam, A., Copperman, R., Rossi, T., Livshits, V., Vallabhaneni, L., Brown, T., DeBoer, K., Innovative methods for collecting data and for modeling travel related to special events (2011) Transp. Res. Rec., 2246 (1), pp. 24-31; Chang, M., Lu, P., A multinomial logit model of mode and arrival time choices for planned special events (2013) J. East. Asia Soc. Transp. Stud., 10, pp. 710-727; Calabrese, F., Pereira, F., Lorenzo, G.D., Liu, L., Ratti, C., The geography of taste: analyzing cell-phone mobility and social events (2010) Pervasive Computing, pp. 22-37. , Springer; Pereira, F., Rodrigues, F., Ben-Akiva, M., Using data from the web to predict public transport arrivals under special events scenarios (2013) J. Intell. Transp. Syst.; Ruiz, E.J., Hristidis, V., Castillo, C., Gionis, A., Jaimes, A., Correlating financial time series with micro-blogging activity (2012) Proceedings of the Fifth ACM International Conference on Web Search and Data Mining, pp. 513-522. , ACM; Wang, B., Huang, H., Wang, X., A novel text mining approach to financial time series forecasting (2012) Neurocomputing, 83, pp. 136-145; Tumasjan, A., Sprenger, T.O., Sandner, P.G., Welpe, I.M., Election forecasts with twitter: how 140 characters reflect the political landscape (2011) Soc. Sci. Comput. Rev., 29 (4), pp. 402-418; Zheng, Y., Methodologies for cross-domain data fusion: an overview (2015) IEEE Trans. Big Data, 1 (1), pp. 16-34; Lv, Y., Duan, Y., Kang, W., Li, Z., Wang, F.-Y., Traffic flow prediction with big data: a deep learning approach (2015) IEEE Trans. Intell. Transp. Syst., 16 (2), pp. 865-873; Ma, X., Tao, Z., Wang, Y., Yu, H., Wang, Y., Long short-term memory neural network for traffic speed prediction using remote microwave sensor data (2015) Transp. Res. Part C, 54, pp. 187-197; Zhang, J., Zheng, Y., Qi, D., Deep spatio-temporal residual networks for citywide crowd flows prediction. (2017) AAAI, pp. 1655-1661; Wu, Z., Huang, N.E., Long, S.R., Peng, C.-K., On the trend, detrending, and variability of nonlinear and nonstationary time series (2007) Proc. Nation. Acad. Sci., 104 (38), pp. 14889-14894; Pennington, J., Socher, R., Manning, C., Glove: global vectors for word representation (2014) Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP), pp. 1532-1543; Srivastava, N., Hinton, G.E., Krizhevsky, A., Sutskever, I., Salakhutdinov, R., Dropout: a simple way to prevent neural networks from overfitting. (2014) J. Mach. Learn. Res., 15 (1), pp. 1929-1958; Cho, K., Courville, A., Bengio, Y., Describing multimedia content using attention-based encoder-decoder networks (2015) IEEE Trans. Multimedia, 17 (11), pp. 1875-1886; Gers, F.A., Eck, D., Schmidhuber, J., Applying lstm to time series predictable through time-window approaches (2002) Neural Nets WIRN Vietri-01, pp. 193-200. , Springer; Ioffe, S., Szegedy, C., Batch normalization: accelerating deep network training by reducing internal covariate shift (2015) International Conference on Machine Learning, pp. 448-456; Kingma, D., Ba, J., (2014), 1412.6980 Adam: a method for stochastic optimization, arXiv; Chollet, F., (2015), Keras; , pp. 08-14. , https:\/\/www.nyc.com\/nyc-guides\/best_concert_venues_in_nyc.308\/, Best concert venues in nyc, Accessed: 2017-"}
{"Authors":"[No author name available]","Author(s) ID":"[No author id available]","Title":"6th International Conference on Mining Intelligence and Knowledge Exploration, MIKE 2018","Year":2018,"Source title":"Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)","Volume":"11308 LNAI","Issue":null,"Art. No.":null,"Page start":null,"Page end":null,"Page count":383.0,"Cited by":null,"DOI":null,"Affiliations":null,"Document Type":"Conference Review","Access Type":null,"Source":"Scopus","EID":"2-s2.0-85059099483","Abstract":"The paper presents a low complexity recurrent Functional Link Artificial Neural Network for predicting the financial time series data like the stock market indices over a time frame varying from 1 day ahead to 1 month ahead. Although different types of basis functions have been used for low complexity neural networks earlier for stock market prediction, a comparative study is needed to choose the optimal combinations of these for a reasonably accurate forecast. Further several evolutionary learning methods like the Particle Swarm Optimization (PSO) and modified version of its new variant (HMRPSO), and the Differential Evolution (DE) are adopted here to find the optimal weights for the recurrent computationally efficient functional link neural network (RCEFLANN) using a combination of linear and hyperbolic tangent basis functions. The performance of the recurrent computationally efficient FLANN model is compared with that of low complexity neural networks using the Trigonometric, Chebyshev, Laguerre, Legendre, and tangent hyperbolic basis functions in predicting stock prices of Bombay Stock Exchange data and Standard & Poor's 500 data sets using different evolutionary methods and has been presented in this paper and the results clearly reveal that the recurrent FLANN model trained with the DE outperforms all other FLANN models similarly trained. \u00a9 2015 The Authors","Author Keywords":"Differential Evolution; Hybrid Moderate Random Search PSO; Low complexity FLANN models; Recurrent computationally efficient FLANN","Index Keywords":null,"References":"(2010), pp. 1-8. , Abdual-Salam, Mustafa E., Abdul-Kader, Hatem M., Abdel-Wahed, Waiel F. Comparative study between differential evolution and particle swarm optimization algorithms in training of feed-forward neural network for stock price prediction. In: 7th International Conference on Informatics and Systems (INFOS); Ampolucci, P., Uncini, A., Piazza, F., Rao, B.D., On-line learning algorithms for locally recurrent neural networks (1999) IEEE Trans. Neural Networks, 10 (2), pp. 253-270; (2011), pp. 2151-2155. , Andrade de Oliveira, Fagner, Nobre, Cristiane Neri. The use of artificial neural networks in the analysis and prediction of stock prices. In: IEEE International Conference on Systems, Man and Cybernetics (SMC); Chakravarty, S., Dash, P.K., (2009), pp. 1225-1230. , Forecasting stock market indices using hybrid network. In: World Congress on Nature & Biologically Inspired Computing (NaBIC); (2009), pp. 832-837. , Chandra, Patra Jagdis, Bornande, C., Meher, P.K. Laguerre neural network based smart sensors for wireless sensor networks. In: IEEE Conference on Instrumentation and Measurement Technology; Das, K.K., Satapathy, J.K., (2011), pp. 40-43. , Legendre neural network for nonlinear active noise cancellation with nonlinear secondary path. In: International Conference on Multimedia, Signal Processing and Communication Technologies; Dehuri, S., Roy, R., Cho, S.B., Ghosh, A., An improved swarm optimized functional link artificial neural network (ISO-FLANN) for classification (2012) J. Syst. Software, 85, pp. 1333-1345; Gao, H., Xu, W., A new particle swarm algorithm and its globally convergent modifications (2011) IEEE Trans. Syst. Man Cybernet., 41 (5), pp. 1334-1351; (2012), pp. 560-563. , George, Nithin V., Panda, Ganapati. A reduced complexity adaptive Legendre neural network for nonlinear active noise control. In: 19th International Conference on Systems, Signals and Image Processing (IWSSIP); Hatem, A.K., Mustafa, A.S., Evaluation of differential evaluation and particle swarm optimization algorithms at training of neural network for stock prediction (2012) Int. Arab J. e-Technol., 2 (3), pp. 145-151; Jiang, L.L., Maskell, D.L., Patra, J.C., (2012), pp. 1-8. , Chebyshev functional link neural network-based modeling and experimental verification for photovoltaic arrays. In: IEEE International Joint Conference on Neural Networks; Kozarzewski, B., (2010), pp. 59-62. , A neural network based time series forecasting system. In: 3rd International Conference on Human System Interaction, Rzeszow, Poland; (2007), pp. 2292-2297. , Lee, Chun-Teh, Chen, Yi-Ping. The efficacy of neural networks and simple technical indicators in predicting stock markets. In: International Conference on Convergence Information Technology; Li, M., Liu, J., Jiang, Y., Feng, W., Complex Chebyshev functional link neural network behavioral model for broadband wireless power amplifiers (2012) IEEE Trans. Microw. Theory Tech., 60 (6), pp. 1979-1989; (2010), pp. 1940-1943. , Lin, QianYu, Feng, ShaoRong. Stock market forecasting research based on neural network and pattern matching. In: International Conference on E-Business and E-Government; (2011), pp. 1-4. , Lu, Bo. A stock prediction method based on PSO and BP hybrid algorithm. In: International Conference on E-Business and E-Government; (2010) Management Science, pp. 57-60. , Ma, Weimin, Wang, Yingying, Dong, Ningfang. Study on stock price prediction based on BP neural network. In: IEEE International conference on Emergency Management and s (ICEMMS); Majhi, B.D., Shalabi, H., Fathi, M., FLANN based forecasting of S&P 500 index (2005) Inf. Technol. J., 4 (3), pp. 289-292; Mili, F., Hamdi, M., A hybrid evolutionary functional link artificial neural network for data mining and classification (2012) Int. J. Adv. Comput. Sci. Appl., 3 (8), pp. 89-95; Mishra, S.K., Panda, G., Meher, S., Chebyshev functional link artificial neural networks for denoising of image corrupted by salt and pepper noise (2009) Int. J. Recent Trends Eng., 1 (1), pp. 413-417; Mohapatra, P., Raj, A., Patra, T.K., Indian stock market prediction using differential evolutionary neural network model (2012) Int. J. Electron. Commun. Comput. Technol., 2 (4), pp. 159-166; (2010), pp. 132-136. , Naeini, Mahdi Pakdaman, Taremian, Hamidreza, Hashemi, Homa Baradaran. Stock market value prediction using neural networks. In: International Conference on Computer Information Systems and Industrial Management Applications (CISIM); (2011), pp. 267-272. , Nanda, Santosh Kumar, Tripathy, Debi Prasad, Mahapatra, S.S. Application of legendre neural network for air quality prediction. In: The 5th PSU-UNS International Conference on Engineering and Technology (ICET-2011); Pao, Y.-H., Adaptive Pattern Recognition and Neural Networks (1989), Addison-Wesley Publishing Co., Inc. Reading, MA (US); Patra, J.C., Bornand, C., (2010), pp. 1-7. , Nonlinear dynamic system identification using Legendre neural network. In: International Joint Conference on Neural Networks (IJCNN); Patra, J.C., Thanh, N.C., Meher, P.K., (2009), pp. 2431-2438. , Computationally efficient FLANN-based intelligent stock price prediction system. In: Proceedings of International Joint Conference on Neural Networks; Qin, A.K., Huang, V.L., Suganthan, P.N., Differential evolution algorithm with strategy adaptation for global numerical optimization (2008) IEEE Trans. Evol. Comput., 13 (2), pp. 398-417; (2009), pp. 598-601. , Rodriguez, Nibaldo. Multiscale Legendre neural network for monthly anchovy catches forecasting. In: Third International Symposium on Intelligent Information Technology Application; Sanjeevi, S.G., Naga Nikhila, A., Khan, T., Sumathi, G., Hybrid PSO-SA algorithm for training a neural network for classification (2011) Int. J. Comput. Sci. Eng. Appl., 1 (6), pp. 73-83; Song, Y., Chen, Z., Yuan, Z., New chaotic PSO-based neural network predictive control for nonlinear process (2007) IEEE Trans. Neural Networks, 18 (2), pp. 595-600; (2011), pp. 123-126. , Tahersima, Hanif, Tahersima, Mohammad Hossein, Fesharaki, Morteza. Forecasting stock exchange movements using neural networks: A case study. In: International Conference on Future Computer Sciences and Application; Wang, Y., Cai, Z., Zhang, Q., Differential evolution with composite trial vector generation strategies and control parameters (2011) IEEE Trans. Evol. Comput., 15 (1), pp. 55-66; Yogi, S., Subhashini, K.R., Satapathy, J.K., (2010), pp. 107-112. , A PSO based functional link artificial neural network training algorithm for equalization of digital communication channels. In: 5th International Conference on Industrial and Information Systems, ICIIS"}
{"Authors":"Yang H., Zhu Y., Huang Q.","Author(s) ID":"57205196792;55648689000;56010143500;","Title":"A multi-indicator feature selection for CNN-driven stock index prediction","Year":2018,"Source title":"Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)","Volume":"11305 LNCS","Issue":null,"Art. No.":null,"Page start":35.0,"Page end":46.0,"Page count":null,"Cited by":1.0,"DOI":"10.1007\/978-3-030-04221-9_4","Affiliations":"College of Computer Science and Software Engineering, Shenzhen University, Shenzhen, 518060, China","Document Type":"Conference Paper","Access Type":null,"Source":"Scopus","EID":"2-s2.0-85059057328","Abstract":"Recurrent Neural Networks (RNNs) is a sub type of neural networks that use feedback connections. Several types of RNN models are used in predicting financial time series. This study was conducted to develop models to predict daily stock prices of selected listed companies of Colombo Stock Exchange (CSE) based on Recurrent Neural Network (RNN) Approach and to measure the accuracy of the models developed and identify the shortcomings of the models if present. Feedforward, Simple Recurrent Neural Network (SRNN), Gated Recurrent Unit (GRU) and Long Short Term Memory (LSTM) architectures were employed in building models. Closing, High and Low prices of past two days were selected as input variables for each company. Feedforward networks produce the highest and lowest forecasting errors. The forecasting accuracy of the best feedforward networks is approximately 99%. SRNN and LSTM networks generally produce lower errors compared with feedforward networks but in some occasions, the error is higher than feed forward networks. Compared to other two networks, GRU networks are having comparatively higher forecasting errors. \u00a9 2017 IEEE.","Author Keywords":"Colombo Stock Exchange; GRU; LSTM; Recurrent Neural Networks; SRNN","Index Keywords":"Costs; Electronic trading; Errors; Financial markets; Forecasting; Information systems; Information use; Recurrent neural networks; Feed-forward network; Financial time series; LSTM; Recurrent neural network (RNN); Recurrent neural network (RNNs); Simple recurrent neural networks; SRNN; Stock exchange; Long short-term memory","References":"Singh, Y., Chauhan, A.S., Neural networks in data mining (2009) Journal of Theoretical and Applied Information Technology, pp. 37-42; Lawrence, R., (1997) Using Neural Networks to Forecast Stock Market Prices; Malkiel, B., (1985) A Random Walk Down Wall Street, , New York: Norton & Company; Rangana, D., Chandrasekara, N., Tilakaratne, C., (2011) Comparison of Support Vector Regression and Artificial Neural Network Models to Forecast Daily Colombo Stock Exchange; Janssen, C., What is Aritificial Neural Network, , http:\/\/www.techopedia.com\/, [Accessed 17 May 2015]; McCulloch, W.S., Pitts, W.H., A logical calculus of the ideas immanent in nervous activity (1943) Bulletin of Mathematical Biophysics, 4, pp. 115-133; Maind, S.B., Wankar, P., Research paper on basic of artificial neural network (2014) International Journal on Recent and Innovation Trends in Computing and Communication, 2 (1), pp. 96-100; Zekic, M., Neural network applications in stock market predictions (1998) 9th International Conference on Information and Intelligent Systems; White, H., Economic prediction using neural networks: The case of IBM daily stock returns (1988) The Second Annual IEEE Conference on Neural Networks, , New York; Cybenko, G., Approximation by superpositions of a sigmodial function (1989) Mathematics of Control, Signals and Systems, 2, pp. 303-314; Singh, J.B., Current approaches in neural network modelling of financial time series (2009) Bangalore; Roman, J., Jameel, A., Backpropagation and recurrent neural networks in financial analysis of multiple stock market returns (1996) 29th Annual Hawaaii International Conference on System Sciences; Naeini, M.P., Taremian, H., Hashemi, H.B., Stock market value prediction using neural networks (2010) International Conference on Computer Information Systems and Industrial Management Applications (CISIM); Bernal, A., Fok, S., Pidaparthi, R., (2012) Financial Market Time Series Prediction with Recurrent Neural Networks, , 14 December; Jacobson, L., (2014) Introduction to Artificial Neural Networks Part 2-Learning, , http:\/\/www.theprojectspot.com\/tutorial-post\/introduction-to-artificialneural-networks-part-2, 26 March, [Accessed 10 February 2016]; Gunawardana, K.D., (2009) An Introduction to Artificial Neural Networks for Accounting and Finance Modelling, , Colombo: Author Publication; (2016) Recurrent Neural Network, , https:\/\/en.wikipedia.org\/wiki\/Recurrent_neural, 21 February, [Accessed 28 February 2016]; (2016) Long Short-term Memory, , https:\/\/en.wikipedia.org\/wiki\/Long_short-term_memory, 9 July, [Accessed 27 August 2016]; (2016) Gated Recurrent Unit, , https:\/\/en.wikipedia.org\/wiki\/Gated_recurrent_unit, 12 July; Basic Concepts for Neural Networks, , http:\/\/www.cheshireeng.com\/Neuralyst\/nnbg.htm, [Accessed 31 January 2016]; (2015) Recurrent Neural Networks Tutorial, Part 1-Introduction to RNNs, , http:\/\/www.wildml.com\/, 17 September, [Accessed 22 January 2016]; Pearlmutter, B.A., (1990) Dynamic Recurrent Neural Networks, , December; Szko\u0142a, J., Pancerz, K., Warcho\u0142, J., Recurrent neural networks in computer-based clinical decision support for laryngopathies: An experimental study (2011) Computational Intelligence and Neuroscience"}
{"Authors":"Zhu H., Zhu Y., Wu D., Wang H., Tian L., Mao W., Feng C., Zha X., Deng G., Chen J., Liu T., Niu X., Tsoi K.H., Luk W.","Author(s) ID":"57205095793;36903371100;57207184322;55877253300;56564629100;55108888000;57205103678;57205096683;57205099256;57205097637;57205099847;54179579300;34882089400;26029526200;","Title":"Correlation coefficient based cluster data preprocessing and LSTM prediction model for time series data in large aircraft test flights","Year":2018,"Source title":"Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)","Volume":"11344 LNCS","Issue":null,"Art. No.":null,"Page start":376.0,"Page end":385.0,"Page count":null,"Cited by":null,"DOI":"10.1007\/978-3-030-05755-8_37","Affiliations":"Shanghai Advanced Research Institute, Chinese Academy of Sciences, Shanghai, China; Commercial Aircraft Corporation of China Ltd., Shanghai, China; Shenzhen Corerain Technologies Co. Ltd., Shenzhen, China; Imperial College London, London, United Kingdom","Document Type":"Conference Paper","Access Type":null,"Source":"Scopus","EID":"2-s2.0-85058536539","Abstract":"Stock market or equity market have a profound impact in today's economy. A rise or fall in the share price has an important role in determining the investor's gain. The existing forecasting methods make use of both linear (AR,MA,ARIMA) and non-linear algorithms (ARCH,GARCH,Neural Networks),but they focus on predicting the stock index movement or price forecasting for a single company using the daily closing price. The proposed method is a model independent approach. Here we are not fitting the data to a specific model, rather we are identifying the latent dynamics existing in the data using deep learning architectures. In this work we use three different deep learning architectures for the price prediction of NSE listed companies and compares their performance. We are applying a sliding window approach for predicting future values on a short term basis.The performance of the models were quantified using percentage error. \u00a9 2017 IEEE.","Author Keywords":"CNN; LSTM; RNN; Stock market; Time series","Index Keywords":"Commerce; Costs; Deep learning; Economics; Electronic trading; Finance; Financial markets; Forecasting; Investments; Network architecture; Time series; Forecasting methods; Learning architectures; LSTM; Model independent; Percentage error; Price forecasting; Sliding window models; Stock price prediction; Long short-term memory","References":"Devadoss, A.V., Ligori, T.A.A., Forecasting of stock prices using multi layer perceptron (2013) Int J Comput Algorithm, 2, pp. 440-449; De Gooijer, J.G., Hyndman, R.J., 25 Years of time series forecasting (2006) International Journal of Forecasting, 22 (3), pp. 443-473; Menon, V.K., Vasireddy, N.C., Jami, S.A., Pedamallu, V.T.N., Sureshkumar, V., Soman, K., Bulk price forecasting using spark over nse data set (2016) International Conference on Data Mining and Big Data, pp. 137-146. , Springer; Box, G.E., Jenkins, G.M., Reinsel, G.C., Ljung, G.M., (2015) Time Series Analysis: Forecasting and Control, , John Wiley & Sons; Batres-Estrada, G., (2015) Deep Learning for Multivariate Financial Time Series, , ser. Technical Report, Stockholm, May; Abinaya, P., Kumar, V.S., Balasubramanian, P., Menon, V.K., Measuring stock price and trading volume causality among nifty50 stocks: The toda yamamoto method (2016) Advances in Computing, Communications and Informatics (ICACCI), 2016 International Conference on, pp. 1886-1890. , IEEE; Heaton, J., Polson, N., Witte, J., (2016) Deep Learning in Finance, , arXiv preprint arXiv:1602.06561; Jia, H., (2016) Investigation into the Effectiveness of Long Short Term Memory Networks for Stock Price Prediction, , arXiv preprint arXiv:1603.07893; Bengio, Y., Goodfellow, I.J., Courville, A., Deep learning (2015) Nature, 521, pp. 436-444; White, H., (1988) Economic Prediction Using Neural Networks: The Case of IBM Daily Stock Returns, , ser. Discussion paper-Department of Economics University of California San Diego. Department of Economics, University of California; Malkiel, B.G., Efficient market hypothesis (1989) The New Palgrave: Finance, pp. 127-134. , Norton, New York; Ding, X., Zhang, Y., Liu, T., Duan, J., Deep learning for event-driven stock prediction (2015) IJCAI, pp. 2327-2333; Roman, J., Jameel, A., Backpropagation and recurrent neural networks in financial analysis of multiple stock market returns System Sciences, 1996., Proceedings of the Twenty-Ninth Hawaii International Conference on, 2 (1996), pp. 454-460. , IEEE; Chan, M.-C., Wong, C.-C., Lam, C.-C., Financial time series forecasting by neural network using conjugate gradient learning algorithm and multiple linear regression weight initialization (2000) Computing in Economics and Finance, 61; Roman, J., Jameel, A., Backpropagation and recurrent neural networks in financial analysis of multiple stock market returns System Sciences, 1996., Proceedings of the Twenty-Ninth Hawaii International Conference on, 2 (1996), pp. 454-460. , IEEE; Saad, E.W., Prokhorov, D.V., Wunsch, D.C., Comparative study of stock trend prediction using time delay, recurrent and probabilistic neural networks (1998) IEEE Transactions on neural networks, 9 (6), pp. 1456-1470; Hegazy, O., Soliman, O.S., Salam, M.A., (2014) A Machine Learning Model for Stock Market Prediction, , arXiv preprint arXiv: 1402.7351; Kim, K.-J., Han, I., Genetic algorithms approach to feature discretization in artificial neural networks for the prediction of stock price index (2000) Expert systems with Applications, 19 (2), pp. 125-132; Kishikawa, Y., Tokinaga, S., Prediction of stock trends by using the wavelet transform and the multi-stage fuzzy inference system optimized by the ga (2000) IEICE Transactions on Fundamentals of Electronics, Communications and Computer Sciences, 83 (2), pp. 357-366; Hochreiter, S., Schmidhuber, J., Long short-Term memory (1997) Neural computation, 9 (8), pp. 1735-1780"}
{"Authors":"Jayanth Balaji A., Harish Ram D.S., Nair B.B.","Author(s) ID":"56607264800;49963634900;35386974400;","Title":"Applicability of deep learning models for stock price forecasting an empirical study on bankex data","Year":2018,"Source title":"Procedia Computer Science","Volume":"143","Issue":null,"Art. No.":null,"Page start":947.0,"Page end":953.0,"Page count":null,"Cited by":null,"DOI":"10.1016\/j.procs.2018.10.340","Affiliations":"SIERS Research Laboratory, Department of Electronics and Communication Engineering, Amrita School of Engineering, Amrita Vishwa Vidyapeetham, Coimbatore, India","Document Type":"Conference Paper","Access Type":"Open Access","Source":"Scopus","EID":"2-s2.0-85058350678","Abstract":"This paper attempts to provide an optimal model for the prediction of stock prices for t + 5th day and consequently provide a daily buying\/selling strategy for the Standard\u2019s and Poor\u2019s 500 Index. A performance comparison between LSTM, GRU, ANN and SVM model has been made and an optimal model has been outlined. Training and prediction data spanned over 12 years from 2000 to 2017. Fifty technical indicator-based attributes were calculated and appended to the open, high, low, close and volume (OHLCV) data for S&P500, each attribute value was converted into a relative standard score followed by minimax scaling and dimensionality reduction, through ICA. Performances of different models on this dataset were then compared using self-defined metrics like optimism and pessimism ratio and returns ratio. The LSTM model proved to outperform the other models with a return of 400% greater than the hold and wait strategy and R2 score of 0.9486. \u00a9 Springer Nature Singapore Pte Ltd. 2019.","Author Keywords":"Artificial neural networks (ANN); Financial time series forecasting; Gated recurrent unit (GRU); Independent components analysis (ICA); Long short-term memory (LSTM); Support vector machines (SVM)","Index Keywords":"Data communication systems; Electronic trading; Financial markets; Forecasting; Independent component analysis; Intelligent systems; Neural networks; Optimization; Support vector machines; Time series analysis; Attribute values; Dimensionality reduction; Financial time series forecasting; Gated recurrent unit (GRU); Independent components analysis; Performance comparison; Stock price prediction; Technical indicator; Long short-term memory","References":"Kwon, Y.-K., Moon, B.-R., A hybrid neurogenetic approach for stock forecasting (2007) IEEE Trans. Neural Netw.\/A Publication of the IEEE Neural Networks Council, pp. 851-864. , pp; Teixeira, L.A., de Oliveira, A.L.I., A method for automatic stock trading combining technical analysis and nearest neighbor classification (2010) Expert Syst. Appl., 37 (10), pp. 6885-6890; Atsalakis, G.S., Valavanis, K.P., Surveying stock market forecasting techniques\u2014Part II: Soft computing methods (2009) Expert Syst. Appl., 36 (3), pp. 5932-5941. , pp; Guresen, E., Kayakutlu, G., Daim, T.U., Using artificial neural network models in stock market index prediction (2011) Expert Syst. Appl., 38 (8), pp. 10389-10397; Patel, J., Shah, S., Thakkar, P., Kotecha, K., Predicting stock market index using fusion of machine learning techniques (2015) Expert Syst. Appl., 42 (4), pp. 2162-2172; Patel, J., Shah, S., Thakkar, P., Kotecha, K., Predicting stock and stock price index movement using trend deterministic data preparation and machine learning techniques (2015) Expert Syst. Appl., 42 (1), pp. 259-268; Singh, R., Srivastava, S., (2017) Multimed. Tools Appl., 76, p. 18569; Chen, K., Zhou, Y., Dai, F., (2015) A Lstm-Based Method for Stock Returns Prediction: A Case Study of China Stock Market, pp. 2823-2824. , pp; Yahoo Finance, , https:\/\/in.finance.yahoo.com\/quote\/SPY?p=SPY; Cheung, Y.-M., Lei, X., Independent component ordering in ICA time series analysis (2001) Neurocomputing, 41 (1-4), pp. 145-152; Ravuri, S., Stolcke, A., (2016) A Comparative Study of Recurrent Neural Network Models for Lexical Domain Classification, pp. 6075-6079. , pp"}
{"Authors":"Shen G., Tan Q., Zhang H., Zeng P., Xu J.","Author(s) ID":"57205712383;13404486500;57193803016;56957755500;7408550256;","Title":"Deep learning with gated recurrent unit networks for financial sequence predictions","Year":2018,"Source title":"Procedia Computer Science","Volume":"131","Issue":null,"Art. No.":null,"Page start":895.0,"Page end":903.0,"Page count":null,"Cited by":6.0,"DOI":"10.1016\/j.procs.2018.04.298","Affiliations":"College of Computer, National University of Defense Technology, Changsha, China","Document Type":"Conference Paper","Access Type":"Open Access","Source":"Scopus","EID":"2-s2.0-85056656183","Abstract":"Computational intelligence techniques for financial trading systems have always been quite popular. In the last decade, deep learning models start getting more attention, especially within the image processing community. In this study, we propose a novel algorithmic trading model CNN-TA using a 2-D convolutional neural network based on image processing properties. In order to convert financial time series into 2-D images, 15 different technical indicators each with different parameter selections are utilized. Each indicator instance generates data for a 15 day period. As a result, 15 \u00d7 15 sized 2-D images are constructed. Each image is then labeled as Buy, Sell or Hold depending on the hills and valleys of the original time series. The results indicate that when compared with the Buy & Hold Strategy and other common trading systems over a long out-of-sample period, the trained model provides better results for stocks and ETFs. \u00a9 2018 Elsevier B.V.","Author Keywords":"Algorithmic trading; Convolutional neural networks; Deep learning; Financial forecasting; Stock market; Technical analysis","Index Keywords":"Commerce; Convolution; Deep learning; Deep neural networks; Financial markets; Image processing; Neural networks; Time series; Algorithmic trading; Algorithmic trading models; Computational intelligence techniques; Convolutional neural network; Deep convolutional neural networks; Financial forecasting; Financial trading system; Technical analysis; Electronic trading","References":"Cavalcante, R.C., Brasileiro, R.C., Souza, V.L., Nobrega, J.P., Oliveira, A.L., Computational intelligence and financial markets: a survey and future directions (2016) Expert Syst. Appl., 55, pp. 194-211; Canziani, A., Paszke, A., Culurciello, E., An Analysis of Deep Neural Network Models for Practical Applications (2016), arXiv:1605.07678; Krauss, C., Do, X.A., Huck, N., Deep neural networks, gradient-boosted trees, random forests: statistical arbitrage on the s&p 500 (2017) Eur. J. Oper. Res., 259 (2), pp. 689-702; Chen, J.-F., Chen, W.-L., Huang, C.-P., Huang, S.-H., Chen, A.-P., Financial time-series data analysis using deep convolutional neural networks (2016) 2016 7th International Conference on Cloud Computing and Big Data (CCBD), pp. 87-92. , IEEE; Fischer, T., Krau\u00df, C., Deep Learning with Long Short-term Memory Networks for Financial Market Predictions (2017), Tech. Rep., FAU Discussion Papers in Economics; Ganz, F., Puschmann, D., Barnaghi, P., Carrez, F., A practical evaluation of information processing and abstraction techniques for the internet of things (2015) IEEE Internet Things J., 2 (4), pp. 340-354; Box, G.E., Jenkins, G.M., Reinsel, G.C., Ljung, G.M., Time Series Analysis: Forecasting and Control (2015), John Wiley & Sons; Hamilton, J.D., (1994) Time Series Analysis, 2. , Princeton University Press Princeton; Das, G., Lin, K.-I., Mannila, H., Renganathan, G., Smyth, P., Rule discovery from time series (1998) AAAI; Ramoni, M., Sebastiani, P., Cohen, P., Bayesian clustering by dynamics (2002) Mach. Learn., 47 (1), pp. 91-121; Cao, L., Support vector machines experts for time series forecasting (2003) Neurocomputing, 51, pp. 321-339; Ahmed, N.K., Atiya, A.F., Gayar, N.E., El-Shishiny, H., An empirical comparison of machine learning models for time series forecasting (2010) Econometr. Rev., 29 (5-6), pp. 594-621; Mohandes, M., Halawani, T., Rehman, S., Hussain, A.A., Support vector machines for wind speed prediction (2004) Renew. Energy, 29 (6), pp. 939-947; Arizmendi, C.M., Sanchez, J.R., Ramos, N.E., Ramos, G.I., Time series predictions with neural nets: application to airborne pollen forecasting (1993) Int. J. Biometeorol., 37 (3), pp. 139-144; Srinivasan, D., Liew, A., Chang, C., A neural network short-term load forecaster (1994) Electr. Power Syst. Res., 28 (3), pp. 227-234; Kaastra, I., Boyd, M., Designing a neural network for forecasting financial and economic time series (1996) Neurocomputing, 10 (3), pp. 215-236; Kalaitzakis, K., Stavrakakis, G., Anagnostakis, E., Short-term load forecasting based on artificial neural networks parallel implementation (2002) Electr. Power Syst. Res., 63 (3), pp. 185-196; Kohonen, T., The self-organizing map (1998) Neurocomputing, 21 (1-3), pp. 1-6; M\u00f6rchen, F., Ultsch, A., Hoos, O., Extracting interpretable muscle activation patterns with time series knowledge mining (2005) Int. J. Knowl-Based Intell. Eng. Syst., 9 (3), pp. 197-208; Kuo, S.-C., Li, S.-T., Cheng, Y.-C., Ho, M.-H., Knowledge discovery with SOM networks in financial investment strategy (2004) Fourth International Conference on Hybrid Intelligent Systems (HIS\u201904), pp. 98-103. , IEEE; Bezerianos, A., Papadimitriou, S., Alexopoulos, D., Radial basis function neural networks for the characterization of heart rate variability dynamics (1999) Artif. Intell. Med., 15 (3), pp. 215-234; Li, Q., Liu, D., Fang, J., Jeary, A., Wong, C., Damping in buildings: its neural network model and AR model (2000) Eng. Struct., 22 (9), pp. 1216-1223; Guan, D., Yuan, W., Cho, S.J., Gavrilov, A., Lee, Y.-K., Lee, S., Devising a context selection-based reasoning engine for context-aware ubiquitous computing middleware (2007) Ubiquitous Intelligence and Computing, pp. 849-857. , Springer Berlin Heidelberg Berlin, Heidelberg; Choi, J., Shin, D., Shin, D., Research and implementation of the context-aware middleware for controlling home appliances (2005) IEEE Trans. Consumer Electron., 51 (1), pp. 301-306; An, N., Zhao, W., Wang, J., Shang, D., Zhao, E., Using multi-output feedforward neural network with empirical mode decomposition based signal filtering for electricity demand forecasting (2013) Energy, 49, pp. 279-288; Krollner, B., Vanstone, B., Finnie, G., Financial Time Series Forecasting with Machine Learning Techniques: A Survey (2010); Wang, J.-Z., Wang, J.-J., Zhang, Z.-G., Guo, S.-P., Forecasting stock indices with back propagation neural network (2011) Expert Syst. Appl., 38 (11), pp. 14346-14355; Liao, Z., Wang, J., Forecasting model of global stock index by stochastic time effective neural network (2010) Expert Syst. Appl., 37 (1), pp. 834-841; Chen, A.-S., Leung, M.T., Daouk, H., Application of neural networks to an emerging financial market: forecasting and trading the Taiwan stock index (2003) Comput. Oper. Res., 30 (6), pp. 901-923; Guresen, E., Kayakutlu, G., Daim, T.U., Using artificial neural network models in stock market index prediction (2011) Expert Syst. Appl., 38 (8), pp. 10389-10397; Sezer, O.B., Ozbayoglu, A.M., Dogdu, E., An artificial neural network-based stock trading system using technical analysis and big data framework (2017) Proceedings of the SouthEast Conference, pp. 223-226. , ACM; Dhar, S., Mukherjee, T., Performance evaluation of neural network approach in financial prediction: evidence from Indian Market (2010) Proceedings of the International Conference on Communication and Computational Intelligence; Vanstone, B., Finnie, G., Hahn, T., Creating trading systems with fundamental variables and neural networks: the Aby case study (2012) Math. Comput. Simul., 86, pp. 78-91; Aguilar-Rivera, R., Valenzuela-Rend\u00f3n, M., Rodr\u00edguez-Ortiz, J., Genetic algorithms and Darwinian approaches in financial applications: a survey (2015) Expert Syst. Appl., 42 (21), pp. 7684-7697; Ozbayoglu, A.M., Erkut, U., Stock market technical indicator optimization by genetic algorithms (2010) Intelligent Engineering Systems through Artificial Neural Networks, vol. 20, , ASME Press; Kwon, Y.-K., Moon, B.-R., A hybrid neurogenetic approach for stock forecasting (2007) IEEE Trans. Neural Netw., 18 (3), pp. 851-864; Sezer, O.B., Ozbayoglu, M., Dogdu, E., A deep neural-network based stock trading system based on evolutionary optimized technical analysis parameters (2017) Proc. Comput. Sci., 114, pp. 473-480; Evans, C., Pappas, K., Xhafa, F., Utilizing artificial neural networks and genetic algorithms to build an algo-trading model for intra-day foreign exchange speculation (2013) Math. Comput. Modell., 58 (5), pp. 1249-1266; Huang, C.-F., A hybrid stock selection model using genetic algorithms and support vector regression (2012) Appl. Soft Comput., 12 (2), pp. 807-818; Pulido, M., Melin, P., Castillo, O., Particle swarm optimization of ensemble neural networks with fuzzy aggregation for time series prediction of the Mexican Stock Exchange (2014) Inform. Sci., 280, pp. 188-204; Wang, J., Hou, R., Wang, C., Shen, L., Improved v-support vector regression model based on variable selection and brain storm optimization for stock price forecasting (2016) Appl. Soft Comput., 49, pp. 164-178; Mabu, S., Obayashi, M., Kuremoto, T., Ensemble learning of rule-based evolutionary algorithm using multi-layer perceptron for supporting decisions in stock trading problems (2015) Appl. Soft Comput., 36, pp. 357-367; Ballings, M., Van den Poel, D., Hespeels, N., Gryp, R., Evaluating multiple classifiers for stock price direction prediction (2015) Expert Syst. Appl., 42 (20), pp. 7046-7056; LeCun, Y., Bengio, Y., Hinton, G., Deep learning (2015) Nature, 521 (7553), pp. 436-444; Krizhevsky, A., Sutskever, I., Hinton, G.E., Imagenet classification with deep convolutional neural networks (2012) Adv. Neural Inform. Process. Syst., pp. 1097-1105; Karpathy, A., Toderici, G., Shetty, S., Leung, T., Sukthankar, R., Fei-Fei, L., Large-scale video classification with convolutional neural networks (2014) Proceedings of the IEEE conference on Computer Vision and Pattern Recognition, pp. 1725-1732; Lawrence, S., Giles, C.L., Tsoi, A.C., Back, A.D., Face recognition: a convolutional neural-network approach (1997) IEEE Trans. Neural Netw., 8 (1), pp. 98-113; Ciresan, D.C., Meier, U., Gambardella, L.M., Schmidhuber, J., Convolutional neural network committees for handwritten character classification (2011) 2011 International Conference on Document Analysis and Recognition (ICDAR), pp. 1135-1139. , IEEE; Kim, Y., Convolutional Neural Networks for Sentence Classification (2014), arXiv:1408.5882; Kalchbrenner, N., Grefenstette, E., Blunsom, P., A Convolutional Neural Network for Modelling Sentences (2014), arXiv:1404.2188; Ding, X., Zhang, Y., Liu, T., Duan, J., Deep learning for event-driven stock prediction (2015) IJCAI, pp. 2327-2333; L\u00e4ngkvist, M., Karlsson, L., Loutfi, A., A review of unsupervised feature learning and deep learning for time-series modeling (2014) Pattern Recogn. Lett., 42, pp. 11-24; Yoshihara, A., Fujikawa, K., Seki, K., Uehara, K., Predicting Stock Market Trends by Recurrent Deep Neural Networks (2014), pp. 759-769; Shen, F., Chao, J., Zhao, J., Forecasting exchange rate using deep belief networks and conjugate gradient method (2015) Neurocomputing, 167, pp. 243-253; Tino, P., Schittenkopf, C., Dorffner, G., Financial volatility trading using recurrent neural networks (2001) IEEE Trans. Neural Netw., 12 (4), pp. 865-874; Deng, Y., Bao, F., Kong, Y., Ren, Z., Dai, Q., Deep direct reinforcement learning for financial signal representation and trading (2017) IEEE Trans. Neural Netw. Learn. Syst., 28 (3), pp. 653-664; LeCun, Y., Boser, B.E., Denker, J.S., Henderson, D., Howard, R.E., Hubbard, W.E., Jackel, L.D., Handwritten digit recognition with a back-propagation network (1990) Advances in Neural Information Processing Systems, pp. 396-404; LeCun, Y., Jackel, L., Bottou, L., Cortes, C., Denker, J.S., Drucker, H., Guyon, I., Simard, P., Learning algorithms for classification: a comparison on handwritten digit recognition (1995) Neural Netw., 261, p. 276; Goodfellow, I., Bengio, Y., Courville, A., Deep Learning (2016), http:\/\/www.deeplearningbook.org, MIT Press; Mostafa, M.M., Forecasting stock exchange movements using neural networks: empirical evidence from Kuwait (2010) Expert Syst. Appl., 37 (9), pp. 6302-6309; Zheng, Y., Liu, Q., Chen, E., Ge, Y., Zhao, J.L., Time series classification using multi-channels deep convolutional neural networks (2014) International Conference on Web-Age Information Management, pp. 298-310. , Springer; Wang, Z., Yan, W., Oates, T., Time series classification from scratch with deep neural networks: a strong baseline (2017) 2017 International Joint Conference on Neural Networks (IJCNN), pp. 1578-1585. , IEEE; Le Guennec, A., Malinowski, S., Tavenard, R., Data augmentation for time series classification using convolutional neural networks (2016) ECML\/PKDD Workshop on Advanced Analytics and Learning on Temporal Data; Seyfioglu, M.S., Ozbayoglu, A.M., Gurbuz, S.Z., Deep convolutional autoencoder for radar-based classification of similar aided and unaided human activities (2018) IEEE Trans. Aerosp. Electron. Syst., PP (99). , 1-1; Kabanga, E.K., Kim, C.H., Malware images classification using convolutional neural network (2017) J. Comput. Commun., 6 (1), p. 153; Yue, S., Imbalanced Malware Images Classification: A CNN Based Approach (2017), arXiv:1708.08042"}
{"Authors":"Tsai Y.-C., Chen J.-H., Wang J.-J.","Author(s) ID":"57203011511;57204046656;57204046789;","Title":"Predict Forex Trend via Convolutional Neural Networks","Year":2018,"Source title":"Journal of Intelligent Systems","Volume":null,"Issue":null,"Art. No.":null,"Page start":null,"Page end":null,"Page count":null,"Cited by":1.0,"DOI":"10.1515\/jisys-2018-0074","Affiliations":"Center for General Education, National Taiwan University, Taipei, Taiwan; Department of Computer Science and Information Engineering, National Taiwan University, Taipei, Taiwan; Department of Computer Science and Information Engineering, National Taipei University, New Taipei City, Taiwan","Document Type":"Article in Press","Access Type":null,"Source":"Scopus","EID":"2-s2.0-85054237730","Abstract":"This paper examines electricity price time series from dynamical system perspective and proposes a hybrid model which employs a synergistic combination of Recurrent Neural Network (RNN) and coupled excitable system for prediction of future prices in deregulated electricity markets. Driven by profit maximizing decisions taken by various agents, these markets belong to the class of financial systems. However presence of intermittent spikes and complex dynamic nonlinearities in electricity price time series render the prediction task extremely challenging. The approximation ability of Recurrent Neural Networks to map dynamic functions together with sharp jumping attribute of coupled excitable systems allows close approximation of spiky time series. The developed hybrid model was applied for point and interval forecasting in various markets worldwide over different seasons for testing its adaptability in different environments. Satisfactory prediction results were obtained in all the markets, in stable as well as spiking regions of the time series. \u00a9 2013 Elsevier Ltd.","Author Keywords":"Excitable system; FHN coupled system; Multiple scale dynamics; Recurrent neural networks","Index Keywords":"Coupled systems; Deregulated electricity market; Excitable systems; Hybrid intelligent model; Multiple scale; Recurrent neural network (RNN); Satisfactory predictions; Synergistic combinations; Commerce; Costs; Dynamical systems; Profitability; Recurrent neural networks; Time series; Forecasting","References":"Anderson, C.L., Davison, M., A hybrid system-econometric model for electricity spot prices: Considering spike sensitivity to forced outage distributions (2008) IEEE Trans. Power Syst., 23, pp. 927-937. , (Copyright 2008, The Institution of Engineering and Technology); Arciniegas, A.I., Arciniegas Rueda, I.E., Forecasting short-term power prices in the Ontario Electricity Market (OEM) with a fuzzy logic based inference system (2008) Utilities Policy, 16, pp. 39-48. , (Copyright 2008, The Institution of Engineering and Technology); Areekul, P., Senjyu, T., A hybrid ARIMA and neural network model for short-term price forecasting in deregulated market (2010) IEEE Trans. Power Syst., 25, pp. 524-530. , (Copyright 2010, The Institution of Engineering and Technology); Beyer, H.-G., (2001) The Theory of Evolution Strattegies, , Springer; Catalao, P.J.S., Pousinho, H.M.I., Neural networks and wavelet transform for short-term electricity prices forecasting (2009) 2009 15th International Conference on Intelligent System Applications to Power Systems (ISAP), , 8-12 November. 2009, Piscataway, NJ, USA, IEEE; Chelidze, D., Cusumano, J.P., Phase space warping: Nonlinear time-series analysis for slowly drifting systems (2006) Philos. Trans. R. Soc. A, 364 (1846), pp. 2495-2513; Christoffersen, P.F., Evaluating interval forecasts (1997) Int. Econ. Rev., 39, pp. 841-862; Conejo, A.J., Contreras, J., Forecasting electricity prices for a day-ahead pool-based electric energy market (2005) Int. J. Forecasting, 21, pp. 435-462. , (Copyright 2006, IEE); Conejo, A.J., Plazas, M.A., Day-ahead electricity price forecasting using the wavelet transform and ARIMA models (2005) IEEE Trans. Power Syst., 20, pp. 1035-1042. , (Copyright 2005, IEE); Contreras, J., Espinola, R., ARIMA models to predict next-day electricity prices (2003) IEEE Trans. Power Syst., 18, pp. 1014-1020. , (Copyright 2003, IEE); Davison, M., Anderson, C.L., Development of a hybrid model for electrical power spot prices (2002) IEEE Trans. Power Syst., 17, pp. 257-264. , (Copyright 2002, IEE); Fan, S., Mao, C., Next-day electricity-price forecasting using a hybrid network (2007) IET Gener. Transm. Distrib., 1, pp. 176-182. , (Copyright 2007, The Institution of Engineering and Technology); Gonzalez, A.M., Roque, A.M.S., Modeling and forecasting electricity prices with input\/output hidden Markov models (2005) IEEE Trans. Power Syst., 20, pp. 13-24. , (Copyright 2005, IEE); Haykin, S., (1992) Neural Networks: A Comprehensive Foundation, , Prentice Hall; Hoppensteadt, F.C., Izhikevich, E.M., (1997) Weakly Connected Neural Networks, , Springer; Jun Hua, Z., Yang, D.Z., A statistical approach for interval forecasting of the electricity price (2008) IEEE Trans. Power Syst., 23, pp. 267-276. , (Copyright 2008, The Institution of Engineering and Technology); Liu, Y., (2005) Value-at-Risk Model Combination Using Artificial Neural Networks, , Emory University Working Paper Series; Lucheroni, C., Resonating models for the electric power market (2007) Phys. Rev. e, 76 (5), p. 056116; Mandal, P., Senjyu, T., A neural network based several-hour-ahead electric load forecasting using similar days approach (2006) Int. J. Electr. Power Energy Syst., 28, pp. 367-373. , (Compendex); Max, S., (2001) Filtering and Forecasting Spot Electricity Prices in the Increasingly Deregulated Australian Electricity Market, , Quantitative Finance Research Centre, University of Technology Sydney; Mirikitani, D., Nikolaev, N., Nonlinear maximum likelihood estimation of electricity spot prices using recurrent neural networks (2010) Neural Comput. Appl; Nandram, B., Petruccelli, J.D., (1999) Applied Statistics for Engineers and Scientists, , Prentice Hall; Nogales, F.J., Contreras, J., Forecasting next-day electricity prices by time series models (2002) IEEE Trans. Power Syst., 17, pp. 342-348. , (Copyright 2002, IEE); Papadopoulos, G., Edwards, P.J., Confidence estimation methods for neural networks: A practical comparison (2001) IEEE Trans. Neural Networks, 12, pp. 1278-1287. , (Copyright 2001, IEE); Pindoriya, N.M., Singh, S.N., An adaptive wavelet neural network-based energy price forecasting in electricity markets (2008) IEEE Trans. Power Syst., 23 (3), pp. 1423-1432; Ranjbar, M., Soleymani, S., Electricity price forecasting using artificial neural network (2006) International Conference on Power Electronics, Drives and Energy Systems, , PEDES '06 2006; Rodriguez, C.P., Anders, G.J., Energy price forecasting in the Ontario competitive power system market (2004) IEEE Trans. Power Syst., 19, pp. 366-374. , (Copyright 2004, IEE); Srinivasan, D., Fen Chao, Y., Electricity price forecasting using evolved neural networks (2007) International Conference on Intelligent Systems Applications to Power Systems, , 2007 ISAP 2007; Wallis, K.F., Chi-squared tests of interval and density forecasts, and the Bank of England's fan charts (2003) Int. J. Forecasting, 19, pp. 165-175. , (Copyright 2004, IEE); Zareipour, H., Bhattacharya, K., Forecasting the hourly ontario energy price by multivariate adaptive regression splines (2006) IEEE Power Engineering Society General Meeting, , 18-22 June 2006, Piscataway, NJ, USA, IEEE 2006; Zareipour, H., Bhattacharya, K., Forecasting the hourly Ontario energy price by multivariate adaptive regression splines (2006) Power Engineering Society General Meeting, , IEEE; Zareipour, H., Canizares, C.A., Application of public-domain market information to forecast Ontario's wholesale electricity prices (2006) IEEE Trans. Power Syst., 21, pp. 1707-1717. , (Copyright 2006, The Institution of Engineering and Technology)"}
{"Authors":"Heinrich K., Flei\u00dfner V.","Author(s) ID":"55204945400;57203926859;","Title":"Deep intelligent systems for time series prediction: Champion or lame duck? - Evidence from crude oil price prediction","Year":2018,"Source title":"Americas Conference on Information Systems 2018: Digital Disruption, AMCIS 2018","Volume":null,"Issue":null,"Art. No.":null,"Page start":null,"Page end":null,"Page count":null,"Cited by":null,"DOI":null,"Affiliations":"TU-Dresden, Germany","Document Type":"Conference Paper","Access Type":null,"Source":"Scopus","EID":"2-s2.0-85054221459","Abstract":"Gated recurrent unit (GRU) networks perform well in sequence learning tasks and overcome the problems of vanishing and explosion of gradients in traditional recurrent neural networks (RNNs) when learning long-term dependencies. Although they apply essentially to financial time series predictions, they are seldom used in the field. To fill this void, we propose GRU networks and its improved version for predicting trading signals for stock indexes of the Hang Seng Indexes (HSI), the Deutscher Aktienindex (DAX) and the S&P 500 Index from 1991 to 2017, and compare the GRU-based models with the traditional deep net and the benchmark classifier support vector machine (SVM). Experimental results show that the two GRU models proposed in this paper both obtain higher prediction accuracy on these data sets, and the improved version can effectively improve the learning ability of the model. \u00a9 2018 The Authors. Published by Elsevier Ltd.","Author Keywords":"Deep learning; Financial time series; GRU; Stock index; SVM","Index Keywords":"Financial data processing; Financial markets; Forecasting; Recurrent neural networks; Support vector machines; Time series; Financial time series; Financial time series predictions; Learning abilities; Long-term dependencies; Prediction accuracy; Recurrent neural network (RNNs); Sequence prediction; Stock indices; Deep learning","References":"Fama, E.F., Efficient capital markets: A review of theory and empirical work (1970) The Journal of Finance, 25 (2), pp. 383-417; Jacobs, H., What explains the dynamics of 100 anomalies? (2015) Journal of Banking & Finance, 57, pp. 65-85; Huck, N., Pairs selection and outranking: An application to the S&P 100 index (2009) European Journal of Operational Research, 196 (2), pp. 819-825; Takeuchi, L., Lee, Y.-Y., (2013) Applying Deep Learning to Enhance Momentum Trading Strategies in Stocks, , Working paper, Stanford University; Dixon, M., Klabjan, D., Bang, J.H., Implementing deep neural networks for financial market prediction on the Intel Xeon Phi (2015) Proceedings of the 8th Workshop on High Performance Computational Finance, pp. 1-6; Moritz, B., Zimmermann, T., (2014) Deep Conditional Portfolio Sorts: The Relation between Past and Future Stock Returns, , Working paper, LMU Munich and Harvard University; Krauss, C., Do, X.A., Huck, N., Deep neural networks, gradient-boosted trees, random forests: Statistical arbitrage on the S&P 500 (2017) European Journal of Operational Research, 259 (2), pp. 689-702; Medsker, L., Recurrent neural networks: Design and applications (2000) International Series on Computational Intelligence, , CRC-Press; Vapnik, V.N., (1995) The Nature of Statistical Learning Theory, , Springer, New York; Enke, D., Thawornwong, S., The use of data mining and neural networks for forecasting stock market returns (2005) Expert Systems with Applications, 29 (4), pp. 927-940; Chang, C.C., Lin, C.J., LiBSVM: A library for support vector machines[J] (2007) Acm Transactions on Intelligent Systems & Technology, 2 (3), pp. 389-396. , article 27"}
{"Authors":"Ni\u00f1o J., Ar\u00e9valo A., Leon D., Hernandez G., Sandoval J.","Author(s) ID":"57190225431;57190281278;57195350225;35897064300;56311250400;","Title":"Price prediction with cnn and limit order book data","Year":2018,"Source title":"Communications in Computer and Information Science","Volume":"915","Issue":null,"Art. No.":null,"Page start":124.0,"Page end":135.0,"Page count":null,"Cited by":null,"DOI":"10.1007\/978-3-030-00350-0_11","Affiliations":"Universidad Nacional de Colombia, Bogot\u00e1, Colombia; Universidad Externado de Colombia, Bogot\u00e1, Colombia","Document Type":"Conference Paper","Access Type":null,"Source":"Scopus","EID":"2-s2.0-85054084759","Abstract":"The recent advance of deep learning has enabled trading algorithms to predict stock price movements more accurately. Unfortunately, there is a significant gap in the real-world deployment of this breakthrough. For example, professional traders in their long-term careers have accumulated numerous trading rules, the myth of which they can understand quite well. On the other hand, deep learning models have been hardly interpretable. This paper presents DeepClue, a system built to bridge text-based deep learning models and end users through visually interpreting the key factors learned in the stock price prediction model. We make three contributions in DeepClue. First, by designing the deep neural network architecture for interpretation and applying an algorithm to extract relevant predictive factors, we provide a useful case on what can be interpreted out of the prediction model for end users. Second, by exploring hierarchies over the extracted factors and displaying these factors in an interactive, hierarchical visualization interface, we shed light on how to effectively communicate the interpreted model to end users. Specially, the interpretation separates the predictables from the unpredictables for stock prediction through the use of intercept model parameters and a risk visualization design. Third, we evaluate the integrated visualization system through two case studies in predicting the stock price with financial news and company-related tweets from social media. Quantitative experiments comparing the proposed neural network architecture with state-of-the-art models and the human baseline are conducted and reported. Feedbacks from an informal user study with domain experts are summarized and discussed in details. The study results demonstrate the effectiveness of DeepClue in helping to complete stock market investment and analysis tasks. \u00a9 1989-2012 IEEE.","Author Keywords":"Deep learning; model interpretation; stock prediction; visualization","Index Keywords":"Commerce; Costs; Data visualization; Deep learning; Deep neural networks; Financial markets; Flow visualization; Forecasting; Human computer interaction; Investments; Learning algorithms; Learning systems; Network architecture; Neural networks; Time series analysis; Visualization; Integrated visualization systems; Model interpretations; Prediction algorithms; Predictive models; Quantitative experiments; Stock predictions; Stock price movements; Stock price prediction; Electronic trading","References":"LeCun, Y., Bengio, Y., Hinton, G., Deep learning (2015) Nature, 521 (7553), pp. 436-444; Krizhevsky, A., Sutskever, I., Hinton, G.E., Imagenet classification with deep convolutional neural networks (2012) Proc. 25th Int. Conf. Neural Inf. Process. Syst, pp. 1097-1105; Bordes, A., Chopra, S., Weston, J., Question answering with subgraph embeddings (2014) Proc. Conf. Empirical Methods Natural Language Process, pp. 615-620; Bahdanau, D., Cho, K., Bengio, Y., Neural machine translation by jointly learning to align and translate (2015) Proc. Int. Conf. Learn. Representations, pp. 1-15; Ding, X., Zhang, Y., Liu, T., Duan, J., Using structured events to predict stock price movement: An empirical investigation (2014) Proc. Conf. Empirical Methods Natural Language Process, pp. 1415-1425; Ding, X., Zhang, Y., Liu, T., Duan, J., Deep learning for eventdriven stock prediction (2015) Proc. 24th Int. Conf. Artif. Intell, pp. 2327-2333; Peng, Y., Jiang, H., Leverage financial news to predict stock price movements using word embeddings and deep neural networks (2016) Proc. Conf. North American Chapter Assoc. Comput. Linguistics: Human Language Technol, pp. 374-379; Erhan, D., Bengio, Y., Courville, A., Vincent, P., Visualizing higher-layer features of a deep network (2009) Univ. Montreal, Montreal, QC, Canada, Tech. Rep. 1341, 1341; Zeiler, M.D., Fergus, R., Visualizing and understanding convolutional networks (2014) Proc. Eur. Conf. Comput. Vis, pp. 818-833; Shneiderman, B., The eyes have it: A task by data type taxonomy for information visualizations (1996) Proc. IEEE Symp. Visual Languages, pp. 336-343; Malkiel, B.G., Fama, E.F., Efficient capital markets: A review of theory and empirical work (1970) J. Finance, 25 (2), pp. 383-417; Yosinski, J., Clune, J., Nguyen, A., Fuchs, T., Lipson, H., (2015) Understanding Neural Networks Through Deep Visualization; (2017) Tensorflow Playground, , http:\/\/playground.tensorflow.org\/; Liu, M., Shi, J., Li, Z., Li, C., Zhu, J., Liu, S., Towards better analysis of deep convolutional neural networks (2017) IEEE Trans. Vis. Comput. Graph, 23 (1), pp. 91-100. , Jan; Simonyan, K., Vedaldi, A., Zisserman, A., (2013) Deep Inside Convolutional Networks: Visualising Image Classification Models and Saliency Maps; Bach, S., Binder, A., Montavon, G., Klauschen, F., Muller, K.-R., Samek, W., On pixel-wise explanations for non-linear classifier decisions by layer-wise relevance propagation (2015) PloS One, 10 (7); Binder, A., Montavon, G., Lapuschkin, S., Muller, K.-R., Samek, W., Layer-wise relevance propagation for neural networks with local renormalization layers (2016) Proc. Int. Conf. Artif. Neural Netw, 9887, pp. 1-9; Dosovitskiy, A., Brox, T., Inverting visual representations with convolutional networks (2016) Proc. IEEE Conf. Comput. Vis. Pattern Recognit, pp. 4829-4837; Zintgraf, L.M., Cohen, T.S., Welling, M., (2016) A New Method to Visualize Deep Neural Networks; (2017) Google Deep Dream, , http:\/\/deepdream-generator.com\/; Kearney, C., Liu, S., Textual sentiment in finance: A survey of methods and models (2014) Int. Rev. Financial Anal, 33, pp. 171-185; Engelberg, J., Costly information processing: Evidence from earnings announcements (2008) Proc. AFA San Francisco Meetings, pp. 1-49; Tetlock, P.C., Saar-Tsechansky, M., Macskassy, S., More than words: Quantifying language to measure firms' fundamentals (2008) J. Finance, 63 (3), pp. 1437-1467; Chen, H., De, P., Hu, Y.J., Hwang, B.-H., Customers as advisors: The role of social media in financial markets (2013) Proc. Annu. Behav. Finance Conf, p. 1; Ziegler, H., Jenny, M., Gruse, T., Keim, D.A., Visual market sector analysis for financial time series data (2010) Proc. IEEE Symp. Visual Anal. Sci. Technol, pp. 83-90; Keim, D.A., Nietzschmann, T., Schelwies, N., Schneidewind, J., Schreck, T., Ziegler, H., A spectral visualization system for analyzing financial time series data (2006) Proc. 8th Joint Eurographics \/ IEEE VGTC Conf. Vis, pp. 195-202; Hullman, J., Diakopoulos, N., Adar, E., Contextifier: Automatic generation of annotated stock visualizations (2013) Proc. Conf. Human Factors Comput. Syst, pp. 2707-2716; Sorenson, E., Brath, R., Financial visualization case study: Correlating financial timeseries and discrete events to support investment decisions (2013) Proc. 17th Int. Conf. Inf. Vis, pp. 232-238; (2012) Twitter Cashtag, , http:\/\/money.cnn.com\/2012\/07\/31\/technology\/twitter-cashtag\/; Mikolov, T., Sutskever, I., Chen, K., Corrado, G.S., Dean, J., Distributed representations of words and phrases and their compositionality (2013) Proc. 26th Int. Conf. Neural Inf. Process. Syst, pp. 3111-3119; He, K., Zhang, X., Ren, S., Sun, J., Deep residual learning for image recognition (2016) Proc. IEEE Conf. Comput. Vis. Pattern Recognit, pp. 770-778; Srivastava, N., Hinton, G.E., Krizhevsky, A., Sutskever, I., Salakhutdinov, R., Dropout: A simple way to prevent neural networks from overfitting (2014) J. Mach. Learn. Res, 15 (1), pp. 1929-1958; Ammar, W., Mulcaire, G., Ballesteros, M., Dyer, C., Smith, N.A., One parser, many languages (2016) Trans. Assoc. Comput. Linguistics, 4, pp. 431-444; Neubig, G., (2017) DyNet: The Dynamic Neural Network Toolkit; Sutskever, I., Martens, J., Dahl, G.E., Hinton, G.E., On the importance of initialization and momentum in deep learning (2013) J. Mach. Learn. Res, 28, pp. 1139-1147; Dyer, C., Ballesteros, M., Ling, W., Matthews, A., Smith, N.A., Transition-based dependency parsing with stack long short-term memory (2015) Proc. Annu. Meeting Assoc. Comput. Linguistics, pp. 334-343; Glorot, X., Bengio, Y., Understanding the difficulty of training deep feedforward neural networks (2010) Proc. 13th Int. Conf. Artif. Intell. Statistics, 9, pp. 249-256; Li, J., Chen, X., Hovy, E., Jurafsky, D., Visualizing and understanding neural models in NLP (2016) Proc. Conf. North American Chapter Assoc. Comput. Linguistics:Human Language Technol, pp. 681-691; Montavon, G., Bach, S., Binder, A., Samek, W., Muller, K., Explaining nonlinear classification decisions with deep taylor decomposition (2015) Pattern Recognit, 65 (C), pp. 211-222; Arras, L., Horn, F., Montavon, G., Muller, K.-R., Samek, W., Explaining predictions of non-linear classifiers in NLP (2016) Proc. ACL Workshop Representation Learn. Natural Language Process, pp. 1-7; Samek, W., Binder, A., Montavon, G., Lapuschkin, S., Muller, K.-R., Evaluating the visualization of what a deep neural network has learned (2017) IEEE Trans. Neural Netw. Learn. Syst, 28 (11), pp. 2660-2673. , Nov; Rumelhart, D.E., Hinton, G.E., Williams, R.J., Learning representations by back-propagating errors (1986) Nature, 323 (6088), pp. 533-536; Kruskal, J.B., Multidimensional scaling by optimizing goodness of fit to a nonmetric hypothesis (1964) Psychometrika, 29 (1), pp. 1-27; Maaten, L.V.D., Hinton, G., Visualizing data using T-SNE (2008) J. Mach. Learn. Res, 9, pp. 2579-2605; Ketchen, D.J., Shook, C.L., The application of cluster analysis in strategic management research: An analysis and critique (1996) Strategic Manage. J, 17 (6), pp. 441-458; (2017) Cross-Correlation, , https:\/\/en.wikipedia.org\/wiki\/Cross-correlation; Cho, K., Van Merrienboer, B., Gulcehre, C., Bahdanau, D., Bougares, F., Schwenk, H., Bengio, Y., Learning phrase representations using RNN encoder-decoder for statistical machine translation (2014) Proc. Conf. Empirical Methods Natural Language Process, pp. 1724-1734; Xie, B., Passonneau, R.J., Wu, L., Creamer, G.G., Semantic frames to predict stock price movement (2013) Proc. 51st Annu. Meeting Assoc. Comput. Linguistics, pp. 873-883; Fama, E.F., French, K.R., Common risk factors in the returns on stocks and bonds (1993) J. Financial Economics, 33 (1), pp. 3-56"}
{"Authors":"Lee S.I., Yoo S.J.","Author(s) ID":"57203921315;55665769500;","Title":"Threshold-based portfolio: the role of the threshold and its applications","Year":2018,"Source title":"Journal of Supercomputing","Volume":null,"Issue":null,"Art. No.":null,"Page start":null,"Page end":null,"Page count":null,"Cited by":null,"DOI":"10.1007\/s11227-018-2577-1","Affiliations":"Department of Computer Engineering, Sejong University, Seoul, 05006, South Korea","Document Type":"Article in Press","Access Type":null,"Source":"Scopus","EID":"2-s2.0-85053528190","Abstract":"Forecasting time series data is an important subject in economics, business, and finance. Traditionally, there are several techniques to effectively forecast the next lag of time series data such as univariate Autoregressive (AR), univariate Moving Average (MA), Simple Exponential Smoothing (SES), and more notably Autoregressive Integrated Moving Average (ARIMA) with its many variations. In particular, ARIMA model has demonstrated its outperformance in precision and accuracy of predicting the next lags of time series. With the recent advancement in computational power of computers and more importantly development of more advanced machine learning algorithms and approaches such as deep learning, new algorithms are developed to analyze and forecast time series data. The research question investigated in this article is that whether and how the newly developed deep learning-based algorithms for forecasting time series data, such as 'Long Short-Term Memory (LSTM)', are superior to the traditional algorithms. The empirical studies conducted and reported in this article show that deep learning-based algorithms such as LSTM outperform traditional-based algorithms such as ARIMA model. More specifically, the average reduction in error rates obtained by LSTM was between 84 - 87 percent when compared to ARIMA indicating the superiority of LSTM to ARIMA. Furthermore, it was noticed that the number of training times, known as 'epoch' in deep learning, had no effect on the performance of the trained forecast model and it exhibited a truly random behavior. \u00a9 2018 IEEE.","Author Keywords":"Autoregressive Integrated Moving Average (ARIMA); Deep Learning; Forecasting; Long Short-Term Memory (LSTM); Time Series Data","Index Keywords":"Brain; Deep learning; Forecasting; Long short-term memory; Machine learning; Time series; Auto-regressive integrated moving average; Computational power; Empirical studies; Forecasting time series; Learning-based algorithms; Research questions; Simple exponential smoothing; Time-series data; Learning algorithms","References":"Adebiyi, A.A., Adewumi, A.O., Ayo, C.K., Stock price prediction using the arima model (2014) UKSim-AMSS 16th International Conference on Computer Modeling and Simulation.; Alonso, A.M., Garcia-Martos, C., Time series analysis-forecasting with arima models (2012) Universidad Carlos III de Madrid, Universidad Politecnica de Madrid; Brownlee, J., (2017) How to Create An ARIMA Model for Time Series Forecasting with Python, , https:\/\/machinelearningmastery.com\/arima-for-time-series-forecasting-with-python\/; Brownlee, J., (2016) Time Series Prediction with LSTM Recurrent Neural Networks in Python with Keras, , https:\/\/machinelearningmastery.com\/time-series-prediction-lstm-recurrent-neural-networks-python-keras\/; Box, G., Jenkins, G., (1970) Time Series Analysis: Forecasting and Control, , San Francisco: Holden-Day; Earnest, A., Chen, M.I., Ng, D., Sin, L.Y., Using autoregressive integrated moving average (arima) models to predict and monitor the number of beds occupied during a sars outbreak in a tertiary hospital in Singapore (2005) BMC Health Service Research, 5 (36); Fischera, T., Kraussb, C., Deep learning with long short-term memory networks for financial market predictions (2017) FAU Discussion Papers in Economics, 11; Gers, F.A., Schmidhuber, J., Cummins, F., Learning to forget: Continual prediction with lstm (2000) Neural Computation, 12 (10), pp. 2451-2471; Hochreiter, S., Schmidhuber, J., Long short-term memory (1997) Neural Computation, 9 (8), pp. 1735-1780; Huck, N., Pairs selection and outranking: An application to the s&p 100 index (2009) European Journal of Operational Research, 196 (2), pp. 819-825; Hyndman, R.J., Athanasopoulos, G., (2014) Forecasting: Principles and Practice, , OTexts; Hyndman, R.J., (2014) Variations on Rolling Forecasts, , https:\/\/robjhyndman.com\/hyndsight\/rolling-forecasts\/; Kane, M.J., Price, N., Scotch, M., Rabinowitz, P., Comparison of arima and random forest time series models for prediction of avian influenza h5n1 outbreaks (2014) BMC Bioinformatics, 15 (1); Khashei, M., Bijari, M., A novel hybridization of artificial neural networks and arima models for time series forecasting (2011) Applied Soft Computing, 11 (2), pp. 2664-2675; Krauss, C., Do, X.A., Huck, N., (2016) Deep Neural Networks, Gradientboosted Trees, Random Forests: Statistical Arbitrage on the s&p 500, , FAU Discussion Papers in Economics 03\/2016, Friedrich-Alexander University Erlangen-Nuremberg, Institute for Economics; Lee, S.I., Seong Joon Yoo, S.J., A deep efficient frontier method for optimal investments (2017) Department of Computer Engineering, , Sejong University, Seoul, 05006, Republic of Korea; Patterson, J., (2017) Deep Learning: A Practitioner's Approach, , OReilly Media; Schmidhuber, J., Deep learning in neural networks: An overview (2015) Neural Networks, 61, pp. 85-117. , bibitemSima-2018; Siami-Namini, A.S., Muhammad, D., Fahimullah, F., The short and long run effects of selected variables on tax revenue-A case study (2018) Applied Economics and Finance, 5 (5), pp. 23-32; Siami-Namini, S., Hudson, D., Trindade, A., Commodity price volatility and u.s. monetary policy: The overshooting hypothesis of agricultural commodity prices (2017) Agricultural and Applied Economics Association (AAEA) Annual Meeting; Siami-Namini, S., Hudson, D., Inflation and income inequality in developed and developing countries (2017) Southern Economics Association Conference; Siami-Namini, S., Hudson, D., The impacts of sector growth and monetary policy on income inequality in developing countries (2017) Available at SSRN; Tavakoli, N., Dai, D., Chen, Y., Log-assisted straggler-aware I\/O scheduler for high-end computing (2016) 45th International Conference on Parallel Processing Workshops (ICPPW)"}
{"Authors":"Bahrpeyma F., Roantree M., McCarren A.","Author(s) ID":"55959195700;6602546023;55894976400;","Title":"Multistep-ahead prediction: A comparison of analytical and algorithmic approaches","Year":2018,"Source title":"Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)","Volume":"11031 LNCS","Issue":null,"Art. No.":null,"Page start":345.0,"Page end":354.0,"Page count":null,"Cited by":1.0,"DOI":"10.1007\/978-3-319-98539-8_26","Affiliations":"Insight Centre for Data Analytics, School of Computing, Dublin City University, Dublin 9, Ireland","Document Type":"Conference Paper","Access Type":null,"Source":"Scopus","EID":"2-s2.0-85052879308","Abstract":"This paper presents a novel framework for the demystification of convolutional deep learning models for time-series analysis. This is a step toward making informed\/explainable decisions in the domain of time series, powered by deep learning. There have been numerous efforts to increase the interpretability of image-centric deep neural network models, where the learned features are more intuitive to visualize. Visualization in the domain of time series is significantly challenging, as there is no direct interpretation of the filters and inputs compared with the imaging modality. In addition, a little or no concentration has been devoted to the development of such tools in the domain of time series in the past. TSViz provides possibilities to explore and analyze the network from different dimensions at different levels of abstraction, which includes the identification of the parts of the input that were responsible for a particular prediction (including per filter saliency), importance of the different filters present in the network, notion of diversity present in the network through filter clustering, understanding of the main sources of variation learned by the network through inverse optimization, and analysis of the network's robustness against adversarial noise. As a sanity check for the computed influence values, we demonstrate our results on pruning of neural networks based on the computed influence information. These representations allow the user to better understand the network so that the acceptability of these deep models for time-series analysis can be enhanced. This is extremely important in domains, such as finance, industry 4.0, self-driving cars, health care, and counter-terrorism, where reasons for reaching a particular prediction are equally important as the prediction itself. We assess the proposed framework for interpretability with a set of desirable properties essential for any method in this direction. \u00a9 2019 IEEE.","Author Keywords":"convolutional neural networks; Deep learning; demystification; feature importance; representation learning; time-series analysis; time-series forecasting; visualization","Index Keywords":"Convolution; Deep learning; Deep neural networks; Flow visualization; Forecasting; Harmonic analysis; Inverse problems; Neural networks; Terrorism; Visualization; Convolutional neural network; demystification; feature importance; representation learning; Time series forecasting; Time series analysis","References":"Krizhevsky, A., Sutskever, I., Hinton, G.E., ImageNet classification with deep convolutional neural networks (2012) Advances in Neural Information Processing Systems 25, pp. 1097-1105. , http:\/\/papers.nips.cc\/paper\/4824-imagenet-classification-with-deep-convolutional-neural-networks.pdf, F. C. N. Pereira, C. J. C. Burges, L. Bottou, and K. Q. Weinberger, Eds. Red Hook, NY, USA: Curran Associates, [Online]; Dahl, G., Ranzato, M., Mohamed, A.R., Hinton, G., Phone recognition with the mean-covariance restricted boltzmann machine (2010) Advances in Neural Information Processing Systems 23, pp. 469-477. , http:\/\/papers.nips.cc\/paper\/4169-phone-recognition-with-themean-covariance-restricted-boltzmann-machine.pdf, J. D. Lafferty, C. K. I. Williams, J. Shawe-Taylor, R. S. Zemel, and A. Culotta, Eds. Red Hook, NY, USA: Curran Associates, [Online]; Wu, Y., (2016) Google's Neural Machine Translation System: Bridging the Gap between Human and Machine Translation, , https:\/\/arxiv.org\/abs\/1609.08144, [Online]; Alvarez-Melis, D., Jaakkola, T.S., Towards robust interpretability with self-explaining neural networks (2018) Advances in Neural Information Processing Systems, pp. 7775-7784; Knight, W., (2017) MIT Technology Review: The Financial World Wants to Open AI's Black Boxes, , https:\/\/www.technologyreview.com\/s\/604122\/the-financial-world-wantsto-open-ais-black-boxes\/, (Apr.) [Online]; Yosinski, J., Clune, J., Nguyen, A., Fuchs, T., Lipson, H., Understanding neural networks through deep visualization (2015) Proc. ICML Workshop Deep Learn., pp. 1-9. , Jun; Zeiler, M.D., Fergus, R., Visualizing and understanding convolutional networks (2014) Proc. Eur. Conf. Comput. Vis., pp. 818-833. , Springer; Simonyan, K., Vedaldi, A., Zisserman, A., (2013) Deep Inside Convolutional Networks: Visualising Image Classification Models and Saliency Maps, , https:\/\/arxiv.org\/abs\/1312.6034, [Online]; Kumar, D., Taylor, G.W., Wong, A., (2017) Opening the Black Box of Financial AI with CLEAR-trade: A Class-enhanced Attentive Response Approach for Explaining and Visualizing Deep Learningdriven Stock Market Prediction, , https:\/\/arxiv.org\/abs\/1709.01574, (Sep.). [Online]; Tishby, N., Zaslavsky, N., Deep learning and the information bottleneck principle (2015) Proc. IEEE Inf. Theory Workshop (ITW), pp. 1-5; Zhang, C., Bengio, S., Hardt, M., Recht, B., Vinyals, O., (2016) Understanding Deep Learning Requires Rethinking Generalization, , https:\/\/arxiv.org\/abs\/1611.03530, [Online]; Goodfellow, I.J., Shlens, J., Szegedy, C., Explaining and harnessing adversarial examples (2015) Proc. Int. Conf. Learn. Representations, pp. 1-11. , https:\/\/arxiv.org\/abs\/1412.6572, Dec., [Online]; Kurakin, A., Goodfellow, I., Bengio, S., (2016) Adversarial Examples in the Physical World., , https:\/\/arxiv.org\/abs\/1607.02533, [Online]; Bach, S., Binder, A., Montavon, G., Klauschen, F., M\u00fcller, K.-R., Samek, W., On pixel-wise explanations for non-linear classifier decisions by layer-wise relevance propagation (2015) PLoS ONE, 10 (7). , Jul; Bojarski, M., (2017) Explaining How A Deep Neural Network Trained with End-to-end Learning Steers A Car., , https:\/\/arxiv.org\/abs\/1704.07911, [Online]; Girshick, R., Donahue, J., Darrell, T., Malik, J., Rich feature hierarchies for accurate object detection and semantic segmentation (2014) Proc. IEEE Conf. Comput. Vis. Pattern Recognit., pp. 580-587; Shrikumar, A., Greenside, P., Kundaje, A., Learning important features through propagating activation differences (2017) Proc. 34th Int. Conf. Mach. Learn., 70, pp. 3145-3153; Li, J., Monroe, W., Jurafsky, D., (2016) Understanding Neural Networks Through Representation Erasure., , https:\/\/arxiv.org\/abs\/1612.08220, [Online]; Koh, P.W., Liang, P., Understanding black-box predictions via influence functions (2017) Proc. 34th Int. Conf. Mach. Learn., pp. 1885-1894. , Aug; Montavon, G., Samek, W., M\u00fcller, K.-R., Methods for interpreting and understanding deep neural networks (2018) Digit. Signal Process, 73, pp. 1-15; Cortez, P., Rio, M., Rocha, M., Sousa, P., Multi-scale Internet traffic forecasting using neural networks and time series methods (2012) Expert Syst., 29 (2), pp. 143-155. , May; Rumelhart, D.E., Hinton, G.E., Williams, R.J., Learning representations by back-propagating errors (1986) Nature, 323, pp. 533-536. , Oct; Kim, J., Rohrbach, A., Darrell, T., Canny, J., Akata, Z., Textual explanations for self-driving vehicles (2018) Proc. Eur. Conf. Comput. Vis., pp. 563-578; Zintgraf, L.M., Cohen, T.S., Adel, T., Welling, M., (2017) Visualizing Deep Neural Network Decisions: Prediction Difference Analysis., , https:\/\/arxiv.org\/abs\/1702.04595, (Feb.). [Online]; Denil, M., Shakibi, B., Dinh, L., Ranzato, M., De Freitas, N., Predicting parameters in deep learning (2013) Advances in Neural Information Processing Systems, pp. 2148-2156; Salvador, S., Chan, P., Toward accurate dynamic time warping in linear time and space (2007) Intell. Data Anal., 11 (5), pp. 561-580. , Oct; Kannan, H., Kurakin, A., Goodfellow, I., (2018) Adversarial Logit Pairing., , https:\/\/arxiv.org\/abs\/1803.06373, [Online]; Carlini, N., Wagner, D., Towards evaluating the robustness of neural networks (2017) Proc. IEEE Symp. Secur. Privacy (SP), pp. 39-57; Molchanov, P., Tyree, S., Karras, T., Aila, T., Kautz, J., (2016) Pruning Convolutional Neural Networks for Resource Efficient Transfer Learning., , http:\/\/arxiv.org\/abs\/1611.06440, (Jan.). [Online]; Theis, L., Korshunova, I., Tejani, A., Husz\u00e1r, F., (2018) Faster Gaze Prediction with Dense Networks and Fisher Pruning., , https:\/\/arxiv.org\/abs\/1801.05787, [Online]; Alvarez-Melis, D., Jaakkola, T.S., (2018) On the Robustness of Interpretability Methods., , https:\/\/arxiv.org\/abs\/1806.08049, [Online]; Chollet, F., (2015) Keras, , https:\/\/github.com\/keras-team\/keras, [Online]; Abadi, M., (2015) TensorFlow: Large-Scale Machine Learning on Hetero- Geneous Systems, , https:\/\/www.tensorflow.org\/, [Online]; (2005) Unity Game Engine, , https:\/\/www.unity3d.com, [Online]"}
{"Authors":"Zhan X., Li Y., Li R., Gu X., Habimana O., Wang H.","Author(s) ID":"57203548515;55719078700;7404724385;13408314400;57203550502;57203550518;","Title":"Stock price prediction using time convolution long short-term memory network","Year":2018,"Source title":"Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)","Volume":"11061 LNAI","Issue":null,"Art. No.":null,"Page start":461.0,"Page end":468.0,"Page count":null,"Cited by":null,"DOI":"10.1007\/978-3-319-99365-2_41","Affiliations":"School of Computer Science and Technology, Huazhong University of Science and Technology, Wuhan, 430074, China","Document Type":"Conference Paper","Access Type":null,"Source":"Scopus","EID":"2-s2.0-85052234200","Abstract":"Stock market is considered chaotic, complex, volatile and dynamic. Undoubtedly, its prediction is one of the most challenging tasks in time series forecasting. Moreover existing Artificial Neural Network (ANN) approaches fail to provide encouraging results. Meanwhile advances in machine learning have presented favourable results for speech recognition, image classification and language processing. Methods applied in digital signal processing can be applied to stock data as both are time series. Similarly, learning outcome of this paper can be applied to speech time series data. Deep learning for stock prediction has been introduced in this paper and its performance is evaluated on Google stock price multimedia data (chart) from NASDAQ. The objective of this paper is to demonstrate that deep learning can improve stock market forecasting accuracy. For this, (2D) 2 PCA + Deep Neural Network (DNN) method is compared with state of the art method 2-Directional 2-Dimensional Principal Component Analysis (2D) 2 PCA + Radial Basis Function Neural Network (RBFNN). It is found that the proposed method is performing better than the existing method RBFNN with an improved accuracy of 4.8% for Hit Rate with a window size of 20. Also the results of the proposed model are compared with the Recurrent Neural Network (RNN) and it is found that the accuracy for Hit Rate is improved by 15.6%. The correlation coefficient between the actual and predicted return for DNN is 17.1% more than RBFNN and it is 43.4% better than RNN. \u00a9 2016, Springer Science+Business Media New York.","Author Keywords":"(2D) 2 PCA; Deep Learning; Multimedia; Neural Network; Radial Basis Function Neural Network; Regularization; Stock Prediction","Index Keywords":"Artificial intelligence; Commerce; Complex networks; Electronic trading; Finance; Financial markets; Forecasting; Functions; Image classification; Learning systems; Neural networks; Radial basis function networks; Recurrent neural networks; Signal processing; Speech recognition; Time series; (2D) <sup>2<\/sup> PCA; Deep learning; Multimedia; Radial basis function neural networks; Regularization; Stock predictions; Principal component analysis","References":"Atsalakis, G.S., Valavanis, K.P., Surveying stock market forecasting techniques--Part II: soft computing methods (2009) Expert Syst Appl, 36, pp. 5932-5941; Elman, J.L., Finding structure in time (1990) Cogn Sci, 14, pp. 179-211; Erhan, D., Bengio, Y., Courville, A., Manzagol, P.A., Vincent, P., Bengio, S., Why does unsupervised pre-training help deep learning? (2010) J Mach Learn Res, 11 (Feb), pp. 625-660; Guo, Z., Wang, H., Yang, J., Miller, D.J., A stock market forecasting model combining two-directional two-dimensional principal component analysis and radial basis function neural network (2015) PLoS One, 10; Gupta, P., (2015) Deep Learning - Regularisation; Guresen, E., Kayakutlu, G., Daim, T.U., Using artificial neural network models in stock market index prediction (2011) Expert Syst Appl, 38, pp. 10389-10397; Hinton, G.E., Osindero, S., Teh, Y.-W., A fast learning algorithm for deep belief nets (2006) Neural Comput, 18, pp. 1527-1554; Hinton, G.E., Salakhutdinov, R.R., Reducing the dimensionality of data with neural networks (2006) Science, 313 (80), pp. 504-507; Huang, C.J., Yang, D.X., Chuang, Y.T., Application of wrapper approach and composite classifier to the stock trend prediction (2008) Expert Syst Appl, 34, pp. 2870-2878; Krizhevsky, A., Sutskever, I., Hinton, G.E., Imagenet classification with deep convolutional neural networks (2012) Adv. Neural Inf. Process. Syst, pp. 1097-1105; Kuremoto, T., Kimura, S., Kobayashi, K., Obayashi, M., Time series forecasting using a deep belief network with restricted Boltzmann machines (2014) Neurocomputing, 137, pp. 47-56; Kuremoto, T., Obayashi, M., Kobayashi, K., Forecast chaotic time series data by DBNs (2014) Image Signal Process. (CISP), 2014 7th. Int Congr, pp. 1130-1135; Kwon, Y.K., Moon, B.R., A hybrid neurogenetic approach for stock forecasting (2007) IEEE Trans Neural Netw, 18, pp. 851-864; Larochelle, H., Bengio, Y., Louradour, J., Lamblin, P., Exploring strategies for training deep neural networks (2009) J Mach Learn Res, 10, pp. 1-40; Le Roux, N., Bengio, Y., Deep belief networks are compact universal approximators (2010) Neural Comput, 22, pp. 2192-2207; Lendasse, A., de Bodt, E., Wertz, V., Verleysen, M., Non-linear financial time series forecasting-Application to the Bel 20 stock market index (2000) Eur J Econ Soc Syst, 14, pp. 81-91; Malkiel, B.G., (2007) A random walk down Wall Street: the time-tested strategy for successful investing, , WW Norton & Company; Mohamed, A., Sainath, T.N., Dahl, G., Deep belief networks using discriminative features for phone recognition. In: 2011 I.E. Int. Conf. Acoust. speech (2011) Signal Process, pp. 5060-5063; Murphy, J.J., (1999) Technical analysis of the financial markets: A comprehensive guide to trading methods and applications, , Penguin; Pan, H., Tilakaratne, C., Yearwood, J., Predicting the Australian stock market index using neural networks exploiting dynamical swings and intermarket influences (2003) Australas. Jt. Conf. Artif. Intell., pp. 327-338; Patel, J., Shah, S., Thakkar, P., Kotecha, K., Predicting stock and stock price index movement using trend deterministic data preparation and machine learning techniques (2015) Expert Syst Appl, 42, pp. 259-268; Patel, J., Shah, S., Thakkar, P., Kotecha, K., Predicting stock market index using fusion of machine learning techniques (2015) Expert Syst Appl, 42, pp. 2162-2172; Shen, W., Guo, X., Wu, C., Wu, D., Forecasting stock indices using radial basis function neural networks optimized by artificial fish swarm algorithm (2011) Knowledge-Based Syst, 24, pp. 378-385; Situngkir, H., Surya, Y., Neural network revisited: perception on modified Poincare map of financial time-series data (2004) Phys A Stat Mech Appl, 344, pp. 100-103; Sun, F., Toh, K.-A., Romay, M.G., Mao, K., (2014) Extreme Learning Machines 2013: Algorithms and Applications, , Springer; Sutskever, I., Hinton, G.E., Deep, narrow sigmoid belief networks are universal approximators (2008) Neural Comput, 20, pp. 2629-2636; Takeuchi, L., Lee, Y.-Y.A., (2013) Applying Deep Learning to Enhance Momentum Trading Strategies in Stocks, , http:\/\/cs229.stanford.edu\/proj2013\/TakeuchiLeeApplyingDeepLearningToEnhanceMomentumTradingStrategiesInStocks.pdf; Teixeira, L.A., De Oliveira, A.L.I., A method for automatic stock trading combining technical analysis and nearest neighbor classification (2010) Expert Syst Appl, 37, pp. 6885-6890; White, H., Economic prediction using neural networks: the case of IBM daily stock returns (1988) IEEE Int Conf. Neural Networks, pp. 451-458; Yu, D., Deng, L., Wang, S., Learning in the deep-structured conditional random fields (2009) Proc. NIPS Work, pp. 1-8; Yu, K., Xu, W., Gong, Y., Deep learning with kernel regularization for visual recognition (2009) Advances in Neural Information Processing Systems, pp. 1889-1896; Zeiler, M.D., (2012) ADADELTA: an adaptive learning rate method. arXiv Prepr. arXiv1212.5701; Zhang, D., Zhou, Z., (2D)2PCA: 2-Directional 2-Dimensional PCA for Efficient Face Representation and Recognition (2005) Neurocomputing, 69, pp. 224-231; Zuo, Z., Wang, G., Learning discriminative hierarchical features for object recognition (2014) IEEE Sig Proc Lett, 21, pp. 1159-1163"}
{"Authors":"Sun H., Guo C., Xu J., Zhu J., Zhang C.","Author(s) ID":"57202469424;35731095300;56115674400;57194067799;57194074432;","Title":"A combined model for time series prediction in financial markets","Year":2018,"Source title":"Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)","Volume":"10988 LNCS","Issue":null,"Art. No.":null,"Page start":138.0,"Page end":147.0,"Page count":null,"Cited by":null,"DOI":"10.1007\/978-3-319-96893-3_11","Affiliations":"College of Computer and Control of Engineering, Nankai University, Tianjin, China","Document Type":"Conference Paper","Access Type":null,"Source":"Scopus","EID":"2-s2.0-85051127390","Abstract":"Using a large-scale Deep Learning approach applied to a high-frequency database containing billions of market quotes and transactions for US equities, we uncover nonparametric evidence for the existence of a universal and stationary relation between order flow history and the direction of price moves. The universal price formation model exhibits a remarkably stable out-of-sample accuracy across a wide range of stocks and time periods. Interestingly, these results also hold for stocks which are not part of the training sample, showing that the relations captured by the model are universal and not asset-specific. The universal model\u2014trained on data from all stocks\u2014outperforms asset-specific models trained on time series of any given stock. This weighs in favor of pooling together financial data from various stocks, rather than designing asset- or sector-specific models, as is currently commonly done. Standard data normalizations based on volatility, price level or average spread, or partitioning the training data into sectors or categories such as large\/small tick stocks, do not improve training results. On the other hand, inclusion of price and order flow history over many past observations improves forecast accuracy, indicating that there is path-dependence in price dynamics. \u00a9 2019, \u00a9 2019 Informa UK Limited, trading as Taylor & Francis Group.","Author Keywords":"Deep learning; Financial econometrics; High-frequency data; Intraday data; Limit order book; Machine learning; Market microstructure; Price formation","Index Keywords":null,"References":"Andersen, T., Bondarenko, O., Obizhaeva, A., Kyle, P., (2018), Intraday trading invariance the E-Mini S&P 500 futures market. Working Paper, and, Social Science Research Network; Bacry, E., Kozhemyak, A., Muzy, J., Continuous cascade models for asset returns (2008) J. Econ. Dyn. Control, 32 (1), pp. 156-199; Bengio, Y., LeCun, Y., Hinton, G., Deep learning (2015) Nature, 521, pp. 436-444; Benzaquen, M., Donier, J., Bouchaud, J.P., Unravelling the trading invariance hypothesis (2016) Market Microstruct. Liq., 2; Bouchaud, J., Gefen, Y., Potters, M., Wyart, M., Fluctuations and response in financial markets: The subtle nature of \u2018random\u2019 price changes (2004) Quant. Finance, 4 (2), pp. 176-190; Cont, R., Empirical properties of asset returns: Stylized facts and statistical issues (2001) Quant. Finance, 1 (2), pp. 223-236; Cont, R., Statistical modeling of high frequency financial data: Facts, models and challenges (2011) IEEE Sig. Process., 28, pp. 16-25; Cont, R., de Larrard, A., Price dynamics in a Markovian limit order market (2013) SIAM J. Financial Math., 4 (1), pp. 1-25; Cont, R., Kukanov, A., Stoikov, S., The price impact of order book events (2014) J. Financial Econom., 12 (1), pp. 47-88; Cont, R., Stoikov, S., Talreja, R., A stochastic model for order book dynamics (2010) Oper. Res., 58 (3), pp. 549-563; Creamer, S., Freund, Y., Automated trading with boosting and expert weighting (2007) Quant. Finance, 10 (4), pp. 401-420; Dixon, M., Sequence classification of the limit order book using recurrent neural networks (2018) J. Comput. Sci., 24 (1), pp. 277-286; Dixon, M., A high frequency trade execution model for supervised learning (2018) High Freq., 1 (1), pp. 32-52; Figueroa-Lopez, J., Chavez-Casillas, J., One-level limit order book model with memory and variable spread (2017) Stoch. Process. Their. Appl., 127, pp. 2447-2481; Gers, F.A., Schmidhuber, J., Cummins, F., Learning to forget: Continual prediction with LSTM (2000) Neural Comput., 12 (10), pp. 2451-2471; Goodfellow, I., Bengio, Y., Courville, A., (2017) Deep Learning, , MIT Press, Cambridge, MA; Hasbrouck, J., (2007) Empirical Market Microstructure: The Institutions, Economics, and Econometrics of Securities Trading, , Oxford University Press, Oxford; Huang, R., Polak, T., (2011), LOBSTER: Limit Order Book Reconstruction System, Technical documentation; Hornik, K., Stinchcombe, M., White, H., Multilayer feedforward networks are universal approximators (1989) Neural Netw., 2 (5), pp. 359-366; Kolanovic, M., Krishnamachari, R.T., (2017), Big data and AI strategies: Machine learning and alternative data approach to investing. J.P. Morgan Global Quantitative & Derivatives Strategy Report; Kyle, A.S., Obizhaeva, A.A., Market microstructure invariance: Empirical hypotheses (2016) Econometrica, 84 (4), pp. 1345-1404; LeCun, Y., Bengio, Y., Hinton, G., Deep Learning (2015) Nature, 521 (7553), p. 436; Lillo, F., Farmer, J., The long memory of the efficient market (2004) Stud. Nonlinear Dyn. Econom., 8 (3); Mandelbrot, B., Calvet, L., Fisher, A., (1997), The multifractal model of asset returns. Cowles Foundation Discussion Paper 1164; Patzelt, F., Bouchaud, J.P., Universal scaling and nonlinearity of aggregate price impact in financial markets (2017) Phys. Rev. E, 97 (1); Sirignano, J.A., Deep learning for limit order books (2019) Quant. Finance, 19 (4), pp. 549-570; Sirignano, J., Sadhwani, A., Chen, L., Giesecke, K., (2016), Deep learning for mortgage risk; Taranto, D.E., Bormetti, G., Lillo, F., The adaptive nature of liquidity taking in limit order books (2014) J. Stat. Mech.: Theory Exp., 6 (3), p. P06002; Toth, B., Eisler, Z., Bouchaud, J., The short-term price impact of trades is universal (2017) Market Microstruct. Liq., 3 (2)"}
{"Authors":"Lu Z., Long W., Guo Y.","Author(s) ID":"57207322594;36792418900;57202708122;","Title":"Extreme Market Prediction for Trading Signal with Deep Recurrent Neural Network","Year":2018,"Source title":"Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)","Volume":"10861 LNCS","Issue":null,"Art. No.":null,"Page start":410.0,"Page end":418.0,"Page count":null,"Cited by":null,"DOI":"10.1007\/978-3-319-93701-4_31","Affiliations":"School of Economics and Management, University of Chinese Academy of Sciences, Beijing, 100190, China; Research Center on Fictitious Economy and Data Science, Chinese Academy of Sciences, Beijing, 100190, China; Key Laboratory of Big Data Mining and Knowledge Management, Chinese Academy of Sciences, Beijing, 100190, China","Document Type":"Conference Paper","Access Type":null,"Source":"Scopus","EID":"2-s2.0-85049119150","Abstract":"In recent years, due to the technological improvements in computers' hardware and enhancements in the machine learning techniques, there are two increasing approaches for problem-solving as the use of 'Big Data' and 'Parallel Processing'. Especially with the emergence of Deep Learning algorithms which can be executed parallelly on multi-core computing devices such as GPUs and CPUs, lots of real-world problems are resolved with these approaches. One of the most critical application areas in the Financial Market especially sits on Stock Markets. In this area, the aim is trying to predict the future value of a specific stock by looking at its previous financial data on the exchange process in the market. In this paper, we proposed a system that uses a Deep Learning based approach for training and constructing a knowledge base on a specific stock such as 'IBM'. We get time series values of the stock from the New York Stock Exchange which starts from 1968 up to 2018. Experimental results showed that this approach produces very good forecasting for specific stocks. \u00a9 2019 IEEE.","Author Keywords":"Big data; Deep learning; Forecasting; Stock exchange","Index Keywords":"Big data; Biomedical engineering; Commerce; Data Analytics; Electronic medical equipment; Engineering education; Financial markets; Forecasting; Knowledge based systems; Learning algorithms; Problem solving; Program processors; Critical applications; Learning-based approach; Machine learning techniques; Multi-core computing; New York Stock Exchange; Parallel processing; Stock exchange; Technological improvements; Deep learning","References":"Korczak, J., Hernes, M., Deep learning for financial time series forecasting in a-trader system (2017) Proceedings of the 2017 Federated Conference on Computer Science and Information Systems; Ar\u00e9valo, A., Ni\u00f1o, J., Hern\u00e1ndez, G., Sandoval, J., High-frequency trading strategy based on deep neural networks (2016) Intelligent Computing Methodologies Lecture Notes in Computer Science, pp. 424-436; Hasan, A., Kalipsiz, O., Akyokus, S., Predicting financial market in big data: Deep learning (2017) 2017 International Conference on Computer Science and Engineering (UBMK); Zhou, X., Pan, Z., Hu, G., Tang, S., Zhao, C., Stock market prediction on high-frequency data using generative adversarial nets (2018) Mathematical Problems in Engineering, 2018, pp. 1-11; Ganesh, P., Rakheja, P., Deep neural networks in high-frequency trading (2018) IEEE; Gunduz, H., Cataltepe, Z., Yaslan, Y., Stock market direction prediction using deep neural networks (2017) 2017 25th Signal Processing and Communications Applications Conference (SIU); Pyo, S., Lee, J., Cha, M., Jang, H., Predictability of machine learning techniques to forecast the trends of market index prices: Hypothesis testing for the Korean stock markets (2017) Plos One, 12 (11); Marjanovic, B., (2017) Huge Stock Market Dataset, , https:\/\/www.kaggle.com\/borismarjanovic\/price-volume-data-for-all-usstocks-etfs, 11.10. Retrieved from; Hochreiter, S., Schmidhuber, J., Long short-term memory (1997) Neural Computation, 9 (8), pp. 1735-1780; Karatas, G., Demir, O., Sahingoz, O.K., Deep learning in intrusion detection systems (2018) 2018 International Congress on Big Data, Deep Learning and Fighting Cyber Terrorism (IBIGDELFT), pp. 113-116. , Ankara, Turkey; Baykal, S.I., Bulut, D., Sahingoz, O.K., Comparing deep learning performance on BigData by using CPUs and GPUs (2018) 2018 Electric Electronics, Computer Science, Biomedical Engineerings' Meeting (EBBT), pp. 1-6. , Istanbul"}
{"Authors":"Ar\u00e9valo A., Nino J., Le\u00f3n D., Hernandez G., Sandoval J.","Author(s) ID":"57190281278;57190225431;57195350225;35897064300;56311250400;","Title":"Deep Learning and Wavelets for High-Frequency Price Forecasting","Year":2018,"Source title":"Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)","Volume":"10861 LNCS","Issue":null,"Art. No.":null,"Page start":385.0,"Page end":399.0,"Page count":null,"Cited by":1.0,"DOI":"10.1007\/978-3-319-93701-4_29","Affiliations":"Universidad Nacional de Colombia, Bogot\u00e1, Colombia; Universidad Externado de Colombia, Bogot\u00e1, Colombia","Document Type":"Conference Paper","Access Type":null,"Source":"Scopus","EID":"2-s2.0-85049058462","Abstract":"Time series prediction is not easy to achieve high accuracy. non-linear and unstable characteristics make the time series prediction difficult. The variety of dataset make the prediction result debatable. In order to solve this problem, in this paper we propose a deep learning prediction method based on decomposition, reconstruction and combination, which combines ways of communication field. The model is decomposed by Empirical Mode Decomposition, Principal Component Analysis and Long Short-Term Memory networks (EPL below). And also, the proposed interval EPL (IEPL below) improve and consummate the EPL model. The EPL and IEPL experiment results will bring average 5% higher accuracy than that of existing research. \u00a9 2018, Springer International Publishing AG, part of Springer Nature.","Author Keywords":"Deep learning; EPL; IEPL; Time series prediction","Index Keywords":"Deep learning; Financial data processing; Financial markets; Forecasting; Information management; Principal component analysis; Time series; Combined model; Communication fields; Empirical Mode Decomposition; High-accuracy; IEPL; Prediction methods; Short term memory; Time series prediction; Big data","References":"Hu, J., Zhang, L., Cai, Z., An intelligent fault diagnosis system for process plant using a functional HAZOP and DBN integrated methodology (2015) Proc. Eng. Appl. Artif. Intell., 45, pp. 119-135; Cao, L., Huang, W., Sun, F., Building feature space of extreme learning machine with sparse denoising stacked-autoencoder (2016) Neurocomputing, 174A, pp. 60-71; Sezer, O.B., Ozbayoglu, M., Dogdu, E., A Deep neural-network based stock trading system based on evolutionary optimized technical analysis parameters (2017) Proc. Comput. Sci., 114, pp. 473-480; Furlaneto, D.C., Oliveira, L.S., Menotti, D., Bias effect on predicting market trends with EMD (2017) Expert Syst. Appl., 82, pp. 16-29; Lahmiri, S., Wavelet low-and high-frequency components as features for predicting stock prices with backpropagation neural networks (2014) J. King Saud Univ. Comput. Inf. Sci., 26 (2), pp. 218-227; Ismail, A., Jeng, D.-S., Zhang, L.L., An optimized product-unit neural network with a novel PSO-BP hybrid training algorithm: Applications to load-deformation analysis of axially loaded piles (2013) Eng. Appl. Artif. Intell., 26 (10), pp. 2305-2314; P\u00e9rez-Ortiz, J., Gers, F.A., Eck, D., Kalman filters improve LSTM network performance in problems unsolvable by traditional recurrent nets (2003) Neural Netw, 16 (2), pp. 241-250"}
{"Authors":"Zhang X., Tan Y.","Author(s) ID":"57202682531;56098810800;","Title":"Deep stock ranker: A LSTM neural network model for stock selection","Year":2018,"Source title":"Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)","Volume":"10943 LNCS","Issue":null,"Art. No.":null,"Page start":614.0,"Page end":623.0,"Page count":null,"Cited by":null,"DOI":"10.1007\/978-3-319-93803-5_58","Affiliations":"Key Laboratory of Machine Perception (MOE), Department of Machine Intelligence, School of Electronics Engineering and Computer Science, Peking University, Beijing, 100871, China","Document Type":"Conference Paper","Access Type":null,"Source":"Scopus","EID":"2-s2.0-85049044403","Abstract":"A hybrid ensemble learning approach is proposed to forecast financial time series combining AdaBoost algorithm and Long Short-Term Memory (LSTM) network. Firstly, by using AdaBoost algorithm the database is trained to get the training samples. Secondly, the LSTM is utilized to forecast each training sample separately. Thirdly, AdaBoost algorithm is used to integrate the forecasting results of all the LSTM predictors to generate the ensemble results. Two major daily exchange rate datasets and two stock market index datasets are selected for model evaluation and comparison. The empirical results demonstrate that the proposed AdaBoost-LSTM ensemble learning approach outperforms some other single forecasting models and ensemble learning approaches. This suggests that the AdaBoost-LSTM ensemble learning approach is a highly promising approach for financial time series data forecasting, especially for the time series data with nonlinearity and irregularity, such as exchange rates and stock indexes. \u00a9 2018, Springer International Publishing AG, part of Springer Nature.","Author Keywords":"AdaBoost algorithm; Ensemble learning; Financial time series forecasting; Long short-term memory network","Index Keywords":"Adaptive boosting; Brain; Electronic trading; Finance; Forecasting; Sampling; Time series; AdaBoost algorithm; Ensemble learning; Ensemble learning approach; Financial time series; Financial time series forecasting; Forecasting models; Short term memory; Stock market index; Long short-term memory","References":"Chortareas, G., Jiang, Y., Nankervis, J.C., Forecasting exchange rate volatility using high-frequency data: Is the euro different? (2011) Int. J. Forecast., 27 (4), pp. 1089-1107; Carriero, A., Kapetanios, G., Marcellino, M., Forecasting exchange rates with a large Bayesian VAR (2009) Int. J. Forecast., 25 (2), pp. 400-417; Moosa, I.A., Vaz, J.J., Cointegration, error correction and exchange rate forecasting (2016) J. Int. Financ. Markets Institutions Money, 44, pp. 21-34; Galeshchuk, S., Neural networks performance in exchange rate prediction (2016) Neurocomputing, 172, pp. 446-452; Zhang, G., Hu, M.Y., Neural network forecasting of the British pound\/US dollar exchange rate (1998) Omega, 26 (4), pp. 495-506; Huang, S., Chuang, P., Wu, C., Lai, H., Chaos-based support vector regressions for exchange rate forecasting (2010) Expert Syst. Appl., 37 (12), pp. 8590-8598; Shen, F., Chao, J., Zhao, J., Forecasting exchange rate using deep belief networks and conjugate gradient method (2015) Neurocomputing, 167, pp. 243-253; Chen, A., Leung, M.T., Regression neural network for error correction in foreign exchange forecasting and trading (2004) Comput. Oper. Res., 31 (7), pp. 1049-1068; Nag, A.K., Mitra, A., Forecasting daily foreign exchange rates using genetically optimized neural networks (2002) J. Forecast., 21 (7), pp. 501-511; Sermpinis, G., Stasinakis, C., Theofilatos, K., Karathanasopoulos, A., Modeling, forecasting and trading the EUR exchange rates with hybrid rolling genetic algorithms\u2014Support vector regression forecast combinations (2015) Eur. J. Oper. Res., 247 (3), pp. 831-846; Sermpinis, G., Theofilatos, K., Karathanasopoulos, A., Georgopoulos, E.F., Dunis, C., Forecasting foreign exchange rates with adaptive neural networks using radial-basis functions and particle swarm optimization (2013) Eur. J. Oper. Res., 225 (3), pp. 528-540; Yu, L., Wang, S., Lai, K.K., A novel nonlinear ensemble forecasting model incorporating GLAR and ANN for foreign exchange rates (2005) Comput. Oper. Res., 32 (10), pp. 2523-2541; Yu, L., Wang, S., Lai, K.K., Forecasting crude oil price with an EMD-based neural network ensemble learning paradigm (2008) Energy Econ, 30 (5), pp. 2623-2635; Plakandaras, V., Papadimitriou, T., Gogas, P., Forecasting daily and monthly exchange rates with machine learning techniques (2015) J. Forecast., 34 (7), pp. 560-573; Yu, L., Wang, S., Lai, K.K., A neural-network-based nonlinear metamodeling approach to financial time series forecasting (2009) Appl. Soft Comput., 9 (2), pp. 563-574; Yu, L., Wang, Z., Tang, L., A decomposition-ensemble model with data-characteristic-driven reconstruction for crude oil price forecasting (2015) Appl. Energ., 156, pp. 251-267; Tang, L., Yu, L., Wang, S., Li, J., Wang, S., A novel hybrid ensemble learning paradigm for nuclear energy consumption forecasting (2012) Appl. Energ., 93, pp. 432-443; Niu, M., Wang, Y., Sun, S., Li, Y., A novel hybrid decomposition-and-ensemble model based on CEEMD and GWO for short-term PM2.5 concentration forecasting (2016) Atmos. Environ., 134, pp. 168-180"}
{"Authors":"Sun S., Wei Y., Wang S.","Author(s) ID":"57193552421;57194829641;35195168500;","Title":"AdaBoost-LSTM Ensemble Learning for Financial Time Series Forecasting","Year":2018,"Source title":"Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)","Volume":"10862 LNCS","Issue":null,"Art. No.":null,"Page start":590.0,"Page end":597.0,"Page count":null,"Cited by":1.0,"DOI":"10.1007\/978-3-319-93713-7_55","Affiliations":"Academy of Mathematics and Systems Science, Chinese Academy of Sciences, Beijing, 100190, China; School of Economics and Management, University of Chinese Academy of Sciences, Beijing, 100190, China; Center for Forecasting Science, Chinese Academy of Sciences, Beijing, 100190, China","Document Type":"Conference Paper","Access Type":null,"Source":"Scopus","EID":"2-s2.0-85049006277","Abstract":"Predicting the trend of stock market prices is a very challengingtask, in that stock markets are complicated and can be influencedby a variety of factors. Despite the great difficulty, predicting thetrend of stock market prices accurately is very meaningful and canbring a large amount of profit. In the past several decades, a lot ofstudies have been done on this problem. But most of the methodstake only the historic prices data as the input, which is not enoughfor such a complicated problem. In this paper, a hybrid methodtaking both historic prices and the news as input is proposed. Thehybrid model combines the best of two kinds of networks-RNN-LSTM for time series data and CNN for abstract highdimensional data. These two different kinds of networks arecombined together to make a prediction. A set of experimentshave been carried out to show the performance of the proposedmethod. The result obtained is promising, and the propose methodachieves a great degree of accuracy in prediction and outperformsthe baselines a lot. \u00a9 2018 Association for Computing Machinery.","Author Keywords":"Combined data; Convolution neural network; Hybrid algorithm; Long-short term memory; Stock market prediction","Index Keywords":"Commerce; Costs; Electronic trading; Financial markets; Forecasting; Learning systems; Combined data; Convolution neural network; Degree of accuracy; High dimensional data; Hybrid algorithms; Stock market prediction; Stock market prices; Time-series data; Long short-term memory","References":"Billah, M., Waheed, S., Stock market prediction using an improved training algorithm of neural network (2017) International Conference on Electrical, Computer & Telecommunication Engineering. 1-4. IEEE; Nelson, D.M.Q., Pereira, A.C.M., Oliveira, R.A.D., Stock market's price movement prediction with LSTM neural networks (2017) International Joint Conference on Neural Networks. 1419-1426. IEEE; Musgrave, G.L., A random walk down wall street (1997) A Random Walk Down Wall Street, 40 (1), pp. 18-23; Chen, K., Zhou, Y., Dai, F., A LSTM-based method for stock returns prediction: A case study of China stock market (2015) IEEE International Conference on Big Data, pp. 2823-2824. , IEEE; Mahalakshmi, G., Sridevi, S., Rajaram, S., A survey on forecasting of time series data (2016) International Conference on Computing Technologies and Intelligent Data Engineering. 1-8. IEEE; Arasu, B.S., Jeevananthan, M., Thamaraiselvan, N., Janarthanan, B., Performances of data mining techniques in forecasting stock index-evidence from India and US (2014) Journal of the National Science Foundation of Sri Lanka, 42 (2); Yoo, P.D., Kim, M.H., Jan, T., Machine learning techniques and use of event information for stock market prediction: A survey and evaluation (2005) Computational Intelligence for Modelling, Control and Automation, 2005 and International Conference on Intelligent Agents, Web Technologies and Internet Commerce, International Conference On. 2, 835-841. IEEE; Qiu, M., Li, C., Song, Y., Application of the artifical neural network in predicting the direction of stock market index (2016) International Conference on Complex, Intelligent, and Software Intensive Systems. 219-223. IEEE; Guo, T., Xu, Z., Yao, X., Chen, H., Aberer, K., Funaya, K., Robust online time series prediction with recurrent neural networks (2016) IEEE International Conference on Data Science and Advanced Analytics. 816-825. IEEE; Bernal, O., Fok, S., Pidaparthi, R., Financial market time series prediction with recurrent neural networks (2012) Citeseer; Jordan, M.I., Serial order: A parallel distributed processing approach (1997) Advances in Psychology, 121, pp. 417-495; Hochreiter, S., Schmidhuber, J., Long short-term memory (1997) Neural Computation, 9 (8), p. 1735; Zaremba, W., Sutskever, I., Vinyals, O., (2014) Recurrent Neural Network Regularization, , arXiv preprint arXiv:1409.2329; Kim, Y., (2014) Convolutional Neural Networks for Sentence Classification, , arXiv preprint arXiv:1408.5882; Le, Q.V., Mikolov, T., Distributed representations of sentences and documents (2014) Proceedings of the 31st International Conference on Machine Learning (ICML-14, pp. 1188-1196; Hassan, A., Mahmood, A., Deep learning for sentence classification (2017) IEEE Long Island Systems, Applications and Technology Conference. 1-5. IEEE; Graves, A., (2012) Supervised Sequence Labelling with Recurrent Neural Networks, , Springer Berlin Heidelber"}
{"Authors":"Di Persio L., Honchar O.","Author(s) ID":"57203636440;57192153071;","Title":"Multitask machine learning for financial forecasting","Year":2018,"Source title":"International Journal of Circuits, Systems and Signal Processing","Volume":"12","Issue":null,"Art. No.":null,"Page start":444.0,"Page end":451.0,"Page count":null,"Cited by":null,"DOI":null,"Affiliations":"Dept. of Computer Science, University of Verona, Strada le Grazie 15, Verona, 37134, Italy","Document Type":"Article","Access Type":null,"Source":"Scopus","EID":"2-s2.0-85046646074","Abstract":"We propose a spatio-temporal model for predicting anomaly price movements in the Stock Exchange of Thailand (SET). The model used a deep neural network classification algorithm that has a time series of of limit order books (LOB) as an input. There were three output classes: anomaly price uptrend, anomaly price downtrend, and normal price movements. We performed experiments to compare the efficiency among convolutional neural network model, Long short-term memory model, and the combination of both in order to classify anomaly price movements. The results of the experiment showed that the combination of both convolutional layers and Long short-term memory model had the highest accuracy with 74.55% for predicting abnormal price movements. \u00a9 2019 IEEE.","Author Keywords":"anomaly detection; deep neural network; spatiotemporal model","Index Keywords":"Anomaly detection; Brain; Convolution; Correlation theory; Electronic trading; Financial markets; Long short-term memory; Robotics; Convolutional neural network; Limit order book; Neural network classification; Price movement; Short term memory; Spatio-temporal models; Stock Exchange of Thailand; Deep neural networks","References":"Dixon, M., Sequence classification of the limit order book using recurrent neural networks (2018) Journal of Computational, 24, pp. 277-286; Kercheval, A.N., Zhang, Y., Modeling high-frequency limit order book dynamics with support vector machines (2015) Journal Quantitative Finance, 15, pp. 1315-1329; Sirignano, J.A., (2016) Deep Learning for Limit Order Books, , arXiv preprint; Park, B., Roy, B.V., Adaptive execution: Exploration and learning of price impact (2015) Operations Research, 63 (5), pp. 1058-1076; Cao, Y., Li, Y., Adaptive hidden markov model with anomaly states for price manipulation detection (2015) IEEE Trans. on Neural and Learning Systems, 26 (2), pp. 310-330; Abadi, M., Tensorflow: A system for largescale machine learning (2016) Proceedings of the 12th USENIX Conference on Operating Systems Design and Implementation, OSDI'16, pp. 265-283; \u00d6g\u00fct, H., Doganay, M.M., Aktas, R., Detecting stock-price manipulation in an emerging market: The case of Turkey (2009) Expert Syst. Appl., 36 (9), pp. 11944-11949"}
{"Authors":"Dixon M.","Author(s) ID":"55982004900;","Title":"Sequence classification of the limit order book using recurrent neural networks","Year":2018,"Source title":"Journal of Computational Science","Volume":"24","Issue":null,"Art. No.":null,"Page start":277.0,"Page end":286.0,"Page count":null,"Cited by":15.0,"DOI":"10.1016\/j.jocs.2017.08.018","Affiliations":"Stuart School of Business, Illinois Institute of Technology, 10 West 35th Street, Chicago, IL  60616, United States","Document Type":"Article","Access Type":null,"Source":"Scopus","EID":"2-s2.0-85029623619","Abstract":"Deep learning is an effective approach to solving image recognition problems. People draw intuitive conclusions from trading charts. This study uses the characteristics of deep learning to train computers in imitating this kind of intuition in the context of trading charts. The main goal of our approach is combining the time-series modeling and convolutional neural networks (CNNs) to build a trading model. We propose three steps to build the trading model. First, we preprocess the input data from quantitative data to images. Second, we use a CNN, which is a type of deep learning, to train our trading model. Third, we evaluate the model's performance in terms of the accuracy of classification. The experimental results show that if the strategy is clear enough to make the images obviously distinguishable the CNN model can predict the prices of a financial asset. Hence, our approach can help devise trading strategies and help clients automatically obtain personalized trading strategies. \u00a92018 Walter de Gruyter GmbH, Berlin\/Boston 2018.","Author Keywords":"convolutional neural network (CNN); Deep learning; Forex (FX); geometric Brownian motion (GBM); trading strategies","Index Keywords":"Brownian movement; Commerce; Convolution; Deep learning; Image recognition; Neural networks; Accuracy of classifications; Convolutional neural network; Convolutional Neural Networks (CNN); Effective approaches; Forex (FX); Geometric Brownian motion; Time series modeling; Trading strategies; Electronic trading","References":"Binkowski, M., Marti, G., Donnat, P., (2017) Autoregressive Convolutional Neural Networks for Asynchronous Time Series, , arXiv preprint arXiv:1703.04122; Borovykh, A., Bohte, S., Oosterlee, C.W., (2017) Conditional Time Series Forecasting with Convolutional Neural Networks, , arXiv preprint arXiv:1703.04691; Browne, S., Optimal investment policies for a firm with a random risk process: Exponential utility and minimizing the probability of ruin (1995) Math. Oper. Res., 20, pp. 937-958; Di Persio, L., Honchar, O., Artificial neural networks approach to the forecast of stock market price movements (2016) Int. J. Econ. Manag. Syst., 1, pp. 158-162; Eun, C.S., Shim, S., International transmission of stock market movements (1989) J. Finan. Quant. Anal., 24, pp. 241-256; Fukushima, K., Miyake, S., Amari, S., Arbib, M.A., (1982) Competition and Cooperation in Neural Nets, pp. 267-285. , Neocognitron: a self-organizing neural network model for a mechanism of visual pattern recognition Springer Berlin, Heidelberg; Mittelman, R., (2015) Time-series Modeling with Undecimated Fully Convolutional Neural Networks, , arXiv preprint arXiv:1508.00317; Shreve, S.E., (2004) Stochastic Calculus for Finance II: Continuous-Time Models, , Springer New York; Wang, H., Raj, B., Xing, E.P., (2017) On the Origin of Deep Learning, , arXiv preprint arXiv:1702.07800"}
{"Authors":"Liu C., Hou W., Liu D.","Author(s) ID":"57194109538;8430631300;56562006300;","Title":"Foreign Exchange Rates Forecasting with Convolutional Neural Network","Year":2017,"Source title":"Neural Processing Letters","Volume":"46","Issue":"3","Art. No.":null,"Page start":1095.0,"Page end":1119.0,"Page count":null,"Cited by":4.0,"DOI":"10.1007\/s11063-017-9629-z","Affiliations":"School of Information Engineering, Zhengzhou University, Zhengzhou, 450001, China","Document Type":"Article","Access Type":null,"Source":"Scopus","EID":"2-s2.0-85018755109","Abstract":"The prediction of financial time series data is a challenging task due to the unpredictable behaviours of investors that are influenced by a multitude of factors. In this paper, we present a novel deep Long Short-Term Memory (LSTM) based time-series data modelling for use in stock market index prediction. A dataset comprised of six market indices from around the world were chosen to demonstrate the robustness in varying market conditions with an aim to forecast the next day closing price. With experimental results showing an average annual profitability performance of up to 200%, our method demonstrates its feasibility and significant results in time-series modelling and prediction of financial markets. \u00a9 2018 IEEE.","Author Keywords":null,"Index Keywords":"Commerce; Electronic trading; Financial markets; Forecasting; Investments; Pattern recognition; Time series; Financial time series; Market condition; Stock market index; Time-series data; Time-series modelling; Long short-term memory","References":"Fama, E.F., Fisher, L., Jensen, M.C., Roll, R., The adjustment of stock prices to new information (1969) Int. Econ. Rev, 10, pp. 1-21; Krollner, B., Vanstone, B., Finnie, G., Financial time series forecasting with machine learning techniques: A survey (2010) Eur. Symp. On Artificial Neural Networks: Computational and Mach. Learning; Sharma, A., Bhuriya, D., Singh, U., Survey of stock market prediction using machine learning approach (2017) Int. Conf. Of Electron., Commun. And Aerospace Technol, 2, pp. 506-509; Choudhry, R., Garg, K., A hybrid machine learning system for stock market forecasting (2008) World Academy of Sci., Eng. And Technol, 2 (15), pp. 315-318; Iacomin, R., Stock market prediction (2015) Int. Conf. On System Theory, Control and Computing, pp. 200-205; Luo, S.-S., Weng, Y., Wang, W.-W., Hong, W.-X., L1-regularized logistic regression for event-driven stock market prediction (2017) Int. Conf. On Comput. Sci. And Edu., pp. 536-541. , August; LeCun, Y., Bengio, Y., Hinton, G., Deep learning (2015) Nature, 521 (7553), pp. 436-444; Deng, L., Three classes of deep learning architectures and their applications: A tutorial survey (2012) APSIPA Transactions on Signal and Information Processing; Heaton, J., Polson, N., Witte, J., (2016) Deep Learning in Finance; Billah, M., Waheed, S., Hanifa, A., Stock market prediction using an improved training algorithm of neural network (2016) Comput. & Telecommunication Eng, 8, pp. 8-10. , December; Chen, W., Zhang, Y., Yeo, C.K., Lau, C.T., Lee, B.S., Stock market prediction using neural network through news on online social networks (2017) Int. Conf. On Smart Cities, pp. 1-6; Bao, W., Yue, J., Rao, Y., A deep learning framework for financial time series using stacked autoencoders and long-short term memory (2017) PLoS One, 12 (7); Kingma, D.P., Ba, J., Adam: A method for stochastic optimization (2014) Int. Conf. On Learning Representations, pp. 1-15; Donoho, D.L., Johnstone, I.M., Adapting to unknown smoothness via wavelet shrinkage (1995) J. Of the Amer. Statistical Assoc, 90 (432); Bengio, Y., Lamblin, P., Popovici, D., Larochelle, H., Greedy layer-wise training of deep networks (2007) Advances in Neural Inform. Process. Syst, 19 (1), p. 153; Greff, K., Srivastava, R.K., Koutnk, J., Steunebrink, B.R., Schmidhuber, J., Lstm: A search space odyssey (2017) Trans. On Neural Networks and Learning Syst.; Yao, J., Tan, C.L., Poh, H.-L., Neural networks for technical analysis: A study on klci (1999) Int. J. Of Theoretical and Appl. Finance, 2 (2), pp. 221-241"}
{"Authors":"Selvin S., Vinayakumar R., Gopalakrishnan E.A., Menon V.K., Soman K.P.","Author(s) ID":"57191042609;56755324000;43761171400;56872448100;57205365723;","Title":"Stock price prediction using LSTM, RNN and CNN-sliding window model","Year":2017,"Source title":"2017 International Conference on Advances in Computing, Communications and Informatics, ICACCI 2017","Volume":"2017-January","Issue":null,"Art. No.":null,"Page start":1643.0,"Page end":1647.0,"Page count":null,"Cited by":16.0,"DOI":"10.1109\/ICACCI.2017.8126078","Affiliations":"Centre for Computational Engineering and Networking (CEN), Amrita School of Engineering, Coimbatore Amrita Vishwa Vidyapeetham, Amrita University, India","Document Type":"Conference Paper","Access Type":null,"Source":"Scopus","EID":"2-s2.0-85042664127","Abstract":"Forecasting financial time-series has long been among the most challenging problems in financial market analysis. In order to recognize the correct circumstances to enter or exit the markets investors usually employ statistical models (or even simple qualitative methods). However, the inherently noisy and stochastic nature of markets severely limits the forecasting accuracy of the used models. The introduction of electronic trading and the availability of large amounts of data allow for developing novel machine learning techniques that address some of the difficulties faced by the aforementioned methods. In this work we propose a deep learning methodology, based on recurrent neural networks, that can be used for predicting future price movements from large-scale high-frequency time-series data on Limit Order Books. The proposed method is evaluated using a large-scale dataset of limit order book events. \u00a9 EURASIP 2017.","Author Keywords":null,"Index Keywords":"Commerce; Correlation theory; Finance; Financial data processing; Financial markets; Forecasting; Investments; Learning systems; Recurrent neural networks; Signal processing; Stochastic models; Stochastic systems; Time series; Time series analysis; Forecasting accuracy; Forecasting financial time series; High frequency time series; Large amounts of data; Large-scale dataset; Machine learning techniques; Qualitative method; Stochastic nature; Deep learning","References":"Dixon, M.F., Klabjan, D., Bang, J.H., (2016) Classification-based Financial Markets Prediction Using Deep Neural Networks; Takeuchi, L., Lee, Y.-Y.A., (2013) Applying Deep Learning to Enhance Momentum Trading Strategies in Stocks; Xiong, R., Nichols, E.P., Shen, Y., (2015) Deep Learning Stock Volatility with Google Domestic Trends; Kercheval, A.N., Zhang, Y., Modelling high-frequency limit order book dynamics with support vector machines (2015) Quantitative Finance, 15 (8), pp. 1315-1329; Graves, A., Mohamed, A.-R., Hinton, G., Speech recognition with deep recurrent neural networks (2013) Proceedings of the IEEE International Conference on Acoustics, Speech and Signal Processing (icassp), pp. 6645-6649; Xu, K., Ba, J., Kiros, R., Cho, K., Courville, A.C., Salakhutdinov, R., Zemel, R.S., Bengio, Y., Show, attend and tell: Neural image caption generation with visual attention (2015) Proceedings of the International Conference on Machine Learning, 14, pp. 77-81; Mao, J., Xu, W., Yang, Y., Wang, J., Huang, Z., Yuille, A., (2014) Deep Captioning with Multimodal Recurrent Neural Networks (m-rnn); Zhu, Y., Groth, O., Bernstein, M., Fei-Fei, L., Visual7w: Grounded question answering in images (2016) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 4995-5004; LeCun, Y., Bengio, Y., Convolutional networks for images, speech, and time series (1995) The Handbook of Brain Theory and Neural Networks, 3361 (10), p. 1995; Hochreiter, S., Schmidhuber, J., Long short-term memory (1997) Neural Computation, 9 (8), pp. 1735-1780; He, K., Zhang, X., Ren, S., Sun, J., Deep residual learning for image recognition (2016) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 770-778; Heaton, J., Polson, N., Witte, J., (2016) Deep Portfolio Theory; Yang, D., Zhang, Q., Drift-independent volatility estimation based on high, low, open, and close prices (2000) The Journal of Business, 73 (3), pp. 477-492; Siikanen, M., Kanniainen, J., Valli, J., Limit order books and liquidity around scheduled and non-scheduled announcements: Empirical evidence from nasdaq nordic (2016) Finance Research Letters, , to appear; Werbos, P.J., Backpropagation through time: What it does and how to do it (1990) Proceedings of the IEEE, 78 (10), pp. 1550-1560; Kingma, D., Ba, J., (2014) Adam: A Method for Stochastic Optimization; Maas, A.L., Hannun, A.Y., Ng, A.Y., Rectifier nonlinearities improve neural network acoustic models (2013) Proceedings of the International Conference on Machine Learning, 30 (1); Cohen, J., A coefficient of agreement for nominal scales (1960) Educational and Psychological Measurement, 20 (1), pp. 37-46; Cho, K., Courville, A., Bengio, Y., Describing multimedia content using attention-based encoder-decoder networks (2015) IEEE Transactions on Multimedia, 17 (11), pp. 1875-1886"}
{"Authors":"Korczak J., Hemes M.","Author(s) ID":"7004001261;57200141372;","Title":"Deep learning for financial time series forecasting in A-Trader system","Year":2017,"Source title":"Proceedings of the 2017 Federated Conference on Computer Science and Information Systems, FedCSIS 2017","Volume":null,"Issue":null,"Art. No.":" 8104660","Page start":905.0,"Page end":912.0,"Page count":null,"Cited by":9.0,"DOI":"10.15439\/2017F449","Affiliations":"Wroc\u0142aw University of Economics, ul. Komandorska 118\/120, Wroc\u0142aw, 53-345, Poland","Document Type":"Conference Paper","Access Type":"Open Access","Source":"Scopus","EID":"2-s2.0-85039923580","Abstract":"In today's financial markets, where most trades are performed in their entirety by electronic means and the largest fraction of them is completely automated, an opportunity has risen from analyzing this vast amount of transactions. Since all the transactions are recorded in great detail, investors can analyze all the generated data and detect repeated patterns of the price movements. Being able to detect them in advance, allows them to take profitable positions or avoid anomalous events in the financial markets. In this work we proposed a deep learning methodology, based on Convolutional Neural Networks (CNNs), that predicts the price movements of stocks, using as input large-scale, high-frequency time-series derived from the order book of financial exchanges. The dataset that we use contains more than 4 million limit order events and our comparison with other methods, like Multilayer Neural Networks and Support Vector Machines, shows that CNNs are better suited for this kind of task. \u00a9 2017 IEEE.","Author Keywords":"Convolutional Neural Networks; Large scale financial data; Limit Orderbook","Index Keywords":"Commerce; Convolution; Correlation theory; Costs; Finance; Financial data processing; Financial markets; Investments; Multilayer neural networks; Neural networks; Anomalous events; Convolutional neural network; Financial data; Forecasting stock prices; High frequency time series; Limit Orderbook; Price movement; Repeated patterns; Electronic trading","References":"Dixon, M.F., Klabjan, D., Bang, J.H., (2016) Classification-based Financial Markets Prediction Using Deep Neural Networks; Takeuchi, L., Lee, Y.-Y.A., (2013) Applying Deep Learning to Enhance Momentum Trading Strategies in Stocks; Xiong, R., Nichols, E.P., Shen, Y., (2015) Deep Learning Stock Volatility with Google Domestic Trends, , arXiv preprint arXiv:1512.04916; Kercheval, A.N., Zhang, Y., Modelling high-frequency limit order book dynamics with support vector machines (2015) Quantitative Finance, 15 (8), pp. 1315-1329; Graves, A., Mohamed, A.-R., Hinton, G., Speech recognition with deep recurrent neural networks (2013) Proceedings of the IEEE International Conference on Acoustics, Speech and Signal Processing (Icassp), pp. 6645-6649; Xu, K., Ba, J., Kiros, R., Cho, K., Courville, A.C., Salakhutdinov, R., Zemel, R.S., Bengio, Y., Show, attend and tell: Neural image caption generation with visual attention (2015) Proceedings of the International Conference on Machine Learning, 14, pp. 77-81; Mao, J., Xu, W., Yang, Y., Wang, J., Huang, Z., Yuille, A., (2014) Deep Captioning with Multimodal Recurrent Neural Networks (M-rnn), , arXiv preprint arXiv:1412.6632; Zhu, Y., Groth, O., Bernstein, M., Fei-Fei, L., Visual7w: Grounded question answering in images (2016) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 4995-5004; LeCun, Y., Bengio, Y., Convolutional networks for images, speech, and time series (1995) The Handbook of Brain Theory and Neural Networks, 3361 (10), p. 1995; Hochreiter, S., Schmidhuber, J., Long short-term memory (1997) Neural Computation, 9 (8), pp. 1735-1780; He, K., Zhang, X., Ren, S., Sun, J., Deep residual learning for image recognition (2016) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 770-778; Heaton, J., Polson, N., Witte, J., (2016) Deep Portfolio Theory, , arXiv preprint arXiv:1605.07230; Yang, D., Zhang, Q., Drift-independent volatility estimation based on high, low, open, and close prices (2000) The Journal of Business, 73 (3), pp. 477-492; Ntakaris, A., Magris, M., Kanniainen, J., Gabbouj, M., Iosifidis, A., (2017) Benchmark Dataset for Mid-price Prediction of Limit Order Book Data; Siikanen, M., Kanniainen, J., Valli, J., Limit order books and liquidity around scheduled and non-scheduled announcements: Empirical evidence from nasdaq nordic (2016) Finance Research Letters, , to appear; Werbos, P.J., Backpropagation through time: What it does and how to do it (1990) Proceedings of the IEEE, 78 (10), pp. 1550-1560; Kingma, D., Ba, J., (2014) Adam: A Method for Stochastic Optimization, , arXiv preprint arXiv:1412.6980; Van Merri\u00ebnboer, B., Bahdanau, D., Dumoulin, V., Serdyuk, D., Warde-Farley, D., Chorowski, J., Bengio, Y., (2015) Blocks and Fuel: Frameworks for Deep Learning, , arXiv preprint arXiv:1506.00619; Bergstra, J., Breuleux, O., Bastien, F., Lamblin, P., Pascanu, R., Desjardins, G., Turian, J., Bengio, Y., Theano: A cpu and GPU math compiler in python (2010) Proc. 9th Python in Science Conf, pp. 1-7; Bastien, F., Lamblin, P., Pascanu, R., Bergstra, J., Goodfellow, I., Bergeron, A., Bouchard, N., Bengio, Y., (2012) Theano: New Features and Speed Improvements, , arXiv preprint arXiv:1211.5590; Pedregosa, F., Varoquaux, G., Gramfort, A., Michel, V., Thirion, B., Grisel, O., Blondel, M., Dubourg, V., Scikit-learn: Machine learning in python (2011) Journal of Machine Learning Research, 12, pp. 2825-2830. , Oct; Maas, A.L., Hannun, A.Y., Ng, A.Y., Rectifier nonlinearities improve neural network acoustic models (2013) Proceedings of the International Conference on Machine Learning, 30 (1); Cohen, J., A coefficient of agreement for nominal scales (1960) Educational and Psychological Measurement, 20 (1), pp. 37-46; Cho, K., Courville, A., Bengio, Y., Describing multimedia content using attention-based encoder-decoder networks (2015) IEEE Transactions on Multimedia, 17 (11), pp. 1875-1886"}
{"Authors":"Afolabi D., Guan S.-U., Man K.L., Wong P.W.H., Zhao X.","Author(s) ID":"55791007800;56000571900;55536496100;9734871500;57191226824;","Title":"Hierarchical meta-learning in time series forecasting for improved interference-less machine learning","Year":2017,"Source title":"Symmetry","Volume":"9","Issue":"11","Art. No.":" 283","Page start":null,"Page end":null,"Page count":null,"Cited by":3.0,"DOI":"10.3390\/sym9110283","Affiliations":"Department of Computer Science and Software Engineering, Xi'an Jiaotong-Liverpool University, Suzhou, 215123, China; Department of Computer Science, University of Liverpool, Liverpool, L69 3BX, United Kingdom","Document Type":"Article","Access Type":"Open Access","Source":"Scopus","EID":"2-s2.0-85034773068","Abstract":"The success of convolutional neural networks in the field of computer vision has attracted the attention of many researchers from other fields. One of the research areas in which neural networks is actively used is financial forecasting. In this paper, we propose a novel method for predicting stock price movements using CNN. To avoid the high volatility of the market and to maximize the profit, ETFs are used as primary financial assets. We extract commonly used trend indicators and momentum indicators from financial time series data and use these as our features. Adopting a sliding window approach, we generate our images by taking snapshots that are bounded by the window over a daily period. We then perform daily predictions, namely, regression for predicting the ETF prices and classification for predicting the movement of the prices on the next day, which can be modified to estimate weekly or monthly trends. To increase the number of images, we use numerous ETFs. Finally, we evaluate our method by performing paper trading and calculating the final capital. We also compare our method's performance to commonly used classical trading strategies. Our results indicate that we can predict the next day's prices with 72% accuracy and end up with 5:1 of our initial capital, taking realistic values of transaction costs into account. \u00a9 2017 IEEE.","Author Keywords":null,"Index Keywords":"Commerce; Costs; Deep learning; Financial markets; Forecasting; Neural networks; Convolutional neural network; Financial assets; Financial forecasting; Financial time series; Stock price movements; Stock trading model; Trading strategies; Transaction cost; Electronic trading","References":"Cavalcante, R.C., Brasileiro, R.C., Souza, V.L., Nobrega, J.P., Oliveira, A.L., Computational intelligence and financial markets: A survey and future directions (2016) Expert Systems with Applications, 55, pp. 194-211; Krollner, B., Vanstone, B., Finnie, G., (2010) Financial Time Series Forecasting with Machine Learning Techniques: A Survey; Adebiyi, A.A., Adewumi, A.O., Ayo, C.K., Comparison of arima and artificial neural networks models for stock price prediction (2014) Journal of Applied Mathematics, 2014; Kelly, B., Pruitt, S., The three-pass regression filter: A new approach to forecasting using many predictors (2015) Journal of Econometrics, 186 (2), pp. 294-316; Heaton, J., An empirical analysis of feature engineering for predictive modeling (2016) SoutheastCon, 2016. IEEE, pp. 1-6; Atsalakis, G.S., Valavanis, K.P., Surveying stock market forecasting techniques Part II: Soft computing methods (2009) Expert Systems with Applications, 36 (3), pp. 5932-5941. , http:\/\/linkinghub.elsevier.com\/retrieve\/pii\/S0957417408004417, apr; Sezer, O.B., Ozbayoglu, A.M., Dogdu, E., An artificial neural network-based stock trading system using technical analysis and big data framework (2017) Proceedings of the SouthEast Conference On-ACM SE '17, pp. 223-226. , http:\/\/dl.acm.org\/citation.cfm?doid=3077286.3077294, New York, New York, USA: ACM Press; Di Persio, L., Honchar, O., Artificial neural networks architectures for stock price prediction: Comparisons and applications (2016) International Journal of Circuits, Systems and Signal Processing; Sahin, U., Ozbayoglu, A.M., TN-RSI: Trend-normalized RSI indicator for stock trading systems with evolutionary computation (2014) Procedia Computer Science, 36, pp. 240-245. , http:\/\/linkinghub.elsevier.com\/retrieve\/pii\/S1877050914013350; Yeh, C.-Y., Huang, C.-W., Lee, S.-J., A multiplekernel support vector regression approach for stock market price forecasting (2011) Expert Systems with Applications, 38 (3), pp. 2177-2186. , http:\/\/linkinghub.elsevier.com\/retrieve\/pii\/S0957417410007876; Choudhry, R., Garg, K., A hybrid machine learning system for stock market forecasting (2008) World Academy of Science, Engineering and Technology, 2 (15), pp. 315-318; Chang, P.C., Wang, D.D., Zhou, C.L., A novel model by evolving partially connected neural network for stock price trend forecasting (2012) Expert Systems with Applications, 39 (1), pp. 611-620. , http:\/\/dx.doi.org\/10.1016\/j.eswa.2011.07.051; Tsai, S.-P., Wang, C.-F., Stock price forecasting by hybrid machine learning techniques (2009) Proceedings of the International MultiConference of Engineers and Computer Scientists, 1. , http:\/\/www.iaeng.org\/publication\/IMECS2009\/IMECS2009pp755-760.pdf; Srivastava, N., Hinton, G., Krizhevsky, A., Sutskever, I., Salakhutdinov, R., Dropout: A simple way to prevent neural networks from overfitting (2014) Journal of Machine Learning Research, 15, pp. 1929-1958. , http:\/\/www.jmlr.org\/papers\/volume15\/srivastava14a.old\/source\/srivastava14a.pdf; Zeiler, M.D., (2012) ADADELTA: An Adaptive Learning Rate Method, , https:\/\/arxiv.org\/abs\/1212.5701, dec; Krizhevsky, A., Sutskever, I., Hinton, G.E., (2012) ImageNet Classification with Deep Convolutional Neural Networks, pp. 1097-1105. , https:\/\/papers.nips.cc\/paper\/4824-imagenetclassification-with-deep-convolutional-neural-networks"}
{"Authors":"Chen W., Zhang Y., Yeo C.K., Lau C.T., Lee B.S.","Author(s) ID":"57188997356;56825288900;7102545548;7401968617;56883413700;","Title":"Stock market prediction using neural network through news on online social networks","Year":2017,"Source title":"2017 International Smart Cities Conference, ISC2 2017","Volume":null,"Issue":null,"Art. No.":" 8090834","Page start":null,"Page end":null,"Page count":null,"Cited by":7.0,"DOI":"10.1109\/ISC2.2017.8090834","Affiliations":"School of Computer Science and Engineering, Nanyang Technological University, Singapore, S639798, Singapore","Document Type":"Conference Paper","Access Type":null,"Source":"Scopus","EID":"2-s2.0-85039937089","Abstract":"Technical analysis is a widely used method for forecasting the price direction on the financial time series data. This method requires the use of different number and types of analysis algorithms (technical indicators) together. Although these algorithms show successful performance on small-scalefinancial time series data, significant performance decreases are detected when the size of data increased. On the large-scale financial time series data, it is necessary to implement these algorithms based on the Map-Reduce programming model and examine the performance of the algorithms which are implemented based on this model comparatively. For this purpose, seven different indicators are studied within the scope of this study, new versions of these indicators are implemented using Map-Reduce parallel data processing model and performance comparisons are made with these algorithms. As a result of these comparisons on single-node and multi-node, significant performance gains have been obtained using Map-Reduce programming model. \u00a9 2018 IEEE.","Author Keywords":"Financial Time Series Data; Map-Reduce Programming Model; Technical Analysis; Technical Analysis Indicators","Index Keywords":"Big data; Deep learning; Finance; Financial data processing; Terrorism; Time series; Time series analysis; Analysis algorithms; Financial time series; Map-reduce programming; Parallel data processing; Performance comparison; Technical analysis; Technical indicator; Time-series data; Data reduction","References":"Murphy, J.J., (1999) Philosophy of Technical Analysis. in Technical Analysis of Financial Markets: A Comprehensive Guide to Trading Methods and Applications, p. 6. , Penguin; Lim, M.A., Introduction to the art and science of technical analysis \/ dual function of technical analysis (2015) The Handbook of Technical Analysis Test Bank: The Practitioner's Comprehensive Guide to Technical Analysis, p. 3. , John Wiley & Sons; Knight, T., Indicators in action (2010) Chart Your Way to Profits: The Online Trader's Guide to Technical Analysis with ProphetCharts, p. 111. , John Wiley & Sons; Fontanills, G.A., Technical analysis of the commodity markets \/ types of indicators: Leading, turning point, and lagging (2007) Getting Started in Commodities, 70, pp. 163-165. , John Wiley & Sons; Kirkpatrick, C.D., Dahlquist, J.R., Introduction to technical analysis (2015) Technical Analysis: The Complete Resource for Financial Market Technicians, p. 1. , FT Press; Kirkpatrick, C.D., Dahlquist, J.R., Moving averages (2015) Technical Analysis: The Complete Resource for Financial Market Technicians, pp. 305-306. , FT Press; Appel, G., (2005) Advanced Moving Average Convergence-Divergence (MACD): The Ultimate Market Timing Indicator?, pp. 165-200. , Technical Analysis: Power Tools for Active Investors, FT Press; Welles, W.J., The relative strength index (1978) New Concepts in Technical Trading Systems, Trend Research, pp. 63-70; Dean, J., Ghemawat, S., MapReduce: Simplified data processing on large clusters (2008) Communications of the ACM, 511, pp. 107-113; Sinha, A., Jana, P.K., MRF: MapReduce based forecasting algorithm for time series data (2018) Procedia Computer Science, 132, pp. 92-102; Baloglu, A., Aktas, M.S., BlogMiner: Web blog mining application for classification of movie reviews (2010) Fifth International Conference on Internet and Web Applications and Services (ICIW), pp. 77-84; Chen, P., Plale, B., Aktas, M.S., Temporal representation for mining scientific data provenance (2014) Future Generation Computer Systems, 36, pp. 363-378; Chen, P., Plale, B., Aktas, M.S., Temporal representation for scientific data provenance (2012) IEEE 8th International Conference on E-Science (E-Science), pp. 1-8; Aktas, M.S., Plale, B., Leake, D., Mukhi, N.K., Unmanaged workflows: Their provenance and use (2012) Data Provenance and Data Management in EScience, pp. 59-81; Jensen, S., Plale, B., Aktas, M.S., Luo, Y., Chen, P., Conover, H., Provenance capture and use in a satellite data processing pipeline (2013) IEEE Transactions on Geoscience and Remote Sensing, 51 (11), pp. 5090-5097; Fox, G.C., Aktas, M.S., Aydin, G., Gadgil, H., Pallickara, S., Pierce, M.E., Sayar, A., Algorithms and the Grid (2009) Computing and Visualization in Science, 12 (3), pp. 115-124; Aktas, M.S., Astekin, M., Provenance aware run time verification of things for self healing Internet of Things applications (2017) Concurrency and Computation: Practice and Experience; Aktas, M.S., Hybrid cloud computing monitoring software architecture (2018) Concurrency and Computation: Practice and Experience; Fox, G.C., Aktas, M.S., Aydin, G., Bulut, H., Pallickara, S., Pierce, M., Sayar, A., Zhai, G., Real time streaming data grid applications (2006) Distributed Cooperative Laboratories: Networking, Instrumentation, and Measurements, pp. 253-267. , Springer, Boston, MA; Aktas, M.S., Pierce, M., High performance hybrid information service architecture (2010) Concurrency and Computation: Practice and Experience, 22 (15), pp. 2095-2123; Aktas, M.S., Fox, G.C., Pierce, M., Fault tolerant high-performance information services for dynamic collections of grid and web services (2007) Future Generation Computer Systems, 23 (3); Aktas, M.S., Fox, G.C., Pierce, M., Information services for dynamically assembled semantic grids (2005) First International Conference on Semantics, Knowledge and Grid, SKG'05; Nacar, M.A., Aktas, M.S., Pierce, M., Lu, Z., Erlebacher, G., Kigelman, D., Bollig, E.F., Yuen, D.A., VLab: Collaborative Grid services and portals to support computational material science (2007) Concurrency and Computation: Practice and Experience, 19 (12); Pierce, M., Fox, G.C., Aktas, M.S., Aydin, G., Gadgil, H., Qi, Z., Sayar, A., The quakesim project: Web services for managing geophysical data and applications (2008) Earthquakes: Simulations, Sources and Tsunamis, pp. 635-651. , Publisher: Birkh\u00e4user Basel; Aktas, M., Aydin, G., Donnellan, A., Fox, G.C., Granat, R., Lyzenga, G., McLeod, D., Sayar, A., (2005) Implementing Geographical Information System Grid Services to Support Computational Geophysics in A Service-oriented Environment, , NASA Earth-Sun System Technology Conference, University of Maryland, Adelphi, Maryland; Aktas, M.S., Fox, G.C., Pierce, M., Oh, S., XML metadata services (2008) Concurrency and Computation: Practice and Experience, 20 (7), pp. 801-823; Aktas, M.S., Pierce, M., Fox, G.C., Designing ontologies and distributed resource discovery services for an earthquake simulation grid (2004) Proc. of the GGF11 Semantic Grid Applications Workshop, , Honolulu, USA; Geli?tirilen K\u00fct\u00fcphanenin GitHub Deposu, Ulam Adresi: github.com\/yasinuygun\/TechnicalIndicators, Ulam Tarihi: 09.11.2018"}
{"Authors":"Tsantekidis A., Passalis N., Tefas A., Kanniainen J., Gabbouj M., Iosifidis A.","Author(s) ID":"57195636516;56897101400;6701672908;23394868200;7005332419;36720841400;","Title":"Using deep learning to detect price change indications in financial markets","Year":2017,"Source title":"25th European Signal Processing Conference, EUSIPCO 2017","Volume":"2017-January","Issue":null,"Art. No.":" 8081663","Page start":2511.0,"Page end":2515.0,"Page count":null,"Cited by":11.0,"DOI":"10.23919\/EUSIPCO.2017.8081663","Affiliations":"Department of Informatics, Aristotle University of Thessaloniki, Thessaloniki, Greece; Laboratory of Industrial and Information Management, Tampere University of Technology, Tampere, Finland; Laboratory of Signal Processing, Tampere University of Technology, Tampere, Finland; Department of Engineering, Electrical and Computer Engineering, Aarhus University, Denmark","Document Type":"Conference Paper","Access Type":null,"Source":"Scopus","EID":"2-s2.0-85041471618","Abstract":"In recent years, artificial neural networks have been employed a lot in forecasting financial price series. Crude oil and natural gas play the most important role in energy markets. Besides, crude oil price fluctuations are closely linked to financial markets. A novel hybrid neural network, DPFWR neural network, is put forward in this paper. The proposed DPFWR combines double parallel feedforward neural network and wavelet analysis theory with a random time effective function. We apply the DPFWR to forecast the energy futures price time series, including WTI crude oil, Brent crude oil, natural gas, RBOB gasoline, heating oil and Rotterdam coal. In order to compare the accuracy of forecasting results, several error criteria are applied to evaluate the forecasting errors of BP, DPF, LSTM, DPFWR and SARIMA models. A new method for error evaluation, called DS-CID, is developed to evaluate the forecasting errors in an attempt to observe the superiority of DPFWR neural network. Based on the empirical analysis, the forecast performance of DPFWR can be distinguished from other models by its great accuracy in this research. \u00a9 2019 Elsevier B.V.","Author Keywords":"Double-scale complexity invariant Distance; DPFWR neural network; Energy futures price series; Forecast; Random time effective function; Wavelet analysis","Index Keywords":"Commerce; Costs; Crude oil; Electronic trading; Errors; Feedforward neural networks; Financial markets; Forecasting; Function evaluation; Natural gas; Time series analysis; Wavelet analysis; Double-scale; Effective function; Empirical analysis; Energy future; Forecast performance; Hybrid neural networks; Oil and natural gas; Prices forecasting; Long short-term memory; coal; gasoline; natural gas; oil; petroleum; Article; artificial neural network; back propagation; double parallel feedforward neural network; double scale complexity invariant distance; energy cost; forecasting; long short term memory network; market; mathematical analysis; measurement accuracy; predictive value; priority journal; seasonal autoregressive integrated moving average; time series analysis; wavelet analysis","References":"Ziolkowska, J.R., Ziolkowski, B., Product generational dematerialization indicator: a case of crude oil in the global economy (2011) Energy, 36, pp. 5925-5934; Cunado, J., Gracia, F., Oil prices, economic activity and inflation: evidence for some asian countries (2005) Q. Rev. Econ. Finance, 45, pp. 65-83; Oladosu, G., Identifying the oil price-macroeconomy relationship: an empirical mode decomposition analysis of US data (2009) Energy Policy, 37, pp. 5417-5426; Park, J., Ratti, R.A., Oil price shocks and stock markets in the u.s. and 13 european countries (2008) Energy Econ., 30, pp. 2587-2608; Yurtsever, C., Zahor, Y., (2007), Oil price shocks and stock market in the netherlands Working Paper, University of Groninge; Wang, J., Pan, H.P., Liu, F.J., Forecasting crude oil price and stock price by jump stochastic time effective neural network model (2012) J. Appl. Math., 2012, pp. 1-7; Wang, F., Wang, J., Statistical analysis and forecasting of return interval for SSE and model by lattice percolation system and neural network (2012) Comput. Ind. Eng., 62, pp. 198-205; Aizenberg, I., Sheremetov, L., Villa-Vargas, L., Martinez-Munoz, J., Multilayer neural network with multi-valued neurons in time series forecasting of oil production (2016) Neurocomputing, 175, pp. 980-989; Ayadi, O.F., Williams, J., Hyman, L.M., Fractional dynamic behavior in forcados oil price series: an application of detrended fluctuation analysis (2009) Energy Sustain. Dev., 13, pp. 11-17; Niu, H.L., Wang, J., Volatility clustering and long memory of financial time series and financial price model (2013) Digit. Signal Process, 23, pp. 489-498; Yu, Y., Wang, J., Lattice-oriented percolation system applied to volatility behavior of stock market (2012) J. Appl. Stat., 39, pp. 785-797; Mantegna, R.N., Stanley, H.E., An Introduction to Econophysics: Correlations and Complexity in Finance (2000), Cambridge University Press Cambridge; Roh, T.H., Forecasting the volatility of stock price index (2007) Expert Syst. Appl., 33, pp. 916-922; Zhang, Y.J., Wei, Y.M., The dynamic influence of advanced stock market risk on international crude oil return: an empirical analysis (2011) Quant. Finance, 11, pp. 967-978; Prieto, A., Prieto, B., Ortigosa, E.M., Ros, E., Pelayo, F., Ortega, J., Rojas, I., Neural networks: an overview of early research, current frameworks and new challenges (2016) Neurocomputing, 214, pp. 242-268; Takahama, T., Sakai, S., Hara, A., Noriyuki, I., Predicting stock price using neural networks optimized by differential evolution with degeneration (2009) Int. J. Innov. Comput. Inf. Control, 5, pp. 5021-5032; Balestrassi, P.P., Popova, E., Paiva, A.P., Lima, J.W.M., Design of experiments on neural networks training for nonlinear time series forecasting (2009) Neurocomputing, 72, pp. 1160-1178; Sermpinis, G., Stasinakis, C., Dunis, C., Stochastic and genetic neural network combinations in trading and hybrid time-varying leverage effects (2014) J. Int. Financ. Mark. Inst. Money, 30, pp. 21-54; Villarrubia, G., De Paz, J.F., Chamoso, P., De la Prieta, F., Artificial neural networks used in optimization problems (2018) Neurocomputing, 272, pp. 10-16; Azadeh, A., Moghaddam, M., Khakzad, M., Ebrahimipour, V., A flexible neural network-fuzzy mathematical programming algorithm for improvement of oil price estimation and forecasting (2012) Comput. Ind. Eng., 62, pp. 421-430; Wang, J., Wang, J., Forecasting stock market indexs using principle component analysis and stochastic time effective neural networks (2015) Neurocomputing, 156, pp. 68-78; Liu, F.J., Wang, J., Fluctuation prediction of stock market index by legendre neural network with random time strength function (2012) Neurocomputing, 83, pp. 12-21; Ghiassi, M., Saidane, H., Zimbra, D.K., A dynamic artificial neural network model for forecasting time series events (2005) Int. J. Forecast., 21, pp. 341-362; Niu, H.L., Wang, J., Financial time series prediction by a random data-time effective RBF neural network (2014) Soft Comput., 18, pp. 497-508; Wang, J., Wang, J., Forecasting energy market indices with recurrent neural networks: case study of crude oil price fluctuations (2016) Energy, 102, pp. 365-374; Mohammadzaheri, M., Chen, L., Ghaffari, A., Willison, J., A combination of linear and nonlinear activation functions in neural networks for modeling a de-superheater (2009) Simul. Model. Pract. Theory, 17, pp. 398-407; Yolcu, U., Egrioglu, E., Aladag, C., A new linear & nonlinear artificial neural network model for time series forecasting (2013) Decis. Support Syst., 54, pp. 1340-1347; Li, G.Q., Niu, P.F., Duan, X.L., Y. Zhang, X., Fast learning network: a novel artificial neural network with a fast learning speed (2014) Neural Comput. Appl., 24, pp. 1683-1695; Khan, A., Yang, J., Wu, W., Double parallel feedforward neural network based on extreme learning machine with l1\/2 regularizer (2014) Neurocomputing, 128, pp. 113-118; Ma, Y.P., Niu, P.F., Zhang, X.X., Li, G.Q., Research and application of quantum-inspired double parallel feed-forward neural network (2017) Knowl.-Based Syst., 136, pp. 140-149; Adamowski, J., Chan, H.F., A wavelet neural network conjunction model for ground-water level forecasting (2011) J. Hydrol., 407, pp. 28-40; Subasi, A., Yilmaz, M., Ozcalik, H.R., Classification of EMG signals using wavelet neural network (2006) J. Neurosci. Methods, 156, pp. 360-367; Wen, X.Q., Jian, S.G., Wang, J.G., Prediction models of calorific value of coal based on wavelet neural networks (2017) Fuel, 199, pp. 512-522; He, K., Xie, C., Chen, S., Lai, K.K., Estimating VaR in crude oil market: a novel multi-scale non-linear ensemble approach incorporating wavelet analysis and neural network (2009) Neurocomputing, 72, pp. 3428-3438; Jammazi, R., Aloui, C., Crude oil forecasting: experimental evidence from wavelet decomposition and neural network modeling (2012) Energy Econ., 34, pp. 828-841; Rana, M., Koprinska, I., Forecasting electricity load with advanced wavelet neural networks (2016) Neurocomputing, 182, pp. 118-132; Khan, M.M., Mendes, A., Zhang, P., Chalup, S.K., Evolving multi-dimensional wavelet neural networks for classification using cartesian genetic programming (2017) Neurocomputing, 247, pp. 39-58; Huang, L.L., Wang, J., Global crude oil price prediction and synchronization based accuracy evaluation using random wavelet neural network (2018) Energy, 151, pp. 875-888; Donate, J.P., Cortez, P., Sanchez, G.G., de Miguel, A.S., Time series forecasting using a weighted cross-validation evolutionary artificial neural network ensemble (2013) Neurocomputing, 109, pp. 27-32; Liao, Z., Wang, J., Forecasting model of global stock index by stochastic time effective neural network (2010) Expert Syst. Appl., 37, pp. 834-841; Zhang, G.P., Time series forecasting using a hybrid ARIMA and neural network model (2003) Neurocomputing, 50, pp. 159-175; Asadi, S., Shahrabi, J., Abbaszadeh, P., Tabanmehr, S., A new hybrid artificial neural networks for rainfall-runoff process modeling (2013) Neurocomputing, 121, pp. 470-480; Wu, S.D., Wu, C.W., Lin, S.G., Wang, C.C., Lee, K.Y., Time series analysis using composite multiscale entropy (2013) Entropy, 15, pp. 1069-1084; Niu, H.L., Wang, J., Quantifying complexity of financial short-term time series by composite multiscale entropy measure (2015) Commun. Nonlinear Sci. Numer. Simul., 22, pp. 375-382; Lam, M., Neural network techniques for financial performance prediction: integrating fundamental and technical analysis (2004) Decis. Support Syst., 37-4, pp. 567-581; Katijani, Y., Hipel, W.K., Mcleod, A.I., Forecasting nonlinear time series with feed-forward neural networks: a case study of Canadian lynx data (2005) J. Forecast., 24, pp. 105-117; Tripathyb, M., Power transformer differential protection using neural network principal component analysis and radial basis function neural network (2010) Simul. Model. Pract. Theory, 18, pp. 600-611; www.wind.com.cn, Wind Financial Database, [DB\/CD], 2017-09-16\/2018-10-01; Han, L.Q., Theory, Design and Application of Artificial Neural Network (2002), Chemical Industry Press; Mohammad, K.Z., Principal component analysis (PCA) for estimating chlorophyll concentration using forward and generalized regression neural networks (2014) Appl. Artif. Intell., 28, pp. 16-29; Fischer, T., Krauss, C., Deep learning with long short-term memory networks for financial market predictions (2018) Eur. J. Oper. Res., 270, pp. 654-669; Graves, A., Schmidhuber, J., Framewise phoneme classification with bidirectional LSTM and other neural network architectures (2005) Neural Netw., 18, pp. 602-610; Choi, T.M., Yu, Y., Au, K.F., A hybrid SARIMA wavelet transform method for sales forecasting (2011) Decis. Support Syst., 51, pp. 130-140; Plumb, A.P., Rowe, R.C., York, P., Brown, M., Optimization of the predictive ability of artificial neural network (ANN) models: a comparison of three ANN programs and four classes of training algorithm (2005) Eur. J. Pharm. Sci., 25, pp. 395-405; Olson, D., Mossman, C., Neural network forecasts of canadian stock returns using accounting ratios (2003) Int. J. Forecast., 19, pp. 453-465; Faruk, D., A hybrid neural network and ARIMA model for water quality time series prediction (2010) Eng. Appl. Artif. Intell., 23, pp. 86-94; Batista, G.E.A.P.A., Keogh, E.J., Tataw, O.M., de Souza, V.M.A., CID: an efficient complexity-invariant distance for time series (2014) Data Mining Knowl. Discov., 28, pp. 634-669"}
{"Authors":"Dingli A., Fournier K.S.","Author(s) ID":"7801315512;57197812381;","Title":"Financial time series forecasting - a deep learning approach","Year":2017,"Source title":"International Journal of Machine Learning and Computing","Volume":"7","Issue":"5","Art. No.":null,"Page start":118.0,"Page end":122.0,"Page count":null,"Cited by":2.0,"DOI":"10.18178\/ijmlc.2017.7.5.632","Affiliations":"Department of Artificial Intelligence, University of Malta, Malta","Document Type":"Article","Access Type":"Open Access","Source":"Scopus","EID":"2-s2.0-85035056992","Abstract":"In recent years, financial market dynamics forecasting has been a focus of economic research. To predict the price indices of stock markets, we developed an architecture which combined Elman recurrent neural networks with stochastic time effective function. By analyzing the proposed model with the linear regression, complexity invariant distance (CID), and multiscale CID (MCID) analysis methods and taking the model compared with different models such as the backpropagation neural network (BPNN), the stochastic time effective neural network (STNN), and the Elman recurrent neural network (ERNN), the empirical results show that the proposed neural network displays the best performance among these neural networks in financial time series forecasting. Further, the empirical research is performed in testing the predictive effects of SSE, TWSE, KOSPI, and Nikkei225 with the established model, and the corresponding statistical comparisons of the above market indices are also exhibited. The experimental results show that this approach gives good performance in predicting the values from the stock market indices. \u00a9 2016 Jie Wang et al.","Author Keywords":null,"Index Keywords":"Commerce; Electronic trading; Financial markets; Forecasting; Stochastic models; Stochastic systems; Time series; Time series analysis; Back-propagation neural networks; Effective function; Elman recurrent neural network; Empirical research; Financial time series forecasting; Financial time series predictions; Random neural network; Statistical comparisons; Recurrent neural networks; algorithm; artificial neural network; commercial phenomena; computer simulation; economic model; human; Markov chain; predictive value; time factor; trends; Algorithms; Commerce; Computer Simulation; Humans; Models, Economic; Neural Networks (Computer); Predictive Value of Tests; Stochastic Processes; Time Factors","References":"Kajitani, Y., Hipel, K.W., McLeod, A.I., Forecasting nonlinear time series with feed-forward neural networks: A case study of Canadian lynx data (2005) Journal of Forecasting, 24 (2), pp. 105-117; Takahama, T., Sakai, S., Hara, A., Iwane, N., Predicting stock price using neural networks optimized by differential evolution with degeneration (2009) International Journal of Innovative Computing, Information and Control, 5 (12), pp. 5021-5031; Huarng, K., Yu, T.H.-K., Theapplication of neural networks to forecast fuzzy time series (2006) Physica A, 363 (2), pp. 481-491; Wang, F., Wang, J., Statistical analysis and forecasting of return interval for SSE and model by lattice percolation system andneural network (2012) Computers and Industrial Engineering, 62 (1), pp. 198-205; Kim, H.-J., Shin, K.-S., A hybrid approach based on neural networks and genetic algorithms for detecting temporal patterns in stock markets (2007) Applied Soft Computing, 7 (2), pp. 569-576; Ghiassi, M., Saidane, H., Zimbra, D.K., A dynamic artificial neural network model for forecasting time series events (2005) International Journal of Forecasting, 21 (2), pp. 341-362; Hassan, M.R., Nath, B., Kirley, M., A fusionmodel of HMM, ANNandGAfor stock market forecasting (2007) Expert Systemswith Applications, 33 (1), pp. 171-180; Devaraj, D., Yegnanarayana, B., Ramar, K., Radial basis function networks for fast contingency ranking (2002) International Journal of Electrical Power and Energy Systems, 24 (5), pp. 387-395; Garroa, B.A., V\u00e1zquez, R.A., Designing artificial neural networks using particle swarm optimization algorithms (2015) Computational Intelligence and Neuroscience, 2015, 20p; Gan, Q., Exponential synchronization of stochastic Cohen- Grossberg neural networks with mixed time-varying delays and reaction-diffusion via periodically intermittent control (2012) Neural Networks, 31, pp. 12-21; Xiao, D., Wang, J., Modeling stock price dynamics by continuum percolation system and relevant complex systems analysis (2012) Physica A: Statistical Mechanics and Its Applications, 391 (20), pp. 4827-4838; Enke, D., Mehdiyev, N., Stock market prediction using a combination of stepwise regression analysis, differential evolution-based fuzzy clustering, and a fuzzy inference Neural Network (2013) Intelligent Automation and Soft Computing, 19 (4), pp. 636-648; Sermpinisa, G., Stasinakisa, C., Dunisb, C., Stochastic and genetic neural network combinations in trading and hybrid time-varying leverage effects (2014) Journal of International Financial Markets, Institutions & Money, 30, pp. 21-54; Ebrahimpour, R., Nikoo, H., Masoudnia, S., Yousefi, M.R., Ghaemi, M.S., Mixture of mlp-experts for trend forecasting of time series: A case study of the Tehran stock exchange (2011) International Journal of Forecasting, 27 (3), pp. 804-816; Bahrammirzaee, A., A comparative survey of artificial intelligence applications in finance: Artificial neural networks, expert system and hybrid intelligent systems (2010) Neural Computing and Applications, 19 (8), pp. 1165-1195; Graves, A., Liwicki, M., Fern\u00e1ndez, S., Bertolami, R., Bunke, H., Schmidhuber, J., A novel connectionist system for unconstrained handwriting recognition (2009) IEEE Transactions on Pattern Analysis and Machine Intelligence, 31 (5), pp. 855-868; Ardalani-Farsa, M., Zolfaghari, S., Chaotic time series prediction with residual analysis method using hybrid Elman- NARX neural networks (2010) Neurocomputing, 73 (13-15), pp. 2540-2553; Paliwal, M., Kumar, U.A., Neural networks and statistical techniques: A review of applications (2009) Expert Systems with Applications, 36 (1), pp. 2-17; Liao, Z., Wang, J., Forecasting model of global stock index by stochastic timeeffective neural network (2010) Expert Systemswith Applications, 37 (1), pp. 834-841; Pan, L., Cao, J., Robust stability for uncertain stochastic neural network with delay and impulses (2012) Neurocomputing, 94, pp. 102-110; Liu, H.F., Wang, J., Integrating independent component analysis and principal component analysis with neural network to predict Chinese stock market (2011) Mathematical Problems in Engineering, 2011, 15p; Guo, Z.Q., Wang, H.Q., Liu, Q., Financial time series forecasting using LPP and SVM optimized by PSO (2013) Soft Computing, 17 (5), pp. 805-818; Niu, H.L., Wang, J., Financial time series prediction by a random data-time effective RBF neural network (2014) Soft Computing, 18 (3), pp. 497-508; Elman, J.L., Finding structure in time (1990) Cognitive Science, 14 (2), pp. 179-211; Cacciola, M., Megali, G., Pellican\u00f3, D., Morabito, F.C., Elman neural networks for characterizing voids in welded strips: A study (2012) Neural Computing and Applications, 21 (5), pp. 869-875; Chandra, R., Zhang, M., Cooperative coevolution of Elman recurrent neural networks for chaotic time series prediction (2012) Neurocomputing, 86, pp. 116-123; Chaturvedi, D.K., Satsangi, P.S., Kalra, P.K., Effect of different mappings and normalization of neural network models (1996) Proceedings of the National Power Systems Conference, 9, pp. 377-386. , Indian Institute of Technology, Kanpur, India; Makridakis, S., Accuracy measures: Theoretical and practical concerns (1993) International Journal of Forecasting, 9 (4), pp. 527-529; Han, L.Q., (2002) Design and Application of Artificial Neural Network, , Chemical Industry Press; Zounemat-Kermani, M., Principal component analysis (PCA) for estimating chlorophyll concentration using forward and generalized regression neural networks (2014) Applied Artificial Intelligence, 28 (1), pp. 16-29; Olson, D., Mossman, C., Neural network forecasts of Canadian stock returns using accounting ratios (2003) International Journal of Forecasting, 19 (3), pp. 453-465; Demuth, H., Beale, M., (1998) Network Toolbox: For Use with MATLAB, the Math Works, , Natick, Mass, USA, 5th edition; Plumb, A.P., Rowe, R.C., York, P., Brown, M., Optimisation of the predictive ability of artificial neural network (ANN) models: A comparison of three ANN programs and four classes of training algorithm (2005) European Journal of Pharmaceutical Sciences, 25 (4-5), pp. 395-405; Faruk, D.O., A hybrid neural network and ARIMA model for water quality time series prediction (2010) Engineering Applications of Artificial Intelligence, 23 (4), pp. 586-594; Tripathy, M., Power transformer differential protection using neural network principal component analysis and radial basis function neural network (2010) Simulation Modelling Practice and Theory, 18 (5), pp. 600-611; Martin, C.E., Reggia, J.A., Fusing swarm intelligence and self-assembly for optimizing echo state networks (2015) Computational Intelligence and Neuroscience, 2015, 15p; Tsay, R.S., (2005) Analysis of Financial Time Series, , JohnWiley & Sons, Hoboken, NJ, USA; Chang, P.-C., Wang, D.-D., Zhou, C.-L., A novel model by evolving partially connected neural network for stock price trend forecasting (2012) Expert Systems with Applications, 39 (1), pp. 611-620; Roy, P., Mahapatra, G.S., Rani, P., Pandey, S.K., Dey, K.N., Robust feed forward and recurrent neural network based dynamic weighted combination models for software reliability prediction (2014) Applied Soft Computing, 22, pp. 629-637; Gabaix, X., Gopikrishnan, P., Plerou, V., Stanley, H.E., A theory of power-law distributions in financialmarket fluctuations (2003) Nature, 423 (6937), pp. 267-270; Mantegna, R.N., Stanley, H.E., (2000) An Introduction to Econophysics: Correlations and Complexity in Finance, , Cambridge University Press, Cambridge, UK; Roh, T.H., Forecasting the volatility of stock price index (2007) Expert Systems with Applications, 33 (4), pp. 916-922; Batista, G.E., Keogh, E.J., Tataw, O.M., De Souza, V.M., CID: An efficient complexity-invariant distance for time series (2014) Data Mining and Knowledge Discovery, 28 (3), pp. 634-669"}
{"Authors":"Rout A.K., Dash P.K., Dash R., Bisoi R.","Author(s) ID":"55602137700;7102314306;42560989800;54941427900;","Title":"Forecasting financial time series using a low complexity recurrent neural network and evolutionary learning approach","Year":2017,"Source title":"Journal of King Saud University - Computer and Information Sciences","Volume":"29","Issue":"4","Art. No.":null,"Page start":536.0,"Page end":552.0,"Page count":null,"Cited by":14.0,"DOI":"10.1016\/j.jksuci.2015.06.002","Affiliations":"G.M.R. Institute of Technology, Rajam, Andhra Pradesh, India; S.O.A. University, Bhubaneswar, India","Document Type":"Article","Access Type":"Open Access","Source":"Scopus","EID":"2-s2.0-85006230902","Abstract":"In this paper, we mainly study the application of Long Short-Term Memory (LSTM) algorithms in the stock market. LSTM originates from the recurrent neural network (RNN) and has a significant effect on the time series problems. In this paper, the BP neural network model and the LSTM model are established respectively. Then we combine them with the stock data, a series of prediction results are obtained. Obviously, the prediction results of LSTM model are more accurate, and the prediction accuracy rate can reach 60%-65%. In the modeling process, in order to solve the 'saw-tooth phenomenon' of the gradient descent algorithm which is inevitable, we have improved the traditional gradient descent algorithm and specially designed the input data of the neural network. In addition, we defined a parameter combination library and use the skill of dropout to get the more ideal prediction results. \u00a9 2018 IEEE.","Author Keywords":"BP neural network; LSTM; stock forecasting","Index Keywords":"Distributed computer systems; Electronic trading; Financial markets; Forecasting; BP neural network model; BP neural networks; Gradient descent algorithms; LSTM; Parameter combination; Recurrent neural network (RNN); Stock forecasting; Stock price forecasting; Long short-term memory","References":"Fama, E.F., French, K.R., Dividend yields and expected stock returns [J] (1988) Journal of Financial Economics, 22 (1), pp. 3-26; Clerk Maxwell, J., (1892) A Treatise on Electricity and Magnetism, 2, pp. 68-73. , 3rd ed., Oxford: Clarendon; Jiang, Z., Xx, D., Liang, J., (2017) A Deep Reinforcement Learning Framework for the Financial Portfolio Management Problem[J], , Papers; Yao, J., Yang, X., Peng, X., Zhang, T., Zheng, S., Decreasing gradient optimization algorithm with variable step length based on chaotic variables[A] (2003) Journal of Tsinghua University(Science and Technology), 43 (12), pp. 1676-1678; Cybenko, G., Approximation by superpositions of a sigmoidal function[J] (1989) Analysis in Theory & Applications, 2 (4), pp. 303-314; Zhang, Q., Li, X., A new method to determine the number of hidden layer nodes in neural networks[A] (2002) Journal of Jishou University(Nature Science Edition), 23 (1), pp. 89-91; Grossberg, S., Neural networks and natural intelligence[J] (1988) Quarterly Review of Biology; Grossberg, S., Nonlinear neural networks: Principles, mechanisms, and architectures[J] (1988) Neural Networks, 1 (1), pp. 17-61; Zhang, L., (1993) Artificial Neural Network Model and Its Application[M], , Fudan University Press"}
{"Authors":"Singh R., Srivastava S.","Author(s) ID":"57202825807;57192430115;","Title":"Stock prediction using deep learning","Year":2017,"Source title":"Multimedia Tools and Applications","Volume":"76","Issue":"18","Art. No.":null,"Page start":18569.0,"Page end":18584.0,"Page count":null,"Cited by":16.0,"DOI":"10.1007\/s11042-016-4159-7","Affiliations":"Indian School of Mines, Dhanbad, India; Faculty of Management Studies, Banaras Hindu University, Varanasi, India","Document Type":"Article","Access Type":null,"Source":"Scopus","EID":"2-s2.0-85006504040","Abstract":"Recently, many academy researchers have proposed several forecasting models by technical analysis to forecast stocks, such as (Yamawaki & Tokuoka 2007) [1]. The traditional approach uses a linear time series model for stock forecasting. However, the results would be in doubt when the forecasting problems are nonlinear. Multifeature data from financial statements usually produce high-dimensional data, and therefore, the proposed model utilizes synthesis feature selection for reducing the number of dimensions. The proposed hybrid model utilizes synthesis feature selection to optimize the recurrent network (RNN) for predicting stock price trends. Three refined processes are proposed in the hybrid model for forecasting: (1) select essential technical indicators from popular indicators by a correlation matrix; (2) use stepwise regression and a decision tree to reduce features; and (3) utilize a recurrent neural network (Elman neural network) to build a forecasting model. A six-year period of the Taiwan stock exchange capitalization weighted stock index (TAIEX) is employed as a verification database to evaluate the proposed model under a performance indicator, root mean squared error (RMSE). The results show that the proposed model is superior to the listing models. \u00a9 2012 ICIC International.","Author Keywords":"Recurrent neural network; Synthesis feature; Technical indicators","Index Keywords":"Correlation matrix; Elman neural network; Financial statements; Forecasting models; Forecasting problems; High dimensional data; Hybrid model; Linear time series model; Neural networks model; Performance indicators; Recurrent networks; Root mean squared errors; Stepwise regression; Stock exchange; Stock forecasting; Stock indices; Stock price; Synthesis features; Taiwan stock markets; Technical analysis; Technical indicator; Benchmarking; Decision trees; Finance; Recurrent neural networks; Forecasting","References":"Tanaka-Yamawaki, M., Tokuoka, S., Adaptive use of technical indicators for the prediction of intraday stock prices (2007) Physica A: Statistical Mechanics and Its Applications, 383 (1), pp. 125-133; Chi, S.-C., Peng, W.-L., Wu, P.-T., Yu, M.-W., The study on the relationship among technical indicators and the development of stock index prediction system (2003) Proc. of the 22nd International Conference on Fuzzy Information Processing Society of the North American, pp. 291-296; Engle, R.F., Autoregressive conditional heteroscedasticity with estimator of the variance of United Kingdom ination (1982) Econometrica, 50 (4), pp. 987-1008; Bollerslev, T., Generalized autoregressive conditional heteroscedasticity (1986) Journal of Econometrics, 31, pp. 307-327; Box, G., Jenkins, G., (1976) Time Series Analysis: Forecasting and Control, , Holden-Day, San Francisco; Aihara, S.I., Bagchi, A., Saha, S., On parameter estimation of stochastic volatility models from stock data using particle filter-application to AEX index (2009) International Journal of Innovative Computing, Information and Control, 5 (1), pp. 17-28; Chang, J.-F., Chen, K.-L., Applying new investment satis\u00e9d capability index and particle swarm optimization to stock portfolio selection (2009) ICIC Express Letters, 3 (3 A), pp. 349-354; Takahama, T., Sakai, S., Hara, A., Noriyuki, I., Predicting stock price using neural networks optimized by differential evolution with degeneration (2009) International Journal of Innovative Computing, Information and Control, 5 (12 B), pp. 5021-5032; Zhang, Y., Chen, Y., Understanding the price uctuations of stock markets through cellular automata (2009) ICIC Express Letters, 3 (3 A), pp. 307-312; Zadeh, L.A., Fuzzy logic, neural networks and soft computing (1994) Communications of the ACM, 37 (3), pp. 77-84; Kimoto, T., Asakawa, K., Yoda, M., Takeoka, M., Stock market prediction system with modular neural network (1990) Proc. of the International Joint Conference on Neural Networks, pp. 1-6. , San Diego, CA; Huarng, K., Yu, H.-K., The application of neural networks to forecast fuzzy time series (2006) Physica A, 363, pp. 481-491; Roh, T.H., Forecasting the volatility of stock price index (2007) Expert Systems with Applications, 33, pp. 916-922; Seker, S., Ayaz, E., Turkcan, E., Elman's recurrent neural network applications to condition monitoring in nuclear power plant and rotating machinery (2003) Engineering Applications of Artificial Intelligence, 16, pp. 647-656; Pring, M.J., (1991) Technical Analysis, , New York; Allen, F., Karalainen, R., Using genetic algorithms to find technical trading rules (1999) Journal of Financial Economics, 51, pp. 245-271; Azo, M.E., (1994) Neural Network Time Series Forecasting of Financial Markets, , Wiley, New York; William, L., Russell, P., James, M.R., Forecasting the NYSE composite index with technical analysis, pattern recognizer, neural network and genetic algorithm: A case study in romantic decision support (2002) Decision Support Systems, 32, pp. 361-377; Draper, N.R., Smith, H., (1981) Applied Regression Analysis, , 2nd Edition, John Wiley & Sons, New York; McClave, J.T., Benson, P.G., Sincich, T., (2005) Statistics for Business and Economics, , 9th Edition, Prentice Hall; Quinlan, J.R., (1993) Programs for Machine Learning, , Morgan Kaufmann; Quinlan, J.R., Improved use of continuous attributes in C4.5 (1996) Arxiv preprint cs. AI\/9603103; Richard, J.B., Julie, R.D., (1999) Technical Market Indicators: Analysis & Performance, , John Wiley, New York; Liou, C.-Y., Backbone structure of hairy memory (2006) Proc. of the 16th International Conference on Artificial Neural Networks, LNCS, 4131, pp. 688-697; Liou, C.-Y., Lin, S.-L., Finite memory loading in hairy neurons (2006) Natural Computing, 5 (1), pp. 15-42; Rumelhart, D.E., McClelland, J.L., (1986) Parallel Distributed Processing: Explorations in the Microstructure of Cognition: Foundations, , MIT Press, Cambridge, MA; Chen, A.-P., Chen, Y.-C., Tseng, W.-C., Applying extending classi\u00e9r system to develop an optionoperation suggestion model of intraday trading-an example of Taiwan index option (2005) Lecture Notes in AI, pp. 27-33; Kim, M.-J., Min, S.-H., Han, I., An evolutionary approach to the combination of multiple classi\u00e9rs to predict a stock price index (2006) Expert Systems with Applications, 31, pp. 241-247; Croxton, F.E., Cowden, D.J., Klein, S., (1899) Applied General Statistics; Jegadeesh, N., Titman, S., Returns to buying winners and selling losers: Implications for stock market efficiency (1993) Journal of Finance, pp. 65-91; Schapire, R., Freund, Y., A decision theoretic generalization of on-line learning and an application to boosting (1997) J Comput. Syst. Sci, 55, pp. 119-139; Sun, Z.-L., Au, K.-F., Choi, T.-M., A neuro-fuzzy inference system through integration of fuzzy logic and extreme learning machines (2007) IEEE Trans. on Systems, Men, and Cybernetices, 37, pp. 1321-1331; Cheng, C.-H., Chen, T.-L., Wei, L.-Y., A hybrid model based on rough sets theory and genetic algorithms for stock price forecasting (2010) Information Science, 180 (9), pp. 1610-1629; Chen, S.-M., Forecasting enrollments based on fuzzy time-series (1996) Fuzzy Sets Systems, 81, pp. 311-319; Yu, H.K., Weighted fuzzy time-series models for TAIEX forecasting (2005) Physica A, 349, pp. 609-624; http:\/\/www.twse.com.tw\/"}
{"Authors":"Tsantekidis A., Passalis N., Tefas A., Kanniainen J., Gabbouj M., Iosifidis A.","Author(s) ID":"57195636516;56897101400;6701672908;23394868200;7005332419;36720841400;","Title":"Forecasting stock prices from the limit order book using convolutional neural networks","Year":2017,"Source title":"Proceedings - 2017 IEEE 19th Conference on Business Informatics, CBI 2017","Volume":"1","Issue":null,"Art. No.":" 8010701","Page start":7.0,"Page end":12.0,"Page count":null,"Cited by":20.0,"DOI":"10.1109\/CBI.2017.23","Affiliations":"Department of Informatics, Aristotle University of Thessaloniki, Thessaloniki, Greece; Laboratory of Industrial and Information Management, Tampere University of Technology, Tampere, Finland; Laboratory of Signal Processing, Tampere University of Technology, Tampere, Finland","Document Type":"Conference Paper","Access Type":null,"Source":"Scopus","EID":"2-s2.0-85029406625","Abstract":"Given a financial time series such as S&P 500, or any historical data in stock markets, how can we obtain useful information from recent transaction data to predict the ups and downs at the next moment? Recent work on this issue shows initial evidence that machine learning techniques are capable of identifying (non-linear) dependency in the stock market price sequences. However, due to the high volatility and non-stationary nature of the stock market, forecasting the trend of a financial time series remains a big challenge. In this paper, we introduced a new method to simplify noisy-filled financial temporal series via sequence reconstruction by leveraging motifs (frequent patterns), and then utilize a convolutional neural network to capture spatial structure of time series. The experimental results show the efficiency of our proposed method in feature learning and outperformance with 4%-7% accuracy improvement compared with the traditional signal process methods and frequency trading patterns modeling approach with deep learning in stock trend prediction. \u00a9 2019 IEEE.","Author Keywords":"convolutional neural network; financial time series; motif extraction; Trend prediction","Index Keywords":"Commerce; Convolution; Deep learning; Electronic trading; Forecasting; Information use; Machine learning; Neural networks; Signal processing; Time series; Accuracy Improvement; Convolutional neural network; Financial time series; Machine learning techniques; Sequence reconstruction; Stock market prices; Stock trend prediction; Trend prediction; Financial markets","References":"Maiorino, E., Bianchi, F.M., Livi, L., Rizzi, A., Sadeghian, A., Data-driven detrending of nonstationary fractal time series with echo state networks (2017) Inf. Sci., 382-383, pp. 359-373. , Mar; Bao, W., Yue, J., Rao, Y., A deep learning framework for financial time series using stacked autoencoders and long-short term memory (2017) PLoS ONE, 12 (7); Ye, F., Liming, Z., Defu, Z., Hamido, F., Zhiguo, G., A novel fore-casting method based on multi-order fuzzy time series and technical analysis (2016) Inf. Sci., 367-368, pp. 41-57. , Nov; Rout, A.K., Forecasting financial time series using a low com-plexity recurrent neural network and evolutionary learning approach (2017) J. King Saud Univ.-Comput. Inf. Sci, 29 (4), pp. 536-552; Lai, G., Chang, W.-C., Yang, Y., Liu, H., Modeling long-and short-term temporal patterns with deep neural networks (2018) Proc. 41st Int. ACM SIGIR Conf. Res. Develop. Inf. Retr, pp. 95-104; Qiu, X., Ren, Y., Suganthan, P.N., Amaratunga, G.A.J., Empirical Mode Decomposition based ensemble deep learning for load demand time series forecasting (2017) Appl. Soft Comput, 54, pp. 246-255. , May; Nava, N., Di Matteo, T., Aste, T., Financial time series forecasting using empirical mode decomposition and support vector regression (2018) Risks, 6 (1), p. 7; Godfrey, L.B., Gashler, M.S., Neural decomposition of time-series data for effective generalization (2018) IEEE Trans. Neural Netw. Learn. Syst, 29 (7), pp. 2973-2985. , Jul; Jeon, S., Hong, B., Chang, V., Pattern graph tracking-based stock price prediction using big data (2018) Future Gener. Comput. Syst, 80, pp. 171-187. , Mar; Dai, X., Bikdash, M., Trend analysis of fragmented time series for mHealth apps: Hypothesis testing based adaptive spline filtering method with importance weighting (2017) IEEE Access, 5, pp. 27767-27776; Wang, Z., Yang, F., Ho, D.W.C., Liu, X., Robust finite-horizon filtering for stochastic systems with missing measurements (2005) IEEE Signal Process. Lett, 12 (6), pp. 437-440. , Jun; Kim, Y., Convolutional neural networks for sentence classification (2014) Proc. Conf. Empirical Methods Natural Language Process. (EMNLP), pp. 1746-1751; Vaswani, A., Attention is all you need (2017) Proc. Neural Inf. Process. Syst, pp. 5998-6008; Box, G.E.P., Jenkins, G.M., Reinsel, G.C., Ljung, G.M., (2015) Time Series Analysis: Forecasting and Control, , Hoboken NJ USA: Wiley; Tay, F.E., Cao, L., Application of support vector machines in financial time series forecasting (2001) Omega, 29 (4), pp. 309-317. , Aug; Kim, K.-J., Financial time series forecasting using support vector machines (2003) Neurocomputing, 55 (1-2), pp. 307-319; Hassan, M.R., Nath, B., Stock market forecasting using hidden Markov model: A new approach (2005) Proc. 5th Int. Conf. Intell. Syst. Design Appl. (ISDA), pp. 192-196. , Sep; Gupta, A., Dhingra, B., Stock market prediction using hidden Markov models (2012) Proc. Students Conf. Eng. Syst. (SCES), pp. 1-4. , Mar; Takens, F., Detecting strange attractors in turbulence (1981) Dynamical Systems and Turbulence, pp. 366-381. , Berlin, Germany: Springer; Stolojescu, C., Cristina, I.R., Moga, S., Lenca, P., Isar, A., A wavelet based prediction method for time series (2010) Proc. Int. Conf. Stochastic Modeling Techn. Data Anal, , Chania, Greece; Stolojescu, C., Cusnir, A., Moga, S., Isar, A., Forecasting WiMAX BS traffic by statistical processing in the wavelet domain (2009) Proc. Int. Symp. Signals, Circuits Syst. (ISSCS), pp. 1-4. , Jul; Conejo, A.J., Plazas, M.A., Espinola, R., Molina, A.B., Day-ahead electricity price forecasting using the wavelet transform and ARIMA models (2005) IEEE Trans. Power Syst, 20 (2), pp. 1035-1042. , May; Lecun, Y., Bengio, Y., Convolutional networks for images, speech, time series (1995) Handbook Brain Theory Neural Netw, 3361 (10), pp. 1-14; Xiong, R., Nichols, E.P., Shen, Y., (2015) Deep Learning Stock Volatility with Google Domestic Trends, , http:\/\/arxiv.org\/abs\/1512.04916; Ding, X., Zhang, Y., Liu, T., Duan, J., Deep learning for event-driven stock prediction (2015) Proc. IJCAI; Ding, X., Zhang, Y., Liu, T., Duan, J., Using structured events to predict stock price movement: An empirical investigation (2014) Proc. Conf. Empirical Methods Natural Lang. Process. (EMNLP), pp. 1415-1425; Ding, X., Zhang, Y., Liu, T., Duan, J., Knowledge-driven event embed-ding for stock prediction (2016) Proc. 26th Int. Conf. Comput. Linguistics, Tech. Papers (COLING), pp. 2133-2142; Xu, X., Zhang, J., Small, M., Superfamily phenomena and motifs of networks induced from time series (2008) Proc. Nat. Acad. Sci, 105 (50), pp. 19601-19605; Yankov, D., Keogh, E., Medina, J., Chiu, B., Zordan, V., Detecting time series motifs under uniform scaling (2007) Proc. 13th ACM SIGKDD Int. Conf. Knowl. Discovery Data Mining, pp. 844-853; Vahdatpour, A., Amini, N., Sarrafzadeh, M., Toward unsupervised activity discovery using multi dimensional motif detection in time series (2009) Proc. IJCAI, 9; Hooi, B., Liu, S., Smailagic, A., Faloutsos, C., BeatLex: Summarizing and forecasting time series with patterns (2017) Proc. Joint Eur. Conf. Mach. Learn. Knowl. Discovery Databases, pp. 3-19. , Cham, Switzerland: Springer; Mueen, A., Keogh, E., Zhu, Q., Cash, S., Westover, B., Exact discovery of time series motifs (2009) Proc. SIAM Int. Conf. Data Mining, pp. 473-484; Zhang, L., Aggarwal, C., Qi, G.-J., Stock price prediction via discov-ering multi-frequency trading patterns (2017) Proc. 23rd ACM SIGKDD Int. Conf. Knowl. Discovery Data Mining, pp. 2141-2149; Krizhevsky, A., Sutskever, I., Hinton, G.E., ImageNet classification with deep convolutional neural networks (2012) Proc. Adv. Neural Inf. Process. Syst, pp. 1097-1105; Hochreiter, S., Schmidhuber, J., Long short-term memory (1997) Neural Comput, 9 (8), pp. 1735-1780; Lecun, Y., Bengio, Y., Hinton, G., Deep learning (2015) Nature, 521 (7553), p. 436; Fischer, T., Krauss, C., Deep learning with long short-term memory networks for fInancial market predictions (2017) Eur. J. Oper. Res, 120 (2), pp. 654-669; Barron, A., Rissanen, J., Yu, B., The minimum description length principle in coding and modeling (1998) IEEE Trans. Inf. Theory, 44 (6), pp. 2743-2760. , Oct; Gao, Z.-K., Li, S., Dang, W.-D., Yang, Y.-X., Do, Y., Grebogi, C., Wavelet multiresolution complex network for analyzing multivariate nonlinear time series (2017) Int. J. Bifurcation Chaos, 27 (8). , Jul; Gao, Z.-K., Small, M., Kurths, J., Complex network analysis of time series (2017) EPL (Europhys. Lett.), 116 (5)"}
{"Authors":"Li J., Bu H., Wu J.","Author(s) ID":"57195521810;57204073569;35313047900;","Title":"Sentiment-aware stock market prediction: A deep learning method","Year":2017,"Source title":"14th International Conference on Services Systems and Services Management, ICSSSM 2017 - Proceedings","Volume":null,"Issue":null,"Art. No.":" 7996306","Page start":null,"Page end":null,"Page count":null,"Cited by":8.0,"DOI":"10.1109\/ICSSSM.2017.7996306","Affiliations":"School of Economics and Management, Beihang University, Beijing, China","Document Type":"Conference Paper","Access Type":null,"Source":"Scopus","EID":"2-s2.0-85028594302","Abstract":"Cash flow prediction is important. It can help increase returns and improve the allocation of capital in healthy, mature firms as well as prevent fast-growing firms, or firms in distress, from running out of cash. In this paper, we predict accounts receivable cash flows employing methods applicable to companies with many customers and many transactions such as e-commerce companies, retailers, airlines and public transportation firms with sales in multiple regions and countries. We first discuss \u201cclassic\u201d forecasting techniques such as ARIMA and Facebook's\u2122 Prophet before moving on to neural networks with multi-layered perceptrons and, finally, long short-term memory networks, that are particularly useful for time series forecasting but were until now not used for cash flows. Our evaluation demonstrates this range of methods to be of increasing sophistication, flexibility and accuracy. We also introduce a new performance measure, interest opportunity cost, that incorporates interest rates and the cost of capital to optimize the models in a financially meaningful, money-saving, way. \u00a9 2019, Springer Science+Business Media, LLC, part of Springer Nature.","Author Keywords":"Accounts receivable; ARIMA; Cash flow prediction; LSTM; MLP; Neural networks; Prophet","Index Keywords":null,"References":"Copeland, T., Koller, T., Murrin, J., (1996) Valuation: Measuring and managing the value of companies, p. 550. , Wiley, New York; Arnold, A., Clubb, C., Manson, S., Wearing, R., The relationship between earnings, funds flows and cash flows: Evidence for the UK (2012) Accounting and Business Research, 22 (1), pp. 13-19; Akinyomi, O., Effect of cash management on profitability of Nigerian manufacturing firms (2014) International Journal of Marketing and Technology, 4 (1), pp. 129-140; Garcia-Teruel, P.J., Effects of working capital management on SME profitability (2005) International Journal of Managerial Finance, 3 (2), pp. 164-177; Cheng, M.-Y., Hoang, N.-D., Wu, Y.-W., (2012) Prediction of Project Cash Flow Using Time-Dependent Evolutionary LS-SVM Inference Model, , https:\/\/pdfs.semanticscholar.org\/c16b\/56e6128f8c69880356ed15d6ad2f9434aa04.pdf, Last visited 2019-07-01; Hu, W.-K., (2016) Overdue Invoice Forecasting and Data Mining, , https:\/\/dspace.mit.edu\/bitstream\/handle\/1721.1\/104327\/958280271-MIT.pdf?sequence=1&isAllowed=y, Last visited 2019-07-01; Hu, P.-G., (2015) Predicting and Improving Invoice-To-Cash Collection through Machine Learning, , https:\/\/dspace.mit.edu\/bitstream\/handle\/1721.1\/99584\/925473704-MIT.pdf?sequence=1, Last visited 2019-07-01; Reddy, V., (2018) Data Analysis Course, Time Series Analysis and Forecasting, , http:\/\/www.trendwiseanalytics.com\/training\/Timeseries_Forecasting.pdf, Last visited 2019-07-01; Nau, R., (2018) Introduction to ARIMA: Nonseasonal Models, , https:\/\/people.duke.edu\/~rnau\/411arim.htm, Last visited 2019-07-01; Taylor, S.J., Letham, B., (2017) Prophet: Forecasting at scale, , https:\/\/research.fb.com\/prophet-forecasting-at-scale\/, Last visited 2019-07-01; Goodfellow, I., Bengio, Y., Courville, A., (2016) Deep learning, , MIT Press, Cambridge; Rumelhart, D.E., Hinton, G.E., Williams, R.J., Learning representations by back-propagating errors (1986) Nature, 323, pp. 533-536; Hochreiter, S., Schmidhuber, J., Long short-term memory (1997) Neural Computation, 9-8, pp. 1735-1780; Brownlee, J., (2017) Long Short-Term Memory Networks with Python, , https:\/\/machinelearningmastery.com\/lstms-with-python\/; Brownlee, J., (2017) On the Suitability of Long Short-Term Memory Networks for Time Series Forecasting, , https:\/\/machinelearningmastery.com\/suitability-long-short-term-memory-networks-time-series-forecasting\/, Last visited 2019-07-01; Upadhyay, R., (2018) Step-By-Step Graphic Guide to Forecasting through ARIMA Modeling Using R\u2014Manufacturing Case Study Example, , http:\/\/ucanalytics.com\/blogs\/step-by-step-graphic-guide-to-forecasting-through-ARIMA-modeling-in-r-manufacturing-case-study-example\/, Last visited 2019-07-01; Choudhary, A., (2018) Generate Quick and Accurate Time Series Forecasts Using Facebook\u2019s Prophet (With Python and R Codes), , https:\/\/www.analyticsvidhya.com\/blog\/2018\/05\/generate-accurate-forecasts-facebook-prophet-python-r\/, Last visited 2019-07-01; Goyal, A., Krishnamurthy, S., Kulkarni, S., Kumar, R., Vartak, M., Lanham, M.A., (2016) Solution to forecast demand using long short-term memory recurrent neural networks for time series forecasting, , https:\/\/mwdsi2018.exordo.com\/files\/papers\/70\/final_draft\/LSTM_Final_Paper_MWDSI.pdf, Last visited 2019-07-01; Cheng, Y., Xu, C., Mashima, D., Wu, Y., PowerLSTM: Power demand forecasting using long short-term memory neural networks (2017) Advanced Data Mining and Applications: 13Th International Conference, ADMA 2017, Singapore, Proceedings; Neil, D., Pfeiffer, M., Liu, S.-C., Phased LSTM: Accelerating recurrent network training for long or event-based sequences (2016) In 30Th Conference on Neural Information Processing Systems (NIPS 2016), , Barcelona, Spain; Kingma, D.P., Ba, J.L., Adam: A method for stochastic optimization (2015) 3Rd International Conference for Learning Representations, , San Diego; Sarle, W.S., (2000) How to measure importance of inputs?, , ftp:\/\/ftp.sas.com\/pub\/neural\/importance.html, Last visited 2019-07-01; Schwartz-Ziv, R., Tishby, N., (2017) Opening the Black Box of Deep Neural Networks via Information, Why and When Deep Learning Works: Looking inside Deep Learning ICRI-CI Paperbundle; Molnar, C., (2019) Interpretable Machine Learning: A Guide for Making Black Box Models Explainable, , https:\/\/christophm.github.io\/interpretable-ml-book\/, Last visited 2019-07-01; Fama, E.F., Miller, M.H., (1972) The theory of finance, , The Dryden Press, New York; Barrons, J.T., (2018) A More General Robust Loss Function, , https:\/\/arxiv.org\/pdf\/1701.03077.pdf, Last visited 2019-07-01; Wang, Q., Yu, J., Deng, W., An adjustable re-ranking approach for improving the individual and aggregate diversities of product recommendations (2019) Electronic Commerce Research, 19, p. 1; Liu, S., Shao, B., Gao, Y., Game theoretic approach of a novel decision policy for customers based on big data (2018) Electronic Commerce Research, 18 (2), p. 2017; Gong, K., Peng, Y., Wang, Y., Time series analysis for C2C conversion rate (2018) Electronic Commerce Research, 18, p. 4. , last visited 2019-07-01 (2017"}
{"Authors":"Chen J.-F., Chen W.-L., Huang C.-P., Huang S.-H., Chen A.-P.","Author(s) ID":"57195363174;57195360094;57195361498;8882763200;21741959100;","Title":"Financial time-series data analysis using deep convolutional neural networks","Year":2017,"Source title":"Proceedings - 2016 7th International Conference on Cloud Computing and Big Data, CCBD 2016","Volume":null,"Issue":null,"Art. No.":" 7979885","Page start":87.0,"Page end":92.0,"Page count":null,"Cited by":14.0,"DOI":"10.1109\/CCBD.2016.027","Affiliations":"Institute of Information Management, National Chiao Tung University, HsinChu, Taiwan; Department of Information Management and Finance, National Chiao Tung University, HsinChu, Taiwan","Document Type":"Conference Paper","Access Type":null,"Source":"Scopus","EID":"2-s2.0-85027469207","Abstract":"Long short-term memory (LSTM) networks are a state-of-the-art sequence learning in deep learning for time series forecasting. However, less study applied to financial time series forecasting especially in cryptocurrency prediction. Therefore, we propose a new forecasting framework with LSTM model to forecasting bitcoin daily price with two various LSTM models (conventional LSTM model and LSTM with AR(2) model). The performance of the proposed models are evaluated using daily bitcoin price data during 2018\/1\/1 to 2018\/7\/28 in total 208 records. The results confirmed the excellent forecasting accuracy of the proposed model with AR(2). The test mean squared error (MSE), root mean square error (RMSE), mean absolute percentage error (MAPE), and mean absolute error (MAE) for bitcoin price prediction, respectively. The our proposed LSTM with AR(2) model outperformed than conventional LSTM model. The contribution of this study is providing a new forecasting framework for bitcoin price prediction can overcome and improve the problem of input variables selection in LSTM without strict assumptions of data assumption. The results revealed its possible applicability in various cryptocurrencies prediction, industry instances such as medical data or financial time-series data. \u00a9 2018 IEEE.","Author Keywords":"Bitcoin; cryptocurrency prediction; long-short term memory (LSTM)","Index Keywords":"Bitcoin; Brain; Correlation theory; Data mining; Deep learning; Errors; Financial data processing; Forecasting; Mean square error; Time series; Financial time series; Financial time series forecasting; Forecasting accuracy; Input variables selections; Mean absolute error; Mean absolute percentage error; Root mean square errors; Time series forecasting; Long short-term memory","References":"Poyser, O., Exploring the Determinants of Bitcoin's Price: An Application of Bayesian Structural Time Series [Online]; Sovbetov, Y., Factors Influencing Cryptocurrency Prices: Evidence from bitcoin, ethereum, dash, litcoin, and monero (2018) Journal of Economics and Financial Analysis, 2 (2), pp. 1-27; Nasrulin, B., Muzammal, M., Qu, Q., ChainMOB: Mobility analytics on blockchain (2018) The 2018 19th IEEE International Conference on Mobile Data Management (MDM), , 2018\/6\/25; Muzammal, M., Qu, Q., Nasrulin, B., Renovating blockchain with distributed databases: An open source system (2019) Future Generation Computer Systems, 90, pp. 105-117; Siami-Namini, S., Namin, A.S., (2018) Forecasting Economics and Financial Time Series: ARIMA Vs. LSTM, , https:\/\/arxiv.org\/abs\/1803.06386v1, vol. abs\/1803 06386; McNally, S., Roche, J., Caton, S., Predicting the price of bitcoin using machine learning (2018) 2018 26th Euromicro International Conference on Parallel, Distributed and Network-based Processing (PDP), pp. 339-343; Karakoyun, A.O., \u00c7ibikdiken, E.J., Comparison of ARIMA time series model and LSTM deep learning algorithm for bitcoin price forecasting (2018) The 13th Multidisciplinary Academic Conference in Prague 2018 (The 13th MAC 2018), pp. 171-180. , ed. Czech Republic; Pichl, L., Kaizoji, T., Volatility analysis of bitcoin price time series (2017) Quantitative Finance and Economics, 1 (4), pp. 474-485; Bartos, J., Does Bitcoin follow the hypothesis of efficient market (2015) International Journal of Economic Sciences, 4 (2), pp. 10-23; Baur, D.G., Hong, K.J., Lee, A.D., Bitcoin-Currency or asset (2015) The 2016 Financial Institutions, Regulation & Corporate Governance (FIRCG) Conference, , Melbourne Business School; Glaser, F., Zimmermann, K., Haferkorn, M., Weber, M.C., Siering, M., Bitcoin-Asset or Currency Revealing Users' Hidden Intentions (2014) The ECIS 2014 (Tel Aviv), , https:\/\/ssrn.com\/abstract=2425247, SSRN; Dyhrberg, A.H., Hedging capabilities of bitcoin. Is it the virtual gold Finance Research Letters, 16, pp. 139-144. , 2016\/02\/01\/2016; Urquhart, A., The inefficiency of bitcoin (2016) Economics Letters, 148, pp. 80-82. , 11\/01\/2016; Latif, S.R., Mohd, M.A., Amin, M.N.M., Mohamad, A.I., Testing the weak form of efficient market in cryptocurrency (2017) Journal of Engineering and Applied Sciences, 12 (9), pp. 2285-2288; Tiwari, A.K., Jana, R.K., Das, D., Roubaud, D., Informational efficiency of Bitcoin-An extension (2018) Economics Letters, 163, pp. 106-109. , 02\/01\/2018; Kristoufek, L., On Bitcoin markets (in)efficiency and its evolution (2018) Physica A: Statistical Mechanics and Its Applications, 503, pp. 257-262. , 08\/01\/2018; Blundell-Wignall, A., (2014) The Bitcoin Question: Currency Versus Trustless Transfer Technology, (OECD Working Papers on Finance), , Insurance and Private Pensions OECD Publishing; Lo, S., Wang, J.C., Bitcoin as money (2014) Federal Reserve Bank of Boston, 14. , Working Paper; Katsiampa, P., Volatility estimation for Bitcoin: A comparison of GARCH models (2017) Economics Letters, 158, pp. 3-6. , 09\/01\/2017; Kim, Y.B., Predicting fluctuations in cryptocurrency transactions based on user comments and replies (2016) PLOS ONE, 11 (8), p. e0161197; Kristoufek, L., What are the main drivers of the bitcoin price Evidence from wavelet coherence analysis (2015) PLOS ONE, 10 (4), p. e0123923; Balcilar, M., Bouri, E., Gupta, R., Roubaud, D., Can volume predict Bitcoin returns and volatility A quantiles-based approach (2017) Economic Modelling, 64, pp. 74-81. , 08\/01\/2017; Shah, D., Zhang, K., Bayesian regression and Bitcoin (2014) The 2014 52nd Annual Allerton Conference on Communication, Control, and Computing (Allerton), , 30 Sept.-3 Oct 2014; Chen, G.H., Nikolov, S., Shah, D., A latent source model for nonparametric time series classification (2013) Advances in Neural Information Processing Systems (NIPS 2013, pp. 1088-1096; Ciaian, P., Rajcaniova, M., Kancs, D.A., The economics of BitCoin price formation (2016) Applied Economics, 48 (19), pp. 1799-1815. , 04\/20\/2016; Greaves, A., Au, B., (2015) Using the Bitcoin Transaction Graph to Predict the Price Ofbitcoin, , https:\/\/zh.scribd.com\/document\/358987167\/using-the-bitcointransaction-graph-to-predict-the-price-of-bitcoin; Hegazy, K., Samumford, S., (2016) Comparitive Automated Bitcoin Trading Strategies; Cocianu, C., Grigoryan, H., (2015) An Artificial Neural Network for Data Forecasting Purposes, pp. 34-45; Guo, T., Antulov-Fantulin, N., (2018) An Experimental Study of Bitcoin Fluctuation Using Machine Learning Methods, , https:\/\/arxiv.org\/abs\/1802.04065; Box, G.E.P., Jenkins, G.M., Reinsel, G.C., Ljung, G.M., (2015) Time Series Analysis: Forecasting and Control, 5th Ed. Hoboken, , New Jersey: John Wiley and Sons Inc; Virtanen, I., Yli-Olli, P., Forecasting stock market prices in a thin security market (1987) Omega, 15 (2), pp. 145-155; Graves, A., (2013) Generating Sequences with Recurrent Neural Networks, , CoRR, arXiv preprint arXiv: 1308.0850; Olah, C., (2015) Understanding LSTM Networks, , http:\/\/colah.github.io\/posts\/2015-08-Understanding-LSTMs; Fischer And, T., Krauss, C., Deep learning with long short-term memory networks for financial market predictions (2018) European Journal of Operational Research, 270 (2), pp. 654-669. , 10\/16\/2018"}
{"Authors":"[No author name available]","Author(s) ID":"[No author id available]","Title":"IEEE Conference on Evolving and Adaptive Intelligent Systems","Year":2017,"Source title":"IEEE Conference on Evolving and Adaptive Intelligent Systems","Volume":"2017-May","Issue":null,"Art. No.":null,"Page start":null,"Page end":null,"Page count":189.0,"Cited by":null,"DOI":null,"Affiliations":null,"Document Type":"Conference Review","Access Type":null,"Source":"Scopus","EID":"2-s2.0-85054328670","Abstract":"Recent advances in the integration of deep recurrent neural networks and statistical inferences have paved new avenues for joint modeling of moments of random variables, which is highly useful for signal processing, time series analysis, and financial forecasting. However, introducing explicit knowledge as exogenous variables has received little attention. In this paper, we propose a novel model termed sentiment-aware volatility forecasting (SAVING), which incorporates market sentiment for stock return fluctuation prediction. Our framework provides an ensemble of symbolic and sub-symbolic AI approaches, that is, including grounded knowledge into a connectionist neural network. The model aims at producing a more accurate estimation of temporal variances of asset returns by better capturing the bi-directional interaction between movements of asset price and market sentiment. The interaction is modeled using Variational Bayes via the data generation and inference operations. We benchmark our model with 9 other popular ones in terms of the likelihood of forecasts given the observed sequence. Experimental results suggest that our model not only outperforms pure statistical models, e.g., GARCH and its variants, Gaussian-process volatility model, but also outperforms the state-of-the-art autoregressive deep neural nets architectures, such as the variational recurrent neural network and the neural stochastic volatility model. \u00a9 2019 Elsevier B.V.","Author Keywords":"Financial text mining; Sentiment knowledge; Time series analysis; Variational neural networks; Volatility modeling","Index Keywords":"Commerce; Data mining; Deep neural networks; Economic analysis; Forecasting; Harmonic analysis; Investments; Recurrent neural networks; Signal processing; Stochastic systems; Time series analysis; Bi-directional interaction; Financial forecasting; Financial text minings; Sentiment knowledge; Statistical inference; Stochastic Volatility Model; Volatility forecasting; Volatility modeling; Stochastic models","References":"Markowitz, H., Portfolio selection (1952) J. Finance, 7 (1), pp. 77-91; Black, F., Scholes, M., The pricing of options and corporate liabilities (1973) J. Polit. Econ., 81 (3), pp. 637-654; Date, P., Islyaev, S., A fast calibrating volatility model for option pricing (2015) European J. Oper. Res., 243 (2), pp. 599-606; Bollerslev, T., Generalized autoregressive conditional heteroskedasticity (1986) J. Econometrics, 31 (3), pp. 307-327; Heston, S., A closed-form solution for options with stochastic volatility with applications to bond and currency options (1993) Rev. Financ. Stud., 6 (2), pp. 327-343; Hermans, M., Schrauwen, B., A recurrent latent variable model for sequential data (2013) Proceedings of NIPS,, 1, pp. 190-198; Chung, J., Kastner, K., Dinh, L., Goel, K., Courville, A., Bengio, Y., A recurrent latent variable model for sequential data (2015) Proceedings of NIPS,, 2, pp. 2980-2988; Luo, R., Zhang, W., Xu, X., Wang, J., A neural stochastic volatility model (2018) Proceedings of AAAI, pp. 6401-6408; Xing, F.Z., Cambria, E., Malandri, L., Vercellis, C., Discovering Bayesian market views for intelligent asset allocation (2018), Proceedings of ECML PKDD; Ding, X., Zhang, Y., Liu, T., Duan, J., Deep learning for event-driven stock prediction (2015) Proceedings of IJCAI, pp. 2327-2333; Malandri, L., Xing, F.Z., Orsenigo, C., Vercellis, C., Cambria, E., Public mood\u2013driven asset allocation: The importance of financial sentiment in portfolio management (2018) Cogn. Comput., 10 (6), pp. 1167-1176; Kelly, S., Ahmad, K., Estimating the impact of domain-specific news sentiment on financial assets (2018) Knowl.-Based Syst., 150, pp. 116-126; Xing, F.Z., Cambria, E., Welsch, R.E., Natural language based financial forecasting: A survey (2018) Artif. Intell. Rev., 50 (1), pp. 49-73; Bollen, J., Mao, H., Zeng, X., Twitter mood predicts the stock market (2011) J. Comput. Sci., 2 (1), pp. 1-8; Smailovi\u0107, J., Gr\u010dar, M., Lavra\u010d, N., \u017dnidar\u0161i\u010d, M., Stream-based active learning for sentiment analysis in the financial domain (2014) Inform. Sci., 285, pp. 181-203; Cambria, E., Rajagopal, D., Olsher, D., Das, D., Big social data analysis (2013) Big Data Computing, pp. 401-414. , Akerkar R. Chapman and Hall\/CRC (Chapter 13); Engle, R.F., Autoregressive conditional heteroscedasticity with estimates of variance of United Kingdom inflation (1982) Econometrica, 50 (4), pp. 987-1008; B.Nelson, D., Conditional heteroskedasticity in asset returns: A new approach (1991) Econometrica, 59 (2), pp. 347-370; Glosten, L.R., Jagannathan, R., Runkle, D.E., On the relation between expected value and the volatility of the nominal excess return on stocks (1993) J. Finance, 48, pp. 1779-1801; Kingma, D.P., Salimans, T., J\u00f3zefowicz, R., Chen, X., Sutskever, I., Welling, M., Improving variational autoencoders with inverse autoregressive flow (2016) Proceedings of NIPS, pp. 4736-4744; Hochreiter, S., Schmidhuber, J., Long short-term memory (1997) Neural Comput., 9 (8), pp. 1735-1780; Cho, K., (2014), pp. 1724-1734. , B. van Merrienboer, C. Gulcehre, D. Bahdanau, F. Bougares, H. Schwenk, Y. Bengio, Learning phrase representations using RNN encoder-decoder for statistical machine translation, in: Proceedings of EMNLP; Elman, J.L., Finding structure in time (1990) Cogn. Sci., 14 (2), pp. 179-211; Cambria, E., Hussain, A., Havasi, C., Eckl, C., Common sense computing: From the society of mind to digital intuition and beyond (2009) Biometric ID Management and Multimodal Communication, Lecture Notes in Computer Science, 5707, pp. 252-259. , Fierrez J. Ortega J. Esposito A. Drygajlo A. Faundez-Zanuy M. Springer Berlin Heidelberg; Cambria, E., Olsher, D., Kwok, K., Sentic activation: A Two-Level affective common sense reasoning framework (2012) Proceedings of AAAI, pp. 186-192; Xing, F.Z., Cambria, E., Welsch, R.E., Intelligent Bayesian asset allocation via market sentiment views (2018) IEEE Comput. Intell. Mag., 13 (4), pp. 25-34; Poria, S., Cambria, E., Gelbukh, A.F., Bisio, F., Hussain, A., Sentiment data flow analysis by means of dynamic linguistic patterns (2015) IEEE Comput. Intell. Mag., 10 (4), pp. 26-36; de Marneffe, M.-C., Manning, C.D., (2008), pp. 1-8. , The stanford typed dependencies representation, in: Coling: Proceedings of the Workshop on Cross-Framework and Cross-Domain Parser Evaluation; Cambria, E., Poria, S., Hazarika, D., Kwok, K., SenticNet 5: Discovering conceptual primitives for sentiment analysis by means of context embeddings (2018) Proceedings of AAAI, pp. 1795-1802; Granger, C.W.J., Investigating Causal relations by econometric models and cross-spectral methods (1969) Econometrica, 37 (3), pp. 424-438; Rezende, D.J., Mohamed, S., Wierstra, D., Stochastic backpropagation and approximate inference in deep generative models (2014) Proceedings of ICML, pp. 1278-1286; Bishop, C.M., Lawrence, N.D., Jaakkola, T., Jordan, M.I., Approximating posterior distributions in belief networks using mixtures (1997) Proceedings of NIPSpp., pp. 1-7; Ranganath, R., Gerrish, S., Blei, D.M., Black box variational inference (2014) Proceedings of AISTATS, pp. 814-822; Rabemananjara, R., Zakoian, J.M., Arch models and asymmetries in volatility (1993) J. Appl. Econometrics, 8 (1), pp. 31-49; Wu, Y., Hern\u00e1ndez-Lobato, J.M., Ghahramani, Z., Gaussian process volatility model (2014) Proceedings of NIPS,, 27, pp. 1044-1052; Duchi, J., Hazan, E., Singer, Y., Adaptive subgradient methods for online learning and stochastic optimization (2011) J. Mach. Learn. Res., 12, pp. 2121-2159; Taylor, S.J., Asset Price Dynamics, Volatility, and Prediction (2005), Princeton University Press; Bao, T., Diks, C., Li, H., A generalized CAPM model with asymmetric power distributed errors with an application to portfolio construction (2018) Econ. Model., 68, pp. 611-621; Kim, S., Shephard, N., Chib, S., Stochastic volatility: Likelihood inference and comparison with ARCH models (1998) Rev. Econom. Stud., 65 (3), pp. 361-393; Song, Q., Chissom, B.S., Fuzzy Time series and its models (1993) Fuzzy Sets and Systems, 54, pp. 269-277; Duru, O., A multivariate model of fuzzy integrated logical forecasting method (M-FILF)and multiplicative time series clustering: A model of time-varying volatility for dry cargo freight market (2012) Expert Syst. Appl., 39 (4), pp. 4135-4142; Ding, Y., Liu, W., Bian, J., Zhang, D., Liu, T.-Y., The, A.C., Investor-imitator: A framework for trading knowledge extraction (2018), pp. 1310-1319. , M SIGKDD International Conference on Knowledge Discovery and Data Mining; Dragoni, M., Federici, M., Rexha, A., ReUS: a real-time unsupervised system for monitoring opinion streams (2019) Cogn. Comput.; Li, Y., Pan, Q., Wang, S., Yang, T., Cambria, E., A generative model for category text generation (2018) Inform. Sci., 450, pp. 301-315; Abualigah, L.M., Khader, A.T., Hanandeh, E.S., Hybrid clustering analysis using improved krill herd algorithm (2018) Appl. Intell., 48 (11), pp. 4047-4071; Luo, L., Ao, X., Pan, F., Wang, J., Zhao, T., Yu, N., He, Q., Beyond Polarity: Interpretable financial sentiment analysis with hierarchical query-driven attention (2018) Proceedings of IJCAI, pp. 4244-4250; Xing, F.Z., Cambria, E., Welsch, R.E., Growing semantic vines for robust asset allocation (2019) Knowl.-Based Syst., 165, pp. 297-305"}
{"Authors":"Zhang G., Xu L., Xue Y.","Author(s) ID":"56670483600;7404745474;56278752300;","Title":"Model and forecast stock market behavior integrating investor sentiment analysis and transaction data","Year":2017,"Source title":"Cluster Computing","Volume":"20","Issue":"1","Art. No.":null,"Page start":789.0,"Page end":803.0,"Page count":null,"Cited by":7.0,"DOI":"10.1007\/s10586-017-0803-x","Affiliations":"Department of Computer Science, Shanghai University, Shanghai, China","Document Type":"Article","Access Type":null,"Source":"Scopus","EID":"2-s2.0-85014019024","Abstract":"By combining wavelet analysis with Long Short-Term Memory (LSTM) neural network, this paper proposes a time series prediction model to capture the complex features such as non-linearity, non-stationary and sequence correlation of financial time series. The LSTM is then applied to the prediction of the daily closing price of the Shanghai Composite Index as well as the comparison of its prediction ability with machine learning models such as multi-layer perceptron, support vector machine and K-nearest neighbors. The empirical results show that the LSTM performs a better prediction effect, and it shows excellent effects on the static prediction and dynamic trend prediction of the financial time series, which indicates its applicability and effectiveness to the prediction of financial time series. At the same time, both wavelet decomposition and reconstruction of financial time series can improve the generalization ability of the LSTM prediction model and the prediction accuracy of long-term dynamic trend. \u00a9 2017, Springer Science+Business Media, LLC, part of Springer Nature.","Author Keywords":"Deep learning; Financial time series prediction; Long Short-Term Memory neural network; Wavelets","Index Keywords":"Brain; Deep learning; Finance; Financial data processing; Forecasting; Nearest neighbor search; Time series; Time series analysis; Wavelet decomposition; Decomposition and reconstruction; Financial time series; Financial time series predictions; Generalization ability; Machine learning models; Multi layer perceptron; Time series prediction; Wavelets; Long short-term memory","References":"Taylor, G.W., (2009) Composable, distributed-state models for high-dimensional time series, , University of Toronto, Toronto; Simonyan, K., Zisserman, A., (2014) Very deep convolutional networks for large-scale image recognition; Sarikaya, R., Hinton, G.E., Deoras, A., Application of Deep Belief Networks for natural language understanding (2014) ACM Transactions on Audio Speech and Language Processing, 22 (4), pp. 778-784; Trafalis, T.B., Ince, H., Support vector machine for regression and applications to financial forecasting (2000) Neural Networks. in Proceedings of the IEEE-INNS-ENNS International Joint Conference on IJCNN 2000, pp. 348-353. , IEEE; Guresen, E., Kayakutlu, G., Daim, T.U., Using artificial neural network models in stock market index prediction (2011) Expert Systems with Applications, 38, pp. 10389-10397; Ahmed, N.K., Atiya, A.F., Gayar, N.E., An empirical comparison of machine learning models for time series forecasting (2010) Econometric Reviews, 2010, pp. 594-621; Bengio, Y., LeCun, Y., Scaling learning algorithms towards AI (2007) Large-scale kernel machines, 34, pp. 1-41; Heaton, J.B., Polson, N.G., Witte, J.H., (2016) Deep Learning in Finance, , preprint; Hinton, G., Deng, L., Yu, D., Deep neural networks for acoustic modeling in speech recognition: The shared views of four research groups (2012) IEEE Signal Processing Magazine, 29, pp. 82-97; Taylor, G.W., Fergus, R., Lecun, Y., Bregler, C., Convolutional learning of spatio-temporal features (2010) European Conference on Computer Vision, 6316, pp. 140-153. , Springer; Hsieh, T.J., Hsiao, H.F., Yeh, W.C., Forecasting stock markets using wavelet transforms and recurrent neural networks: An integrated system based on artificial bee colony algorithm (2011) Applied soft computing, 11, pp. 2510-2525; Hochreiter, S., Bengio, Y., Frasconi, P., Gradient flow in recurrent nets: The difficulty of learning long-term dependencies (2001) A Field Guide to Dynamical Recurrent Neural Networks, 28, pp. 237-244. , J. F. Kolen, S. C. Kremer (Eds.), IEEE Press; Sutskever, I., Vinyals, O., Le, Q.V., Sequence to sequence learning with neural networks (2014) Advances in Neural Information Processing Systems, pp. 3104-3112; Pang, Z.Y., Liu, L., Can agricultural product price fluctuation be stabilized by future market: Empirical study based on discrete wavelet transform and GARCH model (2013) Journal of Finance Research, 11, pp. 126-139; L\u00e4ngkvist, M., Karlsson, L., Loutfi, A., A review of unsupervised feature learning and deep learning for time-series modeling (2014) Pattern Recognition Letters, 42, pp. 11-24; Tesauro, G., Practical issues in temporal difference learning (1992) Machine Learning, 8, pp. 257-277; Goodfellow, I., Bengio, Y., Courville, A., (2016) Deep learning, , MIT Press, Cambridge; Graves, A., (2012) Supervised sequence labelling with recurrent neural networks, pp. 5-13. , Springer, Berlin"}
{"Authors":"Galeshchuk S., Mukherjee S.","Author(s) ID":"56205106000;7401816816;","Title":"Deep learning for predictions in emerging currency markets","Year":2017,"Source title":"ICAART 2017 - Proceedings of the 9th International Conference on Agents and Artificial Intelligence","Volume":"2","Issue":null,"Art. No.":null,"Page start":681.0,"Page end":686.0,"Page count":null,"Cited by":1.0,"DOI":null,"Affiliations":"Department of Accounting and Audit, Ternopil National Economic University, Ternopil, Ukraine; Laboratoire d'Informatique de Grenoble, Universit\u00e9 Grenoble Alpes, Grenoble, France; College of Engineering and Computing, Nova Southeastern University, Fort Lauderdale, United States","Document Type":"Conference Paper","Access Type":null,"Source":"Scopus","EID":"2-s2.0-85049629999","Abstract":"The world economy is in a stage of rapid development, and financial development is also continuing. Financial activities are increasing, and the uncertainty of its changing trend is also increasing. An effective financial forecast can provide a basis for financial planning and decision-making while maintaining the healthy development of financial markets. Convolution neural network is a multilayer neural network structure that simulates the operation mechanism of biological vision system. It is a neural network composed of multiple layers of convolution layers and down sampling layers. It can obtain useful feature descriptions from raw data and is an effective method for extracting features from data. Therefore, this paper introduces the convolution neural network structure to predict the financial time series data, establishes a convolution neural network model, and studies the influence of model parameters on the stock prediction results. Through simulation and comparison, the feasibility and effectiveness of the prediction model given in this paper are verified. \u00a9 2019 IEEE.","Author Keywords":"convolutional neural network; financial forecasting; stock forecasting; support vector machine","Index Keywords":"Advanced Analytics; Big data; Cloud computing; Convolution; Decision making; Electronic trading; Forecasting; Multilayer neural networks; Support vector machines; Biological vision systems; Convolution neural network; Convolutional neural network; Extracting features; Financial development; Financial forecasting; Financial time series; Stock forecasting; Finance","References":"Min, G., Hui, P., Xiaoyang, P., Xiaohong, C., Inoussa, G., A locally linear RBF network-based state-dependent AR model for nonlinear time series modeling (2010) Information Sciences, 180, pp. 4370-4383; Cao, J., Lin, Z., Huang, G.-B., Composite function wavelet neural networks with extreme learning machine (2011) Neural Process Lett, 33, pp. 251-265; Lin, K., Lin, Q., Zhou, C., Yao, J., Time series prediction based on linear regression and SVR (2007) Processing of the Third International Conference on Natrual Computation., pp. 688-691; Vapnik, V., (1995) The Nature of Statistical Learning Theory, , Springer-Verlag, New York, NY; Peng, H., Nakano, K., Shioya, H., Nonlinear predictive control using neural nets-based local linearization ARX model Stability and industrial application (2007) IEEE Trans. on Control Systems Technology, 15 (1), pp. 130-143; De Nicolao, G., Magni, L., Scattolini, R., Stabilizing Predictive control of Nonlinear ARX Models (1997) Automatica, 33 (9), pp. 1691-1697; Mayne, D.Q., Rawlings, J.B., Rao, C.V., Scokaert, P.O.M., Constrained model predictive control: Stability and optimality (2000) Automatica, 36 (6), pp. 789-814"}
{"Authors":"[No author name available]","Author(s) ID":"[No author id available]","Title":"European Conference on Machine Learning and Principles and Practice of Knowledge Discovery in Databases, ECML PKDD 2017","Year":2017,"Source title":"Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)","Volume":"10534 LNAI","Issue":null,"Art. No.":null,"Page start":null,"Page end":null,"Page count":2148.0,"Cited by":null,"DOI":null,"Affiliations":null,"Document Type":"Conference Review","Access Type":null,"Source":"Scopus","EID":"2-s2.0-85040242291","Abstract":"We propose a parsimonious quantile regression framework to learn the dynamic tail behaviors of financial asset returns. Our model captures well both the time-varying characteristic and the asymmetrical heavy-tail property of financial time series. It combines the merits of a popular sequential neural network model, i.e., LSTM, with a novel parametric quantile function that we construct to represent the conditional distribution of asset returns. Our model also captures individually the serial dependences of higher moments, rather than just the volatility. Across a wide range of asset classes, the out-of-sample forecasts of conditional quantiles or VaR of our model outperform the GARCH family. Further, the proposed approach does not suffer from the issue of quantile crossing, nor does it expose to the ill-posedness comparing to the parametric probability density function approach. \u00a9 2018 Curran Associates Inc.All rights reserved.","Author Keywords":null,"Index Keywords":"Finance; Financial data processing; Probability density function; Conditional distribution; Conditional quantiles; Financial asset returns; Financial time series; Out-of-sample forecast; Sequential learning; Sequential neural networks; Time-varying characteristics; Long short-term memory","References":"Bali, T.G., Mo, H., Tang, Y., The role of autoregressive conditional skewness and kurtosis in the estimation of conditional var (2008) Journal of Banking & Finance, 32 (2), pp. 269-282; Bollerslev, T., Generalized autoregressive conditional heteroskedasticity (1986) Journal of Econometrics, 31 (3), pp. 307-327; Angeles Carnero, M., Pe\u00f1a, D., Ruiz, E., Persistence and kurtosis in garch and stochastic volatility models (2004) Journal of Financial Econometrics, 2 (2), pp. 319-342; Chen, X., Chen, J., Ma, L., Yao, J., Liu, W., Luo, J., Zhang, T., Fine-grained video attractiveness prediction using multimodal deep learning on a large real-world dataset (2018) Companion of the the Web Conference 2018 on the Web Conference 2018, pp. 671-678. , International World Wide Web Conferences Steering Committee; Chernozhukov, V., Fern\u00e1ndez-Val, I., Galichon, A., Quantile and probability curves without crossing (2010) Econometrica, 78 (3), pp. 1093-1125; Christoffersen, P.F., Evaluating interval forecasts (1998) International Economic Review, pp. 841-862; Cont, R., Empirical properties of asset returns: Stylized facts and statistical issues (2001) Quantitative Finance, 1 (2), pp. 223-236; Dias, A., Market capitalization and value-at-risk (2013) Journal of Banking & Finance, 37 (12), pp. 5248-5260; Engle, R.F., Autoregressive conditional heteroscedasticity with estimates of the variance of United Kingdom inflation (1982) Econometrica: Journal of the Econometric Society, pp. 987-1007; Engle, R.F., Manganelli, S., CaviAR: Conditional autoregressive value at risk by regression quantiles (2004) Journal of Business & Economic Statistics, 22 (4), pp. 367-381; Fan, L., Huang, W., Gan, S.E.C., Gong, B., Huang, J., End-to-end learning of motion representation for video understanding (2018) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 6016-6025; Feng, Y., Ma, L., Liu, W., Zhang, T., Luo, J., Video re-localization (2018) Proceedings of the European Conference on Computer Vision (ECCV), pp. 51-66; Fleming, J., Kirby, C., A closer look at the relation between garch and stochastic autoregressive volatility (2003) Journal of Financial Econometrics, 1 (3), pp. 365-419; Franses, P.H., Van Der Leij, M., Paap, R., A simple test for garch against a stochastic volatility model (2007) Journal of Financial Econometrics, 6 (3), pp. 291-306; Glasserman, P., Wu, Q., Persistence and procyclicality in margin requirements (2018) Management Science; Glosten, L.R., Jagannathan, R., Runkle, D.E., On the relation between the expected value and the volatility of the nominal excess return on stocks (1993) The Journal of Finance, 48 (5), pp. 1779-1801; Hansen, B.E., Autoregressive conditional density estimation (1994) International Economic Review, pp. 705-730; Hochreiter, S., Schmidhuber, J., Long short-term memory (1997) Neural Computation, 9 (8), pp. 1735-1780; Koenker, R., Gilbert, G.B., Jr., Regression quantiles (1978) Econometrica: Journal of the Econometric Society, pp. 33-50; Koenker, R., Hallock, K.F., Quantile regression (2001) Journal of Economic Perspectives, 15 (4), pp. 143-156; Kupiec, P.H., Techniques for verifying the accuracy of risk measurement models (1995) The Journal of Derivatives, 3 (2), pp. 73-84; Le\u00f3n, \u00c1., Rubio, G., Serna, G., Autoregresive conditional volatility, skewness and kurtosis (2005) The Quarterly Review of Economics and Finance, 45 (4-5), pp. 599-618; Lipton, Z.C., Berkowitz, J., Elkan, C., (2015) A Critical Review of Recurrent Neural Networks for Sequence Learning, , arXiv preprint; Nelson, D.B., Conditional heteroskedasticity in asset returns: A new approach (1991) Econometrica: Journal of the Econometric Society, pp. 347-370; Rockinger, M., Jondeau, E., Entropy densities with an application to autoregressive conditional skewness and kurtosis (2002) Journal of Econometrics, 106 (1), pp. 119-142; Sivakumar, V., Banerjee, A., High-dimensional structured quantile regression (2017) International Conference on Machine Learning, pp. 3220-3229; Takeuchi, I., Le, Q.V., Sears, T.D., Smola, A.J., Nonparametric quantile estimation (2006) Journal of Machine Learning Research, 7, pp. 1231-1264. , Jul; Taylor, S.J., Modeling stochastic volatility: A review and comparative study (1994) Mathematical Finance, 4 (2), pp. 183-204; Wang, B., Ma, L., Zhang, W., Liu, W., Reconstruction network for video captioning (2018) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 7622-7631; Wang, J., Jiang, W., Ma, L., Liu, W., Xu, Y., Bidirectional attentive fusion with context gating for dense video captioning (2018) Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 7190-7198; Yang, J., Meng, X., Mahoney, M., Quantile regression for large-scale applications (2013) International Conference on Machine Learning, pp. 881-887; Zakoian, J.-M., Threshold heteroskedastic models (1994) Journal of Economic Dynamics and Control, 18 (5), pp. 931-955"}
{"Authors":"[No author name available]","Author(s) ID":"[No author id available]","Title":"European Conference on Machine Learning and Principles and Practice of Knowledge Discovery in Databases, ECML PKDD 2017","Year":2017,"Source title":"Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)","Volume":"10536 LNAI","Issue":null,"Art. No.":null,"Page start":null,"Page end":null,"Page count":2148.0,"Cited by":null,"DOI":null,"Affiliations":null,"Document Type":"Conference Review","Access Type":null,"Source":"Scopus","EID":"2-s2.0-85040239499","Abstract":"Stock index prediction is regarded as a challenging task due to the phenomena of non-linearity and random drift in trends of stock indices. In practical applications, different indicator features have significant impact when predicting stock index. In addition, different technical indicators which contained in the same matrix will interfere with each other when convolutional neural network (CNN) is applied to feature extraction. To solve the above problem, this paper suggests a multi-indicator feature selection for stock index prediction based on a multi-channel CNN structure, named MI-CNN framework. In this method, candidate indicators are selected by maximal information coefficient feature selection (MICFS) approach, to ensure the correlation with stock movements while reduce redundancy between different indicators. Then an effective CNN structure without sub-sampling is designed to extract abstract features of each indicator, avoiding mutual interference between different indicators. Extensive experiments support that our proposed method performs well on different stock indices and achieves higher returns than the benchmark in trading simulations, providing good potential for further research in a wide range of financial time series prediction with deep learning based approaches. \u00a9 2018, Springer Nature Switzerland AG.","Author Keywords":"Convolutional neural networks; Feature selection; Maximal information coefficient; Stock index prediction","Index Keywords":"Convolution; Deep learning; Finance; Financial data processing; Forecasting; Neural networks; Convolutional neural network; Convolutional Neural Networks (CNN); Financial time series predictions; Learning-based approach; Maximal information; Mutual interference; Stock index predictions; Technical indicator; Feature extraction","References":"Bollerslev, T., Generalized autoregressive conditional heteroskedasticity (1986) J. Econom., 31 (3), pp. 307-327; Box, G.E., Jenkins, G.M., Reinsel, G.C., Ljung, G.M., (2015) Time Series Analysis: Forecasting and Control, , Wiley, Hoboken; Chiang, W.C., Enke, D., Wu, T., Wang, R., An adaptive stock index trading decision support system (2016) Expert Syst. Appl., 59, pp. 195-207; Donaldson, R.G., Kamstra, M., An artificial neural network-garch model for international stock return volatility (1997) J. Empirical Finance, 4 (1), pp. 17-46; Enke, D., Thawornwong, S., The use of data mining and neural networks for forecasting stock market returns (2005) Expert Syst. Appl., 29 (4), pp. 927-940; Gudelek, M.U., Boluk, S.A., Ozbayoglu, A.M., A deep learning based stock trading model with 2-D CNN trend detection 2017 IEEE Symposium Series on Computational Intelligence (SSCI), pp. 1-8. , https:\/\/doi.org\/10.1109\/SSCI.2017.8285188, November 2017; Gunduz, H., Yaslan, Y., Cataltepe, Z., Gunduz, H., Yaslan, Y., Cataltepe, Z., Intraday prediction of Borsa Istanbul using convolutional neural networks and feature correlations (2017) Knowl.-Based Syst., 137, pp. 138-148; Guresen, E., Kayakutlu, G., Daim, T.U., Using artificial neural network models in stock market index prediction (2011) Expert Syst. Appl., 38 (8), pp. 10389-10397; Huang, C.L., Tsai, C.Y., A hybrid SOFM-SVR with a filter-based feature selection for stock market forecasting (2009) Expert Syst. Appl., 36 (2), pp. 1529-1539; Krizhevsky, A., Sutskever, I., Hinton, G.E., Imagenet classification with deep convolutional neural networks (2012) Advances in Neural Information Processing Systems, pp. 1097-1105; Lee, M.C., Using support vector machine with a hybrid feature selection method to the stock trend prediction (2009) Expert Syst. Appl., 36 (8), pp. 10896-10904; Malagrino, L.S., Roman, N.T., Monteiro, A.M., Forecasting stock market index daily direction: A Bayesian network approach (2018) Expert Syst. Appl., 105, pp. 11-22; Oriani, F.B., Coelho, G.P., Evaluating the impact of technical indicators on stock forecasting (2016) 2016 IEEE Symposium Series on Computational Intelligence (SSCI), pp. 1-8. , IEEE; Reshef, D.N., Reshef, Y.A., Finucane, H.K., Grossman, S.R., McVean, G., Turn-Baugh, P.J., Lander, E.S., Sabeti, P.C., Detecting novel associations in large datasets (2011) Science, 334 (6062), p. 1518; Sezer, O.B., Ozbayoglu, A.M., Algorithmic financial trading with deep convolutional neural networks: Time series to image conversion approach (2018) Appl. Soft Comput., 70, pp. 525-538; Su, C.H., Cheng, C.H., (2016) A Hybrid Fuzzy Time Series Model Based on ANFIS and Integrated Nonlinear Feature Selection Method for Forecasting Stock, , Elsevier Science Publishers B. V., Amsterdam; Swingler, K., (1996) Applying Neural Networks: A Practical Guide, , Morgan Kaufmann, Burlington; Tsantekidis, A., Passalis, N., Tefas, A., Kanniainen, J., Gabbouj, M., Iosifidis, A., Forecasting stock prices from the limit order book using convolutional neural networks (2017) Business Informatics, pp. 7-12; Wen, Q., Yang, Z., Song, Y., Jia, P., Automatic stock decision support system based on box theory and SVM algorithm (2010) Expert Syst. Appl. Int. J., 37 (2), pp. 1015-1022"}
{"Authors":"[No author name available]","Author(s) ID":"[No author id available]","Title":"European Conference on Machine Learning and Principles and Practice of Knowledge Discovery in Databases, ECML PKDD 2017","Year":2017,"Source title":"Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)","Volume":"10535 LNAI","Issue":null,"Art. No.":null,"Page start":null,"Page end":null,"Page count":2148.0,"Cited by":null,"DOI":null,"Affiliations":null,"Document Type":"Conference Review","Access Type":null,"Source":"Scopus","EID":"2-s2.0-85040219278","Abstract":"Appropriate monetary liquidity is important for financial institutions. When institutions lack adequate cash flow for customer redemption, their income will decrease, their reputation will be affected, and they may even go bankrupt. However, the opposite extreme in which more cash is reserved than needed may result in lost opportunities to make successful investments. This study uses Yu'e Bao transaction data to investigate a method for forecasting financial capital flow. Yu'e Bao, which is a financial product launched by Alibaba, faces the core challenge of maximizing commercial profits to reduce investment risks. Liquidity risk is considered the main factor in Yu'e Bao's investment strategy. First, a linear model called YEB-ARIMA is proposed by determining the autocorrelation (ACF) and partial autocorrelation (PACF) parameters, which are optimized by the grid search method. Second, a deep learning model called YEB-LSTM is introduced to strengthen the expressiveness of the model that yields nonlinear transaction features. Then, a hybrid learning method called YEB-Hybrid is applied to improve the original weak classifiers. This model includes both a linear combination and logistic regression learning. Third, a set of experiments and analyses are conducted based on subscription and redemption datasets to demonstrate that the hybrid model achieves an accuracy of 84.39% and 84.36%, respectively, under a variety of evaluation indexes. Finally, various proposed fund reserve ratios are provided based on capital forecasts. \u00a9 2013 IEEE.","Author Keywords":"ARIMA; big data financial analysis; capital flow prediction; Liquidity risk; LSTM; time series","Index Keywords":"Autocorrelation; Economics; Forecasting; Investments; Long short-term memory; Risk assessment; Time series; Time series analysis; ARIMA; Capital flow; Financial analysis; Liquidity risk; LSTM; Deep learning","References":"Yin, Y., Xu, W., Xu, Y., Li, H., Yu, L., Collaborative QoS prediction for mobile service with data filtering and SlopeOne model (2017) Mobile Inf. Syst., 2017, pp. 73562131-735621314. , Jun; Chen, Y., Deng, S., Ma, H., Yin, J., Deploying data-intensive applications with multiple services components on edge (2019) Mobile Networks and Applications, , Berlin, Germany: Springer; Harvie, C., Van Hoa, T., (2016) The Causes and Impact of the Asian Financial Crisis, , Berlin, Germany: Springer; Liu, Q., Zhang, F., Mao, M., Xue, B., Lin, Z., An empirical study on factors affecting continuance intention of using Yu'e Bao (2018) Tehniki Vjesnik, 25 (5), pp. 1414-1420; Gibbons, J.C., (2017) Experiments in Quantitative Finance, , Abingdon, U.K.: Routledge; Russell, S., Norvig, P., (2016) Artificial Intelligence: A Modern Approach, , Kuala Lumpur, Malaysia: Pearson; Deng, S., Huang, L., Xu, G., Wu, X., Wu, Z., On deep learning for trustaware recommendations in social networks (2017) IEEE Trans. Neural Netw. Learn. Syst., 28 (5), pp. 1164-1177. , May; Ding, C., Duan, J., Zhang, Y., Wu, X., Yu, G., Using an ARIMAGARCH modeling approach to improve subway short-term ridership forecasting accounting for dynamic volatility (2018) IEEE Trans. Intell. Transp. Syst., 19 (4), pp. 1054-1064. , Apr; Gong, J., Ye, X., Liang, Z., An empirical study about the effect which Bao Bao' Internet monetary funds make on deposits in Chinese commercial banks (2016) Amer. J. Ind. Bus. Manage., 6 (9), p. 993; Mathur, P., Overview of machine learning in finance (2019) Machine Learning Applications Using Python, pp. 259-270. , Berkeley, CA, USA: Apress; Hamid, O.H., Smith, N.L., Barzanji, A., Automation, per se, is not job elimination: How artificial intelligence forwards cooperative humanmachine coexistence (2017) Proc. IEEE 15th Int. Conf. Ind. Inform. (INDIN), pp. 899-904. , Jul; Box, G.E.P., Jenkins, G.M., Reinsel, G.C., Ljung, G.M., (2015) Time Series Analysis: Forecasting and Control, , Hoboken, NJ, USA: Wiley; Wang, W.-C., Chau, K.-W., Xu, D.-M., Chen, X.-Y., Improving forecasting accuracy of annual runoff time series using ARIMA based on EEMD decomposition (2015) Water Resour. Manage., 29 (8), pp. 2655-2675; Paradis, E., (2009) Moran's Autocorrelation Coefficient in Comparative Methods, pp. 1-9. , https:\/\/cran.r-project.org\/web\/packages\/ape\/vignettes\/MoranI.pdf, R Found. Stat. Comput., Vienna, U.K., Tech. Rep; Su, C.-W., Li, Z.-Z., Tao, R., Si, D.-K., Testing for multiple bubbles in bitcoin markets: A generalized sup ADF test (2018) Jpn. World Economy, 46, pp. 56-63. , Jun; Khashei, M., Hajirahimi, Z., A comparative study of series arima\/mlp hybrid models for stock price forecasting (2018) Commun. Statist.-Simul. Comput., pp. 1-16. , http:\/\/www.stat.ucla.edu\/~frederic\/415\/F18\/stockprice.pdf, May; Pontes, F.J., Amorim, G.F., Balestrassi, P.P., Paiva, A.P., Ferreira, J.R., Design of experiments and focused grid search for neural network parameter optimization (2016) Neurocomputing, 186, pp. 22-34. , Apr; Kim, S., Kim, H., A new metric of absolute percentage error for intermittent demand forecasts (2016) Int. J. Forecasting, 32 (3), pp. 669-679. , Jul.\/Sep; Kallsen, J., Muhle-Karbe, J., The general structure of optimal investment and consumption with small transaction costs (2017) Math. Finance, 27 (3), pp. 659-703; Zhang, S., Zhou, D., Yildirim, M.Y., Alcorn, S., He, J., Davulcu, H., Tong, H., HiDDen: Hierarchical dense subgraph detection with application to financial fraud detection (2017) Proc. SIAM Int. Conf. Data Mining Soc. Ind. Appl. Math., pp. 570-578; Rout, A.K., Forecasting financial time series using a low complexity recurrent neural network and evolutionary learning approach (2017) J. King Saud Univ.-Comput. Inf. Sci., 29 (4), pp. 536-552; Fischer, T., Krauss, C., Deep learning with long short-term memory networks for financial market predictions (2018) Eur. J. Oper. Res., 270 (2), pp. 654-669; Tran, D.T., Iosidis, A., Kanniainen, J., Gabbouj, M., Temporal attention-augmented bilinear network for financial time-series data analysis (2019) IEEE Trans. Neural Netw. Learn. Syst., 30 (5), pp. 1407-1418. , May; Huang, G., Liu, Z., Van Dre Maaten, L., Weinberger, K.Q., Densely connected convolutional networks (2017) Proc. IEEE Conf. Comput. Vis. Pattern Recognit. (CVPR), pp. 2261-2269. , Jul; Huang, L., Liu, X., Lang, B., Yu, A.W., Wang, Y., Li, B., Orthogonal weight normalization: Solution to optimization over multiple dependent stiefel manifolds in deep neural networks (2018) Proc. 32nd AAAI Conf. Artif. Intell., pp. 3271-3278; Yin, Y., Xu, Y., Xu, W., Gao, M., Yu, L., Pei, Y., Collaborative service selection via ensemble learning in mixed mobile network environments (2017) Entropy, 19 (7), p. 358; Alobaidi, M.H., Chebana, F., Meguid, M.A., Robust ensemble learning framework for day-ahead forecasting of household based energy consumption (2018) Appl. Energy, 212, pp. 997-1012. , Feb; Gao, H., Mao, S., Huang, W., Yang, X., Applying probabilistic model checking to financial production risk evaluation and control: A case study of Alibaba's Yu'e Bao (2018) IEEE Trans. Comput. Social Syst., 5 (3), pp. 785-795. , Sep; Bagchi, P., Characiejus, V., Dette, H., A simple test for white noise in functional time series (2018) J. Time Ser. Anal., 39 (1), pp. 54-74; Brunnermeier, M., Palia, D., Sastry, K.A., Sims, C.A., (2017) Feedbacks: Financial Markets and Economic Activity, pp. 1-64. , https:\/\/scholar.princeton.edu\/sites\/default\/files\/markus\/files\/02bpss_draft.pdf, Princeton Univ., Princeton, NJ, USA, Tech. Rep; Perera, I., Hidalgo, J., Silvapulle, M.J., A goodness-of-fit test for a class of autoregressive conditional duration models (2016) Econ. Rev., 35 (6), pp. 1111-1141; Ye, T., Dianbo, S., Yichuan, Z., Statistical modeling analysis of fund flow of Yu'ebao (2015) Proc. 4th Nat. College Students Stat. Modeling Contest, pp. 1-32; Duru, O., Golan, R., Quintana, D., Computational intelligence in finance and economics [guest editorial] (2018) IEEE Comput. Intell. Mag., 13 (4), p. 13. , Nov; Agarwal, V., Ruenzi, S., Weigert, F., Tail risk in hedge funds: Aunique viewfrom portfolio holdings (2017) J. Financial Econ., 125 (3), pp. 610-636. , Sep; Yongxin, L., Discussing on securities investment fund hedging risks and countermeasures (2012) Proc. Int. Conf. Inf. Manage., Innov. Manage. Ind. Eng., pp. 94-97. , Sanya, China, Oct; Sun, Y., Aw, G., Loxton, R., Teo, K.L., Chance-constrained optimization for pension fund portfolios in the presence of default risk (2017) Eur. J. Oper. Res., 256 (1), pp. 205-214; Zhang, X., Meng, H., Xiong, J., Shen, Y., Robust optimal investment and reinsurance of an insurer under Jump-diffusion models (2019) Math. Control Related Fields, 9 (1), pp. 59-76; Yan, H., Ouyang, H., Financial time series prediction based on deep learning (2018) Wireless Pers. Commun., 102 (2), pp. 1-8; Yang, Y., Kolesnikova, A., Lessmann, S., Ma, T., Sung, M.-C., Johnson, J.E.V., (2018) Can Deep Learning Predict Risky Retail Investors? A Case Study in Financial Risk Behavior Forecasting, , https:\/\/arxiv.org\/abs\/1812.06175; Liu, M., Huang, M., Zhang, Y., Feng, W., Lai, J., Li, X., Using deep residual networks to deal with financial risk control problems (2018) Proc. ACAI, , New York, NY, USA; Ahmed, M., Choudhury, N., Uddin, S., Anomaly detection on big data in financial markets (2017) Proc. IEEE\/ACMASONAM, pp. 998-1001. , J. Diesner, E. Ferrari, and G. Xu, Eds. New York, NY, USA; Shi, H., Xu, M., Li, R., Deep learning for household load forecasting A novel pooling deep RNN (2018) IEEE Trans. Smart Grid, 9 (5), pp. 5271-5280. , Sep; Yin, Y., Chen, L., Xu, Y., Wan, J., Zhang, H., Mai, Z., QoS prediction for service recommendation with deep feature learning in edge computing environment (2019) Mobile Networks and Applications, , Berlin, Germany: Springer; Deng, S., Xiang, Z., Yin, J., Taheri, J., Zomaya, A.Y., Compositiondriven IoT service provisioning in distributed edges (2018) IEEE Access, 6, pp. 54258-54269"}
{"Authors":"Yu H., Xu L., Zhang G.","Author(s) ID":"57197735758;7404745474;56670483600;","Title":"A convolutional neural network based approach for stock forecasting","Year":2017,"Source title":"Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)","Volume":"10614 LNCS","Issue":null,"Art. No.":null,"Page start":731.0,"Page end":732.0,"Page count":null,"Cited by":1.0,"DOI":"10.1007\/978-3-319-68612-7","Affiliations":"Department of Computer Science, Shanghai University, Shanghai, China; Shanghai Advanced Research Institute, Chinese Academy of Sciences, Beijing, China","Document Type":"Conference Paper","Access Type":null,"Source":"Scopus","EID":"2-s2.0-85034241812","Abstract":"The prediction of price trend in stock market is a challenging task due to the inherent complexity and dynamics in price movement. Many machine learning algorithms, such as Support Vector Machine, Artificial Neural Network, and Hidden Markov Model, have been applied to it and achieved positive results. Long Short-Term Memory (LSTM), as a variant of RNN, can obtain hidden dependencies in data and has shown a significant performance in processing time series data. In this paper, we apply LSTM networks to predict the price movement of a short-term and test it by an experiment on some stocks randomly selected from CSI 300 constituent stocks. The experiment shows that the precision, recall rate and critical error of LSTM are all better than that of the random prediction. It indicates that LSTM can be used in the trend prediction of stock price. We also notice that many improvements need to be done in future. \u00a9 2018 IEEE.","Author Keywords":"Financial time series; Long Short-Term Memory; Trend prediction","Index Keywords":"Brain; Data handling; Education computing; Electronic trading; Financial markets; Forecasting; Hidden Markov models; Learning algorithms; Learning systems; Time series; Financial time series; High frequency HF; Inherent complexity; Price movement; Price trends; Processing time; Trend forecast; Trend prediction; Long short-term memory","References":"Graham, B., Dodd, D.L., (1934) Security Analysis: Principles and Technique, , McGraw-Hill; White, H., (1988) Economic Prediction Using Neural Networks: The Case of IBM Daily Stock Returns; Hassan, M.R., Nath, B., Stock market forecasting using hidden Markov model: A new approach (2005) Intelligent Systems Design and Applications, 2005. ISDA'05. Proceedings. 5th International Conference On. IEEE, pp. 192-196; Kazem, A., Sharifi, E., Hussain, F.K., Support vector regression with chaos-based firefly algorithm for stock market price forecasting (2013) Applied Soft Computing, 13 (2), pp. 947-958; Rather, A.M., Agarwal, A., Sastry, V.N., Recurrent neural network and a hybrid model for prediction of stock returns (2015) Expert Systems with Applications, 42 (6), pp. 3234-3241; Hochreiter, S., Schmidhuber, J., Long short-term memory (1997) Neural Computation, 9 (8), pp. 1735-1780; Hochreiter, S., Bengio, Y., Frasconi, P., (2001) Gradient Flow in Recurrent Nets: The Difficulty of Learning Long-term Dependencies; https:\/\/www.tensorflow.org\/; Luo, L., You, S., Xu, Y., Improving the integration of piece wise linear representation and weighted support vector machine for stock trading signal prediction (2017) Applied Soft Computing, 56, pp. 199-216; Ba, J.L., Kiros, J.R., Hinton, G.E., (2016) Layer Normalization; Murphy, J.J., (1999) Technical Analysis of the Financial Markets: A Comprehensive Guide to Trading Methods and Applications, , Penguin"}
{"Authors":"Borovykh A., Bohte S., Oosterlee C.W.","Author(s) ID":"57193126885;55893905100;6701797256;","Title":"Conditional time series forecasting with convolutional neural networks","Year":2017,"Source title":"Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)","Volume":"10614 LNCS","Issue":null,"Art. No.":null,"Page start":729.0,"Page end":730.0,"Page count":null,"Cited by":3.0,"DOI":"10.1007\/978-3-319-68612-7","Affiliations":"Dipartimento di Matematica, Universit\u00e0 di Bologna, Bologna, Italy; Centrum Wiskunde and Informatica, Amsterdam, Netherlands; Delft University of Technology, Delft, Netherlands","Document Type":"Conference Paper","Access Type":null,"Source":"Scopus","EID":"2-s2.0-85034213008","Abstract":"Financial time series analysis is an important research area that can predict various economic indicators such as the foreign currency exchange rate. In this paper, a deep-learning-based model is proposed to forecast the foreign exchange rate. Since the currency market is volatile and susceptible to ongoing social and political events, the proposed model incorporates event sentiments to accurately predict the exchange rate. Moreover, as the currency market is heavily dependent upon highly volatile factors such as gold and crude oil prices, we considered these sensitive factors for exchange rate forecasting. The validity of the model is tested over three currency exchange rates, which are Pak Rupee to US dollar (PKR\/USD), British pound sterling to US dollar (GBP\/USD), and Hong Kong Dollar to US dollar (HKD\/USD). The study also shows the importance of incorporating investor sentiment of local and foreign macro-level events for accurate forecasting of the exchange rate. We processed approximately 5.9 million tweets to extract major events' sentiment. The results show that this deep-learning-based model is a better predictor of foreign currency exchange rate in comparison with statistical techniques normally employed for prediction. The results present evidence that the exchange rate of all the three countries is more exposed to events happening in the US. \u00a9 2019 by the authors.","Author Keywords":"Deep learning; Event sentiment; Forecasting; Foreign exchange rate; Regression; SVM","Index Keywords":null,"References":"Meese, R.A., Rogoff, K., Empirical exchange rate models of the seventies: Do they fit out of sample? (1983) J. Int. Econ, 14, pp. 3-24; Meese, R., Rogoff, K., The out-of-sample failure of empirical exchange rate models: Sampling error or misspecification? (1983) Exchange Rates and International Macroeconomics, pp. 67-112. , University of Chicago Press: Chicago, IL, USA; \u0160tepni\u010dka, M., Cortez, P., Donate, J.P., \u0160tepni\u010dkov\u00e1, L., Forecasting seasonal time series with computational intelligence: On recent methods and the potential of their combinations (2013) Expert Syst. Appl, 40, pp. 1981-1992; Cavalli, F., Naimzada, A., Pireddu, M., An evolutive financial market model with animal spirits: Imitation and endogenous beliefs (2017) J. Evol. Econ, 27, pp. 1007-1040; Contreras, J., Espinola, R., Nogales, F.J., Conejo, A.J., ARIMA models to predict next-day electricity prices (2003) IEEE Trans. Power Syst, 18, pp. 1014-1020; Bollerslev, T., Generalized autoregressive conditional heteroskedasticity (1986) J. Econom, 31, pp. 307-327; Galeshchuk, S., Neural networks performance in exchange rate prediction (2016) Neurocomputing, 172, pp. 446-452; Khashei, M., Bijari, M., An artificial neural network (p, d, q) model for timeseries forecasting (2010) Expert Syst. Appl, 37, pp. 479-489; Yadav, A.K., Chandel, S., Solar radiation prediction using Artificial Neural Network techniques: A review (2014) Renew. Sustain. Energy Rev, 33, pp. 772-781; Agatonovic-Kustrin, S., Beresford, R., Basic concepts of artificial neural network (ANN) modeling and its application in pharmaceutical research (2000) J. Pharm. Biomed. Anal, 22, pp. 717-727; Majhi, R., Panda, G., Sahoo, G., Efficient prediction of exchange rates with low complexity artificial neural network models (2009) Expert Syst. Appl, 36, pp. 181-189; Pradeepkumar, D., Ravi, V., Forecasting financial time series volatility using particle swarm optimization trained quantile regression neural network (2017) Appl. Soft Comput, 58, pp. 35-52; Tang, Z., Fishwick, P., Back-propagation neural nets as models for time series forecasting (1993) ORSA J. Comput, 5, pp. 374-385; Mundell, R.A., Capital mobility and stabilization policy under fixed and flexible exchange rates (1963) Can. J. Econ. Political Sci, 29, pp. 475-485; Dornbusch, R., Exchange rate expectations and monetary policy (1976) J. Int. Econ, 6, pp. 231-244; Engel, C., Exchange rates and interest parity (2013) Handbook of International Economics, 4. , Gopinath, G., Helpman, E., Rogoff, K., Eds.; Elsevier: Amsterdam, The Netherlands; Neely, C.J., Sarno, L., How well do monetary fundamentals forecast exchange rates? (2002) Federal Reserve Bank of St. Louis Working Paper Series, , Federal Reserve Bank of St. Louis: St. Louis, MO, USA; Box, G.E., Jenkins, G.M., Reinsel, G.C., Ljung, G.M., (2015) Time Series Analysis: Forecasting and Control, , John Wiley & Sons: Hoboken, NJ, USA; Lam, M., Neural network techniques for financial performance prediction: Integrating fundamental and technical analysis (2004) Decis. Support Syst, 37, pp. 567-581; Thinyane, H., Millin, J., An investigation into the use of intelligent systems for currency trading (2011) Comput. Econ, 37, pp. 363-374; \u00d6nder, E., Bayir, F., Hepsen, A., Forecasting macroeconomic variables using artificial neural network and traditional smoothing techniques (2013) J. Appl. Financ. Bank, 3, pp. 73-104; Ahmad, J., Fatmi, H., Quadric neural network for the prediction of financial time series data (1994) Proceedings of the 1994 IEEE International Conference on Neural Networks (ICNN'94), pp. 3667-3670. , Orlando, FL, USA, 28 June-2 July; Swanson, N.R., White, H., Forecasting economic time series using flexible versus fixed specification and linear versus nonlinear econometric models (1997) Int. J. Forecast, 13, pp. 439-461; Kuan, C.-M., White, H., Artificial neural networks: An econometric perspective (1994) Econom. Rev, 13, pp. 1-91; Qi, M., Maddala, G., Economic factors and the stock market: A new perspective (1999) J. Forecast, 18, pp. 151-166; Gencay, R., Linear, non-linear and essential foreign exchange rate prediction with simple technical trading rules (1999) J. Int. Econ, 47, pp. 91-107; Santos, A.A.P., da Costa, N.C.A., Jr., dos Santos Coelho, L., Computational intelligence approaches and linear models in case studies of forecasting exchange rates (2007) Expert Syst. Appl, 33, pp. 816-823; Ozkan, F., A comparison of the monetary model and artificial neural networks in exchange rate forecasting (2012) Bus. Econ. Res. J, 3, pp. 1-27; Dunis, C.L., Huang, X., Forecasting and trading currency volatility: An application of recurrent neural regression and model combination (2002) J. Forecast, 21, pp. 317-354; Jena, P.R., Majhi, R., Majhi, B., Development and performance evaluation of a novel knowledge guided artificial neural network (KGANN) model for exchange rate prediction (2015) J. King Saud Univ.-Comput. Inf. Sci, 27, pp. 450-457; Kamruzzaman, J., Sarker, R.A., ANN-based forecasting of foreign currency exchange rates (2004) Neural Inf. Process.-Lett. Rev, 3, pp. 49-58; Chen, A.-S., Leung, M.T., Regression neural network for error correction in foreign exchange forecasting and trading (2004) Comput. Oper. Res, 31, pp. 1049-1068; Dunis, C.L., Laws, J., Sermpinis, G., Higher order and recurrent neural architectures for trading the EUR\/USD exchange rate (2011) Quant. Financ, 11, pp. 615-629; Nag, A.K., Mitra, A., Forecasting daily foreign exchange rates using genetically optimized neural networks (2002) J. Forecast, 21, pp. 501-511; Hinton, G.E., Training products of experts by minimizing contrastive divergence (2002) Neural Comput, 14, pp. 1771-1800; Hinton, G.E., Osindero, S., Teh, Y.-W., A fast learning algorithm for deep belief nets (2006) Neural Comput, 18, pp. 1527-1554; Nasse, F., Thurau, C., Fink, G.A., Face detection using gpu-based convolutional neural networks (2009) Proceedings of the International Conference on Computer Analysis of Images and Patterns, pp. 83-90. , M\u00fcnster, Germany, 2-4 September; Osadchy, M., Cun, Y.L., Miller, M.L., Synergistic face detection and pose estimation with energy-based models (2007) J. Mach. Learn. Res, 8, pp. 1197-1215; Sukittanon, S., Surendran, A.C., Platt, J.C., Burges, C.J., Convolutional networks for speech detection (2004) Proceedings of the Eighth International Conference on Spoken Language Processing, , Jeju Island, Korea, 4-8 October; Lee, H., Pham, P., Largman, Y., Ng, A.Y., Unsupervised feature learning for audio classification using convolutional deep belief networks (2009) Proceedings of the Advances in Neural Information Processing Systems, pp. 1096-1104. , Vancouver, BC, Canada, 7-10 December; Busseti, E., Osband, I., Wong, S., Deep learning for time series modeling (2012) Tech. Rep. Stanf. Univ, pp. 1-5; L\u00e4ngkvist, M., Karlsson, L., Loutfi, A., A review of unsupervised feature learning and deep learning for time-series modeling (2014) Pattern Recognit. Lett, 42, pp. 11-24; Ribeiro, B., Lopes, N., Deep belief networks for financial prediction (2011) Proceedings of the International Conference on Neural Information Processing, pp. 766-773. , Shanghai, China, 13-17 November; Chao, J., Shen, F., Zhao, J., Forecasting exchange rate with deep belief networks (2011) Proceedings of the 2011 International Joint Conference on Neural Networks, pp. 1259-1266. , San Jose, CA, USA, 31 July-5 August; Yeh, S.-H., Wang, C.-J., Tsai, M.-F., Corporate default prediction via deep learning (2014) Proceedings of the 34th International Symposium on Forecasting (ISF'14), , Rotterdam, The Netherlands, 29 June-2 July; Hinton, G.E., Salakhutdinov, R.R., Reducing the dimensionality of data with neural networks (2006) Science, 313, pp. 504-507; Schmidhuber, J., Deep learning in neural networks: An overview (2015) Neural Netw, 61, pp. 85-117; Larochelle, H., Bengio, Y., Louradour, J., Lamblin, P., Exploring strategies for training deep neural networks (2009) J. Mach. Learn. Res, 10, pp. 1-40; Masci, J., Meier, U., Cire\u015fan, D., Schmidhuber, J., Stacked convolutional auto-encoders for hierarchical feature extraction (2011) Proceedings of the International Conference on Artificial Neural Networks, pp. 52-59. , Espoo, Finland, 14-17 June; Ranzato, M.A., Huang, F.J., Boureau, Y.-L., LeCun, Y., Unsupervised learning of invariant feature 7hierarchies with applications to object recognition (2007) Proceedings of the 2007 IEEE Conference on Computer Vision and Pattern Recognition, , Minneapolis, MN, USA, 17-22 June; Vincent, P., Larochelle, H., Bengio, Y., Manzagol, P.-A., Extracting and composing robust features with denoising autoencoders (2008) Proceedings of the 25th International Conference on Machine Learning, pp. 1096-1103. , Helsinki, Finland, 5-9 July; LeCun, Y., Bengio, Y., Hinton, G., Deep learning (2015) Nature, 521, pp. 436-444; Zubiaga, A., A longitudinal assessment of the persistence of twitter datasets (2018) J. Assoc. Inf. Sci. Technol, 69, pp. 974-984; Nazir, F., Ghazanfar, M.A., Maqsood, M., Aadil, F., Rho, S., Mehmood, I., Social media signal detection using tweets volume, hashtag, and sentiment analysis (2019) Multimed. Tools Appl, 78, pp. 3553-3586; Iqbal, M., Ghazanfar, M.A., Sattar, A., Maqsood, M., Khan, S., Mehmood, I., Baik, S.W., Kernel Context Recommender System (KCR): A Scalable Context-Aware Recommender System Algorithm (2019) IEEE Access, 7, pp. 24719-24737; Khan, S., Khan, A., Maqsood, M., Aadil, F., Ghazanfar, M.A., Optimized gabor feature extraction for mass classification using cuckoo search for big data e-healthcare (2018) J. Grid Comput, 17, pp. 239-254; Kalsoom, A., Maqsood, M., Ghazanfar, M.A., Aadil, F., Rho, S., A dimensionality reduction-based efficient software fault prediction using Fisher linear discriminant analysis (FLDA) (2018) J. Supercomput, 74, pp. 4568-4602; Ateeq, T., Majeed, M.N., Anwar, S.M., Maqsood, M., Rehman, Z.-U., Lee, J.W., Muhammad, K., Mehmood, I., Ensemble-classifiers-assisted detection of cerebral microbleeds in brain MRI (2018) Comput. Electr. Eng, 69, pp. 768-781"}
{"Authors":"Figueroa-Garc\u00eda J.C., L\u00f3Pez-Santana E., Franco-Franco C.","Author(s) ID":"24767828800;57189442448;56583596000;","Title":"A three-step deep neural network methodology for exchange rate forecasting","Year":2017,"Source title":"Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)","Volume":"10361 LNCS","Issue":null,"Art. No.":null,"Page start":786.0,"Page end":795.0,"Page count":null,"Cited by":null,"DOI":"10.1007\/978-3-319-63309-1_70","Affiliations":"Universidad Distrital Francisco Jos\u00e9 de Caldas, Bogot\u00e1, Colombia; Management Department, Universidad del Rosario, Bogot\u00e1, Colombia","Document Type":"Conference Paper","Access Type":null,"Source":"Scopus","EID":"2-s2.0-85027707850","Abstract":"Stock market is one of the most important components of the financial system. It directs money from investors to support the activity and development of the associated company. Therefore, understanding and modeling the stock price dynamics become critically important, in terms of financial system stability, investment strategy, and market risk control. To better model the temporal dynamics of stock price, we propose a combined machine learning framework with information theory and Artificial Neural Network (ANN). This method creatively uses information entropy to inform non-linear causality as well as stock relevance and uses it to facilitate the ANN time series modeling. Our analysis with Google, Amazon, Facebook, and Apple stock prices demonstrates the feasibility of this machine learning framework. \u00a9 2019 IEEE.","Author Keywords":"LSTM; Neural network; Stock prediction; Transfer entropy","Index Keywords":"Commerce; Electronic trading; Financial markets; Information management; Information theory; Investments; Machine learning; Neural networks; System stability; Information entropy; Investment strategy; LSTM; Stock predictions; Stock price prediction; Temporal dynamics; Time series modeling; Transfer entropy; Long short-term memory","References":"Gerasimo, M., Konstantions, P., Yannis, T., Babis, T., Intelligent stock market assistant using temporal data mining (2005) Proc. of 10th Panhellenics Conference in Informatics (PCI05), , Volos, Greece; Roh, T.H., Forecasting the volatility of stock price index (2007) Journal of Expert Systems with Applications, 33, pp. 916-922; Ravichandran, K.S., Thirunavukarasu, P., Nallaswamy, R., Babu, R., Estimation of return on investment in share market through ANN (2005) Journal of Theoretical and Applied Information Technology, pp. 44-54; Assaf, N.A., (2011) Mercado Financeiro, , (10th ed.) S\u00e3o Paulo: Editora Atlas; Clements, M.P., Milas, C., Van Dijk, D., Forecasting returns and risk in financial markets using linear and nonlinear models (2009) International Journal of Forecasting, 25, pp. 215-217; White, H., Economic prediction using neural networks: The case ofIBM daily stock returns (1988) IEEE International on Neural Networks, 2, pp. 451-458; Shannon, C.E., A mathematical theory of communication (1948) Bell Syst. Tech. J., 27, pp. 379-423; Knuth, K.H., Lattice duality: The origin of probability and entropy (2005) Neurocomputing, 67, pp. 245-274; Hochreiter, S., Schmidhuber, J., Long short-term memory [J] (1997) Neural Computation, 9 (8), pp. 1735-1780; Guresen, E., Kayakutlu, G., Daim, T.U., Using artificial neural network models in stock market index prediction [J] (2011) Expert Systems with Applications, 38 (8), pp. 10389-10397; Patel, J., Shah, S., Thakkar, P., Predicting stock and stock price index movement using trend deterministic data preparation and machine learning techniques [J] (2015) Expert Systems with Applications, 42 (1), pp. 259-268; Kantz, H., Schreiber, T., (2000) Nonlinear Time Series Analysis, , Cambridge Univ. Press, Cambridge, U. K"}
{"Authors":"Buczkowski P.","Author(s) ID":"57194777223;","Title":"Predicting stock trends based on expert recommendations using GRU\/LSTM neural networks","Year":2017,"Source title":"Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)","Volume":"10352 LNAI","Issue":null,"Art. No.":null,"Page start":708.0,"Page end":717.0,"Page count":null,"Cited by":1.0,"DOI":"10.1007\/978-3-319-60438-1_69","Affiliations":"National Information Processing Institute, Warsaw, Poland; Warsaw University of Technology, Warsaw, Poland","Document Type":"Conference Paper","Access Type":null,"Source":"Scopus","EID":"2-s2.0-85021906449","Abstract":"Most of the existing literature on stock price analysis is based on the historical price of a single stock, where models are trained to identify the pattern of price movements and, predict future stock the prices. However, the stock price is not an isolated variable. It is correlated with and influenced by many factors. These factors are highly time dependent, it which means that the stock price movement is also time dependent. Therefore, existing prediction models often fail in applications. In this paper, our model is not based on single stock. Instead, we study a class of stocks with similar historical price movements. We get the training and forecast data of the prediction model based on time series window sliding. We then train a CART (Classification and Regression Trees) and evaluate the model on testing data. Compared with the classical models for price movement forecast including the time series analysis model ARIMA (Autoregressive Integrated Moving Average) and the recursive neural network model LSTM (Long-Short Term Memory), our l empirical results support the effectiveness of the proposed method in the stock trend forecast. \u00a9 2017 IEEE.","Author Keywords":"ARIMA; CART; Similar Stock; Slide Window; Stock Data","Index Keywords":"Costs; Forecasting; Long short-term memory; Time series analysis; Trees (mathematics); ARIMA; CART; Similar Stock; Slide windows; Stock data; Financial markets","References":"Wu, Z.-Y., Forecasting stock indexes based on a revised grey model and the ARMA model (2010) CAAI Transactions on Intelligent Systems, 5 (3), pp. 277-281; Kai-Xu, D., Bao-Rui, S., Applying wavelet in the analysis of financial data (2006) Applicatuon of Statistics and Management, 25 (2), pp. 215-219. , China, Mar; Zhiyun, X., Ming, G., Complicated financial data time series forecasting analysis based on least square support vector machine (2008) J Ysinghua Univ(Sci&Tech), 48 (7), pp. 1147-1149; Cao, L., Feh, T., Financial forecasting using support vector machines (2001) Neural Computing and Applications, 10 (2), pp. 184-192; Dong Yun, Y.I., Zhang, W.M., Changsha, Nonlinear correlation tracking technique in data mining of financial markets (2000) Journal of Software, 11 (12), pp. 1581-1586; Yin, T., A survey of approaches for time series similarity analysis (2006) Computer Engineering and Applications, 42 (1), pp. 68-71. , (China); Breiman, L.I., Friedman, J.H., Olshen, R.A., Stone, C.J., Classification and regression trees (CART) (1984) Biometrics, 40 (3), p. 358; Contreras, J., Espinola, R., Nogales, F.J., Conejo, A.J., ARIMA models to predict next-day electricity prices (2003) IEEE Transactions on Power Systems, 18 (3), pp. 1014-1020; Haiyong, Z., Xiaojiang, M., Qiang, G., A new method for ARMA model of non-stationary signal (2002) Journal of Electronics & Information Technology, 24 (7), pp. 992-996. , China; Tsenga, F.M., Tzeng, G.H., Fuzzy ARIM A model for forecasting the foreign exchange market (2001) Fuzzy Sets & Systems, 118 (1), pp. 9-19; Yurui, Z., Jianbo, C., Time series prediction based on RBF neural network (2005) Computer Engineering and Applications, 41 (11), pp. 74-76. , China; Chen, Y., Yang, B., Dong, J., Time-series prediction using a local linear wavelet neural network (2006) Neurocomputing, 69 (4-6), pp. 449-465; Lee, C.M., Ko, C.N., Time series prediction using RBF neural networks with a nonlinear time-varying evolution PSO algorithm (2009) Neurocomputing, 73 (1-3), pp. 449-460; Gers, F., Eck, D., Applying LSTM to time series predictable through time-window approaches (2001) International Conference on Artificial Neural Networks, 2130, pp. 669-676; Hansson, M., On stock return prediction with LSTM networks (2017) Asaio Journal, 40 (4), p. 928; Gupta, S., Wang, L.P., (2010) Stock Forecasting with Feedforward Neural Networks and Gradual Data Sub-Sampling\" Australian Journal of Intelligent Information Processing Systems, 11, pp. 14-17; Ghazali, R., Hussain, A.J., Al-Jumeily, D., Lisboa, P., Time series prediction using dynamic ridge polynomial neural networks (2009) Second International Conference on Developments in ESystems Engineering (DESE), pp. 354-363; Morgan, J., Stocken, P.C., An analysis of stock recommendations (2003) Rand Journal of Economics, 34 (1), pp. 183-203; Wurgler, J., Investor sentiment in the stock market M baker (2007) Journal of Economic Perspectives, 21 (2), pp. 129-151"}
{"Authors":"Karathanasopoulos A.","Author(s) ID":"36608193100;","Title":"Modelling and trading the London, New York and frankfurt stock exchanges with a new gene expression programming trader tool","Year":2017,"Source title":"Intelligent Systems in Accounting, Finance and Management","Volume":"24","Issue":"1","Art. No.":null,"Page start":3.0,"Page end":11.0,"Page count":null,"Cited by":null,"DOI":"10.1002\/isaf.1401","Affiliations":"Olayan School of Business, American University of Beirut, Beirut, Lebanon","Document Type":"Article","Access Type":null,"Source":"Scopus","EID":"2-s2.0-85002813412","Abstract":"The Artificial Neural Network is widely applied to the forecasting of financial time series, and has got certain effects. The problem, however, is that most of these methods is based on daily trading data. When facing the high frequency trading data which is more powerful in short-term forecasting, these methods become incapable. Inspired by the development of Convolutional Neural Network in image recognition tasks, this paper tries to apply the Convolutional Neural Network on the high frequency financial trading data, and has achieved good results. We collect the close price of Shanghai Composite Index from 2006 to 2008 and from 2014 to 2015, about 1000 trading days in total. The frequency of the trading data is 5 min. The paper intends to forecast the stock\u2019s future trend of the next day from historical data, namely, go up or down. First, we apply Hodrick-Prescott decomposition [1] on the original time series. The Hodrick-Prescott filter(decomposition) is a mathematical tool used in macroeconomics to separate the cyclical component ct and trend component \u03c4t from a time series. After preprocessing, the proposed method novelly transforms the time series into pictures. We apply GASF, GADF and MTF algorithm [2] on the time series respectively, forming the R, G and B channels of a picture. By transforming each of the time series into picture mode, the trading time series produces a picture library. Finally, the proposed method uses AlexNet architecture as feature extractor and classifier. The net has five convolution layers, three pooling layers, and two fully-connected layers. In data set of time series from 2006 to 2008, we choose the training data and the testing data randomly, and the proposed method can keep the accuracy at about 0.55 on the binary classification problem. In data set of time series from 2014 to 2015, we choose the last 16 training days of the data set as testing data and the accuracy can reach up to 0.60. \u00a9 Springer International Publishing AG 2017.","Author Keywords":"Convolutional neural network; Stock forecasting","Index Keywords":"Commerce; Convolution; Economics; Electronic trading; Financial data processing; Forecasting; Image recognition; Learning systems; Neural networks; Statistical tests; Time series; Binary classification problems; Convolutional neural network; Financial time series; High-frequency trading; Hodrick-prescott filters; Mathematical tools; Short-term forecasting; Stock forecasting; Classification (of information)","References":"Hodric, R.J., Prescott, E.C., Postwar U.S. business cycles: An empirical investigation (1997) J. Money Credit Bank., 29 (1), pp. 1-16; Wang, Z., Oates, T., Imaging time-series to improve classification and imputation (2015) Int. Conf. Artif. Intell, 1043 (1), pp. 3939-3945"}
{"Authors":"Akita R., Yoshihara A., Matsubara T., Uehara K.","Author(s) ID":"57191226854;56425644100;53863900700;7201993612;","Title":"Deep learning for stock prediction using numerical and textual information","Year":2016,"Source title":"2016 IEEE\/ACIS 15th International Conference on Computer and Information Science, ICIS 2016 - Proceedings","Volume":null,"Issue":null,"Art. No.":" 7550882","Page start":null,"Page end":null,"Page count":null,"Cited by":37.0,"DOI":"10.1109\/ICIS.2016.7550882","Affiliations":"Graduate School of System Informatics, Kobe University, Japan","Document Type":"Conference Paper","Access Type":null,"Source":"Scopus","EID":"2-s2.0-84987989524","Abstract":"This paper presents a novel deep learning approach for the stock price prediction using a cycle embeddings with attention mechanism (CEAM) applying on Dual-Stage Attention-Based RNN (DA-RNN) model. The cycle characteristic is an important factor in time series prediction problem since it affects the trend of stock price. Thus, an effective cycle information can improve the prediction performance of stock price. In past years, many researches use the cycle feature with other features together as equally important, which might dilute the weight of cycle information since the cycle information should be paid more attention when making prediction on periodic data. As the result, we use CEAM making prediction with cycle information hidden in periodic data. The deep learning-based method has been developed in many fields and is a powerful prediction system. In addition, many researches use the embeddings feature and the attention mechanism to improve the prediction performance. In this paper, we propose a novel approach to capture the cycle information and use it to predict stock prices in U.S. stock market. The cycle information can be formed as a distributed vector as embeddings, called cycle embeddings. The CEAM approach use cycle embeddings to pay attention on periodically historical time series data by learning the cycle semantic relations between cycle characteristics and historical stock prices to optimize the prediction model. Therefore, the CEAM approach can improve the prediction performance for stock price. The experiments in this paper show that our proposed CEAM approach outperforms the another model which combines cycle feature with other features together as equally important. \u00a9 2019 IEEE.","Author Keywords":"attention mechanism; cycle embeddings; deep recurrent neural network; stock price prediction; time series","Index Keywords":"Big data; Costs; Deep learning; Embeddings; Financial markets; Recurrent neural networks; Semantics; Time series; Attention mechanisms; Cycle characteristic; Learning-based methods; Prediction performance; Prediction systems; Semantic relations; Stock price prediction; Time series prediction; Forecasting","References":"Hatcher, W.G., Yu, W., A survey of deep learning: Platforms, applications and emerging research trends (2018) IEEE Access, 6, pp. 24411-24432. , April; Qin, Y., Song, D., Chen, H., Cheng, W., Jiang, G., Cottrell, G., A dualstage attention-based recurrent neural network for time series prediction (2017) Proceedings of the 26th IJCAI, pp. 2627-2633; Long short-term memory (1997) Neural Computation, 9 (8), pp. 1735-1780. , Hochreiter and Schmidhuber; Cho, K., Van Merri\u00ebnboer, B., Gulcehre, C., Bahdanau, D., Bougares, F., Schwenk, H., Bengio, Y., Learning phrase representations us-ing rnn encoder-decoder for statistical machine translation (2014) Proceedings of the 2014 EMNLP, pp. 1724-1734; Kingma, D., Ba, J., Adam: A method for stochastic optimization (2014) Proceeding of 2015 ICLR, pp. 1-15; Achelis, S., (2013) Technical Analysis from A to Z, , McGraw-Hill Companies; Plutowski, M., Cottrell, G., White, H., Experience with selecting exemplars from clean data (1996) Neural Networks, 9 (2), pp. 273-294"}
{"Authors":"Hussain A.J., Al-Jumeily D., Al-Askar H., Radi N.","Author(s) ID":"56212648400;23090210900;56288742400;6505760939;","Title":"Regularized dynamic self-organized neural network inspired by the immune algorithm for financial time series prediction","Year":2016,"Source title":"Neurocomputing","Volume":"188","Issue":null,"Art. No.":null,"Page start":23.0,"Page end":30.0,"Page count":null,"Cited by":10.0,"DOI":"10.1016\/j.neucom.2015.01.109","Affiliations":"Faculty of Engineering and Technology Liverpool John Moores University, Liverpool, L3 3AF, United Kingdom; Al Khawarizmi International College, Abu Dhabi, United Arab Emirates","Document Type":"Article","Access Type":null,"Source":"Scopus","EID":"2-s2.0-84962094403","Abstract":"Understanding the pattern of financial activities and predicting their development and changes are research hotspots in academic and financial circles. Because financial data contain complex, incomplete and fuzzy information, predicting their development trends is an extremely difficult challenge. Fluctuations in financial data depend on a myriad of correlated constantly changing factors. Therefore, predicting and analysing financial data are a nonlinear, time-dependent problem. Deep neural networks (DNNs) combine the advantages of deep learning (DL) and neural networks and can be used to solve nonlinear problems more satisfactorily compared to conventional machine learning algorithms. In this paper, financial product price data are treated as a one-dimensional series generated by the projection of a chaotic system composed of multiple factors into the time dimension, and the price series is reconstructed using the time series phase-space reconstruction (PSR) method. A DNN-based prediction model is designed based on the PSR method and a long- and short-term memory networks (LSTMs) for DL and used to predict stock prices. The proposed and some other prediction models are used to predict multiple stock indices for different periods. A comparison of the results shows that the proposed prediction model has higher prediction accuracy. \u00a9 2019, Springer-Verlag London Ltd., part of Springer Nature.","Author Keywords":"Deep learning; Financial data prediction; Neural networks; Phase-space reconstruction","Index Keywords":"Chaotic systems; Deep learning; Electronic trading; Financial markets; Forecasting; Learning algorithms; Machine learning; Neural networks; Object oriented programming; Conventional machines; Financial data; Long and short term memory; Phase space reconstruction; Phase space reconstructions (PSR); Prediction accuracy; Stock price prediction; Time-dependent problem; Deep neural networks","References":"Zhang, L., Wang, F., Bing, X., Chi, W., Wang, Q., Sun, T., Prediction of stock prices based on LM-BP neural network and the estimation of overfitting point by RDCI (2018) Neural Comput Appl, 30 (5), pp. 1425-1444; Oliveira, A.L.I., Meira, S.R.L., Detecting novelties in time series through neural networks forecasting with robust confidence intervals (2006) Neurocomputing, 70 (1), pp. 79-92; Lecun, Y., Bengio, Y., Hinton, G., Deep learning (2015) Nature, 521 (7553), p. 436; White, H., (1988) Economic prediction using neural networks: The case of IBM daily stock returns, pp. 451-458; Zhang, G.P., Time series forecasting using a hybrid ARIMA and neural network model (2003) Neurocomputing, 50, pp. 159-175; Vanstone, B., Finnie, G., An empirical methodology for developing stockmarket trading systems using artificial neural networks (2009) Expert Syst Appl, 36 (3), pp. 6668-6680; Jasemi, M., Kimiagari, A.M., Memariani, A., A modern neural network model to do stock market timing on the basis of the ancient investment technique of Japanese Candlestick (2011) Expert Syst Appl, 38 (4), pp. 3884-3890; Ticknor, J.L., A Bayesian regularized artificial neural network for stock market forecasting (2013) Expert Syst Appl, 40 (14), pp. 5501-5506; Wang, J., Forecasting stock market indexes using principle component analysis and stochastic time effective neural networks (2015) Neurocomputing, 156, pp. 68-78; Xiong, Z., Research on RMB exchange rate forecasting model based on combining ARIMA with Neural networks (2011) J Quant Tech Econ, 28 (6), pp. 64-76. , (in Chinese; Wu, Q., Wang, C., Tang, Y., Empirical research on volume-price relationship based on GARCH models and BP neural network (2013) J Sichuan Univ Nat Sci Edn, 50 (4), pp. 703-708. , (in Chinese; Li, X., Zhang, Z., Support vector machine method for financial time series prediction based on simultaneous error prediction (2014) J Tianjin Univ Sci Technol, 47 (1), pp. 86-94. , (in Chinese; Schmidhuber, J., Deep learning in neural networks: an overview (2015) Neural Netw, 61, pp. 85-117; Shen, F., Chao, J., Zhao, J., Forecasting exchange rate using deep belief networks and conjugate gradient method (2015) Neurocomputing, 167, pp. 243-253; Ding, X., Zhang, Y., Liu, T., Deep learning for event-driven stock prediction (2015) Twenty-Fourth International Joint Conference on Artificial Intelligence, pp. 2327-2333; Zhao, Y., Li, J., Yu, L., A deep learning ensemble approach for crude oil price forecasting (2017) Energy Econ, 66, pp. 9-16; Krauss, C., Do, X.A., Huck, N., Deep neural networks, gradient-boosted trees, random forests: statistical arbitrage on the S&P 500 (2017) Eur J Oper Res, 259 (2), pp. 689-702; Song, Y., Lee, J.W., Lee, J., A study on novel filtering and relationship between input-features and target-vectors in a deep learning model for stock price prediction (2018) Appl Intell, 49, pp. 1-15; Minh, D.L., Sadeghi-Niaraki, A., Huy, H.D., Deep learning approach for short-term stock trends prediction based on two-stream gated recurrent unit network (2018) IEEE Access, 6, p. 1; G\u00f6\u00e7ken, M., \u00d6z\u00e7alici, M., Boru, A., Dosdogru, A.T., Stock price prediction using hybrid soft computing models incorporating parameter tuning and input variable selection (2019) Neural Comput Appl, 31 (2), pp. 577-592; Graves, A., Jaitly, N., Towards end-to-end speech recognition with recurrent neural networks (2014) International Conference on Machine Learning, pp. 1764-1772; Greff, K., Srivastava, R.K., Koutnik, J., LSTM: a search space Odyssey (2016) IEEE Trans Neural Netw, 28, pp. 1-11"}
{"Authors":"Horelu A., Leordeanu C., Apostol E., Huru D., Mocanu M., Cristea V.","Author(s) ID":"57189040270;23469633000;55365937600;57189034829;24376506600;22833950300;","Title":"Forecasting Techniques for Time Series from Sensor Data","Year":2016,"Source title":"Proceedings - 17th International Symposium on Symbolic and Numeric Algorithms for Scientific Computing, SYNASC 2015","Volume":null,"Issue":null,"Art. No.":" 7426093","Page start":261.0,"Page end":264.0,"Page count":null,"Cited by":null,"DOI":"10.1109\/SYNASC.2015.49","Affiliations":"Faculty of Automatic Control and Computers, University Politehnica of Bucharest, Romania","Document Type":"Conference Paper","Access Type":null,"Source":"Scopus","EID":"2-s2.0-84964875760","Abstract":"Forecasting the foreign exchange rate is an uphill task. Numerous methods have been used over the years to develop an efficient and reliable network for forecasting the foreign exchange rate. This study utilizes recurrent neural networks (RNNs) for forecasting the foreign currency exchange rates. Cartesian genetic programming (CGP) is used for evolving the artificial neural network (ANN) to produce the prediction model. RNNs that are evolved through CGP have shown great promise in time series forecasting. The proposed approach utilizes the trends present in the historical data for its training purpose. Thirteen different currencies along with the trade-weighted index (TWI) and special drawing rights (SDR) is used for the performance analysis of recurrent Cartesian genetic programming-based artificial neural networks (RCGPANN) in comparison with various other prediction models proposed to date. The experimental results show that RCGPANN is not only capable of obtaining an accurate but also a computationally efficient prediction model for the foreign currency exchange rates. The results demonstrated a prediction accuracy of 98.872 percent (using 6 neurons only) for a single-day prediction in advance and, on average, 92% for predicting a 1000 days exchange rate in advance based on ten days of data history. The results prove RCGPANN to be the ultimate choice for any time series data prediction, and its capabilities can be explored in a range of other fields. \u00a9 2014 Taylor & Francis Group, LLC.","Author Keywords":null,"Index Keywords":"Economics; Finance; Genetic algorithms; Genetic programming; Mathematical models; Recurrent neural networks; Time series; Cartesian genetic programming; Computationally efficient; Foreign exchange rates; Performance analysis; Prediction accuracy; Recurrent neural network (RNNs); Reliable Networks; Time series forecasting; Forecasting","References":"Atiya, A.F., Member, S., El-Shoura, S.M., Shaheen, S.I., El-Sherif, M.S., A comparison between neural-network forecasting techniques - Case study: River flow forecasting (1999) IEEE Transa Ctions on Neural Networks, 10 (2), pp. 402-409; Aussem, A., Murtagh, F., Sarazin, M., Dynamical recurrent neural network towards environmental series prediction (1995) International Journal of Neural Systems, 6 (2), pp. 145-170; Bhattacharya, A., Parlos, A.G., Atiya, A.F., Prediction of mpeg-coded video source trace using recurrent neural networks (2003) IEEE Transactions on Neural Networks, 51 (8), pp. 2177-2190; Bon\u00e9, R., Assaad, M., Crucianu, M., Boosting recurrent neural networks for time series prediction (2003) Artificial Neural Nets and Genetic Algorithms, pp. 18-22. , Vienna: Spinger; Cai, X., Zhang, N., Venayagamoorthy, G.K., Wunsch II, D.C., Time series prediction with recurrent neural networks using a hybrid PSO-EA algorithm (2004) IEEE International Conference on Neural Networks - Conference Proceedings, 2, pp. 1647-1652. , 2004 IEEE International Joint Conference on Neural Networks - Proceedings; Chen, A.N.-S., Leung, M.T., Performance evaluation of neural network architectures: The case of predicting foreign exchange correlations (2005) Journal of Forecasting, 24 (6), pp. 403-420. , DOI 10.1002\/for.967; Connor, J.T., Martin, D., Atlas, L.E., Recurrent neural networks and robust time series prediction (1994) IEEE Transactions on Neural Networks, 5 (2), pp. 240-254; Dablemont, S., Simon, G., Lendasse, A., Ruttiens, A., Blayo, F., Verleysen, M., Time series forecasting with som and local non-linear models-Application to the dax30 index prediction (2003) Presented at Proceedings of the 4th Workshop on Self-Organizing Maps, (WSOM'03), pp. 340-345. , Hibikino, Japan, Septembe r; Dunis, C.L., Huang, X., Forecasting and trading currency volatility: An application of recurrent neural regression and model combination (2002) Journal of Forecasting, 21 (5), pp. 317-357; Farsa, M.A., Zolfaghari, S., Residual analysis and combination of embedding theorem and artificial intelligence in chaotic time series forecasting. Applied artificial intelligence (2011) An International Journal, 25 (1), pp. 45-73; Giles, C.L., Lawrence, S., Tsoi, A.C., Noisy time series prediction using recurrent neural networks and grammatical inference (2001) Machine Learning, 44 (1-2), pp. 161-183. , DOI 10.1023\/A:1010884214864; Gomez, F., Schmidhuber, J., Accelerated neural evolution through cooperatively coevolved synapses (2008) Journal of Machine Learning Research, 9, pp. 937-965; Gradojevic, N., Yang, J., Non-linear, non-parametric, non-fundamental exchange rate forecasting (2006) Journal of Forecasting, 25 (4), pp. 227-245. , DOI 10.1002\/for.986; Haykin, S., (1999) Neural Networks: A Comprehensive Foundation, pp. 20-21. , (2nd ed.), Upper Saddle River, NJ: Prentice Hall; Huang, W., Wang, S., Yu, L., Bao, Y., Wang, L., A new computational method of input selection for stock market forecasting with neural networks (2006) Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics), 3994 LNCS - IV, pp. 308-315. , Computational Science - ICCS 2006: 6th International Conference, Proceedings; Husken, M., Stagge, P., Recurrent neural networks for time series classification (2003) Neurocomputing, 50, pp. 223-235. , DOI 10.1016\/S0925-2312(01)00706-8, PII S0925231201007068; Joseph, N.L., Model specification and forecasting foreign exchange rates with vector autoregressions (2001) Journal of Forecasting, 20 (7), pp. 451-484. , DOI 10.1002\/for.808; Kaashoek, J.F., Dijk, H.K.V., Neural network pruning applied to real exchange rate analysis (2002) Journal of Forecasting, 21 (8), pp. 559-577; Kadilar, C., Simsek, M., Aladag, C.H., Forecasting the exc hange rate series with ann: The case of turkey (2009) Istanbul University Econometrics and Statistics E-Journal, 9 (1), pp. 17-29; Khan, G.M., Khan, S., Ullah, F., Short-term daily peak load forecasting using fast learning neural network (2011) 2011 International Conference on Intelligent System Design and Applications, 843-848. , IEEE; Khan, M.M., Khan, G.M., Miller, J.F., Efficient representation of recurrent neural networks for markovian\/non-markovian non-linear control problems (2010) 2010 International Conference on Intelligent System Design and Applications ISDA'10, pp. 615-620. , IEEE; Khan, M.M., Khan, G.M., Miller, J.F., Evolution of optimal anns for non-linear control problems using cartesian genetic programming (2010) The 2010 International Conference on Artificial Intelligence, pp. 339-346. , AIA Press; Khan, M.M., Khan, G.M., Miller, J.F., Evolution of neural networks using cartesian genetic programming (2010) IEEE Congress on Evolutionary Computation, pp. 1-8. , IEEE; Nagesh Kumar, D., Srinivasa Raju, K., Sathish, T., River flow forecasting using recurrent neural networks (2004) Water Resources Management, 18 (2), pp. 143-161. , DOI 10.1023\/B:WARM.0000024727.94701.12; Linkens, D., Nyongesa, Y., Learning systems in intelligent control: An appraisal of fuzzy, neural and genetic algorithm control applications (1996) IEEE Proceedings of Control Theory and Applications, 134 (4), pp. 367-385; Madhavan, P.G., A recurrent neural network learning algorithm for time series prediction (2011) Journal of Intelligent Systems, 7 (1-2), pp. 103-116; Marra, S., Morabito, F.C., A new technique for solar activity forecasting using recurrent elman networks (2005) IEC Prague, 1 (7), pp. 68-73; Marsh, I.W., High-frequency markov switching models in the foreign exchange market (2000) Journal of Forecasting, 19 (2), pp. 123-134; Miller, J., Harding, S.L., Cartesian genetic programming (2008) Proceedings of the 2008 GECCO Conference Companion on Genetic and Evolutionary Computation, Ser. GECCO, 8, pp. 2701-2726. , New York, NY, USA: ACM; Nag, A.K., Mitra, A., Forecasting daily foreign exchange rates using genetically optimized neural networks (2002) Journal of Forecasting, 21 (7), pp. 501-511. , DOI 10.1002\/for.838; Parikakis, G.S., Merika, A., Evaluating volatility dynamics and the forecasting ability of markov switching models (2009) Journal of Forecasting, 28 (8), pp. 736-744; Philip, A., Tofiki, A.A., Bidemi, A.A., Artificial neural network model for forecasting foreign exchange rate (2011) World of Computer Science and Information Technology Journal, 1 (3), pp. 110-118; Qian, B., Rasheed, K., Foreign exchange market prediction with multiple classifiers (2010) Journal of Forecasting, 29 (3), pp. 271-284; Refenes, A.N., Azema-Barac, M., Chen, L., Karoussos, S.A., Currency exchange rate prediction and neural network design strategies (1993) Neural Computing & Applications, 1 (1), pp. 46-58; Rivero, S.S., Garcia, E., Forecasting the dollar\/euro exchange rate (2005) Are International Parities Useful? Journal of Forecasting, 24 (5), pp. 369-377; Rothermich, J.A., Miller, J.F., Studying the emergence of multi-cellularity with cartesian genetic programming in artificial life (2002) U.K. Workshop on Computational Intelligence (UKCI'02), pp. 397-403. , Birmingham, UK; Skintzi, V.D., Sisinis, S.X., Evaluation of correlation forecasting models for risk management (2007) Journal of Forecasting, 26 (7), pp. 497-526. , DOI 10.1002\/for.1036; Taremian, H., Stock market value prediction usi ng neural networks (2010) 2010 International Conference on Computer Information Systems and Industrial Management Applications (CISIM), pp. 132-136. , IEEE; Tenti, P., Forecasting foreign exchange rates using recurrent neural networks (1996) Applied Artificial Intelligence: An International Journal, 10 (6), pp. 567-582; Toha, S.F., Tokhi, M.O., Mlp and elman recurrent neural network modeling for the trms (2008) Proceedings of the 7th IEEE International Conference on Cybernetic Intelligent Systems, pp. 1-6. , IEEE; Vasicek, Z., Sakanina, L., Hardware accelerator of cartesian genetic programming with multiple fitness units (2010) Computing and Informatics, 29, pp. 1359-1371; William, J.R., Zipser, D., Experimental analysis of the real time recurrent learning algorithm (1989) Connections Science, 1 (1), pp. 1-25; Zhang, B., Muhlenbein, H., Evolving optimal neural networks using genetic algorithms with occam's razor (1993) Complex Systems, 7 (3), pp. 199-220; Zhang, G., Eddy Patuwo, B., Hu, M.Y., Forecasting with artificial neural networks: The state of the art (1998) International Journal of Forecasting, 14 (1), pp. 35-62. , PII S0169207097000447"}
{"Authors":"Di Persio L., Honchar O.","Author(s) ID":"57203636440;57192153071;","Title":"Artificial neural networks architectures for stock price prediction: Comparisons and applications","Year":2016,"Source title":"International Journal of Circuits, Systems and Signal Processing","Volume":"10","Issue":null,"Art. No.":null,"Page start":403.0,"Page end":413.0,"Page count":null,"Cited by":19.0,"DOI":null,"Affiliations":"University of Verona, Department of Computer Science, Strada le Grazie, 15, Verona, Italy","Document Type":"Article","Access Type":null,"Source":"Scopus","EID":"2-s2.0-84998705847","Abstract":"Neural networks have been popular in time series prediction in financial area for their advantages in handling nonlinear systems. However, conventional neural networks are confronted with the problem to include time property and the risk of local convergence. This paper presents a study of using a novel recurrent neural network-Echo State Network (ESN) to predict next value in a financial time series. In order to prove the predictability of financial time series, we attain the Hurst exponent through rescaled range (R\/S) analysis first. In feature selection, technical analysis is utilized to extract underlying information in the time series and principal component analysis (PCA) helps to filter noise and obtain faithful representation of principle components. The data of six major stock indices in the world, DJIA, S&P 500, NASDAQ, HSI, FTSE 100 and NIKKEI 225, are employed to test our model. For comparison purpose, other neural networks such as back-propagation network and Elman network are also considered. Experiment results demonstrate that ESN performs much better than other neural networks in forecasting the next closing price and the combination of PCA with technical analysis improves the prediction accuracy a little comparing with a model using only raw price data. Our preliminary study also suggests that ESN is effective in short-term financial time series prediction and worth further investigation. \u00a9 2010 IEEE.","Author Keywords":"Echo State Network; Financial time series; Principle component analysis; Technical analysis","Index Keywords":"Feature extraction; Finance; Financial data processing; Forecasting; Recurrent neural networks; Time series; Time series analysis; Backpropagation network; Echo state networks; Elman network; Feature selection; Filter noise; Financial time series; Financial time series predictions; Hurst exponents; Local Convergence; Prediction accuracy; Principle component; Principle component analysis; Rescaled range analysis; Stock indices; Technical analysis; Time properties; Time series prediction; Principal component analysis","References":"Peters, E.E., (1994) Fractal Market Analysis: Applying Chaos Theory to Investment and Economics, , Willey & Sons, Inc. New York; Armono, G., Marchesi, M., Murru, A., A hybrid genetic-neural architecture for stock indexes forecasting (2005) Information Sciences, 170, pp. 3-33; Kim, H.-J., Shin, K.-S., A hybrid approach based on neural networks and genetic algorithms for detecting temporal patterns in stock markets (2007) Applied Soft Computing, 7 (2), pp. 569-576; White, H., Economic prediction using neural networks: A case of IBM daily stock returns (1998) IEEE International Conference on Neural Networks, 2, pp. 451-458; Lam, M., Neural network techniques for financial performance prediction: Integrating fundamental and technical analysis (2004) Decision Supoort Systems, 37, pp. 567-581; Doeksen, B., Abraham, A., Thomas, J., Paprzycki, M., Real stock trading using soft computing models (2005) Proceedings of the International Conference on Information Technology: Coding and Computing (ITCC'05); Azzini, A., Tettamanzi, A.G.B., A neural evolutionary approach to financial modeling (2006) Proceedings of the 8th Annual Conference on Genetic and Evolutionary Computation, pp. 1605-1612. , Seattle, Washington, USA; Sitte, R., Sitte, J., Analysis of predictive ability of time delay neural networks applied to the S&P 500 time series (2000) IEEE Trans on Systems, Man, and Cybernetics-Part C: Applications and Reviews, 30 (4); Saad, E.W., Prokhorov, D.V., Wunsch, D.C., Comparative study of stock trend prediction using time delay, recurrent and probabilistic neural networks (1998) IEEE Transactions on Neural Networks, 19 (6). , Nov; Yakuwa, F., Dote, Y., Yoneyama, M., Uzurabashi, S., Novel time series analysis and prediction of stock trading using fractal theory and time delayed neural network International Journal of Hybrid Intelligent Systems, 1 (1-2), pp. 72-79; Lee, R.S.T., IJADE stock advisor: An intelligent agent based stock prediction system using hybrid RBF recurrent network (2004) IEEE Transactions on Systems, Man, and Cybernetics-Part A: Systems and Humans, 64 (3). , May; Jaeger, H., Tutorial on training recurrent neural networks covering BPPT, RTRL, EKF and the Echo State Network approach (2002) Technical Report, GMD Forschungszentrum Informationstechnic GmbH; He, H., Long-term storage of reservoirs: An experimental study (1951) Trans Amer Soc Civil Engi, 116, pp. 770-799; Qian, B., Rasheed, K., Stock market prediction with multiple classifiers (2007) Applied Intelligence, 26 (1), pp. 25-33; Jaeger, H., Haas, H., Harnessing nolinearity: Predicting chaotic systems and saving energy in wireless communications (2004) Science, 3; Jaeger, H., The 'Echo State' approach to analyzing and training recurrent nerual networks (2001) Technical Report, GMD-German National Research Institute for Computer Science, GMD Report, 148; Martinetz, T.M., Berkovich, S.G., Schulten, K.J., 'Neural-Gas' network for vector quantization and its application to time-series prediction (1993) IEEE Transactions on Neural Networks, 14 (4). , July; Zhu, J.-Y., Ren, B., Zhang, H.-X., Deng, Z.-T., Time series prediction via new support vector machines (2002) Proceedings of the First International Conference on Machine Learning and Cybernetics, , 4-5, Nov; Mok, P.Y., Lam, K.P., Ng, H.S., An ICA design of intraday stock prediction models with automatic variable selection (2004) IEEE International Joint Conference on Neural Networks; Jaeger, H., Short term memory in echo state networks (2002) Technical Report, GMD-Report 152, GMD-German National Research Institute for Computer Science; Smith, L.I., A Tutorial on Principle Components Analysis, , http:\/\/csnet.otago.ac.nz\/cosc453\/student_tutorials\/principal_components. pdf"}
{"Authors":"Wang J., Wang J., Fang W., Niu H.","Author(s) ID":"56527464300;55946707000;42361194900;55286614500;","Title":"Financial Time Series Prediction Using Elman Recurrent Random Neural Networks","Year":2016,"Source title":"Computational Intelligence and Neuroscience","Volume":"2016","Issue":null,"Art. No.":" 4742515","Page start":null,"Page end":null,"Page count":null,"Cited by":19.0,"DOI":"10.1155\/2016\/4742515","Affiliations":"School of Science, Beijing Jiaotong University, Beijing, 100044, China; School of Economics and Management, Beijing Jiaotong University, Beijing, 100044, China","Document Type":"Article","Access Type":"Open Access","Source":"Scopus","EID":"2-s2.0-84973369468","Abstract":"The time series of stock prices are non-stationary and non-linear, making the prediction of future price trends much challenging. Inspired by Convolutional Neural Network (CNN), we make convolution on the time dimension to capture the long-term fluctuation features of stock series. To learn long-term dependencies of stock prices, we combine the time convolution with Long Short-Term Memory (LSTM), and propose a novel deep learning model named Time Convolution Long Short-Term Memory (TC-LSTM) networks. TC-LSTM can obtain the stock longer data dependence and overall change pattern. The experiments on two real market datasets demonstrate that the proposed model outperforms other three baseline models in the mean square error. \u00a9 2018, Springer Nature Switzerland AG.","Author Keywords":"Long Short-Term Memory (LSTM); Stock price prediction; Time convolution","Index Keywords":"Brain; Convolution; Costs; Deep learning; Financial markets; Forecasting; Mean square error; Baseline models; Change patterns; Convolutional Neural Networks (CNN); Data dependence; Long-term dependencies; Short term memory; Stock price prediction; Time convolution; Long short-term memory","References":"Adam, K., Marcet, A., Nicolini, J.P., Stock market volatility and learning (2016) J. Fin., 71 (1), pp. 419-438; Akita, R., Yoshihara, A., Matsubara, T., Uehara, K., Deep learning for stock prediction using numerical and textual information (2016) IEEE\/ACIS International Conference on Computer and Information Science, pp. 1-6; Ariyo, A.A., Adewumi, A.O., Ayo, C.K., Stock price prediction using the ARIMA model (2014) 2014 Uksim-Amss 16Th International Conference on Computer Modelling and Simulation, pp. 106-112. , https:\/\/doi.org\/10.1109\/UKSim.2014.67, March; Bao, W., Yue, J., Rao, Y., A deep learning framework for financial time series using stacked autoencoders and long-short term memory (2017) Plos ONE, 12 (7); Cho, K., van Merrienboer, B., Bahdanau, D., Bengio, Y., (2014) On the Properties of Neural Machine Translation: Encoder-Decoder Approaches, , http:\/\/arxiv.org\/abs\/1409.1259, CoRR abs\/1409.1259; Gao, Q., Stock Market Forecasting Using Recurrent Neural Network, , Ph.D. thesis, University of Missouri-Columbia; Huynh, H.D., Dang, L.M., Duong, D., A new model for stock price movements prediction using deep neural network (2017) The Eighth International Symposium, pp. 57-62; Kolen, J.F., Kremer, S.C., Gradient flow in recurrent nets: The difficulty of learning longterm dependencies. Field Guide Dyn (2001) Recurr. Neural Netw., 28 (2), pp. 237-243; Patel, J., Shah, S., Thakkar, P., Kotecha, K., Predicting stock and stock price index movement using trend deterministic data preparation and machine learning techniques (2015) Expert Syst. Appl. Int. J., 42 (1), pp. 259-268; Hochreiter, S., Schmidhuber, J., Long short-term memory (1997) Neural Comput, 9 (8), pp. 1735-1780; Werbos, P.J., Backpropagation through time: What it does and how to do it (1990) Proc. IEEE, 78 (10), pp. 1550-1560; Xiao, Y., Xiao, J., Liu, J., Wang, S., A multiscale modeling approach incorporating ARIMA and anns for financial market volatility forecasting (2014) J. Syst. Sci. Complex., 27 (1), pp. 225-236; Zhang, L., Aggarwal, C., Qi, G.J., Stock price prediction via discovering multi-frequency trading patterns (2017) ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, pp. 2141-2149"}
{"Authors":"Nascimento J.B., Cristo M.","Author(s) ID":"57169827100;8358717400;","Title":"The impact of structured event embeddings on scalable stock forecasting models","Year":2015,"Source title":"WebMedia 2015 - Proceedings of the 21st Brazilian Symposium on Multimedia and the Web","Volume":null,"Issue":null,"Art. No.":null,"Page start":121.0,"Page end":124.0,"Page count":null,"Cited by":1.0,"DOI":"10.1145\/2820426.2820467","Affiliations":"FPF Tech, Av. Danilo Areosa 1170, Distrito-Industrial-Manaus-AM, Brazil; Institute of Computing, Federal University of Amazonas, Av. Rodrigo Ot\u00e1vio 6200, Japiim, Manaus-AM, Brazil","Document Type":"Conference Paper","Access Type":null,"Source":"Scopus","EID":"2-s2.0-84960936929","Abstract":"Noisy and nonstationary real-world time series predictions (TSPs) are challenging tasks. Confronted with these challenging tasks, the predictive power of traditional shallow models is commonly not satisfactory enough. While the research on deep learning (DL) has made milestone breakthrough in recent years, and DL paradigm has gradually become indispensable for accomplishing these complex tasks. In this work, a cascading deep architecture based on weak results (DeepCascade-WR) is established, which possesses deep models\u2019 marked capability of feature representation learning based on complex data. In DeepCascade-WR, weak prediction results are defined, innovating the forecasting mode of traditional TSP. The original data will be properly reconstituted with prior knowledge, generating attribute vectors with valid predictive information. DeepCascade-WR possesses online learning ability and effectively avoids the retraining problem, owing to the property of OS-ELM, one base model of DeepCascade-WR. Besides, ELM is exploited as another base model of DeepCascade-WR, therefore, DeepCascade-WR naturally inherits some valuable virtues from ELM, including faster training speed, better generalization ability and the avoidance of being fallen into local optima. Ultimately, in the empirical results, DeepCascade-WR demonstrates its superior predictive performance on five benchmark financial datasets, i.e., ^DJI, ^GSK, ^HSI, JOUT, and S&P 500 Index, compared with its base learners and other state-of-the-art algorithms. \u00a9 2019, Springer-Verlag GmbH Germany, part of Springer Nature.","Author Keywords":"Deep learning (DL); Extreme learning machine (ELM); Online sequential extreme learning machine (OS-ELM); Time series prediction (TSP); Weak results","Index Keywords":"Benchmarking; E-learning; Forecasting; Knowledge acquisition; Machine learning; Time series; Extreme learning machine; Feature representation; Online sequential extreme learning machine; Predictive information; Predictive performance; State-of-the-art algorithms; Time series prediction; Weak results; Deep learning","References":"Crone, S.F., Hibon, M., Nikolopoulos, K., Advances in forecasting with neural networks? Empirical evidence from the NN3 competition on time series prediction (2011) Int J Forecast, 27, pp. 635-660; Villarreal, J., Baffes, P., Time series prediction using neural networks (2015) In: Expert Systems for Civil Engineers: Knowledge Representation, pp. 268-282. , American Society of Civil Engineers; Chandra, R., Competition and collaboration in cooperative coevolution of Elman recurrent neural networks for time-series prediction (2015) IEEE Trans Neural Netw Learn Syst, 26, pp. 3123-3136; Dieleman, S., Willett, K.W., Dambre, J., Rotation-invariant convolutional neural networks for galaxy morphology prediction (2015) Mon Not R Astron Soc, 450, pp. 1441-1459; Gaxiola, F., Melin, P., Valdez, F., Castillo, O., Generalized type-2 fuzzy weight adjustment for backpropagation neural networks in time series prediction (2015) Inf Sci, 325, pp. 159-174; Melin, P., Castillo, O., Mancilla, A., Lopez, M., Simulation and forecasting complex economic time series using neural network models (2016) J Intell Syst, 14, pp. 193-212; Wang, L., Zeng, Y., Chen, T., Back propagation neural network with adaptive differential evolution algorithm for time series forecasting (2015) Expert Syst Appl, 42, pp. 855-863; Rumelhart, D.E., Hinton, G.E., Williams, R.J., Learning representations by back-propagating errors (1986) J. Nature, 323, pp. 533-536; Huang, G.B., Zhu, Q.Y., Siew, C.K., Extreme learning machine: theory and applications (2006) Neurocomputing, 70, pp. 489-501; Collobert, R., Weston, J., A unified architecture for natural language processing: Deep neural networks with multitask learning (2008) Proceedings of International Conference on Machine Learning, pp. 160-167; Goodfellow, I.J., Bulatov, Y., Ibarz, J., Arnoud, S., Shet, V., (2014) Multi-digit number recognition from street view imagery using deep convolutional neural networks.; Hinton, G.E., Salakhutdinov, R.R., Reducing the dimensionality of data with neural networks (2006) Science, 313, pp. 504-507; Huval, B., Coates, A., Ng, A.Y., (2013) Deep learning for class-generic object detection.; Shin, H.C., Orton, M.R., Collins, D.J., Doran, S.J., Leach, M.O., Stacked autoencoders for unsupervised feature learning and multiple organ detection in a pilot study using 4d patient data (2013) IEEE Trans Pattern Anal Mach Intell, 35, pp. 1930-1943; Liang, N.Y., Huang, G.B., Saratchandran, P., A fast and accurate online sequential learning algorithm for feedforward networks (2006) IEEE Trans Neural Netw, 17, pp. 1411-1423; Sch\u00f6lkopf, B., Platt, J., Hofmann, T., Greedy layer-wise training of deep networks (2006) Expert Systems for Civil Engineers: Advances in Neural Information Processing Systems, pp. 153-160; Golub, G.H., Loan, C.F.V., (1996) Matrix Computations, pp. 463-535. , 3rd ed. DBLP; Wei, B., Yue, J., Rao, Y., A deep learning framework for financial time series using stacked autoencoders and long-short term memory (2017) PLoS One, 12 (7); Kuremoto, T., Kimura, S., Kobayashi, K., Obayashi, M., Time series forecasting using a deep belief network with restricted Boltzmann machines (2014) Neurocomputing, 137, pp. 47-56; (2014) Electronic Bulletin Board Online, , http:\/\/finance.yahoo.com; Bartley, W.W., Evolutionary epistemology, rationality, and the sociology of knowledge (2010) Philosophical Books, 30, pp. 94-97; Pearsall, J., (2001) The concise Oxford Dictionary, , Oxford University Press, Oxford; Krizhevsky, A., Sutskever, I., Hinton, G.E., ImageNet classification with deep convolutional neural networks (2012) In: Advances in Neural Information Processing Systems 25 (NIPS 2012); Tang, J., Deng, C., Huang, G.B., Extreme learning machine for multilayer perceptron (2015) IEEE Trans Neural Netw Learn Syst, 27, pp. 809-821"}
{"Authors":"Bebarta D.K., Biswal B., Dash P.K.","Author(s) ID":"36809160400;16642346800;7102314306;","Title":"Polynomial Based Functional Link Artificial Recurrent Neural Network adaptive System for predicting Indian Stocks","Year":2015,"Source title":"International Journal of Computational Intelligence Systems","Volume":"8","Issue":"6","Art. No.":null,"Page start":1004.0,"Page end":1016.0,"Page count":null,"Cited by":5.0,"DOI":"10.1080\/18756891.2015.1099910","Affiliations":"G.M.R. Institute of Technology, Rajam, A.P, India; Siksha \u2018O\u2019 Anusandhan University, Bhubaneswar, Odisha, India","Document Type":"Article","Access Type":"Open Access","Source":"Scopus","EID":"2-s2.0-84943244653","Abstract":"Social network media analytics is showing promise for prediction of financial markets. However, the true value of such data is unclear due to a lack of consensus on which instruments can be predicted. In this paper, we investigate whether measurements of collective emotional states derived from large scale network feeds are correlated to the stock transaction data over time. The information space corresponding to stocks is divided into the network public opinion space Opinion_Space and the realistic transaction space Behavior_Space. We then handle the information and generate the multidimensional time series from them respectively. Furthermore, Granger causality analysis and information theory measures are used to find and demonstrate that social media sentiments contain statistically significant ex-ante information on the future prices. At last, we propose our separate-LSTM model and the experimental results of six stocks which are randomly selected indicate that financial data predictions can be significantly improved through our model by the fusion of network public opinion emotions and realistic transaction data. \u00a9 2017, Springer Science+Business Media New York.","Author Keywords":"Emotions; Granger causality; LSTM; Network public opinion; Predictive analysis; Stock transaction; Time dependence","Index Keywords":"Commerce; Finance; Financial data processing; Financial markets; Forecasting; Information theory; Predictive analytics; Social aspects; Statistical tests; Emotions; Granger Causality; LSTM; Network public opinions; Stock transaction; Time dependence; Investments","References":"Kietzmann, J.H., Hermkens, K., McCarthy, I.P., Silvestre, B.S., Social media? Get serious! Understanding the functional building blocks of social media (2011) Bus. Horiz., 54 (3), pp. 241-251; Chairi, I., Griol, D., Manuel, M.J., Modeling human-machine interaction by means of a sample selection method (2015) 13th International Conference on Practical Applications of Agents, Multi-Agent Systems, and Sustainability, vol. 524, pp. 191-200; Tu, W., Cheung, D., Mamoulis, N., Time-sensitive opinion mining for prediction (2015) Proceedings of the Twenty-Ninth AAAI Conference on Artificial Intelligence; Wang, S., Burst time prediction in cascades (2015) Twenty-Ninth AAAI Conference on Artificial Intelligence AAAI Press; Mislove, A., Lehmann, S., Ahn, Y.-Y., Onnela, J.-P., Rosenquist, J.N., Understanding the demographics of twitter users (2011) The Fifth International AAAI Conference on Weblogs and Social Media, Barcelona, Spain, pp. 554-557. , The AAAI Press, Menlo Park, CA; Zheludev, I., Smith, R., Aste, T., When can social media lead financial markets? (2015) Sci. Rep., 4 (7489), p. 4213; de Vries, L., Gensler, S., Leeflang, P.S.H., Popularity of brand posts on BrandFan pages: an investigation of the effects of social media marketing (2012) J. Interact. Mark., 26, pp. 83-91; (2010) Predicting the future with social media. In: The 2010 IEEE\/WIC\/ACM International Conference on Web Intelligence and Intelligent Agent Theory, , Asur, S., Huberman, B.A.: Toronto, Canada; O\u2019Connor, B., Balasubramanyan, R., Routledge, B.R., Smith, N.A., From tweets to polls: linking text sentiment to public opinion time series (2010) The Fourth International AAAI Conference on Weblogs and Social Media, Washington, DC, USA. The AAAI Press Menlo Park, CA; Bollena, J., Maoa, H., Zeng, X., Twitter mood predicts the stock market (2011) J. Comput. Sci., 2 (1), pp. 1-8; Wang, C., Huberman, B.A., How random are online social interactions? (2012) Sci. Rep., 2 (9), p. 168; Li, X., Xie, H., Chen, L., Wang, J., Deng, X., News impact on stock price return via sentiment analysis (2014) Knowl. Based Syst., 69, pp. 14-23; Siganos, A., Vagenas-Nanos, E., Verwijmeren, P.P., Facebook\u2019s daily sentiment and international stock markets (2014) J. Econ. Behav. Org., 107, pp. 730-743; Smailovi\u0107, J., Gr\u010dar, M., Lavra\u010d, N., \u017dnidar\u0161i\u010d, M., Stream-based active learning for sentiment analysis in the financial domain (2014) Inform. Sci., 285 (1), pp. 181-203; Kukacka, J., Barunik, J., Behavioural breaks in the heterogeneous agent model: the impact of herding, overconfidence, and market sentiment (2013) Phys. A, 392 (23), pp. 5920-5938; Li, Q., Wang, T.J., Li, P., Liu, L., Gong, Q., Chen, Y., The effect of news and public mood on stock movements (2014) Inform. Sci., 278 (10), pp. 826-840; Cabrera-Paniagua, D., Cubillos, C., Vicari, R., Urra, E., Decision-making system for stock exchange market using artificial emotions (2015) Expert Syst. Appl., 42 (20), pp. 7070-7083; Jheng-Long, W., Liang-Chih, Y., Chang, P.-C., An intelligent stock trading system using comprehensive features (2014) Appl. Soft Comput., 23 (5), pp. 39-50; Saavedra, S., Duch, J., Uzzi, B., Tracking traders\u2019 understanding of the market using e-communication data (2011) PLoS ONE, 6 (10); Mao, Y., Wei, W., Wang, B., Liu, B., Correlating S&P500 stocks with Twitter data. The First ACM International Workshop on Hot Topics on Interdisciplinary Social Networks Research, Beijing, China. ACM (2012) New York; Ruiz, E.J., Hristidis, V., Castillo, C., Gionis, A., Jaimes, A., Correlating financial time series with micro blogging activity (2012) The Fifth ACM International Conference on Web search and Data Mining, Seattle, USA, , ACM, New York; Preis, T., Moat, H.S., Stanley, H.E., Quantifying trading behavior in financial markets using google trends (2013) Scientific Reports, 3 (1684); Challet, D., Bel Hadj Ayed, A., (2013) Predicting financial markets with Google Trends and not so random keywords. arXiv, 1307, p. 4643. , arXiv:1307.4643; Preis, T., Reith, D., Stanley, H.E., Complex dynamics of our economic life on different scales: insights from search engine query data (2010) Philos. T. R. Soc. A, 368, pp. 5707-5719; Bordino, I., Battiston, S., Caldarelli, G., Cristelli, M., Web search queries can predict stock market volumes (2012) PloS ONE, 7; Zhang, X., Fuehres, H., Gloor, P.A., Predicting stock market indicators through twitter I hope it is not as bad as I fear (2011) Proc. Soc. Behav. Sci., 26, pp. 55-62; Kallas, M., Honeine, P., Francis, C., Amoud, H., Kernel autoregressive models using Yule\u2013Walker equations (2013) Signal Process., 93 (11), pp. 3053-3061; Liu, C.-S., A method of Lie-symmetry GL(n,image) for solving non-linear dynamical systems (2013) Int. J. Non-Linear Mech., 52, pp. 85-95; Upadhyay, A., Bandyopadhyay, G., Dutta, A., Forecasting stock performance in Indian market using multinomial logistic regression (2012) J. Bus. Stud. Q., 3 (3), pp. 16-39; Sureshkumar, K.K., Elango, N.M., An efficient approach to forecast Indian stock market price and their performance analysis (2011) Int. J. Comput. Appl., 34, pp. 44-49; Mehrara, M., Moeini, A., Ahrari, M., Ghafari, A., Using technical analysis with neural network for forecasting stock price index in Tehran stock exchange (2010) Middle East. Fin. Econ., 6 (6), pp. 50-61; Agrawal, S., Jindal, M., Pillai, G.N., Momentum analysis based stock market prediction using adaptive Neuro-Fuzzy inference system(ANFIS) (2010) Proceedings of the International MultiConference of Engineers and Computer Scientists, Hong Kong vol. 1, March, pp. 17-19; Brody, D., Meister, B., Parry, M., Informational inefficiency in financial markets (2012) Math. Fin. Econ, 6, pp. 249-259"}
{"Authors":"Zafari F., Khan G.M., Rehman M., Ali Mahmud S.","Author(s) ID":"56028822400;19639163400;56278299400;56278649100;","Title":"Evolving recurrent neural network using cartesian genetic programming to predict the trend in foreign currency exchange rates","Year":2014,"Source title":"Applied Artificial Intelligence","Volume":"28","Issue":"6","Art. No.":null,"Page start":597.0,"Page end":628.0,"Page count":null,"Cited by":3.0,"DOI":"10.1080\/08839514.2014.923174","Affiliations":"Centre of Intelligent Systems and Network Research, Electrical Engineering Department, University of Engineering and Technology Peshawar, Peshawar 25125, Pakistan","Document Type":"Article","Access Type":null,"Source":"Scopus","EID":"2-s2.0-84904512745","Abstract":"To predicate the future with high accuracy is a holy grail in financial market. However, the volatility of chaotic financial market challenges new technologies from computer science to economic science all the time. Recently, Recurrent Neural Network (RNN) plays a new role in financial market prediction. However, results from RNN are restricted by sample size of training datasets, and show predication accuracy can hardly be guaranteed in a long term. On the other hand, Representative Pattern Discovery (RPD) is an effective way in long-term prediction while it is ineffective in short-term prediction. In this paper, we define a representative pattern for time series, and propose a fusion financial prediction strategy based on RNN and RPD. We take the advantages of both RNN and RPD, in the way that the proposed strategy is stateful to keep the short-term trend and it rectifies the predication by a time-dependent incremental factor in a long-term way. Compared with RNN and pattern discovery respectively, our experimental results demonstrate that our proposed strategy performs much better than that of others. It can increase the prediction accuracy by 6% on the basis of RNN at most, but at a cost of higher Mean Squared Error. \u00a9 2017 IEEE.","Author Keywords":"Financial prediction; Fusion method; Representative pattern discovery; RNNs","Index Keywords":"Commerce; Distributed computer systems; Financial markets; Mean square error; Recurrent neural networks; Financial prediction; Fusion methods; Long-term prediction; Prediction accuracy; Recurrent neural network (RNN); Representative patterns; RNNs; Short term prediction; Forecasting","References":"Barab\u00e1si, A.-L., (2010) Bursts: The Hidden Patterns behind Everything We Do, from Your E-mail to Bloody Crusades, , Penguin; Wang, H., Clustering by pattern similarity in large data sets (2002) ACM SIGMOD International Conference on Management of Data, pp. 394-405; Das, G., Lin, K.-I., Mannila, H., Renganathan, G., Smyth, P., Rule discovery from time series (1998) KDD, 98 (1), pp. 16-22; Fu, T.C., Chung, F.L., Ng, V., Luk, R., Pattern discovery from stock time series using self-organizing maps (2001) Workshop Notes of Kdd Workshop on Temporal Data Mining, pp. 1-8; Keogh, E., Lin, J., Truppel, W., Clustering of time series subsequences is meaningless: Implications for previous and future research (2003) IEEE International Conference on Data Mining, pp. 115-122; Rodriguez, A., Laio, A., Clustering by fast search and find of density peaks (2014) Science, 344 (6191), pp. 1492-1496; Lonardi, J., Patel, P., Finding motifs in time series (2002) Proc. of the 2nd Workshop on Temporal Data Mining, pp. 53-68; Petitjean, F., Ketterlin, A., Gancarski, P., A global averaging method for dynamic time warping, with applications to clustering (2011) Pattern Recognition, 44 (3), pp. 678-693; Guo, C., Jia, H., Zhang, N., Time series clustering based on ica for stock data analysis (2008) International Conference on Wireless Communications, NETWORKING and Mobile Computing, pp. 1-4; Wang, X., Smith, K., Hyndman, R., Characteristic-based clustering for time series data (2006) Data Mining & Knowledge Discovery, 13 (3), pp. 335-364; Di Persio, L., Honchar, O., Artificial neural networks architectures for stock price prediction: Comparisons and applications (2016) International Journal of Circuits, Systems and Signal Processing, 10, pp. 403-413; Maknickiene, N., Maknickas, A., Financial market prediction system with evolino neural network and delphi method (2013) Journal of Business Economics and Management, 14 (2), pp. 403-413; Shieh, J., Keogh, E., I sax: Indexing and mining terabyte sized time series (2008) Proceedings of the 14th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining. ACM, pp. 623-631; Goodfellow, I., Bengio, Y., Courville, A., (2016) Deep Learning, , http:\/\/www.deeplearningbook.org, MIT Press"}
{"Authors":"Ortega L., Khashanah K.","Author(s) ID":"55797136900;6506999405;","Title":"A neuro-wavelet model for the short-term forecasting of high-frequency time series of stock returns","Year":2014,"Source title":"Journal of Forecasting","Volume":"33","Issue":"2","Art. No.":null,"Page start":134.0,"Page end":146.0,"Page count":null,"Cited by":20.0,"DOI":"10.1002\/for.2270","Affiliations":"Stevens Institute of Technology, Castle Point on Hudson, Hoboken, NJ 07030, United States","Document Type":"Article","Access Type":null,"Source":"Scopus","EID":"2-s2.0-84894900843","Abstract":"The combination of Convolutional Neural Networks (CNNs) and Recurrent Neural Networks (RNNs) have played important roles in deep learning in recent years to improve the prediction performance, especially in the context of temporal data analysis. Previous research has shown that certain time series could have common time-dependent characteristics. Therefore, in order to make good prediction, it is necessary to take into account the correlation between different temporal data in modeling. However, general RNN models have serious limitation to achieve this goal. In this paper, a new architecture, Deep and Wide Neural Networks (DWNN), is proposed, where CNN's convolution layer is added to the RNN's hidden state transfer process. CNN is combined with RNN to extract the correlation characteristics of different RNN models while RNNs running along the time steps. This new architecture not only has the depth of RNN in the time dimension, but also has the width of the number of temporal data. The intuition behind the DWNN model, as well as different kinds of DWNN model structures are discussed in this paper. We use stock data from the sandstorm sector of Shanghai Stock Exchange for our experiment. As shown in the result, our proposed DWNN model can reduce the prediction mean squared error by 30% compared with the general RNN model. \u00a9 2018 IEEE.","Author Keywords":"CNNs; Convolution layer; Correlated temporal data; DNNs; RNNs","Index Keywords":"Application programs; Convolution; Deep learning; Electronic trading; Financial markets; Forecasting; Mean square error; Model structures; Network architecture; Storms; CNNs; Convolutional neural network; DNNs; Prediction mean-squared errors; Recurrent neural network (RNNs); RNNs; Temporal Data; Time-dependent characteristics; Recurrent neural networks","References":"Pineda, F.J., Generalization of back-propagation to recurrent neural networks (1987) Physical Review Letters, 59, p. 2229; Williams, R.J., Zipser, D., A learning algorithm for continually running fully recurrent neural networks (1989) Neural Computation, 1, pp. 270-280; LeCun, Y., Bengio, Y., Convolutional networks for images, speech, and time series (1995) The Handbook of Brain Theory and Neural Networks, 3361, p. 1995; Hochreiter, S., Schmidhuber, J., Long short-term memory (1997) Neural Computation, 9, pp. 1735-1780; Sercu, T., Puhrsch, C., Kingsbury, B., LeCun, Y., Very deep multilingual convolutional neural networks for LVCSR (2016) Proc. IEEE ICASSP, pp. 4955-4959. , IEEE; Qian, Y., Bi, M., Tan, T., Yu, K., Very deep convolutional neural networks for noise robust speech recognition (2016) IEEE\/ACM Trans. Audio, Speech, and Language Processing, 24, pp. 2263-2276. , Aug; Medennikov, I., Prudnikov, A., Zatvornitskiy, A., Improving English conversational telephone speech recognition (2016) Proc. Interspeech, pp. 2-6; Sainath, T.N., Mohamed, A., Kingsbury, B., Ramabhadran, B., Deep convolutional neural networks for LVCSR (2013) Proc. ICASSP; Sak, H., Senior, A., Beaufays, F., Long short-term memory recurrent neural network architectures for large scale acoustic modeling (2014) Proc. Interspeech; Sainath, T.N., Vinyals, O., Senior, A., Sak, H., Convolutional (2015) Long Short-term Memory, Fully Connected Deep Neural Networks, in Proc. IEEE ICASSP; Deng, L., Platt, J., Ensemble deep learning for speech recognition (2014) Proc. Interspeech; Pascanu, R., Gulcehre, C., Cho, K., Bengio, Y., How to construct deep recurrent neural networks (2014) Proc. ICLR; Xiong, W., Droppo, J., Huang, X., Seide, F., Seltzer, M., Stolcke, A., Yu, D., Zweig, G., The Microsoft 2016 conversational speech recognition system (2017) Proc. IEEE ICASSP, pp. 5255-5259; Xiong, W., Wu, L., Alleva, F., (2017) The Microsoft 2017 Conversational Speech Recognition System[J]; Baofeng, D., Peng, C., Sheng, H., Yong, Y., Sediment yields and impact factors in xerothermic valley in Jinsha River in the last 50 years: A Case study in Yuanmou County, Yunnan Province[J] (2006) Science of Soil and Water Conservation, 4 (5), pp. 20-24; Xuemin, G., Jinsheng, C., Lixin, W., Application of logistic regression to the study of nitrogen in surface water[J] (2000) Acta Scientiae Cirumstantiae, 20 (6), pp. 676-681; Yinlong, Y., The cointegration analysis to stock market plate indexs based on association rules[J] (2008) Statistical Thinktank, 9, p. 015; Zhang, J., Zhou, C., Application of association rules in stock plate cointegration analysis[J] (2013) Jisuanji Gongcheng Yu Yingyong(Computer Engineering and Applications), 49 (2), pp. 242-245; Cho, K., Merrienboer, B.V., Gulcehre, C., Learning phrase representations using rnn encoder-decoder for statistical machine translation[J] (2014) Computer Science; Sutskever, I., Vinyals, O., Le, Q.V., (2014) Sequence to Sequence Learning with Neural Networks[J], 4, pp. 3104-3112; Graves, A., Schmidhuber, J., Framewise phoneme classification with bidirectional LSTM and other neural network architectures (2005) Neural Networks, 18, pp. 602-610"}
{"Authors":"Al-Askar H., Hussain A.J., Al-Jumeily D., Radi N.","Author(s) ID":"56288742400;56212648400;23090210900;6505760939;","Title":"Regularized dynamic self organized neural network inspired by the immune algorithm for financial time series prediction","Year":2014,"Source title":"Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)","Volume":"8590 LNBI","Issue":null,"Art. No.":null,"Page start":56.0,"Page end":62.0,"Page count":null,"Cited by":3.0,"DOI":"10.1007\/978-3-319-09330-7_8","Affiliations":"Liverpool John Moores University, Byroom Street, Liverpool L3 3AF, United Kingdom; Al-Khawarizmi International College, P.O. Box 25669, Abu Dhabi, United Arab Emirates","Document Type":"Conference Paper","Access Type":null,"Source":"Scopus","EID":"2-s2.0-84958535711","Abstract":"Stock prediction is a great challenge for the past decades because of the fact that it is a non-stationary, noisy, chaotic environment. Traditional stock prediction models including statistical and machine learning based methods almost use handcrafted features as input. With the development of deep learning, end-to-end models achieve state-of-the-art in many other tasks. However financial time series data is too noise to apply end-to-end models straightly, instead of predicting stocks\u2019 absolute future return, we propose a novel stock selection model DeepStockRanker to predict stocks\u2019 future return ranking. Experimental results show that our method is able to extract information from raw data to predict stocks\u2019 future return ranking and achieves much better performance compared with several advanced models. \u00a9 Springer International Publishing AG, part of Springer Nature 2018.","Author Keywords":"End-to-end; Learning to rank; LSTM; Stock selection","Index Keywords":"Big data; Deep learning; Financial data processing; Forecasting; Long short-term memory; End to end; Extract informations; Financial time series; Learning to rank; LSTM; Neural network model; Stock predictions; Stock selections; Data mining","References":"Ariyo, A.A., Adewumi, A.O., Ayo, C.K., Stock price prediction using the arima model (2014) 2014 Uksim-Amss 16Th International Conference on Computer Modelling and Simulation (Uksim, pp. 106-112. , IEEE; Azevedo, J.M., Almeida, R., Almeida, P., Using data mining with time series data in short-term stocks prediction (2012) Int. J. Intell. Sci., 2 (4), pp. 177-181; Bahdanau, D., Cho, K., Bengio, Y., (2014) Neural machine translation by jointly learning to align and translate, , arXiv preprint arXiv; Bengio, Y., Courville, A., Vincent, P., Representation learning: A review and new perspectives (2013) IEEE Trans. Pattern Anal. Mach. Intell., 35 (8), pp. 1798-1828; Bisoi, R., Dash, P.K., A hybrid evolutionary dynamic neural network for stock market trend analysis and prediction using unscented kalman filter (2014) Appl. Soft Comput., 19, pp. 41-56; Boyacioglu, M.A., Avci, D., An adaptive network-based fuzzy inference system (Anfis) for the prediction of stock market return: The case of the istanbul stock exchange (2010) Expert Syst. Appl., 37 (12), pp. 7908-7912; Chen, Z., Du, X., Study of stock prediction based on social network (2013) 2013 International Conference on Social Computing (Socialcom), pp. 913-916. , IEEE; Chou, R.Y., Volatility persistence and stock valuations: Some empirical evidence using garch (1988) J. Appl. Econ., 3 (4), pp. 279-294; Ding, X., Zhang, Y., Liu, T., Duan, J., Using structured events to predict stock price movement: An empirical investigation (2014) Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP), pp. 1415-1425; Dong, G., Fataliyev, K., Wang, L., One-step and multi-step ahead stock prediction using backpropagation neural networks (2013) 2013 9Th International Conference on Information, Communications and Signal Processing (ICICS), pp. 1-5. , IEEE; Graves, A., (2012) Supervised Sequence Labelling with Recurrent Neural Networks, 385. , https:\/\/doi.org\/10.1007\/978-3-642-24797-2, Springer, Heidelberg; Grinold, R.C., Kahn, R.N., (2000) Active Portfolio Management; Guresen, E., Kayakutlu, G., Daim, T.U., Using artificial neural network models in stock market index prediction (2011) Expert Syst. Appl., 38 (8), pp. 10389-10397; Hinton, G., Deng, L., Yu, D., Dahl, G.E., Mohamed, A.R., Jaitly, N., Senior, A., Sainath, T.N., Deep neural networks for acoustic modeling in speech recognition: The shared views of four research groups (2012) IEEE Sig. Process. Mag., 29 (6), pp. 82-97; Hochreiter, S., Schmidhuber, J., Long short-term memory (1997) Neural Comput, 9 (8), pp. 1735-1780; Karpathy, A., Fei-Fei, L., (2014) Deep visual-semantic alignments for generating image descriptions, , arXiv preprint arXiv; Kingma, D., Ba, J., Adam: A method for stochastic optimization (2015) The International Conference on Learning Representations (ICLR), San Diego, USA; Kon, S.J., Models of stock returns a comparison (1984) J. Financ., 39 (1), pp. 147-165; Li, X., Xie, H., Song, Y., Zhu, S., Li, Q., Wang, F.L., Does summarization help stock prediction? A news impact analysis (2015) IEEE Intell. Syst., 30 (3), pp. 26-34; Liang, Q., Rong, W., Zhang, J., Liu, J., Xiong, Z., Restricted boltzmann machine based stock market trend prediction (2017) 2017 International Joint Conference on Neural Networks (IJCNN), pp. 1380-1387. , IEEE; Makrehchi, M., Shah, S., Liao, W., Stock prediction using event-based sentiment analysis (2013) 2013 IEEE\/WIC\/ACM International Joint Conferences on Web Intelligence (WI) and Intelligent Agent Technologies (IAT), 1, pp. 337-342. , IEEE; Nelson, D.M., Pereira, A.C., de Oliveira, R.A., Stock market\u2019s price movement prediction with LSTM neural networks (2017) 2017 International Joint Conference on Neural Networks (IJCNN), pp. 1419-1426. , IEEE; Park, K., Shin, H., Stock price prediction based on a complex interrelation network of economic factors (2013) Eng. Appl. Artif. Intell., 26 (5-6), pp. 1550-1561; Patel, J., Shah, S., Thakkar, P., Kotecha, K., Predicting stock and stock price index movement using trend deterministic data preparation and machine learning techniques (2015) Expert Syst. Appl., 42 (1), pp. 259-268; Quan, Z.Y., Stock prediction by searching similar candlestick charts (2013) 2013 IEEE 29Th International Conference on Data Engineering Workshops (ICDEW), pp. 322-325. , IEEE; Schumaker, R.P., Chen, H., A quantitative stock prediction system based on financial news (2009) Inf. Process. Manag., 45 (5), pp. 571-583; Skuza, M., Romanowski, A., Sentiment analysis of twitter data within big data distributed environment for stock prediction (2015) 2015 Federated Conference on Computer Science and Information Systems (Fedcsis), pp. 1349-1354. , IEEE; Tetlock, P.C., Saar-Tsechansky, M., Macskassy, S., More than words: Quantifying language to measure firms\u2019 fundamentals (2008) J. Financ., 63 (3), pp. 1437-1467; Tsai, C.F., Quan, Z.Y., Stock prediction by searching for similarities in candlestick charts (2014) ACM Trans. Manag. Inf. Syst. (TMIS), 5 (2), p. 9; Wu, D., Fung, G.P.C., Yu, J.X., Pan, Q., Stock prediction: An event-driven approach based on bursty keywords (2009) Front. Comput. Sci. China, 3 (2), pp. 145-157; Xie, B., Passonneau, R.J., Wu, L., Creamer, G.G., (2013) Semantic Frames to Predict Stock Price Movement"}
{"Authors":"Hussain A.J., Al-Askar H., Al-Jumeily D.","Author(s) ID":"56212648400;56288742400;23090210900;","Title":"Physical time series prediction using dynamic neural network inspired by the immune algorithm","Year":2014,"Source title":"Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)","Volume":"8779 LNAI","Issue":null,"Art. No.":null,"Page start":152.0,"Page end":161.0,"Page count":null,"Cited by":null,"DOI":"10.1007\/978-3-319-11298-5_16","Affiliations":"Applied Computing Research Group, Liverpool John Moores University, Byroom Street, Liverpool L3 3AF, United Kingdom","Document Type":"Conference Paper","Access Type":null,"Source":"Scopus","EID":"2-s2.0-84958527313","Abstract":"We develop a large-scale deep learning model to predict price movements from limit order book (LOB) data of cash equities. The architecture utilizes convolutional filters to capture the spatial structure of the LOBs as well as long short-term memory modules to capture longer time dependencies. The proposed network outperforms all existing state-of-the-art algorithms on the benchmark LOB dataset [A. Ntakaris, M. Magris, J. Kanniainen, M. Gabbouj, and A. Iosifidis, 'Benchmark dataset for mid-price prediction of limit order book data with machine learning methods,' J. Forecasting, vol. 37, no. 8, 852-866, 2018]. In a more realistic setting, we test our model by using one-year market quotes from the London Stock Exchange, and the model delivers a remarkably stable out-of-sample prediction accuracy for a variety of instruments. Importantly, our model translates well to instruments that were not part of the training set, indicating the model's ability to extract universal features. In order to better understand these features and to go beyond a 'black box' model, we perform a sensitivity analysis to understand the rationale behind the model predictions and reveal the components of LOBs that are most relevant. The ability to extract robust features that translate well to other instruments is an important property of our model, which has many other applications. \u00a9 1991-2012 IEEE.","Author Keywords":"Convolutional neural network; limit order book; LSTM; microstructure market data; time series analysis","Index Keywords":"Commerce; Convolution; Correlation theory; Deep neural networks; Electronic trading; Financial markets; Forecasting; Memory architecture; Sensitivity analysis; Time series analysis; Convolutional neural network; Limit order book; London Stock Exchange; LSTM; Machine learning methods; Market data; Prediction accuracy; State-of-the-art algorithms; Long short-term memory","References":"Ntakaris, A., Magris, M., Kanniainen, J., Gabbouj, M., Iosifidis, A., Benchmark dataset for mid-price prediction of limit order book data with machine learning methods (2018) J. Forecasting, 37 (8), pp. 852-866; Parlour, C.A., Seppi, D.J., Limit order markets: A survey (2008) Handbook of Financial Intermediation and Banking. Amsterdam, the Netherlands: Elsevier, 5, pp. 63-95; Rosu, I., Liquidity and information in order driven markets (2010) Tech. Rep; Zivot, E., Wang, J., Vector autoregressive models for multivariate time series (2006) Modeling Financial Time Series S-PLUS, pp. 385-429; Ariyo, A.A., Adewumi, A.O., Ayo, C.K., Stock price prediction using the ARIMA model (2014) Proc. 16th IEEE Int. Conf. Comput. Model. Simulation, pp. 106-112; Carrie, C., The new electronic trading regime of dark books, mashups and algorithmic trading (2006) Trading, 2006 (1), pp. 14-20; Gould, M.D., Porter, M.A., Williams, S., McDonald, M., Fenn, D.J., Howison, S.D., Limit order books (2013) Quantitative Finance, 13 (11), pp. 1709-1742; Chiang, W.-C., Enke, D., Wu, T., Wang, R., An adaptive stock index trading decision support system (2016) Expert Syst. Appl, 59, pp. 195-207; Szegedy, C., Going deeper with convolutions (2015) Proc. IEEE Conf. Comput. Vis. Pattern Recognit, pp. 1-9; Ribeiro, M.T., Singh, S., Guestrin, C., Why should i trust you?: Explaining the predictions of any classifier (2016) Proc. 22nd ACM SIGKDD Int. Conf. Knowl. Discov. Data Mining., ACM, pp. 1135-1144; Ang, A., Bekaert, G., Stock return predictability: Is it there? (2006) Rev. Financial Studies, 20 (3), pp. 651-707; Bacchetta, P., Mertens, E., VanWincoop, E., Predictability in financial markets: What do survey expectations tell us? (2009) J. Int. Money Finance, 28 (3), pp. 406-426; Bollerslev, T., Marrone, J., Xu, L., Zhou, H., Stock return predictability and variance risk premia: Statistical inference and international evidence (2014) J. Financial Quantitative Anal, 49 (3), pp. 633-661; Ferreira, M.A., Santa-Clara, P., Forecasting stock market returns: The sum of the parts is more than the whole (2011) J. Financial Econ, 100 (3), pp. 514-537; Mandelbrot, B., Hudson, R.L., (2007) The Misbehavior of Markets: A Fractal View of Financial Turbulence. New York, , NY, USA: Basic books; Mandelbrot, B.B., How fractals can explain what's wrong with Wall Street (2008) Sci. Amer, 15 (9); Agrawal, J., Chourasia, V., Mittra, A., State-of-The-art in stock prediction techniques (2013) Int. J. Adv. Res. Elect., Electron. Instrum. Eng, 2 (4), pp. 1360-1366; Cavalcante, R.C., Brasileiro, R.C., Souza, V.L., Nobrega, J.P., Oliveira, A.L., Computational intelligence and financial markets: A survey and future directions (2016) Expert Syst. Appl, 55, pp. 194-211; Cao, Q., Leggio, K.B., Schniederjans, M.J., A comparison between Fama and French's model and artificial neural networks in predicting the Chinese stock market (2005) Comput.Oper. Res, 32 (10), pp. 2499-2512; Sirignano, J., Cont, R., Universal Features of Price Formation in Financial Markets: Perspectives from Deep Learning; Atsalakis, G.S., Valavanis, K.P., Surveying stock market forecasting techniques-Part II: Soft computing methods (2009) Expert Syst. Appl, 36 (3), pp. 5932-5941; Tran, D.T., Magris, M., Kanniainen, J., Gabbouj, M., Iosifidis, A., Tensor representation in high-frequency financial data for price change prediction (2017) Proc. IEEE Symp. Series Comput. Intell, pp. 1-7; Tran, D.T., Gabbouj, M., Iosifidis, A., Multilinear class-specific discriminant analysis (2017) Pattern Recognit. Lett, 100, pp. 131-136; Passalis, N., Tefas, A., Kanniainen, J., Gabbouj, M., Iosifidis, A., Temporal bag-of-features learning for predicting mid price movements using high frequency limit order book data IEEE Trans. Emerg. Topics Comput. Intell., to Be Published; Tran, D.T., Iosifidis, A., Kanniainen, J., Gabbouj, M., Temporal attention-augmented bilinear network for financial time-series data analysis IEEE Trans. Neural Netw. Learn. Syst., to Be Published; Tsantekidis, A., Passalis, N., Tefas, A., Kanniainen, J., Gabbouj, M., Iosifidis, A., Forecasting stock prices from the limit order book using convolutional neural networks (2017) Proc. IEEE 19th Conf. Business Inform, 1, pp. 7-12; Tsantekidis, A., Passalis, N., Tefas, A., Kanniainen, J., Gabbouj, M., Iosifidis, A., (2018) Using Deep Learning for Price Prediction by Exploiting Stationary Limit Order Book Features; Tsantekidis, A., Passalis, N., Tefas, A., Kanniainen, J., Gabbouj, M., Iosifidis, A., Using deep learning to detect price change indications in financial markets (2017) Proc. 25th IEEE Eur. Signal Process. Conf, pp. 2511-2515; Dixon, M., Klabjan, D., Bang, J.H., Classification-based financial markets prediction using deep neural networks (2017) Algorithmic Finance, 6 (3-4), pp. 67-77; LeCun, Y., Bengio, Y., Convolutional networks for images, speech, and time series (1998) The Handbook of Brain Theory and Neural Networks, pp. 255-258. , Cambridge, MA, USA: MIT Press; Wang, N., Yeung, D.-Y., Learning a deep compact image representation for visual tracking (2013) Proc Adv. Neural Inf. Process. Syst, pp. 809-817; Girshick, R., Donahue, J., Darrell, T., Malik, J., Rich feature hierarchies for accurate object detection and semantic segmentation (2014) Proc. IEEE Conf. Comput. Vis. Pattern Recognit, pp. 580-587; Long, J., Shelhamer, E., Darrell, T., Fully convolutional networks for semantic segmentation (2015) Proc. IEEE Conf. Comput. Vis. Pattern Recognit, pp. 3431-3440; Chen, J.-F., Chen, W.-L., Huang, C.-P., Huang, S.-H., Chen, A.-P., Financial time-series data analysis using deep convolutional neural networks (2016) Proc. 7th IEEE Int. Conf. Cloud Comput. Big Data, pp. 87-92; Doering, J., Fairbank, M., Markose, S., Convolutional neural networks applied to high-frequency market microstructure forecasting (2017) Proc. IEEE Comput. Sci. Electron. Eng, pp. 31-36; Krizhevsky, A., Sutskever, I., Hinton, G.E., Imagenet classification with deep convolutional neural networks (2012) Adv. Neural Inf. Process. Syst, pp. 1097-1105; Simonyan, K., Zisserman, A., Very deep convolutional networks for large-scale image recognition Int. Conf. Learn. Represent., to Be Published; Hochreiter, S., Schmidhuber, J., Long short-term memory (1997) Neural Comput, 9 (8), pp. 1735-1780; Bengio, Y., Simard, P., Frasconi, P., Learning long-term dependencies with gradient descent is difficult (1994) IEEE Trans. Neural Netw, 5 (2), pp. 157-166; Sundermeyer, M., Schl\u00fcter, R., Ney, H., LSTM neural networks for language modeling (2012) Proc. 13th Annu. Conf. Int. Speech Commun. Assoc; Sutskever, I., Vinyals, O., Le, Q.V., Sequence to sequence learning with neural networks (2014) Proc. Advances Neural Inf. Process. Syst, pp. 3104-3112; Bao, W., Yue, J., Rao, Y., A deep learning framework for financial time series using stacked autoencoders and long-short term memory (2017) PLoS One, 12 (7); Selvin, S., Vinayakumar, R., Gopalakrishnan, E., Menon, V.K., Soman, K., Stock price prediction using LSTM,RNNandCNN-slidingwindow model (2017) Proc. IEEE Int. Conf. Adv. Comput., Commun. Inform, pp. 1643-1647; Fischer, T., Krauss, C., Deep learning with long short-term memory networks for financial market predictions (2018) Eur. J. Oper. Res, 270 (2), pp. 654-669; Di Persio, L., Honchar, O., Artificial neural networks architectures for stock price prediction: Comparisons and applications (2016) Int. J. Circuits, Syst. Signal Process, 10, pp. 403-413; Dixon, M., Sequence classification of the limit order book using recurrent neural networks (2018) J. Comput. Sci, 24, pp. 277-286; Nelson, D.M., Pereira, A.C., De Oliveira, R.A., Stock market's price movement prediction with LSTM neural networks (2017) Proc. IEEE Int. Joint Conf. Neural Netw, pp. 1419-1426; Harris, L., (2003) Trading and Exchanges: Market Microstructure for Practitioners. New York, , NY, USA: Oxford Univ. Press; O'Hara, M., (1995) Market Microstructure Theory. Cambridge,MA, 108. , USA: Blackwell Publishers; Kercheval, A.N., Zhang, Y., Modelling high-frequency limit order book dynamics with Support Vector Machines (2015) Quantitative Finance, 15 (8), pp. 1315-1329; Abraham, A., Nath, B., Mahanti, P.K., Hybrid intelligent systems for stock market analysis (2001) Proc. Int. Conf. Comput. Sci, pp. 337-345; Hendershott, T., Jones, C.M., Menkveld, A.J., Does algorithmic trading improve liquidity? (2011) J. Finance, 66 (1), pp. 1-33; Cao, C., Hansch, O., Wang, X., The information content of an open limit-order book (2009) J. Futures Markets, 29 (1), pp. 16-41; Orfanidis, S.J., (1995) Introduction to Signal Processing. Englewood Cliffs, , NJ, USA: Prentice-Hall; Gatheral, J., Oomen, R.C., Zero-intelligence realized variance estimation (2010) Finance Stochastics, 14 (2), pp. 249-283; Nevmyvaka, Y., Feng, Y., Kearns, M., Reinforcement learning for optimized trade execution (2006) Proc. 23rd Int. Conf. Mach. Learn., ACM, pp. 673-680; Avellaneda, M., Reed, J., Stoikov, S., Forecasting prices from Level-I quotes in the presence of hidden liquidity (2011) Algorithmic Finance, 1 (1), pp. 35-43; Burlakov, Y., Kamal, M., Salvadore, M., (2012) Optimal Limit Order Execution in A Simple Model for Market Microstructure Dynamics; Harris, L., Maker-taker pricing effects on market quotations (2013) USC Marshall School of Business Working Paper, , http:\/\/bschool.huji.ac.il\/.upload\/hujibusiness\/Maker-taker.pdf; Lipton, A., Pesavento, U., Sotiropoulos, M.G., (2013) Trade Arrival Dynamics and Quote Imbalance in A Limit Order Book; Maas, A.L., Hannun, A.Y., Ng, A.Y., Rectifier nonlinearities improve neural network acoustic models (2013) Proc. 30th Int. Conf. Mach. Learn, 30, p. 3; Goodfellow, I., Bengio, Y., Courville, A., (2016) Deep Learning. Cambridge, , http:\/\/www.deeplearningbook.org, MA, USA: MIT Press; Moskowitz, T.J., Ooi, Y.H., Pedersen, L.H., Time series momentum (2012) J. Financial Econ, 104 (2), pp. 228-250; Lin, M., Chen, Q., Yan, S., Network in network Int. Conf. Learn. Represent., to Be Published; Kingma, D., Ba, J., Adam: A method for stochastic optimization Proc. Int. Conf. Learn. Represent., to Be Published; Keskar, N.S., Mudigere, D., Nocedal, J., Smelyanskiy, M., Tang, P.T.P., On large-batch training for deep learning: Generalization gap and sharp minima Int. Conf. Learn. Represent., to Be Published; https:\/\/keras.io, F. Chollet et al. 2015; Abadi, M., (2015) TensorFlow: Large-scale Machine Learning on Heterogeneous Systems, , https:\/\/www.tensorflow.org; Zhang, Z., Zohren, S., Roberts, S., Bdlob: Bayesian deep convolutional neural networks for limit order books Proc. 3rd Workshop Bayesian Deep Learn., to Be Published"}
{"Authors":"[No author name available]","Author(s) ID":"[No author id available]","Title":"Intelligent Computing in Bioinformatics - 10th International Conference, ICIC 2014, Proceedings","Year":2014,"Source title":"Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)","Volume":"8590 LNBI","Issue":null,"Art. No.":null,"Page start":null,"Page end":null,"Page count":526.0,"Cited by":null,"DOI":null,"Affiliations":null,"Document Type":"Conference Review","Access Type":null,"Source":"Scopus","EID":"2-s2.0-84904694665","Abstract":"Stock price is one of intricate non-linear dynamic system. Typically, Elman neural network is a local recurrent neural network, having one context layer that memorizes the past states, which is quite fit for resolving time series issues. Given this, this paper takes Elman network to predict the opening price of stock market. Considering that Elman network is limited, this paper adopts self-adapting variant PSO algorithm to optimize the weights and thresholds of network. Afterwards, the optimized data, regarded as initial weight and threshold value, is given to Elman network for training, accordingly the prediction model for opening price of stock market based on self-adapting variant PSO-Elman network is formed. Finally, this paper verifies that model by some stock prices, and compares with BP network and Elman network, so as to draw the result that shows the precision and stability of this predication model both are superior to the traditional neural network. \u00a9 2017 IEEE.","Author Keywords":"Elman network; MATLAB; Self-adapting variant PSO; stock market prediction","Index Keywords":"Commerce; Costs; Financial markets; Forecasting; Linear control systems; MATLAB; Recurrent neural networks; Elman network; Elman neural network; Local recurrent neural networks; Non-linear dynamic systems; Predication model; Self adapting; Short term prediction; Stock market prediction; Electronic trading","References":"Xiaojie, W., Short term prediction of stock price based on elman recursive neural network[j] (2016) Journal of Xinxiang University, 33 (9), pp. 27-29; Cao, F., The research and application of hybird model based on elman neural network and optimization algorithm[D] (2015) Lanzhou : Lanzhou University, pp. 19-22; Jingtian, T., Yang, C., Jiaying, X., Predication of plasma concentration of remifentanil based on Elman neural network[J] (2013) Journal of Central South University, 20 (11), pp. 3187-3192; Zhou, J.-M., Zhu, Z.-X., Liu, Y.-J., Peng, H.-Y., Qiang, G., Predication of calorific value and ignition temperature of blended coal based on Elman neural network[J] (2011) Journal of Central South University (Science and Technology), 42 (12), pp. 3871-3875; Qi, Z., Zhijian, X., Kunrong, Z., Prediction of data from pollution sources based on elman neural network[J] (2009) Journal of South China University of Technology (Natural Science Edition), 37 (5), pp. 135-138; Huaijun, L.I., Xiaopeng, X., Xinyuan, X., Study on Particle Swarm Optimization algorithm with parameters adaptive mutation based on particle entropy[J] (2014) Computer Engineering and Applications, 50 (19), pp. 27-31; Wang, J., Wenyu Zhang, B., Li, Y., Wang, J., Dang, Z., Forecasting wind speed using empirical mode decomposition and Elman neural network[J] (2014) Applied Soft Computing, 23, pp. 452-459; Liu, R., (2013) Short-term Load Forecasting Based on Elman Neural Network, pp. 24-27. , Zhejiang : Zhejiang University; Yuwan, H., (2008) Research and Simulation on Neural Network Predictive Control for Freeway Ramp Based on Elman, pp. 27-30. , Chengdu: Southwest Jiaotong University; Wang, J., Wang, J., Fang, W., Financial time series prediction using elman recurrent random neural networks[J] (2016) Computational Intelligence & Neuroscience, 2016 (12), pp. 1-14"}
{"Authors":"Bekiros S.D.","Author(s) ID":"8560165000;","Title":"Irrational fads, short-term memory emulation, and asset predictability","Year":2013,"Source title":"Review of Financial Economics","Volume":"22","Issue":"4","Art. No.":null,"Page start":213.0,"Page end":219.0,"Page count":null,"Cited by":2.0,"DOI":"10.1016\/j.rfe.2013.05.005","Affiliations":"European University Institute, Florence, Italy; Athens University of Economics and Business, Athens, Greece; Rimini Centre for Economic Analysis (RCEA), Canada; Department of Accounting and Finance, 76 Patission str, GR104 34, Athens, Greece; RCEA, Via Patara, 3, 47900, Rimini, Italy","Document Type":"Article","Access Type":null,"Source":"Scopus","EID":"2-s2.0-84887614624","Abstract":"Various techniques have been applied to predict stock market trends. However, the results are not quite satisfactory due to stock market's complexity. Many approaches either lack a clear and reasonable definition of trend or neglect the uniqueness of time attribute in stock data, treating them like other attributes, and use one-size-fits-All models to solve such a typical time-series problem. In this paper, we attempted to exploit the time attribute of stock data to improve prediction accuracy. Firstly, instead of treating data indiscriminately, we used time weight function to carefully assign weights to data according to their temporal nearness towards the data to be predicted. Secondly, the stock trend definitions were formally given by referencing financial theories and best practices. Lastly, Long Short-Term Memory (LSTM) network was customized to discover the underlying temporal dependencies in data. The trials of different time-weighted functions showed that the relation between the importance of data and their time-series is not constant. Instead, it falls within linear and quadratic, roughly a quasilinear function. Equipped with the time-weighted function, LSTM outperformed other models and can be generalized to other stock indexes. In the test with CSI 300 index, we achieved 83.91% in accuracy when fed with the redefined trends. \u00a9 2017 IEEE.","Author Keywords":"LSTM; stock; Time series; Time weighted","Index Keywords":"Commerce; Financial markets; Forecasting; Time series; CSI 300 indices; LSTM; Prediction accuracy; Quasi-linear functions; stock; Stock trend prediction; Time weighted; Weighted function; Long short-term memory","References":"Dimson, E., Mussavian, M., A brief history of market efficiency (1998) European Financial Management, 4 (1), pp. 91-103; Malkiel, B.G., The efficient market hypothesis and its critics (2003) The Journal of Economic Perspectives, 17 (1), pp. 59-82; Burton, F.E.T., Shah, S.N., Efficient market hypo thesis CMT Level i 2017: An Introduction to Technical Analysis, 2017; Ballings, M., Van den Poel, D., Hespeels, N., Gryp, R., Evaluating multiple classifiers for stock price direction prediction (2015) Expert Systems with Applications, 42 (20), pp. 7046-7056; Murphy, J.J., (1999) Technical Analysis of the Financial Markets: A Comprehensive Guide to Trading Methods and Applications, , Penguin; Agrawal, J., Chourasia, V., Mittra, A., State-of-The-Art in stock prediction techniques (2013) International Journal of Advanced Research in Electrical, Electronics and Instrumentation Engineering, 2 (4), pp. 1360-1366; Si, J., Mukherjee, A., Liu, B., Li, Q., Li, H., Deng, X., Exploiting topic based twitter sentiment for stock prediction (2013) ACL, 2013 (2), pp. 24-29; Frost, A.J., Prechter, R.R., Elliott wave principle: Key to market behavior (2005) Elliott Wave International; Atsalakis, G.S., Valavanis, K.P., Surveying stock market forecasting techniques-part II: Soft computing methods (2009) Expert Systems with Applications, 36 (3), pp. 5932-5941; Ding, X., Zhang, Y., Liu, T., Duan, J., Deep learning for event-driven stock prediction (2015) Ijcai, pp. 2327-2333; Gers, F.A., Schmidhuber, J., Cummins, F., (1999) Learning to Forget: Continual Prediction with Lstm; Graves, A., (2013) Generating Sequences with Recurrent Neural Networks, , arXiv preprint arXiv:1308 0850; Sak, H., Senior, A., Beaufays, F., Long short-Term memory recurrent neural network architectures for large scale acoustic modeling (2014) Fifteenth Annual Conference of the International Speech Communication Association; Chen, K., Zhou, Y., Dai, F., A lstm-based method for stock returns prediction: A case study of China stock market (2015) Big Data (Big Data) 2015 IEEE International Conference On. IEEE, pp. 2823-2824; Akita, R., Yoshihara, A., Matsubara, T., Uehara, K., Deep learning for stock prediction using numerical and textual information (2016) Computer and Information Science (ICIS), 2016 IEEE\/ACIS 15th International Conference On. IEEE, pp. 1-6; Di Persio, L., Honchar, O., Recurrent Neural Networks Approach to the Financial Forecast of Google Assets; Jozefowicz, R., Zaremba, W., Sutskever, I., An empirical exploration of recurrent network architectures (2015) Proceedings of the 32nd International Conference on Machine Learning ICML-15, pp. 2342-2350; Pedregosa, F., Varoquaux, G., Gramfort, A., Michel, V., Thirion, B., Grisel, O., Blondel, M., Dubourg, V., Scikit-learn: Machine learning in python (2011) Journal of Machine Learning Research, 12, pp. 2825-2830. , no. Oct; Abadi, M., Barham, P., Chen, J., Chen, Z., Davis, A., Dean, J., Devin, M., Isard, M., Tensorflow: A system for large-scale machine learning OSDI, 16 (2016), pp. 265-283; Breiman, L., Random forests (2001) Machine Learning, 45 (1), pp. 5-32; Zhu, J., Zou, H., Rosset, S., Hastie, T., Multi-class adaboost (2009) Statistics and Its Interface, 2 (3), pp. 349-360"}
{"Authors":"Sharma V., Srinivasan D.","Author(s) ID":"57199918726;7006684979;","Title":"A hybrid intelligent model based on recurrent neural networks and excitable dynamics for price prediction in deregulated electricity market","Year":2013,"Source title":"Engineering Applications of Artificial Intelligence","Volume":"26","Issue":"5-6","Art. No.":null,"Page start":1562.0,"Page end":1574.0,"Page count":null,"Cited by":28.0,"DOI":"10.1016\/j.engappai.2012.12.012","Affiliations":"National University of Singapore, Department of Electrical and Computer Engineering, 4 Engineering Drive 3, Singapore 117576, Singapore","Document Type":"Article","Access Type":null,"Source":"Scopus","EID":"2-s2.0-84876945790","Abstract":"Exchange rate forecasting has always been a research hot spot of international finance studies. Deep belief network (DBN) model of deep learning is a new method of predicting the exchange rate data, and the designing of DBN structure and the learning rules of parameters are the most important parts of DBN model. The paper firstly divides the time series data into training and testing sets. By optimizing the DBN parameters, the paper analyses the results of the training analysis and answers how to do node setting. Then, the paper adjusts the number of hidden nodes, inputs nodes and hidden layers, and by using multiple variance analysis, it determines the sensitive range of the node. Finally, the experiments of INR\/USD and CNY\/USD have proved that compared with the FFNN model, the improved DBN model could better forecast the exchange rate. \u00a9 2017, The Natural Computing Applications Forum.","Author Keywords":"DBN; Deep learning; Exchange rate forecasting","Index Keywords":"Finance; Forecasting; International trade; Deep belief network (DBN); Deep belief networks; Exchange rate forecasting; Exchange rates; Paper analysis; Time-series data; Training and testing; Variance analysis; Deep learning","References":"Zhang, G., Hu, M.Y., Neural network forecasting of the British pound\/US dollar exchange rate (1998) Omega, 26 (4), pp. 495-506; Zhang, R., Shen, F., Zhao, J., A model with fuzzy granulation and deep belief networks for exchange rate forecasting (2014) International Joint Conference on Neural Networks, pp. 366-373; LeCun, Y., Bengio, Y., Hinton, G., Deep learning (2015) Nature, 521 (7553), pp. 436-444; Schmidhuber, J., Deep learning in neural networks: an overview (2015) Neural Netw, 61, pp. 85-117; Hinton, G.E., Osindero, S., Teh, Y.W., A fast learning algorithm for deep belief nets (2006) Neural Comput, 18, pp. 1527-1554; Hinton, G.E., Salakhutdinov, R.R., Using deep belief nets to learn covariance kernels for Gaussian processes (2008) Advances in Neural Information Processing Systems, pp. 1249-1256; Kuremotoa, T., Kimuraa, S., Kobayashib, K., Obayashia, M., Time series forecasting using a deep belief network with restricted Boltzmann machines (2014) Neurocomputing, 137 (15), pp. 47-56; Shen, F., Chao, J., Zhao, J., Forecasting exchange rate using deep belief networks and conjugate gradient method (2015) Neurocomputing, 167 (C), pp. 243-253; Chen, H., Murray, A.F., Continuous restricted Boltzmann machine with an implementable training algorithm (2003) IEE Proc Vis Image Signal Process, 150 (3), pp. 153-158; Minsky, M., Papert, S., (1988) Perceptrons, 841, pp. 449-452. , MIT Press, Cambridge; Erhan, D., Manzagol, P.A., Bengio, Y., Bengio, S., Vincent, P., The difficulty of training deep architectures and the effect of unsupervised pre-training (2009) Immunology of Fungal Infections, 5, pp. 153-160; Erhan, D., Bengio, Y., Courville, A., Manzagol, P.A., Vincent, P., Why does unsupervised pre-training help deep learning? (2010) J Mach Learn Res, 11, pp. 625-660; Hinton, G.E., Dayan, P., Frey, B.J., The \u201cwake\u2013sleep\u201d algorithm for unsupervised neural networks (1995) Science, 268 (5214), pp. 1158-1161; Hinton, G.E., Training products of experts by minimizing contrastive divergence (2002) Neural Comput, 14 (8), pp. 1771-1800; Ma, X., Wang, X., Average contrastive divergence for training restricted Boltzmann machines (2016) Entropy, 18 (1), p. 35; Chen, H., Murray, A., A continuous restricted Boltzmann machine with a hardware-amenable learning algorithm (2002) Artificial neural networks\u2014ICANN 2002, pp. 358-363. , (,),. In; Frey, B.J., Continuous sigmoidal belief networks trained using slice sampling (1997) Advances in Neural Information Processing Systems, pp. 452-458; Khashei, M., Bijari, M., Ardali, G.A.R., Improvement of auto-regressive integrated moving average models using fuzzy logic and artificial neural networks (2009) Neurocomputing, 72 (4), pp. 956-967; Dhamija, A.K., Bhalla, V.K., Exchange rate forecasting: comparison of various architectures of neural networks (2011) Neural Comput Appl, 20 (3), pp. 355-363; Kodogiannis, V., Lolis, A., Forecasting financial time series using neural network and fuzzy system-based techniques (2002) Neural Comput Appl, 11 (2), pp. 90-102"}
{"Authors":"Cai X., Lai G., Lin X.","Author(s) ID":"55366093200;56256904700;8208832700;","Title":"Forecasting large scale conditional volatility and covariance using neural network on GPU","Year":2013,"Source title":"Journal of Supercomputing","Volume":"63","Issue":"2","Art. No.":null,"Page start":490.0,"Page end":507.0,"Page count":null,"Cited by":5.0,"DOI":"10.1007\/s11227-012-0827-1","Affiliations":"School of Information Science and Technology, Sun Yat-sen University, High Education Mega Center, Guangzhou, 51006, China; Department of Computer Application and Technology, Hanshan Normal University, Chaozhou, 521041, China","Document Type":"Article","Access Type":null,"Source":"Scopus","EID":"2-s2.0-84882350479","Abstract":"The Long Short-Term Memory (LSTM) model has been applied in recent years to handle time series data in multiple application domains, such as speech recognition and financial prediction. While the LSTM prediction model has shown promise in anomaly detection in previous research, uncorrelated features can lead to unsatisfactory analysis result and can complicate the prediction model due to the curse of dimensionality. This paper proposes a novel method of clustering and predicting multidimensional aircraft time series. The purpose is to detect anomalies in flight vibration in the form of high dimensional data series, which are collected by dozens of sensors during test flights of large aircraft. The new method is based on calculating the Spearman\u2019s rank correlation coefficient between two series, and on a hierarchical clustering method to cluster related time series. Monotonically similar series are gathered together and each cluster of series is trained to predict independently. Thus series which are uncorrelated or of low relevance do not influence each other in the LSTM prediction model. The experimental results on COMAC\u2019s (Commercial Aircraft Corporation of China Ltd) C919 flight test data show that our method of combining clustering and LSTM model significantly reduces the root mean square error of predicted results. \u00a9 2018, Springer Nature Switzerland AG.","Author Keywords":"Cluster; Correlation coefficient; LSTM; Time series","Index Keywords":"Aircraft; Chemical detection; Cluster analysis; Clustering algorithms; Forecasting; Mean square error; Speech recognition; Time series; Cluster; Correlation coefficient; Curse of dimensionality; Hierarchical clustering methods; High dimensional data; LSTM; Rank correlation coefficient; Root mean square errors; Long short-term memory","References":"Cao, Z., Zhu, Y., Improving prediction accuracy in LSTM network model for aircraft testing flight data (2018) IEEE International Conference on Smart Cloud; Hsu, H., Hsieh, C., Feature selection via correlation coefficient clustering (2010) J. Softw., 5 (12), pp. 1371-1377; Gauthier, T., Detecting trends using spearman\u2019s rank correlation coefficient (2001) Environ. Forensics, 2, pp. 359-362; Nanduri, A., Sherry, L., Anomaly detection in aircraft data using recurrent neural networks (2016) Integrated Communications Navigation and Surveillance (ICNS) Conference; Grabusts, P., Borisov, A., Clustering methodology for time series mining (2009) Sci. J. Riga Tech. Univ., 40 (1), pp. 81-86; Singhal, A., Seborg, D., Clustering multivariate time-series data (2005) J. Chemom., 19, pp. 427-438; Funie, A.-I., Grigoras, P., Burovskiy, P., Luk, W., Salmon, M., Run-time reconfigurable acceleration for genetic programming fitness evaluation in trading strategies (2018) J. Signal Process. Sys., 90 (1), pp. 39-52; Gai, K., Qiu, M., Zhao, H., Dynamic energy-aware cloudlet-based mobile cloud computing model for green computing (2016) J. Netw. Comput. Appl., 59, pp. 46-54; Bara, A., Niu, X., Luk, W., A dataflow system for anomaly detection analysis (2014) International Conference on Field Programmable Technology; Graves, A., Generating Sequences with Recurrent Neural Networks, , https:\/\/arxiv.org\/abs\/1308.0850; Cui, L., Luo, Y., Li, G., Lu, N., Artificial bee colony algorithm with hierarchical groups for global numerical optimization (2017) Smartcom 2016. LNCS, 10135, pp. 72-85. , https:\/\/doi.org\/10.1007\/978-3-319-52015-5_8, Qiu, M. (ed.), Springer, Cham; Gai, K., Qiu, M., Liu, M., Zhao, H., Smart resource allocation using reinforcement learning in content-centric cyber-physical systems (2018) Smartcom 2017. LNCS, 10699, pp. 39-52. , https:\/\/doi.org\/10.1007\/978-3-319-73830-7_5, Qiu, M. (ed.), Springer, Cham"}
{"Authors":"Zimmermann H.G., Grothmann R., von Mettenheim H.-J.","Author(s) ID":"35615968500;23024809400;8947545100;","Title":"Planning purchase decisions with advanced neural networks","Year":2013,"Source title":"Advanced Information and Knowledge Processing","Volume":null,"Issue":"9781447148654","Art. No.":null,"Page start":125.0,"Page end":141.0,"Page count":null,"Cited by":1.0,"DOI":"10.1007\/978-1-4471-4866-1_9","Affiliations":"Siemens AG Munich, Corporate Technology, Munich, Germany; Institut f\u00fcr Wirtschaftsinformatik, Leibniz Universit\u00e4t Hannover, Hannover, Germany","Document Type":"Book Chapter","Access Type":null,"Source":"Scopus","EID":"2-s2.0-84905957085","Abstract":"In this chapter we investigate a typical situation of a corporate treasurer: on an ongoing basis some kind of transaction is performed. This may be a regular monthly investment in equities for a pension plan, or a fixed income placement. It might be a foreign exchange transaction to pay monthly costs in another currency. Or it could be the monthly supply of some commodity, like fuel or metal. All these cases have in common that the treasurer has to choose an appropriate time for the transaction. This is the day on which the price is the most favorable. Ideally, we want to buy at the lowest price within the month, and we also want to invest our money at the highest available interest rate. This problem is complex, because the underlying financial time series are not moving independently. Rather, they are interconnected. In order to truly understand our time series of choice, we have to model other influences as well: equities, currencies, interest rates, commodities, and so on. To achieve this we present a novel recurrent neural network approach: Historically Consistent Neural Networks (HCNN). HCNNs allow to model dynamics of entire markets using a state space equation: st+1=tanh(W\u22c5st). Here, W represents a weight matrix and st the state of our dynamic system at time t. This iterative formulation easily produces multi step forecasts for several time points into the future. We analyze monthly purchasing decisions for a market of 25 financial time series. This market approximates a world market: it includes various asset classes from Europe, the US, and Asia. Our benchmar, an averaging strategy, shows that using HCNNs to forecast an entry point for ongoing investments results in better prices for every time series in the sample. \u00a9 Springer-Verlag London 2013.","Author Keywords":null,"Index Keywords":null,"References":"Breitner, M.H., Luedtke, C., Von Mettenheim, H.J., R\u00f6sch, D., Sibbertsen, P., Tymchenko, G., Modeling portfolio value at risk with statistical and neural network approaches (2010) Proceedings of the 17Th International Conference on Forecasting Financial Markets, Hannover, 26\u201328 May 2010, , Dunis, C., Dempster, M., Breitner, M.H., R\u00f6sch, D., von Mettenheim, H.J. (eds.), Advances for Exchange Rates, Interest Rates and Asset Management; Dunis, C.L., Laws, J., Evans, B., Modelling and trading the soybean-oil crush spread with recurrent and higher order networks: A comparative analysis (2006) Neural Netw. World, 13 (3-6), pp. 193-213; Gibbons, M.R., Hess, P., Day of the week effects and asset returns (1981) J. Bus., 54 (4), pp. 579-596; Hornik, K., Stinchcombe, M., White, H., Multilayer feedforward networks are universal approximators (1989) Neural Netw, 2, pp. 359-366; Kreyszig, E., (2011) Advanced Engineering Mathematics, , Wiley, New York; Lindemann, A., Dunis, C.L., Lisboa, P., Probability distribution architectures for trading silver (2005) Neural Netw. World, 15 (5), pp. 437-470; Von Mettenheim, H.J., (2009) Advanced Neural Networks: Finance, Forecast, and Other Applications, , Ph.D. thesis, Faculty of Economics, Leibniz Universit\u00e4t Hannover, December; Von Mettenheim, H.J., Breitner, M.H., Robust forecasts with shared layer perceptrons (2010) Proceedings of the 17Th International Conference on Forecasting Financial Markets, , Dunis, C., Dempster, M., Breitner, M.H., R\u00f6sch, D., von Mettenheim, H.J. (eds.), Hannover, 26\u201328 May 2010. Advances for Exchange Rates, Interest Rates and Asset Management; Von Mettenheim, H.J., Breitner, M.H., Neural network model building: A practical approach (2011) Proceedings of the 18Th International Conference on Forecasting Financial Markets, , Dunis, C., Dempster, M., Girardin, E., P\u00e9guin-Feissolle, A. (eds.), Marseille, 25\u201327 May 2011. Advances for Exchange Rates, Interest Rates and Asset Management; Weithers, T., (2006) Foreign Exchange: A Practical Guide to the FX Markets, , Wiley, Hoboken; Zimmermann, H.G., Forecasting the Dow Jones with historical consistent neural networks (2009) Proceedings of the 16Th International Conference on Forecasting Financial Markets, , Dunis, C., Dempster, M., Terraza, V. (eds.), Luxembourg, 27\u201329 May 2009. Advances for Exchange Rates, Interest Rates and Asset Management; Zimmermann, H.G., Advanced forecasting with neural networks (2010) Proceedings of the 17Th International Conference on Forecasting Financial Markets, , Dunis, C., Dempster, M., Breitner, M.H., R\u00f6sch, D., von Mettenheim, H.J. (eds.), Hannover, 26\u201328 May 2010. Advances for Exchange Rates, Interest Rates and Asset Management"}
{"Authors":"Wei L.-Y., Cheng C.-H.","Author(s) ID":"23062367300;7404797459;","Title":"A hybrid recurrent neural networks model based on synthesis features to forecast the Taiwan stock market","Year":2012,"Source title":"International Journal of Innovative Computing, Information and Control","Volume":"8","Issue":"8","Art. No.":null,"Page start":5559.0,"Page end":5571.0,"Page count":null,"Cited by":14.0,"DOI":null,"Affiliations":"Department of Information Management, Yuanpei University, No. 306, Yuanpei Street, Hsin Chu 30015, Taiwan; National Yunlin University of Science and Technology, No. 123, Section 3, University Road, Touliu, Yunlin 640, Taiwan","Document Type":"Article","Access Type":null,"Source":"Scopus","EID":"2-s2.0-84866037441","Abstract":"The proceedings contain 33 papers. The special focus in this conference is on Mining Intelligence and Knowledge Exploration. The topics include: Categorical modeling method of intelligent WorkFlow; classification of dengue serotypes using protein sequence based on rule extraction from neural network; orienting social event streams as data stories; software driven optimal design for maintenance man hour; modeling trajectory data as a directed graph; connected cars traffic flow balancing based on classification and calibration; identification and control of a car speed dynamics using artificial intelligence; industry 4.0, intelligent visual assisted picking approach; Detection and mapping of a toxic cloud using UAVs and emergent techniques; Meaningful clusterings of recurrent neural network activations for NLP; convolutional neural networks for multi-class intrusion detection system; wraudit: A tool to transparently monitor web resources\u2019 integrity; using stigmergy to incorporate the time into artificial neural networks; modeling sustainability reporting with ternary attractor neural networks; analysing a periodical and multi-dimensional time series; stock price forecasting over adaptive timescale using supervised learning and receptive fields; Periodically diluted BEGNN model of corruption perception; neural machine translation with recurrent highway networks; a comparative study of methods used in the analysis and prediction of financial data; skin lesion images segmentation: A survey of the state-of-the-art; automatic extraction of structured information from drug descriptions; skin lesion segmentation using enhanced unified Markov random field; texture classification using deep convolutional neural network with ensemble learning; a novel decision tree approach for the handling of time series; reference metadata extraction from Korean research papers.","Author Keywords":null,"Index Keywords":null,"References":null}
{"Authors":"Ortega L.F.","Author(s) ID":"55797136900;","Title":"A neuro-wavelet method for the forecasting of financial time series","Year":2012,"Source title":"Lecture Notes in Engineering and Computer Science","Volume":"1","Issue":null,"Art. No.":null,"Page start":577.0,"Page end":582.0,"Page count":null,"Cited by":2.0,"DOI":null,"Affiliations":"Stevens Institute of Technology, School of Systems and Enterprises, Hoboken, NJ  7030, United States","Document Type":"Conference Paper","Access Type":null,"Source":"Scopus","EID":"2-s2.0-85040642723","Abstract":"The proceedings contain 26 papers. The topics discussed include: evolving fuzzy models for the position control of magnetic levitation systems; comparison of conventional closed-loop controller with an adaptive controller for a disturbed thermodynamic system; granular evolving fuzzy robust feedback linearization; robust evolving control of a two-tanks pilot plant; an implementation of an evolving fuzzy controller; evolving participatory learning fuzzy modeling for financial interval time series forecasting; incremental rule splitting in generalized evolving fuzzy regression models; on-line identification with regularised evolving Gaussian process; introduction of adaptive TS model using recursive Gustafson-Kessel algorithm in short term load forecasting; evolving fuzzy model in fault detection system; autonomous learning for autonomous systems; evolving principal component clustering for 2-D LIDAR data; robust evolving cloud-based controller (RECCo); Self-evolving kernel recursive least squares algorithm for control and prediction; monitoring of vulcano Purace\u00c1 through seismic signals: description of a real dataset; autonomous learning multi-model classifier of 0-order (ALMMo-0); estimation of moving agents density in 2D space based on LSTM neural network; multi-expert evolving system for objective psychophysiological monitoring and fast discovery of effective personalized therapies; combining evolutionary algorithms and case-based reasoning for learning high-quality shooting strategies in AI birds; online anomaly detection on the Webscope S5 dataset: a comparative study; and modeling and simulation of a small wind turbine system based on PMSG generator.","Author Keywords":null,"Index Keywords":null,"References":null}
{"Authors":"Ghazali R., Hussain A.J., Liatsis P.","Author(s) ID":"23388956400;56212648400;8410551000;","Title":"Dynamic Ridge Polynomial Neural Network: Forecasting the univariate non-stationary and stationary trading signals","Year":2011,"Source title":"Expert Systems with Applications","Volume":"38","Issue":"4","Art. No.":null,"Page start":3765.0,"Page end":3776.0,"Page count":null,"Cited by":42.0,"DOI":"10.1016\/j.eswa.2010.09.037","Affiliations":"Information Technology and Multimedia Faculty, Universiti Tun Hussein Onn Malaysia, Malaysia; School of Computing and Mathematical Sciences, Liverpool John Moores University, United Kingdom; School of Engineering and Mathematical Sciences, City University, London, United Kingdom","Document Type":"Article","Access Type":null,"Source":"Scopus","EID":"2-s2.0-78650716107","Abstract":"The proceedings contain 148 papers. The special focus in this conference is on Machine Learning, Principles and Practice of Knowledge Discovery in Databases. The topics include: Koopman Spectral Kernels for Comparing Complex Dynamics: Application to Multiagent Sport Plays; modeling the Temporal Nature of Human Behavior for Demographics Prediction; MRNet-Product2Vec: A Multi-task Recurrent Neural Network for Product Embeddings; optimal Client Recommendation for Market Makers in Illiquid Financial Products; predicting Self-reported Customer Satisfaction of Interactions with a Corporate Call Center; probabilistic Inference of Twitter Users\u2019 Age Based on What They Follow; quantifying Heterogeneous Causal Treatment Effects in World Bank Development Finance Projects; RSSI-Based Supervised Learning for Uncooperative Direction-Finding; sequential Keystroke Behavioral Biometrics for Mobile User Identification via Multi-view Deep Learning; analyzing Granger Causality in Climate Data with Time Series Classification Methods; session-Based Fraud Detection in Online E-Commerce Transactions Using Recurrent Neural Networks; SINAS: Suspect Investigation Using Offenders\u2019 Activity Space; stance Classification of Tweets Using Skip Char Ngrams; structural Semantic Models for Automatic Analysis of Urban Areas; taking It for a Test Drive: A Hybrid Spatio-Temporal Model for Wildlife Poaching Prediction Evaluated Through a Controlled Field Test; unsupervised Signature Extraction from Forensic Logs; urban Water Flow and Water Level Prediction Based on Deep Learning; using Machine Learning for Labour Market Intelligence; activity-Driven Influence Maximization in Social Networks; An AI Planning System for Data Cleaning; automatic Detection and Recognition of Individuals in Patterned Species; comparing Hypotheses About Sequential Data: A Bayesian Approach and Its Applications; data-Driven Approaches for Smart Parking; tetrahedron: Barycentric Measure Visualizer.","Author Keywords":null,"Index Keywords":null,"References":null}
{"Authors":"Hsieh T.-J., Hsiao H.-F., Yeh W.-C.","Author(s) ID":"36188164200;35292259200;7202860325;","Title":"Forecasting stock markets using wavelet transforms and recurrent neural networks: An integrated system based on artificial bee colony algorithm","Year":2011,"Source title":"Applied Soft Computing Journal","Volume":"11","Issue":"2","Art. No.":null,"Page start":2510.0,"Page end":2525.0,"Page count":null,"Cited by":188.0,"DOI":"10.1016\/j.asoc.2010.09.007","Affiliations":"Department of Industrial Engineering and Engineering Management, National Tsing Hua University, P.O. Box 24-60, Hsinchu 30013, Taiwan; Department of Finance, Mingdao University, 369 Wen-Hua Rd., Peetow, Changhua 52345, Taiwan","Document Type":"Conference Paper","Access Type":null,"Source":"Scopus","EID":"2-s2.0-78751613501","Abstract":"The proceedings contain 148 papers. The special focus in this conference is on Machine Learning, Principles and Practice of Knowledge Discovery in Databases. The topics include: Koopman Spectral Kernels for Comparing Complex Dynamics: Application to Multiagent Sport Plays; modeling the Temporal Nature of Human Behavior for Demographics Prediction; MRNet-Product2Vec: A Multi-task Recurrent Neural Network for Product Embeddings; optimal Client Recommendation for Market Makers in Illiquid Financial Products; predicting Self-reported Customer Satisfaction of Interactions with a Corporate Call Center; probabilistic Inference of Twitter Users\u2019 Age Based on What They Follow; quantifying Heterogeneous Causal Treatment Effects in World Bank Development Finance Projects; RSSI-Based Supervised Learning for Uncooperative Direction-Finding; sequential Keystroke Behavioral Biometrics for Mobile User Identification via Multi-view Deep Learning; analyzing Granger Causality in Climate Data with Time Series Classification Methods; session-Based Fraud Detection in Online E-Commerce Transactions Using Recurrent Neural Networks; SINAS: Suspect Investigation Using Offenders\u2019 Activity Space; stance Classification of Tweets Using Skip Char Ngrams; structural Semantic Models for Automatic Analysis of Urban Areas; taking It for a Test Drive: A Hybrid Spatio-Temporal Model for Wildlife Poaching Prediction Evaluated Through a Controlled Field Test; unsupervised Signature Extraction from Forensic Logs; urban Water Flow and Water Level Prediction Based on Deep Learning; using Machine Learning for Labour Market Intelligence; activity-Driven Influence Maximization in Social Networks; An AI Planning System for Data Cleaning; automatic Detection and Recognition of Individuals in Patterned Species; comparing Hypotheses About Sequential Data: A Bayesian Approach and Its Applications; data-Driven Approaches for Smart Parking; tetrahedron: Barycentric Measure Visualizer.","Author Keywords":null,"Index Keywords":null,"References":null}
{"Authors":"[No author name available]","Author(s) ID":"[No author id available]","Title":"18th European Symposium on Artificial Neural Networks, Computational Intelligence and Machine Learning, ESANN 2010","Year":2010,"Source title":"Proceedings of the 18th European Symposium on Artificial Neural Networks - Computational Intelligence and Machine Learning, ESANN 2010","Volume":null,"Issue":null,"Art. No.":null,"Page start":null,"Page end":null,"Page count":null,"Cited by":null,"DOI":null,"Affiliations":null,"Document Type":"Conference Review","Access Type":null,"Source":"Scopus","EID":"2-s2.0-84886999502","Abstract":"The proceedings contain 148 papers. The special focus in this conference is on Machine Learning, Principles and Practice of Knowledge Discovery in Databases. The topics include: Koopman Spectral Kernels for Comparing Complex Dynamics: Application to Multiagent Sport Plays; modeling the Temporal Nature of Human Behavior for Demographics Prediction; MRNet-Product2Vec: A Multi-task Recurrent Neural Network for Product Embeddings; optimal Client Recommendation for Market Makers in Illiquid Financial Products; predicting Self-reported Customer Satisfaction of Interactions with a Corporate Call Center; probabilistic Inference of Twitter Users\u2019 Age Based on What They Follow; quantifying Heterogeneous Causal Treatment Effects in World Bank Development Finance Projects; RSSI-Based Supervised Learning for Uncooperative Direction-Finding; sequential Keystroke Behavioral Biometrics for Mobile User Identification via Multi-view Deep Learning; analyzing Granger Causality in Climate Data with Time Series Classification Methods; session-Based Fraud Detection in Online E-Commerce Transactions Using Recurrent Neural Networks; SINAS: Suspect Investigation Using Offenders\u2019 Activity Space; stance Classification of Tweets Using Skip Char Ngrams; structural Semantic Models for Automatic Analysis of Urban Areas; taking It for a Test Drive: A Hybrid Spatio-Temporal Model for Wildlife Poaching Prediction Evaluated Through a Controlled Field Test; unsupervised Signature Extraction from Forensic Logs; urban Water Flow and Water Level Prediction Based on Deep Learning; using Machine Learning for Labour Market Intelligence; activity-Driven Influence Maximization in Social Networks; An AI Planning System for Data Cleaning; automatic Detection and Recognition of Individuals in Patterned Species; comparing Hypotheses About Sequential Data: A Bayesian Approach and Its Applications; data-Driven Approaches for Smart Parking; tetrahedron: Barycentric Measure Visualizer.","Author Keywords":null,"Index Keywords":null,"References":null}
{"Authors":"Dunis C.L., Laws J., Sermpinis G.","Author(s) ID":"6602234892;7005939268;35099556100;","Title":"Modelling and trading the EUR\/USD exchange rate at the ECB fixing","Year":2010,"Source title":"European Journal of Finance","Volume":"16","Issue":"6","Art. No.":null,"Page start":541.0,"Page end":560.0,"Page count":null,"Cited by":12.0,"DOI":"10.1080\/13518470903037771","Affiliations":"Liverpool Business School, Centre for International Banking, Economics and Finance, Liverpool John Moores University, Liverpool L3 5UZ, United Kingdom","Document Type":"Article","Access Type":null,"Source":"Scopus","EID":"2-s2.0-77955159878","Abstract":"The proceedings contain 58 papers. The topics discussed include: predicting the outer\/inner betastrands in protein beta sheets based on the random forest algorithm; extract features using stacked denoised autoencoder; cancer classification using ensemble of error correcting output codes; early detection method of Alzheimer's disease using EEG signals; tumor clustering using independent component analysis and adaptive affinity propagation; research of training feedforward neural networks based on hybrid chaos particle swarm optimization-back-propagation; training deep Fourier neural networks to fit time-series data; regularized dynamic self organized neural network inspired by the immune algorithm for financial time series prediction; and multi-scale level set method for medical image segmentation without re-initialization.","Author Keywords":null,"Index Keywords":null,"References":null}
{"Authors":"Zhai F., Lin X., Yang Z., Song Y.","Author(s) ID":"35747648300;24338421700;55832871000;15124457200;","Title":"RETRACTED ARTICLE: Financial time series prediction based on Echo State Network","Year":2010,"Source title":"Proceedings - 2010 6th International Conference on Natural Computation, ICNC 2010","Volume":"8","Issue":null,"Art. No.":" 5584802","Page start":3983.0,"Page end":3987.0,"Page count":null,"Cited by":9.0,"DOI":"10.1109\/ICNC.2010.5584802","Affiliations":"Department of Computer Science and Technology, Tsinghua National Laboratory for Information Science and Technology, Tsinghua University, Beijing, 100084, China","Document Type":"Conference Paper","Access Type":null,"Source":"Scopus","EID":"2-s2.0-78149351825","Abstract":"The proceedings contain 87 papers. The special focus in this conference is on Artificial Neural Networks, Computational Intelligence and Machine Learning. The topics include: Efficient online learning of a non-negative sparse autoencoder; the Markov decision process extraction network; maximal discrepancy for support vector machines; financial time series forecasting with machine learning techniques; introduction to computational intelligence business applications; machine learning analysis and modeling of interest rate curves; modeling contextualized textual knowledge as a long-term working memory; neural competition for motion segmentation; adaptive velocity tuning for visual motion estimation; curvilinear component analysis and Bregman divergences; adaptive matrix distances aiming at optimum regression subspaces; reliability of dimension reduction visualizations of hierarchical structures; mapping without visualizing local default is nonsense; active set training of support vector regressors; fast and good initialization of RBF networks; model learning from weights by adaptive enhanced probabilistic convergent network; autoregressive independent process analysis with missing observations; a pseudoregression formulation of emphasized soft target procedures for classification problems; exploiting hierarchical prediction structures for mixed 2d-3d tracking; hybrid soft computing for PVT properties prediction; approximation of chemical reaction rates in turbulent combustion simulation; asymptotic properties of mixture-of-experts models; towards sub-quadratic learning of probability density models in the form of mixtures of trees; sparse representation of data; highly sparse kernel spectral clustering with predictive out-of-sample extensions; divergence based learning vector quantization; finding correlations in multimodal data using decomposition approaches; deep learning of visual control policies; learning vector quantization for heterogeneous structured data; relational generative topographic map; machine learning techniques based on random projections; solving large regression problems using an ensemble of GPU-accelerated ELMs; a Markovian characterization of redundancy in echo state networks by PCA; random search enhancement of error minimized extreme learning machine; a novel interactive biometric passport photograph alignment system; identifying informative features for ERP speller systems based on RSVP paradigm; a critique of BCM behavior verification for STDP-type plasticity models; an automated SOM clustering based on data topology; a randomized algorithm for spectral clustering; relevance learning in generative topographic maps; extending FSNPC to handle data points with fuzzy class assignments; figure-ground segmentation using metrics adaptation in level set methods; computational intelligence in biomedicine; spectral prototype extraction for dimensionality reduction in brain tumour diagnosis; neural models for the analysis of kidney disease patients; KNN behavior with set-valued attributes; kernel generative topographic mapping; consensus clustering by graph based approach; online speaker diarization with a size-monitored growing neural gas algorithm; a novel two-phase SOM clustering approach to discover visitor interests in a website; image registration by the extended evolutionary self-organizing map; evolution of adaptive center-crossing continuous time recurrent neural networks for biped robot control and free-energy-based reinforcement learning in a partially observable environment.","Author Keywords":null,"Index Keywords":null,"References":null}